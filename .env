# =============================================================================
# RAG Factory - VM Development Configuration
# =============================================================================
# This configuration is for when your VM connects to services on the host machine
# 
# Architecture:
#   - Host Machine: Runs Docker (PostgreSQL, Neo4j) + LM Studio
#   - VM: Runs your RAG Factory tests and development
#
# Run ./find-host-ip.sh to automatically detect your host IP
# =============================================================================

# Host IP Configuration
# Common values:
#   - 10.0.2.2        (VirtualBox NAT - most common)
#   - 192.168.56.1    (VirtualBox Host-Only)
#   - 192.168.122.1   (KVM/QEMU)
#   - 172.16.0.1      (VMware NAT)
# To find yours: ip route | grep default
HOST_IP=192.168.56.1

# =============================================================================
# Database Configuration (Docker on Host)
# =============================================================================

# Main database URL
DATABASE_URL=postgresql://rag_user:rag_password@192.168.56.1:5432/rag_factory

# Test database URL (STANDARD NAME)
#TEST_DATABASE_URL=postgresql://rag_user:rag_password@192.168.56.1:5432/rag_test

DB_DATABASE_URL=postgresql://rag_user:rag_password@192.168.56.1:5432/rag_factory
#DB_TEST_DATABASE_URL=postgresql://rag_user:rag_password@192.168.56.1:5432/rag_test


# DEPRECATED: Old variable name (kept for backward compatibility)
# Will be removed in future version - please use TEST_DATABASE_URL instead
#DATABASE_TEST_URL=postgresql://rag_user:rag_password@192.168.56.1:5432/rag_test

# Neo4j Configuration (Docker on Host)
NEO4J_URI=bolt://192.168.56.1:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=rag_password

# =============================================================================
# LLM Configuration (LM Studio on Host)
# =============================================================================

# LM Studio uses OpenAI-compatible API
# Server: Host machine (same as database server)
# Default port: 1234
OPENAI_API_BASE=http://192.168.56.1:1234/v1
OPENAI_API_KEY=lm-studio  # Any value works with LM Studio
OPENAI_MODEL=phi-4-mini-instruct

# LM Studio Configuration (dedicated variables)
LM_STUDIO_BASE_URL=http://192.168.56.1:1234/v1
#LM_STUDIO_MODEL=qwen3-zero-coder-reasoning-v2-0.8b-neo-ex
LM_STUDIO_MODEL=phi-4-mini-instruct
LM_STUDIO_API_KEY=lm-studio

# =============================================================================
# Test Configuration
# =============================================================================

# Enable all tests since everything is local
RUN_DB_TESTS=true
RUN_LLM_TESTS=true
RUN_INTEGRATION_TESTS=true

# =============================================================================
# Optional: Additional LLM Providers
# =============================================================================

# If you also want to use cloud providers:
# OPENAI_API_KEY=sk-your-actual-openai-key
# COHERE_API_KEY=your-cohere-key

# =============================================================================
# Embedding Models Configuration
# =============================================================================

# ONNX Embedding Model (Xenova models have pre-converted ONNX files)
# Recommended: Xenova/all-mpnet-base-v2 (768 dimensions, high quality)
# Alternative: Xenova/all-MiniLM-L6-v2 (384 dimensions, faster)
EMBEDDING_MODEL_NAME=Xenova/all-MiniLM-L6-v2
EMBEDDING_MODEL_PATH=models/embeddings

# HuggingFace cache directory (optional)
# HF_HOME=~/.cache/huggingface

# =============================================================================
# Development Settings
# =============================================================================

# Logging
LOG_LEVEL=INFO

# Python path
# PYTHONPATH=./src

# =============================================================================
# Quick Setup Guide
# =============================================================================
#
# 1. On Host Machine:
#    cd ~/rag-databases
#    docker compose up -d
#    # Start LM Studio and load a model
#
# 2. In This VM:
#    ./find-host-ip.sh          # Find and update HOST_IP
#    make test-db                # Test database connection
#    make test-llm               # Test LM Studio connection
#
# 3. Verify Connections:
#    nc -zv $HOST_IP 5432        # PostgreSQL
#    nc -zv $HOST_IP 7687        # Neo4j
#    curl http://$HOST_IP:1234/v1/models  # LM Studio
#
# =============================================================================
