✓ Virtual environment activated
✓ Environment variables loaded from .env
  EMBEDDING_MODEL_NAME: Xenova/all-MiniLM-L6-v2
  EMBEDDING_MODEL_PATH: models/embeddings

Running tests...
Output will be saved to: test_result.txt

============================= test session starts ==============================
platform linux -- Python 3.12.3, pytest-9.0.1, pluggy-1.6.0 -- /mnt/MCPProyects/ragTools/venv/bin/python3
cachedir: .pytest_cache
rootdir: /mnt/MCPProyects/ragTools
configfile: pytest.ini (WARNING: ignoring pytest config in pyproject.toml!)
testpaths: tests
plugins: anyio-4.12.0, cov-7.0.0, asyncio-1.3.0
asyncio: mode=Mode.STRICT, debug=False, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function
collecting ... collected 2135 items

tests/benchmarks/test_contextual_performance.py::test_batch_processing_throughput PASSED [  0%]
tests/benchmarks/test_contextual_performance.py::test_parallel_vs_sequential_performance PASSED [  0%]
tests/benchmarks/test_contextual_performance.py::test_large_document_processing_time PASSED [  0%]
tests/benchmarks/test_contextual_performance.py::test_batch_size_impact PASSED [  0%]
tests/benchmarks/test_contextual_performance.py::test_cost_tracker_performance PASSED [  0%]
tests/benchmarks/test_contextual_performance.py::test_context_generation_latency PASSED [  0%]
tests/benchmarks/test_late_chunking_performance.py::test_document_embedding_speed PASSED [  0%]
tests/benchmarks/test_late_chunking_performance.py::test_embedding_chunking_speed PASSED [  0%]
tests/benchmarks/test_late_chunking_performance.py::test_semantic_boundary_speed PASSED [  0%]
tests/benchmarks/test_late_chunking_performance.py::test_end_to_end_latency PASSED [  0%]
tests/benchmarks/test_late_chunking_performance.py::test_coherence_analysis_overhead PASSED [  0%]
tests/benchmarks/test_late_chunking_performance.py::test_batch_processing_speed PASSED [  0%]
tests/benchmarks/test_late_chunking_performance.py::test_adaptive_chunking_speed PASSED [  0%]
tests/benchmarks/test_late_chunking_performance.py::test_memory_efficiency PASSED [  0%]
tests/benchmarks/test_model_comparison_performance.py::test_model_loading_speed SKIPPED [  0%]
tests/benchmarks/test_model_comparison_performance.py::test_model_loading_cached SKIPPED [  0%]
tests/benchmarks/test_model_comparison_performance.py::test_inference_speed SKIPPED [  0%]
tests/benchmarks/test_model_comparison_performance.py::test_batch_size_comparison SKIPPED [  0%]
tests/benchmarks/test_model_comparison_performance.py::test_embedding_quality SKIPPED [  0%]
tests/benchmarks/test_model_comparison_performance.py::test_memory_efficiency SKIPPED [  0%]
tests/integration/cli/test_benchmark_integration.py::TestBenchmarkIntegration::test_benchmark_execution_flow PASSED [  0%]
tests/integration/cli/test_config_validation_integration.py::TestConfigValidationIntegration::test_validate_valid_config_flow PASSED [  1%]
tests/integration/cli/test_config_validation_integration.py::TestConfigValidationIntegration::test_validate_invalid_config_flow PASSED [  1%]
tests/integration/cli/test_index_query_flow.py::TestIndexQueryFlow::test_index_single_file PASSED [  1%]
tests/integration/cli/test_index_query_flow.py::TestIndexQueryFlow::test_index_directory PASSED [  1%]
tests/integration/cli/test_index_query_flow.py::TestIndexQueryFlow::test_index_with_custom_strategy PASSED [  1%]
tests/integration/cli/test_index_query_flow.py::TestIndexQueryFlow::test_index_with_config_file PASSED [  1%]
tests/integration/cli/test_index_query_flow.py::TestIndexQueryFlow::test_index_nonexistent_path PASSED [  1%]
tests/integration/cli/test_index_query_flow.py::TestIndexQueryFlow::test_query_basic PASSED [  1%]
tests/integration/cli/test_index_query_flow.py::TestIndexQueryFlow::test_query_with_strategies PASSED [  1%]
tests/integration/cli/test_index_query_flow.py::TestIndexQueryFlow::test_query_with_top_k PASSED [  1%]
tests/integration/cli/test_index_query_flow.py::TestIndexQueryFlow::test_query_without_index PASSED [  1%]
tests/integration/cli/test_index_query_flow.py::TestFullWorkflow::test_complete_workflow PASSED [  1%]
tests/integration/cli/test_index_query_flow.py::TestFullWorkflow::test_workflow_with_config PASSED [  1%]
tests/integration/config/test_config_integration.py::TestConfigIntegration::test_load_real_services_yaml PASSED [  1%]
tests/integration/config/test_config_integration.py::TestConfigIntegration::test_load_real_strategy_pair_yaml PASSED [  1%]
tests/integration/config/test_config_integration.py::TestConfigIntegration::test_full_workflow_with_env_vars PASSED [  1%]
tests/integration/config/test_config_integration.py::TestConfigIntegration::test_missing_required_env_var PASSED [  1%]
tests/integration/config/test_config_integration.py::TestConfigIntegration::test_service_reference_validation_integration PASSED [  1%]
tests/integration/config/test_config_integration.py::TestConfigIntegration::test_plaintext_secret_warning_integration PASSED [  1%]
tests/integration/config/test_config_integration.py::TestConfigIntegration::test_complex_strategy_pair_with_all_features PASSED [  1%]
tests/integration/config/test_config_integration.py::TestExampleConfigurations::test_example_services_yaml_is_valid PASSED [  1%]
tests/integration/config/test_config_integration.py::TestExampleConfigurations::test_example_strategy_pairs_are_valid PASSED [  2%]
tests/integration/database/test_database_integration.py::TestDatabaseIntegration::test_full_database_workflow PASSED [  2%]
tests/integration/database/test_database_integration.py::TestDatabaseIntegration::test_batch_insert_chunks PASSED [  2%]
tests/integration/database/test_database_integration.py::TestDatabaseIntegration::test_query_with_filters PASSED [  2%]
tests/integration/database/test_database_integration.py::TestDatabaseIntegration::test_metadata_queries SKIPPED [  2%]
tests/integration/database/test_database_integration.py::TestDatabaseIntegration::test_chunk_ordering PASSED [  2%]
tests/integration/database/test_database_integration.py::TestDatabaseIntegration::test_document_deduplication PASSED [  2%]
tests/integration/database/test_database_integration.py::TestVectorOperations::test_insert_chunk_with_embedding PASSED [  2%]
tests/integration/database/test_database_integration.py::TestVectorOperations::test_vector_similarity_search PASSED [  2%]
tests/integration/database/test_database_integration.py::TestVectorOperations::test_null_embeddings PASSED [  2%]
tests/integration/database/test_database_integration.py::TestConnectionPooling::test_connection_pool_concurrent_access PASSED [  2%]
tests/integration/database/test_database_integration.py::TestConnectionPooling::test_connection_pool_metrics PASSED [  2%]
tests/integration/database/test_database_integration.py::TestConnectionPooling::test_session_isolation PASSED [  2%]
tests/integration/database/test_database_integration.py::TestPerformance::test_batch_insert_performance PASSED [  2%]
tests/integration/database/test_database_integration.py::TestPerformance::test_query_performance PASSED [  2%]
tests/integration/database/test_migration_integration.py::TestMigrationIntegration::test_real_migration_execution FAILED [  2%]
tests/integration/database/test_migration_integration.py::TestMigrationIntegration::test_migration_with_existing_data FAILED [  2%]
tests/integration/database/test_migration_integration.py::TestMigrationIntegration::test_rollback_functionality FAILED [  2%]
tests/integration/database/test_migration_integration.py::TestMigrationIntegration::test_pgvector_extension_installed FAILED [  2%]
tests/integration/database/test_migration_validator_integration.py::TestMigrationValidatorIntegration::test_validate_with_no_migrations FAILED [  2%]
tests/integration/database/test_migration_validator_integration.py::TestMigrationValidatorIntegration::test_validate_with_partial_migrations FAILED [  2%]
tests/integration/database/test_migration_validator_integration.py::TestMigrationValidatorIntegration::test_validate_with_all_migrations FAILED [  2%]
tests/integration/database/test_migration_validator_integration.py::TestMigrationValidatorIntegration::test_validate_or_raise_success FAILED [  3%]
tests/integration/database/test_migration_validator_integration.py::TestMigrationValidatorIntegration::test_validate_or_raise_failure FAILED [  3%]
tests/integration/database/test_migration_validator_integration.py::TestMigrationValidatorIntegration::test_get_current_revision FAILED [  3%]
tests/integration/database/test_migration_validator_integration.py::TestMigrationValidatorIntegration::test_get_all_revisions PASSED [  3%]
tests/integration/database/test_migration_validator_integration.py::TestMigrationValidatorIntegration::test_is_at_head FAILED [  3%]
tests/integration/database/test_migration_validator_integration.py::TestMigrationValidatorIntegration::test_error_message_details FAILED [  3%]
tests/integration/database/test_migration_validator_integration.py::TestMigrationValidatorIntegration::test_validate_single_migration FAILED [  3%]
tests/integration/database/test_migration_validator_integration.py::TestMigrationValidatorIntegration::test_validate_nonexistent_migration FAILED [  3%]
tests/integration/database/test_migration_validator_integration.py::TestMigrationValidatorIntegration::test_validate_after_downgrade FAILED [  3%]
tests/integration/database/test_migration_validator_integration.py::TestMigrationValidatorIntegration::test_multiple_validators_same_database FAILED [  3%]
tests/integration/database/test_migration_validator_integration.py::TestMigrationValidatorEdgeCases::test_validator_with_auto_discovered_config PASSED [  3%]
tests/integration/database/test_migration_validator_integration.py::TestMigrationValidatorEdgeCases::test_validate_empty_requirements PASSED [  3%]
tests/integration/database/test_multi_context_isolation.py::TestMultiContextIsolation::test_contexts_share_same_engine SKIPPED [  3%]
tests/integration/database/test_multi_context_isolation.py::TestMultiContextIsolation::test_contexts_isolated_different_tables SKIPPED [  3%]
tests/integration/database/test_multi_context_isolation.py::TestMultiContextIsolation::test_contexts_with_same_logical_names_different_physical SKIPPED [  3%]
tests/integration/database/test_multi_context_isolation.py::TestMultiContextIsolation::test_concurrent_operations_on_different_contexts SKIPPED [  3%]
tests/integration/database/test_multi_context_isolation.py::TestMultiContextIsolation::test_update_in_one_context_doesnt_affect_other SKIPPED [  3%]
tests/integration/database/test_multi_context_isolation.py::TestMultiContextIsolation::test_delete_in_one_context_doesnt_affect_other SKIPPED [  3%]
tests/integration/database/test_multi_context_isolation.py::TestPostgresServiceMultiContext::test_service_creates_contexts_with_shared_engine SKIPPED [  3%]
tests/integration/database/test_multi_context_isolation.py::TestPostgresServiceMultiContext::test_service_caches_contexts PASSED [  3%]
tests/integration/database/test_multi_context_isolation.py::TestPostgresServiceMultiContext::test_service_creates_different_contexts_for_different_mappings PASSED [  3%]
tests/integration/database/test_multi_context_isolation.py::TestPostgresServiceMultiContext::test_multiple_strategies_scenario SKIPPED [  4%]
tests/integration/documentation/test_documentation_integration.py::TestDocumentationBuild::test_mkdocs_build_succeeds SKIPPED [  4%]
tests/integration/documentation/test_documentation_integration.py::TestDocumentationBuild::test_mkdocs_serve_starts SKIPPED [  4%]
tests/integration/documentation/test_documentation_integration.py::TestDocumentationBuild::test_search_index_generated SKIPPED [  4%]
tests/integration/documentation/test_documentation_integration.py::test_documentation_time_to_first_example SKIPPED [  4%]
tests/integration/documentation/test_documentation_integration.py::test_api_reference_generated SKIPPED [  4%]
tests/integration/documentation/test_documentation_integration.py::test_diagrams_rendered SKIPPED [  4%]
tests/integration/evaluation/test_evaluation_integration.py::TestEvaluationIntegration::test_full_benchmark_workflow PASSED [  4%]
tests/integration/evaluation/test_evaluation_integration.py::TestEvaluationIntegration::test_compare_multiple_strategies PASSED [  4%]
tests/integration/evaluation/test_evaluation_integration.py::TestEvaluationIntegration::test_statistical_analysis_workflow PASSED [  4%]
tests/integration/evaluation/test_evaluation_integration.py::TestEvaluationIntegration::test_export_workflow_csv PASSED [  4%]
tests/integration/evaluation/test_evaluation_integration.py::TestEvaluationIntegration::test_export_workflow_json PASSED [  4%]
tests/integration/evaluation/test_evaluation_integration.py::TestEvaluationIntegration::test_comparison_report_generation PASSED [  4%]
tests/integration/evaluation/test_evaluation_integration.py::TestEvaluationIntegration::test_checkpoint_resume_workflow PASSED [  4%]
tests/integration/models/test_fine_tuned_embeddings_integration.py::test_register_and_load_model PASSED [  4%]
tests/integration/models/test_fine_tuned_embeddings_integration.py::test_ab_testing_workflow PASSED [  4%]
tests/integration/models/test_fine_tuned_embeddings_integration.py::test_model_registry_persistence_workflow PASSED [  4%]
tests/integration/models/test_fine_tuned_embeddings_integration.py::test_ab_testing_framework_logic PASSED [  4%]
tests/integration/models/test_fine_tuned_embeddings_integration.py::test_model_comparison_workflow PASSED [  4%]
tests/integration/models/test_fine_tuned_embeddings_integration.py::test_multiple_models_registry PASSED [  4%]
tests/integration/observability/test_monitoring_integration.py::TestCompleteQueryLogging::test_complete_query_workflow PASSED [  4%]
tests/integration/observability/test_monitoring_integration.py::TestCompleteQueryLogging::test_failed_query_workflow PASSED [  5%]
tests/integration/observability/test_monitoring_integration.py::TestCompleteQueryLogging::test_multiple_strategy_workflow PASSED [  5%]
tests/integration/observability/test_monitoring_integration.py::TestPerformanceMonitoring::test_performance_tracking PASSED [  5%]
tests/integration/observability/test_monitoring_integration.py::TestPerformanceMonitoring::test_multiple_operations_tracking PASSED [  5%]
tests/integration/observability/test_monitoring_integration.py::TestDashboardAPI::test_dashboard_endpoints PASSED [  5%]
tests/integration/observability/test_monitoring_integration.py::TestDashboardAPI::test_dashboard_error_handling PASSED [  5%]
tests/integration/observability/test_monitoring_integration.py::TestEndToEndMonitoring::test_complete_monitoring_stack PASSED [  5%]
tests/integration/observability/test_monitoring_integration.py::TestEndToEndMonitoring::test_high_volume_simulation PASSED [  5%]
tests/integration/observability/test_monitoring_integration.py::TestEndToEndMonitoring::test_error_rate_monitoring PASSED [  5%]
tests/integration/observability/test_monitoring_integration.py::TestPrometheusIntegration::test_prometheus_metrics_export PASSED [  5%]
tests/integration/registry/test_registry_integration.py::TestRealServiceInstantiation::test_instantiate_onnx_embedding_service PASSED [  5%]
tests/integration/registry/test_registry_integration.py::TestRealServiceInstantiation::test_embedding_service_functionality PASSED [  5%]
tests/integration/registry/test_registry_integration.py::TestRealServiceInstantiation::test_multiple_service_instantiation FAILED [  5%]
tests/integration/registry/test_registry_integration.py::TestEnvironmentVariableResolution::test_env_var_resolution PASSED [  5%]
tests/integration/registry/test_registry_integration.py::TestEnvironmentVariableResolution::test_env_var_defaults PASSED [  5%]
tests/integration/registry/test_registry_integration.py::TestServiceLifecycle::test_context_manager_cleanup PASSED [  5%]
tests/integration/registry/test_registry_integration.py::TestServiceLifecycle::test_reload_service PASSED [  5%]
tests/integration/registry/test_registry_integration.py::TestServiceLifecycle::test_shutdown_cleanup PASSED [  5%]
tests/integration/registry/test_registry_integration.py::TestServiceSharing::test_service_instance_sharing PASSED [  5%]
tests/integration/registry/test_registry_integration.py::TestServiceSharing::test_service_sharing_memory_efficiency PASSED [  5%]
tests/integration/registry/test_registry_integration.py::TestErrorHandling::test_invalid_service_config FAILED [  5%]
tests/integration/registry/test_registry_integration.py::TestErrorHandling::test_missing_service_file PASSED [  5%]
tests/integration/registry/test_registry_integration.py::TestOpenAIServices::test_openai_llm_instantiation PASSED [  6%]
tests/integration/registry/test_registry_integration.py::TestOpenAIServices::test_openai_embedding_instantiation PASSED [  6%]
tests/integration/registry/test_registry_integration.py::TestConfigurationValidation::test_valid_configuration_loads PASSED [  6%]
tests/integration/registry/test_registry_integration.py::TestConfigurationValidation::test_configuration_warnings FAILED [  6%]
tests/integration/repositories/test_repository_integration.py::TestDocumentRepositoryIntegration::test_complete_document_lifecycle PASSED [  6%]
tests/integration/repositories/test_repository_integration.py::TestDocumentRepositoryIntegration::test_document_deduplication PASSED [  6%]
tests/integration/repositories/test_repository_integration.py::TestDocumentRepositoryIntegration::test_document_pagination PASSED [  6%]
tests/integration/repositories/test_repository_integration.py::TestDocumentRepositoryIntegration::test_document_status_filtering PASSED [  6%]
tests/integration/repositories/test_repository_integration.py::TestDocumentRepositoryIntegration::test_bulk_operations PASSED [  6%]
tests/integration/repositories/test_repository_integration.py::TestChunkRepositoryIntegration::test_complete_chunk_lifecycle PASSED [  6%]
tests/integration/repositories/test_repository_integration.py::TestChunkRepositoryIntegration::test_chunk_document_relationship PASSED [  6%]
tests/integration/repositories/test_repository_integration.py::TestChunkRepositoryIntegration::test_cascade_delete PASSED [  6%]
tests/integration/repositories/test_repository_integration.py::TestChunkRepositoryIntegration::test_bulk_chunk_operations PASSED [  6%]
tests/integration/repositories/test_repository_integration.py::TestVectorSearchIntegration::test_vector_similarity_search PASSED [  6%]
tests/integration/repositories/test_repository_integration.py::TestVectorSearchIntegration::test_vector_search_with_threshold PASSED [  6%]
tests/integration/repositories/test_repository_integration.py::TestVectorSearchIntegration::test_vector_search_with_document_filter PASSED [  6%]
tests/integration/repositories/test_repository_integration.py::TestVectorSearchIntegration::test_vector_search_with_metadata_filter PASSED [  6%]
tests/integration/repositories/test_repository_integration.py::TestVectorSearchIntegration::test_vector_search_identical_embedding PASSED [  6%]
tests/integration/repositories/test_repository_integration.py::TestRepositoryTransactions::test_transaction_commit PASSED [  6%]
tests/integration/repositories/test_repository_integration.py::TestRepositoryTransactions::test_transaction_rollback PASSED [  6%]
tests/integration/repositories/test_repository_integration.py::TestRepositoryTransactions::test_multiple_operations_in_transaction PASSED [  6%]
tests/integration/repositories/test_repository_integration.py::TestRepositoryTransactions::test_transaction_context_manager PASSED [  7%]
tests/integration/repositories/test_repository_integration.py::TestRepositoryTransactions::test_transaction_rollback_on_error PASSED [  7%]
tests/integration/services/test_embedding_integration.py::test_openai_full_workflow SKIPPED [  7%]
tests/integration/services/test_embedding_integration.py::test_cohere_full_workflow SKIPPED [  7%]
tests/integration/services/test_embedding_integration.py::test_local_embedding_provider PASSED [  7%]
tests/integration/services/test_embedding_integration.py::test_large_batch_processing PASSED [  7%]
tests/integration/services/test_embedding_integration.py::test_concurrent_embedding_requests PASSED [  7%]
tests/integration/services/test_embedding_integration.py::test_cache_persistence_across_batches PASSED [  7%]
tests/integration/services/test_embedding_integration.py::test_error_handling PASSED [  7%]
tests/integration/services/test_embedding_integration.py::test_onnx_provider_compatibility PASSED [  7%]
tests/integration/services/test_fine_tuned_onnx_integration.py::TestFineTunedONNXIntegration::test_end_to_end_flow PASSED [  7%]
tests/integration/services/test_llm_integration.py::test_full_llm_workflow SKIPPED [  7%]
tests/integration/services/test_llm_integration.py::test_streaming_response SKIPPED [  7%]
tests/integration/services/test_llm_integration.py::test_local_ollama_provider SKIPPED [  7%]
tests/integration/services/test_llm_integration.py::test_prompt_template_with_real_llm SKIPPED [  7%]
tests/integration/services/test_llm_integration.py::test_openai_provider PASSED [  7%]
tests/integration/services/test_llm_integration.py::test_concurrent_llm_requests SKIPPED [  7%]
tests/integration/services/test_llm_integration.py::test_cost_tracking SKIPPED [  7%]
tests/integration/services/test_llm_integration.py::test_token_counting SKIPPED [  7%]
tests/integration/services/test_lm_studio_connection.py::test_lm_studio_models_endpoint PASSED [  7%]
tests/integration/services/test_lm_studio_connection.py::test_lm_studio_completion PASSED [  7%]
tests/integration/services/test_onnx_embeddings_integration.py::TestONNXEmbeddingsIntegration::test_embed_single_document PASSED [  8%]
tests/integration/services/test_onnx_embeddings_integration.py::TestONNXEmbeddingsIntegration::test_embed_multiple_documents PASSED [  8%]
tests/integration/services/test_onnx_embeddings_integration.py::TestONNXEmbeddingsIntegration::test_semantic_similarity PASSED [  8%]
tests/integration/services/test_onnx_embeddings_integration.py::TestONNXEmbeddingsIntegration::test_batch_consistency PASSED [  8%]
tests/integration/services/test_onnx_embeddings_integration.py::TestONNXEmbeddingsIntegration::test_empty_input PASSED [  8%]
tests/integration/services/test_onnx_embeddings_integration.py::TestONNXEmbeddingsIntegration::test_long_text_handling PASSED [  8%]
tests/integration/services/test_onnx_embeddings_integration.py::TestONNXEmbeddingsIntegration::test_special_characters PASSED [  8%]
tests/integration/services/test_onnx_embeddings_integration.py::TestONNXEmbeddingsIntegration::test_performance_target PASSED [  8%]
tests/integration/services/test_onnx_embeddings_integration.py::TestONNXEmbeddingsIntegration::test_provider_metadata PASSED [  8%]
tests/integration/services/test_onnx_embeddings_integration.py::TestONNXEmbeddingsIntegration::test_result_metadata PASSED [  8%]
tests/integration/services/test_service_implementations.py::TestONNXServices::test_onnx_embedding_service_implements_interface PASSED [  8%]
tests/integration/services/test_service_implementations.py::TestONNXServices::test_onnx_embedding_service_basic_functionality PASSED [  8%]
tests/integration/services/test_service_implementations.py::TestAPIServices::test_anthropic_llm_service_implements_interface PASSED [  8%]
tests/integration/services/test_service_implementations.py::TestAPIServices::test_anthropic_llm_service_basic_functionality PASSED [  8%]
tests/integration/services/test_service_implementations.py::TestAPIServices::test_openai_llm_service_implements_interface PASSED [  8%]
tests/integration/services/test_service_implementations.py::TestAPIServices::test_openai_embedding_service_implements_interface PASSED [  8%]
tests/integration/services/test_service_implementations.py::TestAPIServices::test_cohere_reranking_service_implements_interface PASSED [  8%]
tests/integration/services/test_service_implementations.py::TestAPIServices::test_cohere_reranking_service_basic_functionality PASSED [  8%]
tests/integration/services/test_service_implementations.py::TestDatabaseServices::test_neo4j_graph_service_implements_interface PASSED [  8%]
tests/integration/services/test_service_implementations.py::TestDatabaseServices::test_neo4j_graph_service_basic_functionality SKIPPED [  8%]
tests/integration/services/test_service_implementations.py::TestDatabaseServices::test_postgresql_database_service_implements_interface PASSED [  8%]
tests/integration/services/test_service_implementations.py::TestDatabaseServices::test_postgresql_database_service_basic_functionality PASSED [  8%]
tests/integration/services/test_service_implementations.py::TestLocalServices::test_cosine_reranking_service_implements_interface PASSED [  9%]
tests/integration/services/test_service_implementations.py::TestLocalServices::test_cosine_reranking_service_basic_functionality PASSED [  9%]
tests/integration/services/test_service_implementations.py::TestInterfaceCompliance::test_all_llm_services_implement_interface PASSED [  9%]
tests/integration/services/test_service_implementations.py::TestInterfaceCompliance::test_all_embedding_services_implement_interface PASSED [  9%]
tests/integration/services/test_service_implementations.py::TestInterfaceCompliance::test_all_reranking_services_implement_interface PASSED [  9%]
tests/integration/services/test_service_implementations.py::TestInterfaceCompliance::test_all_graph_services_implement_interface PASSED [  9%]
tests/integration/services/test_service_implementations.py::TestInterfaceCompliance::test_all_database_services_implement_interface PASSED [  9%]
tests/integration/services/test_service_integration.py::test_rag_workflow FAILED [  9%]
tests/integration/services/test_service_integration.py::test_embedding_database_consistency FAILED [  9%]
tests/integration/strategies/test_base_integration.py::test_strategy_full_lifecycle PASSED [  9%]
tests/integration/strategies/test_base_integration.py::test_multiple_strategies_implement_interface PASSED [  9%]
tests/integration/strategies/test_base_integration.py::test_async_retrieve_works PASSED [  9%]
tests/integration/strategies/test_base_integration.py::test_strategy_error_handling PASSED [  9%]
tests/integration/strategies/test_base_integration.py::test_strategy_configuration_override PASSED [  9%]
tests/integration/strategies/test_chunking_integration.py::test_structural_chunking_markdown_document PASSED [  9%]
tests/integration/strategies/test_chunking_integration.py::test_structural_chunking_plain_text PASSED [  9%]
tests/integration/strategies/test_chunking_integration.py::test_structural_chunking_code_blocks PASSED [  9%]
tests/integration/strategies/test_chunking_integration.py::test_fixed_size_chunking_consistency PASSED [  9%]
tests/integration/strategies/test_chunking_integration.py::test_compare_chunking_strategies PASSED [  9%]
tests/integration/strategies/test_chunking_integration.py::test_chunking_empty_document PASSED [  9%]
tests/integration/strategies/test_chunking_integration.py::test_chunking_very_long_document PASSED [  9%]
tests/integration/strategies/test_chunking_integration.py::test_chunking_with_special_characters PASSED [ 10%]
tests/integration/strategies/test_chunking_integration.py::test_batch_document_processing PASSED [ 10%]
tests/integration/strategies/test_chunking_integration.py::test_chunk_metadata_completeness PASSED [ 10%]
tests/integration/strategies/test_chunking_integration.py::test_chunk_validation PASSED [ 10%]
tests/integration/strategies/test_chunking_integration.py::test_get_stats_functionality PASSED [ 10%]
tests/integration/strategies/test_contextual_integration.py::test_contextual_retrieval_complete_workflow PASSED [ 10%]
tests/integration/strategies/test_contextual_integration.py::test_cost_tracking_accuracy PASSED [ 10%]
tests/integration/strategies/test_contextual_integration.py::test_retrieval_with_different_formats PASSED [ 10%]
tests/integration/strategies/test_contextual_integration.py::test_error_recovery PASSED [ 10%]
tests/integration/strategies/test_contextual_integration.py::test_synchronous_indexing PASSED [ 10%]
tests/integration/strategies/test_contextual_integration.py::test_large_document_processing PASSED [ 10%]
tests/integration/strategies/test_hierarchical_indexing.py::TestHierarchicalIndexing::test_produces_capabilities PASSED [ 10%]
tests/integration/strategies/test_hierarchical_indexing.py::TestHierarchicalIndexing::test_requires_services PASSED [ 10%]
tests/integration/strategies/test_hierarchical_indexing.py::TestHierarchicalIndexing::test_process_basic_document PASSED [ 10%]
tests/integration/strategies/test_hierarchical_indexing.py::TestHierarchicalIndexing::test_process_document_with_headings PASSED [ 10%]
tests/integration/strategies/test_hierarchical_indexing.py::TestHierarchicalIndexing::test_hierarchy_metadata PASSED [ 10%]
tests/integration/strategies/test_hierarchical_indexing.py::TestHierarchicalIndexing::test_max_depth_configuration PASSED [ 10%]
tests/integration/strategies/test_hierarchical_indexing.py::TestHierarchicalIndexing::test_empty_document PASSED [ 10%]
tests/integration/strategies/test_hierarchical_indexing.py::TestHierarchicalIndexing::test_multiple_documents PASSED [ 10%]
tests/integration/strategies/test_hierarchical_indexing.py::TestHierarchicalIndexing::test_path_tracking PASSED [ 10%]
tests/integration/strategies/test_hierarchical_indexing.py::TestHierarchicalIndexing::test_split_by_headings_markdown PASSED [ 10%]
tests/integration/strategies/test_hierarchical_indexing.py::TestHierarchicalIndexing::test_split_by_headings_no_headings PASSED [ 11%]
tests/integration/strategies/test_hierarchical_indexing.py::TestHierarchicalIndexing::test_split_by_paragraphs PASSED [ 11%]
tests/integration/strategies/test_hierarchical_indexing.py::TestHierarchicalIndexing::test_split_by_paragraphs_single PASSED [ 11%]
tests/integration/strategies/test_hierarchical_indexing.py::TestHierarchicalIndexing::test_document_metadata_preserved PASSED [ 11%]
tests/integration/strategies/test_hierarchical_integration.py::TestHierarchicalIntegration::test_end_to_end_workflow PASSED [ 11%]
tests/integration/strategies/test_hierarchical_integration.py::TestHierarchicalIntegration::test_expansion_strategy_comparison PASSED [ 11%]
tests/integration/strategies/test_hierarchical_integration.py::TestHierarchicalIntegration::test_hierarchy_validation PASSED [ 11%]
tests/integration/strategies/test_hierarchical_integration.py::TestHierarchicalIntegration::test_multiple_documents PASSED [ 11%]
tests/integration/strategies/test_in_memory_indexing.py::test_capabilities PASSED [ 11%]
tests/integration/strategies/test_in_memory_indexing.py::test_dependencies PASSED [ 11%]
tests/integration/strategies/test_in_memory_indexing.py::test_process_success PASSED [ 11%]
tests/integration/strategies/test_in_memory_indexing.py::test_storage_operations PASSED [ 11%]
tests/integration/strategies/test_in_memory_indexing.py::test_clear_storage PASSED [ 11%]
tests/integration/strategies/test_in_memory_indexing.py::test_get_chunk PASSED [ 11%]
tests/integration/strategies/test_in_memory_indexing.py::test_multiple_documents PASSED [ 11%]
tests/integration/strategies/test_in_memory_indexing.py::test_empty_documents PASSED [ 11%]
tests/integration/strategies/test_in_memory_indexing.py::test_custom_chunk_size PASSED [ 11%]
tests/integration/strategies/test_in_memory_indexing.py::test_chunk_metadata_preservation PASSED [ 11%]
tests/integration/strategies/test_in_memory_indexing.py::test_shared_storage_across_instances PASSED [ 11%]
tests/integration/strategies/test_in_memory_indexing.py::test_document_without_id PASSED [ 11%]
tests/integration/strategies/test_keyword_indexing.py::test_capabilities PASSED [ 11%]
tests/integration/strategies/test_keyword_indexing.py::test_dependencies PASSED [ 11%]
tests/integration/strategies/test_keyword_indexing.py::test_process_success PASSED [ 12%]
tests/integration/strategies/test_keyword_indexing.py::test_process_no_chunks PASSED [ 12%]
tests/integration/strategies/test_keyword_indexing.py::test_process_empty_text PASSED [ 12%]
tests/integration/strategies/test_keyword_indexing.py::test_process_stop_words_only PASSED [ 12%]
tests/integration/strategies/test_knowledge_graph_integration.py::test_knowledge_graph_workflow PASSED [ 12%]
tests/integration/strategies/test_knowledge_graph_integration.py::test_hybrid_retrieval PASSED [ 12%]
tests/integration/strategies/test_knowledge_graph_integration.py::test_relationship_queries PASSED [ 12%]
tests/integration/strategies/test_knowledge_graph_integration.py::test_graph_statistics PASSED [ 12%]
tests/integration/strategies/test_late_chunking_integration.py::test_late_chunking_workflow PASSED [ 12%]
tests/integration/strategies/test_late_chunking_integration.py::test_fixed_size_chunking_integration PASSED [ 12%]
tests/integration/strategies/test_late_chunking_integration.py::test_adaptive_chunking_integration PASSED [ 12%]
tests/integration/strategies/test_late_chunking_integration.py::test_multiple_documents PASSED [ 12%]
tests/integration/strategies/test_late_chunking_integration.py::test_strategy_properties PASSED [ 12%]
tests/integration/strategies/test_late_chunking_integration.py::test_coherence_scores_computed PASSED [ 12%]
tests/integration/strategies/test_late_chunking_integration.py::test_short_document PASSED [ 12%]
tests/integration/strategies/test_late_chunking_integration.py::test_chunk_embeddings_valid PASSED [ 12%]
tests/integration/strategies/test_late_chunking_integration.py::test_embedding_quality PASSED [ 12%]
tests/integration/strategies/test_multi_query_integration.py::TestMultiQueryIntegration::test_multi_query_complete_workflow PASSED [ 12%]
tests/integration/strategies/test_multi_query_integration.py::TestMultiQueryIntegration::test_multi_query_async_workflow PASSED [ 12%]
tests/integration/strategies/test_multi_query_integration.py::TestMultiQueryIntegration::test_variant_diversity PASSED [ 12%]
tests/integration/strategies/test_multi_query_integration.py::TestMultiQueryIntegration::test_performance_requirements PASSED [ 12%]
tests/integration/strategies/test_multi_query_integration.py::TestMultiQueryIntegration::test_fallback_on_failure PASSED [ 13%]
tests/integration/strategies/test_multi_query_integration.py::TestMultiQueryIntegration::test_ranking_strategy_comparison PASSED [ 13%]
tests/integration/strategies/test_multi_query_integration.py::TestMultiQueryIntegration::test_deduplication_across_variants PASSED [ 13%]
tests/integration/strategies/test_multi_query_integration.py::TestMultiQueryIntegration::test_strategy_properties PASSED [ 13%]
tests/integration/strategies/test_multi_query_integration.py::TestMultiQueryWithLMStudio::test_with_real_llm PASSED [ 13%]
tests/integration/strategies/test_query_expansion_integration.py::TestQueryExpansionIntegration::test_keyword_expansion_real_llm PASSED [ 13%]
tests/integration/strategies/test_query_expansion_integration.py::TestQueryExpansionIntegration::test_query_reformulation PASSED [ 13%]
tests/integration/strategies/test_query_expansion_integration.py::TestQueryExpansionIntegration::test_question_generation PASSED [ 13%]
tests/integration/strategies/test_query_expansion_integration.py::TestQueryExpansionIntegration::test_hyde_expansion PASSED [ 13%]
tests/integration/strategies/test_query_expansion_integration.py::TestQueryExpansionIntegration::test_multi_query_generation PASSED [ 13%]
tests/integration/strategies/test_query_expansion_integration.py::TestQueryExpansionIntegration::test_expansion_performance PASSED [ 13%]
tests/integration/strategies/test_query_expansion_integration.py::TestQueryExpansionIntegration::test_cache_functionality PASSED [ 13%]
tests/integration/strategies/test_query_expansion_integration.py::TestQueryExpansionIntegration::test_ab_testing_functionality PASSED [ 13%]
tests/integration/strategies/test_query_expansion_integration.py::TestQueryExpansionIntegration::test_domain_context PASSED [ 13%]
tests/integration/strategies/test_query_expansion_integration.py::TestQueryExpansionIntegration::test_error_handling_fallback PASSED [ 13%]
tests/integration/strategies/test_query_expansion_integration.py::TestQueryExpansionIntegration::test_stats_tracking PASSED [ 13%]
tests/integration/strategies/test_reranking_integration.py::TestMockRerankerIntegration::test_end_to_end_reranking PASSED [ 13%]
tests/integration/strategies/test_reranking_integration.py::TestMockRerankerIntegration::test_performance_with_many_candidates PASSED [ 13%]
tests/integration/strategies/test_reranking_integration.py::TestMockRerankerIntegration::test_cache_effectiveness PASSED [ 13%]
tests/integration/strategies/test_reranking_integration.py::TestMockRerankerIntegration::test_score_threshold_filtering PASSED [ 13%]
tests/integration/strategies/test_reranking_integration.py::TestMockRerankerIntegration::test_ranking_position_tracking PASSED [ 13%]
tests/integration/strategies/test_reranking_integration.py::TestMockRerankerIntegration::test_fallback_preserves_order PASSED [ 14%]
tests/integration/strategies/test_reranking_integration.py::TestMockRerankerIntegration::test_batch_processing PASSED [ 14%]
tests/integration/strategies/test_reranking_integration.py::TestMockRerankerIntegration::test_statistics_accumulation PASSED [ 14%]
tests/integration/strategies/test_reranking_integration.py::TestRealCrossEncoderIntegration::test_real_model_reranking SKIPPED [ 14%]
tests/integration/strategies/test_self_reflective_integration.py::TestSelfReflectiveIntegration::test_end_to_end_workflow FAILED [ 14%]
tests/integration/strategies/test_self_reflective_integration.py::TestSelfReflectiveIntegration::test_retry_with_poor_results FAILED [ 14%]
tests/integration/strategies/test_self_reflective_integration.py::TestSelfReflectiveIntegration::test_performance_within_limits FAILED [ 14%]
tests/integration/strategies/test_self_reflective_integration.py::TestSelfReflectiveWithLMStudio::test_with_real_llm FAILED [ 14%]
tests/integration/strategies/test_vector_embedding_indexing.py::TestVectorEmbeddingIndexing::test_capabilities_and_dependencies PASSED [ 14%]
tests/integration/strategies/test_vector_embedding_indexing.py::TestVectorEmbeddingIndexing::test_process_success PASSED [ 14%]
tests/integration/strategies/test_vector_embedding_indexing.py::TestVectorEmbeddingIndexing::test_process_batching PASSED [ 14%]
tests/integration/strategies/test_vector_embedding_indexing.py::TestVectorEmbeddingIndexing::test_empty_documents_handled_gracefully PASSED [ 14%]
tests/integration/strategies/test_vector_embedding_indexing.py::TestVectorEmbeddingIndexing::test_service_error PASSED [ 14%]
tests/integration/test_agentic_rag_pair.py::test_agentic_rag_pair_loading PASSED [ 14%]
tests/integration/test_config_integration.py::test_load_validate_use_config PASSED [ 14%]
tests/integration/test_config_integration.py::test_multi_environment_configuration PASSED [ 14%]
tests/integration/test_config_integration.py::test_config_with_factory PASSED [ 14%]
tests/integration/test_config_integration.py::test_config_with_pipeline PASSED [ 14%]
tests/integration/test_config_integration.py::test_complete_real_world_scenario PASSED [ 14%]
tests/integration/test_config_integration.py::test_config_export_and_reimport PASSED [ 14%]
tests/integration/test_config_integration.py::test_json_configuration_integration PASSED [ 14%]
tests/integration/test_config_integration.py::test_deeply_nested_configuration_access PASSED [ 14%]
tests/integration/test_context_aware_chunking_pair.py::test_context_aware_chunking_pair_loading PASSED [ 15%]
tests/integration/test_contextual_retrieval_pair.py::test_contextual_retrieval_pair_loading PASSED [ 15%]
tests/integration/test_factory_consistency.py::TestFactoryConsistencyIntegration::test_consistent_indexing_strategy_no_warnings PASSED [ 15%]
tests/integration/test_factory_consistency.py::TestFactoryConsistencyIntegration::test_inconsistent_indexing_strategy_logs_warnings FAILED [ 15%]
tests/integration/test_factory_consistency.py::TestFactoryConsistencyIntegration::test_consistent_retrieval_strategy_no_warnings PASSED [ 15%]
tests/integration/test_factory_consistency.py::TestFactoryConsistencyIntegration::test_inconsistent_retrieval_strategy_logs_warnings FAILED [ 15%]
tests/integration/test_factory_consistency.py::TestFactoryConsistencyIntegration::test_legacy_strategy_without_capability_methods PASSED [ 15%]
tests/integration/test_factory_consistency.py::TestFactoryConsistencyIntegration::test_warning_messages_include_strategy_name PASSED [ 15%]
tests/integration/test_factory_consistency.py::TestFactoryConsistencyIntegration::test_warning_messages_include_emoji PASSED [ 15%]
tests/integration/test_factory_consistency.py::TestFactoryConsistencyIntegration::test_override_dependencies_checked PASSED [ 15%]
tests/integration/test_factory_integration.py::test_register_create_use_strategy PASSED [ 15%]
tests/integration/test_factory_integration.py::test_create_multiple_different_strategies PASSED [ 15%]
tests/integration/test_factory_integration.py::test_create_multiple_instances_of_same_strategy PASSED [ 15%]
tests/integration/test_factory_integration.py::test_dependency_injection PASSED [ 15%]
tests/integration/test_factory_integration.py::test_config_file_with_yaml PASSED [ 15%]
tests/integration/test_factory_integration.py::test_config_file_with_json PASSED [ 15%]
tests/integration/test_factory_integration.py::test_factory_error_recovery PASSED [ 15%]
tests/integration/test_factory_integration.py::test_factory_state_after_failed_creation PASSED [ 15%]
tests/integration/test_factory_integration.py::test_decorator_integration PASSED [ 15%]
tests/integration/test_factory_integration.py::test_full_rag_workflow PASSED [ 15%]
tests/integration/test_factory_integration.py::test_async_retrieve_integration PASSED [ 15%]
tests/integration/test_fine_tuned_embeddings_pair.py::test_fine_tuned_embeddings_pair_loading FAILED [ 16%]
tests/integration/test_hierarchical_rag_pair.py::test_hierarchical_rag_pair_loading FAILED [ 16%]
tests/integration/test_hybrid_search_pair.py::test_hybrid_search_pair_loading FAILED [ 16%]
tests/integration/test_keyword_pair.py::test_keyword_pair_loading FAILED [ 16%]
tests/integration/test_knowledge_graph_pair.py::test_knowledge_graph_pair_loading FAILED [ 16%]
tests/integration/test_late_chunking_pair.py::test_late_chunking_pair_loading FAILED [ 16%]
tests/integration/test_multi_query_pair.py::test_multi_query_pair_loading FAILED [ 16%]
tests/integration/test_package_integration.py::TestPackageInstallation::test_package_installable PASSED [ 16%]
tests/integration/test_package_integration.py::TestSmokeTest::test_basic_usage_smoke_test FAILED [ 16%]
tests/integration/test_package_integration.py::TestFullWorkflow::test_full_workflow_with_installed_package FAILED [ 16%]
tests/integration/test_package_integration.py::TestBuildAndDistribution::test_package_can_be_built SKIPPED [ 16%]
tests/integration/test_pipeline_integration.py::test_three_strategy_pipeline PASSED [ 16%]
tests/integration/test_pipeline_integration.py::test_parallel_faster_than_sequential PASSED [ 16%]
tests/integration/test_pipeline_integration.py::test_pipeline_continues_after_non_critical_failure PASSED [ 16%]
tests/integration/test_pipeline_integration.py::test_load_pipeline_from_yaml PASSED [ 16%]
tests/integration/test_pipeline_integration.py::test_async_sequential_execution PASSED [ 16%]
tests/integration/test_pipeline_integration.py::test_async_fallback_execution PASSED [ 16%]
tests/integration/test_pipeline_integration.py::test_parallel_execution_with_failures PASSED [ 16%]
tests/integration/test_query_expansion_pair.py::test_query_expansion_pair_loading FAILED [ 16%]
tests/integration/test_reranking_pair.py::test_reranking_pair_loading FAILED [ 16%]
tests/integration/test_self_reflective_pair.py::test_self_reflective_pair_loading FAILED [ 16%]
tests/integration/test_semantic_api_pair.py::test_semantic_api_pair_loading FAILED [ 17%]
tests/integration/test_semantic_local_pair.py::test_semantic_local_pair_loading FAILED [ 17%]
tests/integration/test_tokenization_integration.py::TestTokenizationIntegration::test_openai_token_count_accuracy PASSED [ 17%]
tests/integration/test_tokenization_integration.py::TestTokenizationIntegration::test_different_encodings PASSED [ 17%]
tests/integration/test_tokenization_integration.py::TestTokenizationIntegration::test_long_text_handling PASSED [ 17%]
tests/integration/test_tokenization_integration.py::TestTokenizationIntegration::test_special_characters PASSED [ 17%]
tests/integration/test_tokenization_integration.py::TestTokenizationIntegration::test_multilingual_text PASSED [ 17%]
tests/integration/test_tokenization_integration.py::TestTokenizationIntegration::test_mixed_content PASSED [ 17%]
tests/integration/test_tokenization_integration.py::TestTokenizationIntegration::test_truncation_accuracy PASSED [ 17%]
tests/integration/test_tokenization_integration.py::TestTokenizationIntegration::test_splitting_accuracy PASSED [ 17%]
tests/integration/test_tokenization_integration.py::TestTokenizationIntegration::test_overlap_behavior PASSED [ 17%]
tests/integration/test_tokenization_integration.py::TestTokenizationIntegration::test_empty_and_whitespace PASSED [ 17%]
tests/integration/test_tokenization_integration.py::TestTokenizationIntegration::test_very_long_single_word PASSED [ 17%]
tests/integration/test_tokenization_integration.py::TestTokenizationIntegration::test_consistency_across_calls PASSED [ 17%]
tests/integration/test_tokenization_integration.py::TestTokenizationIntegration::test_different_models PASSED [ 17%]
tests/integration/test_tokenization_integration.py::TestPerformance::test_tokenization_speed PASSED [ 17%]
tests/integration/test_tokenization_integration.py::TestPerformance::test_token_counting_speed PASSED [ 17%]
tests/integration/test_tokenization_integration.py::TestPerformance::test_batch_tokenization_performance PASSED [ 17%]
tests/integration_real/test_database_real.py::test_postgres_connection PASSED [ 17%]
tests/integration_real/test_database_real.py::test_table_creation PASSED [ 17%]
tests/integration_real/test_database_real.py::test_store_and_retrieve_chunks PASSED [ 17%]
tests/integration_real/test_database_real.py::test_vector_similarity_search PASSED [ 17%]
tests/integration_real/test_database_real.py::test_batch_embedding_and_storage PASSED [ 18%]
tests/integration_real/test_database_real.py::test_chunk_metadata_persistence PASSED [ 18%]
tests/integration_real/test_database_real.py::test_database_context_table_mapping PASSED [ 18%]
tests/integration_real/test_database_real.py::test_connection_pooling PASSED [ 18%]
tests/integration_real/test_embedding_real.py::test_onnx_embedding_generation PASSED [ 18%]
tests/integration_real/test_embedding_real.py::test_embedding_consistency PASSED [ 18%]
tests/integration_real/test_embedding_real.py::test_batch_embedding_generation PASSED [ 18%]
tests/integration_real/test_embedding_real.py::test_semantic_similarity PASSED [ 18%]
tests/integration_real/test_embedding_real.py::test_embedding_dimensions PASSED [ 18%]
tests/integration_real/test_embedding_real.py::test_openai_embedding_generation SKIPPED [ 18%]
tests/integration_real/test_embedding_real.py::test_openai_batch_embedding SKIPPED [ 18%]
tests/integration_real/test_embedding_real.py::test_cohere_embedding_generation SKIPPED [ 18%]
tests/integration_real/test_embedding_real.py::test_empty_text_handling PASSED [ 18%]
tests/integration_real/test_embedding_real.py::test_long_text_handling PASSED [ 18%]
tests/integration_real/test_embedding_real.py::test_special_characters_handling PASSED [ 18%]
tests/integration_real/test_end_to_end_real.py::test_document_indexing_pipeline PASSED [ 18%]
tests/integration_real/test_end_to_end_real.py::test_retrieval_pipeline PASSED [ 18%]
tests/integration_real/test_end_to_end_real.py::test_full_rag_pipeline PASSED [ 18%]
tests/integration_real/test_end_to_end_real.py::test_multiple_document_batches PASSED [ 18%]
tests/integration_real/test_end_to_end_real.py::test_retrieval_with_metadata_filtering PASSED [ 18%]
tests/integration_real/test_end_to_end_real.py::test_large_document_indexing PASSED [ 18%]
tests/integration_real/test_end_to_end_real.py::test_retrieval_accuracy PASSED [ 19%]
tests/integration_real/test_llm_real.py::test_llm_basic_generation PASSED [ 19%]
tests/integration_real/test_llm_real.py::test_llm_conversation PASSED    [ 19%]
tests/integration_real/test_llm_real.py::test_llm_token_counting PASSED  [ 19%]
tests/integration_real/test_llm_real.py::test_llm_with_system_prompt PASSED [ 19%]
tests/integration_real/test_llm_real.py::test_llm_json_response PASSED   [ 19%]
tests/integration_real/test_llm_real.py::test_llm_max_tokens PASSED      [ 19%]
tests/integration_real/test_llm_real.py::test_llm_temperature PASSED     [ 19%]
tests/integration_real/test_llm_real.py::test_llm_streaming FAILED       [ 19%]
tests/integration_real/test_llm_real.py::test_llm_rag_context PASSED     [ 19%]
tests/integration_real/test_llm_real.py::test_llm_error_handling PASSED  [ 19%]
tests/integration_real/test_neo4j_real.py::test_neo4j_connection SKIPPED [ 19%]
tests/integration_real/test_neo4j_real.py::test_create_and_retrieve_node SKIPPED [ 19%]
tests/integration_real/test_neo4j_real.py::test_create_relationship SKIPPED [ 19%]
tests/integration_real/test_neo4j_real.py::test_graph_traversal SKIPPED  [ 19%]
tests/integration_real/test_neo4j_real.py::test_entity_storage SKIPPED   [ 19%]
tests/integration_real/test_neo4j_real.py::test_batch_node_creation SKIPPED [ 19%]
tests/integration_real/test_neo4j_real.py::test_update_node_properties SKIPPED [ 19%]
tests/integration_real/test_neo4j_real.py::test_delete_nodes SKIPPED     [ 19%]
tests/integration_real/test_neo4j_real.py::test_complex_query SKIPPED    [ 19%]
tests/mocks/test_standalone.py::test_embedding_service PASSED            [ 19%]
tests/mocks/test_standalone.py::test_database_service PASSED             [ 20%]
tests/mocks/test_standalone.py::test_llm_service PASSED                  [ 20%]
tests/mocks/test_standalone.py::test_neo4j_service PASSED                [ 20%]
tests/mocks/test_standalone.py::test_registry PASSED                     [ 20%]
tests/mocks/test_standalone.py::test_chunk PASSED                        [ 20%]
tests/unit/cli/test_benchmark_command.py::TestBenchmarkCommand::test_benchmark_default_strategies PASSED [ 20%]
tests/unit/cli/test_benchmark_command.py::TestBenchmarkCommand::test_benchmark_specific_strategies PASSED [ 20%]
tests/unit/cli/test_benchmark_command.py::TestBenchmarkCommand::test_benchmark_export_results PASSED [ 20%]
tests/unit/cli/test_benchmark_command.py::TestBenchmarkCommand::test_benchmark_missing_dataset PASSED [ 20%]
tests/unit/cli/test_benchmark_command.py::TestBenchmarkCommand::test_benchmark_missing_index PASSED [ 20%]
tests/unit/cli/test_check_consistency_command.py::TestCheckConsistencyCommand::test_command_help PASSED [ 20%]
tests/unit/cli/test_check_consistency_command.py::TestCheckConsistencyCommand::test_all_strategies_consistent PASSED [ 20%]
tests/unit/cli/test_check_consistency_command.py::TestCheckConsistencyCommand::test_strategies_with_warnings PASSED [ 20%]
tests/unit/cli/test_check_consistency_command.py::TestCheckConsistencyCommand::test_type_filter_indexing PASSED [ 20%]
tests/unit/cli/test_check_consistency_command.py::TestCheckConsistencyCommand::test_type_filter_retrieval PASSED [ 20%]
tests/unit/cli/test_check_consistency_command.py::TestCheckConsistencyCommand::test_invalid_type_filter PASSED [ 20%]
tests/unit/cli/test_check_consistency_command.py::TestCheckConsistencyCommand::test_strategy_filter PASSED [ 20%]
tests/unit/cli/test_check_consistency_command.py::TestCheckConsistencyCommand::test_verbose_mode PASSED [ 20%]
tests/unit/cli/test_check_consistency_command.py::TestCheckConsistencyCommand::test_config_file_loading PASSED [ 20%]
tests/unit/cli/test_check_consistency_command.py::TestCheckConsistencyCommand::test_system_error_returns_exit_code_1 PASSED [ 20%]
tests/unit/cli/test_check_consistency_command.py::TestCheckConsistencyCommand::test_strategies_with_errors PASSED [ 20%]
tests/unit/cli/test_config_validation_command.py::TestConfigValidationCommand::test_validate_valid_config PASSED [ 20%]
tests/unit/cli/test_config_validation_command.py::TestConfigValidationCommand::test_validate_invalid_config_missing_field PASSED [ 21%]
tests/unit/cli/test_config_validation_command.py::TestConfigValidationCommand::test_validate_invalid_config_values PASSED [ 21%]
tests/unit/cli/test_config_validation_command.py::TestConfigValidationCommand::test_validate_config_warnings PASSED [ 21%]
tests/unit/cli/test_config_validation_command.py::TestConfigValidationCommand::test_validate_config_strict_mode PASSED [ 21%]
tests/unit/cli/test_config_validation_command.py::TestConfigValidationCommand::test_validate_show_config PASSED [ 21%]
tests/unit/cli/test_consistency_formatter.py::TestConsistencyFormatter::test_format_empty_results PASSED [ 21%]
tests/unit/cli/test_consistency_formatter.py::TestConsistencyFormatter::test_format_consistent_strategies PASSED [ 21%]
tests/unit/cli/test_consistency_formatter.py::TestConsistencyFormatter::test_format_strategies_with_warnings PASSED [ 21%]
tests/unit/cli/test_consistency_formatter.py::TestConsistencyFormatter::test_format_strategies_with_errors PASSED [ 21%]
tests/unit/cli/test_consistency_formatter.py::TestConsistencyFormatter::test_grouping_by_type PASSED [ 21%]
tests/unit/cli/test_consistency_formatter.py::TestConsistencyFormatter::test_verbose_mode PASSED [ 21%]
tests/unit/cli/test_consistency_formatter.py::TestConsistencyFormatter::test_display_strategy_group PASSED [ 21%]
tests/unit/cli/test_consistency_formatter.py::TestConsistencyFormatter::test_display_summary PASSED [ 21%]
tests/unit/cli/test_consistency_formatter.py::TestConsistencyFormatter::test_warning_note_displayed PASSED [ 21%]
tests/unit/cli/test_consistency_formatter.py::TestConsistencyFormatter::test_multiple_warnings_per_strategy PASSED [ 21%]
tests/unit/cli/test_formatters.py::TestOutputFormatters::test_format_success PASSED [ 21%]
tests/unit/cli/test_formatters.py::TestOutputFormatters::test_format_success_with_title PASSED [ 21%]
tests/unit/cli/test_formatters.py::TestOutputFormatters::test_format_error PASSED [ 21%]
tests/unit/cli/test_formatters.py::TestOutputFormatters::test_format_warning PASSED [ 21%]
tests/unit/cli/test_formatters.py::TestQueryResultsFormatter::test_format_query_results_basic PASSED [ 21%]
tests/unit/cli/test_formatters.py::TestQueryResultsFormatter::test_format_query_results_with_strategy PASSED [ 21%]
tests/unit/cli/test_formatters.py::TestQueryResultsFormatter::test_format_empty_results PASSED [ 22%]
tests/unit/cli/test_formatters.py::TestQueryResultsFormatter::test_format_results_with_long_text PASSED [ 22%]
tests/unit/cli/test_formatters.py::TestStrategyListFormatter::test_format_strategy_list_basic PASSED [ 22%]
tests/unit/cli/test_formatters.py::TestStrategyListFormatter::test_format_strategy_list_with_filter PASSED [ 22%]
tests/unit/cli/test_formatters.py::TestStrategyListFormatter::test_format_empty_strategy_list PASSED [ 22%]
tests/unit/cli/test_formatters.py::TestStrategyListFormatter::test_format_strategy_list_grouped_by_type PASSED [ 22%]
tests/unit/cli/test_formatters.py::TestBenchmarkResultsFormatter::test_format_benchmark_results_basic PASSED [ 22%]
tests/unit/cli/test_formatters.py::TestBenchmarkResultsFormatter::test_format_single_strategy_benchmark PASSED [ 22%]
tests/unit/cli/test_formatters.py::TestBenchmarkResultsFormatter::test_format_empty_benchmark_results PASSED [ 22%]
tests/unit/cli/test_formatters.py::TestStatisticsFormatter::test_format_statistics_basic PASSED [ 22%]
tests/unit/cli/test_formatters.py::TestStatisticsFormatter::test_format_statistics_with_floats PASSED [ 22%]
tests/unit/cli/test_formatters.py::TestStatisticsFormatter::test_format_empty_statistics PASSED [ 22%]
tests/unit/cli/test_formatters.py::TestStatisticsFormatter::test_format_statistics_key_transformation PASSED [ 22%]
tests/unit/cli/test_index_command.py::TestIndexCommand::test_index_success PASSED [ 22%]
tests/unit/cli/test_index_command.py::TestIndexCommand::test_index_with_invalid_path PASSED [ 22%]
tests/unit/cli/test_index_command.py::TestIndexCommand::test_index_no_documents_found PASSED [ 22%]
tests/unit/cli/test_index_command.py::TestIndexCommand::test_index_with_config PASSED [ 22%]
tests/unit/cli/test_index_command.py::TestIndexCommand::test_index_output_directory PASSED [ 22%]
tests/unit/cli/test_list_strategies_command.py::TestListStrategiesCommand::test_list_all_strategies PASSED [ 22%]
tests/unit/cli/test_list_strategies_command.py::TestListStrategiesCommand::test_list_strategies_empty PASSED [ 22%]
tests/unit/cli/test_list_strategies_command.py::TestListStrategiesCommand::test_filter_strategies_by_type PASSED [ 22%]
tests/unit/cli/test_list_strategies_command.py::TestListStrategiesCommand::test_filter_strategies_no_match PASSED [ 22%]
tests/unit/cli/test_list_strategies_command.py::TestListStrategiesCommand::test_list_strategies_verbose PASSED [ 23%]
tests/unit/cli/test_query_command.py::TestQueryCommand::test_query_success PASSED [ 23%]
tests/unit/cli/test_query_command.py::TestQueryCommand::test_query_index_not_found PASSED [ 23%]
tests/unit/cli/test_query_command.py::TestQueryCommand::test_query_with_config PASSED [ 23%]
tests/unit/cli/test_query_command.py::TestQueryCommand::test_query_multiple_strategies PASSED [ 23%]
tests/unit/cli/test_query_command.py::TestQueryCommand::test_query_no_results PASSED [ 23%]
tests/unit/cli/test_repl_command.py::TestREPLCommand::test_repl_start PASSED [ 23%]
tests/unit/cli/test_repl_command.py::TestREPLCommand::test_repl_with_config PASSED [ 23%]
tests/unit/cli/test_repl_command.py::TestREPLSession::test_repl_session_init PASSED [ 23%]
tests/unit/cli/test_repl_command.py::TestREPLSession::test_repl_set_command PASSED [ 23%]
tests/unit/cli/test_validate_pipeline_command.py::TestValidatePipelineCommand::test_command_help PASSED [ 23%]
tests/unit/cli/test_validate_pipeline_command.py::TestValidatePipelineCommand::test_missing_indexing_argument PASSED [ 23%]
tests/unit/cli/test_validate_pipeline_command.py::TestValidatePipelineCommand::test_missing_retrieval_argument PASSED [ 23%]
tests/unit/cli/test_validate_pipeline_command.py::TestValidatePipelineCommand::test_valid_pipeline_returns_zero PASSED [ 23%]
tests/unit/cli/test_validate_pipeline_command.py::TestValidatePipelineCommand::test_invalid_pipeline_returns_nonzero PASSED [ 23%]
tests/unit/cli/test_validate_pipeline_command.py::TestValidatePipelineCommand::test_invalid_strategy_name_error PASSED [ 23%]
tests/unit/cli/test_validate_pipeline_command.py::TestValidatePipelineCommand::test_parse_multiple_strategies PASSED [ 23%]
tests/unit/cli/test_validate_pipeline_command.py::TestValidatePipelineCommand::test_config_file_loading PASSED [ 23%]
tests/unit/cli/test_validation.py::TestValidatePathExists::test_validate_existing_file PASSED [ 23%]
tests/unit/cli/test_validation.py::TestValidatePathExists::test_validate_existing_directory PASSED [ 23%]
tests/unit/cli/test_validation.py::TestValidatePathExists::test_validate_nonexistent_path PASSED [ 23%]
tests/unit/cli/test_validation.py::TestValidatePathExists::test_validate_file_when_directory PASSED [ 24%]
tests/unit/cli/test_validation.py::TestValidatePathExists::test_validate_directory_when_file PASSED [ 24%]
tests/unit/cli/test_validation.py::TestValidateConfigFile::test_validate_yaml_config PASSED [ 24%]
tests/unit/cli/test_validation.py::TestValidateConfigFile::test_validate_json_config PASSED [ 24%]
tests/unit/cli/test_validation.py::TestValidateConfigFile::test_validate_invalid_yaml PASSED [ 24%]
tests/unit/cli/test_validation.py::TestValidateConfigFile::test_validate_invalid_json PASSED [ 24%]
tests/unit/cli/test_validation.py::TestValidateConfigFile::test_validate_unsupported_format PASSED [ 24%]
tests/unit/cli/test_validation.py::TestValidateConfigFile::test_validate_nonexistent_file PASSED [ 24%]
tests/unit/cli/test_validation.py::TestValidateConfigFile::test_validate_non_dict_config PASSED [ 24%]
tests/unit/cli/test_validation.py::TestParseStrategyList::test_parse_single_strategy PASSED [ 24%]
tests/unit/cli/test_validation.py::TestParseStrategyList::test_parse_multiple_strategies PASSED [ 24%]
tests/unit/cli/test_validation.py::TestParseStrategyList::test_parse_strategies_with_spaces PASSED [ 24%]
tests/unit/cli/test_validation.py::TestParseStrategyList::test_parse_empty_string PASSED [ 24%]
tests/unit/cli/test_validation.py::TestParseStrategyList::test_parse_only_commas PASSED [ 24%]
tests/unit/cli/test_validation_formatter.py::TestDisplayCapabilities::test_display_capabilities_with_capabilities PASSED [ 24%]
tests/unit/cli/test_validation_formatter.py::TestDisplayCapabilities::test_display_capabilities_empty PASSED [ 24%]
tests/unit/cli/test_validation_formatter.py::TestDisplayRequirements::test_display_requirements_all_met PASSED [ 24%]
tests/unit/cli/test_validation_formatter.py::TestDisplayRequirements::test_display_requirements_unmet PASSED [ 24%]
tests/unit/cli/test_validation_formatter.py::TestDisplayRequirements::test_display_requirements_empty PASSED [ 24%]
tests/unit/cli/test_validation_formatter.py::TestDisplayServiceRequirements::test_display_service_requirements_all_available PASSED [ 24%]
tests/unit/cli/test_validation_formatter.py::TestDisplayServiceRequirements::test_display_service_requirements_missing PASSED [ 24%]
tests/unit/cli/test_validation_formatter.py::TestDisplayServiceRequirements::test_display_service_requirements_empty PASSED [ 25%]
tests/unit/cli/test_validation_formatter.py::TestDisplayValidationStatus::test_display_valid_status PASSED [ 25%]
tests/unit/cli/test_validation_formatter.py::TestDisplayValidationStatus::test_display_invalid_status_missing_capabilities PASSED [ 25%]
tests/unit/cli/test_validation_formatter.py::TestDisplayValidationStatus::test_display_invalid_status_missing_services PASSED [ 25%]
tests/unit/cli/test_validation_formatter.py::TestDisplaySuggestions::test_display_suggestions PASSED [ 25%]
tests/unit/cli/test_validation_formatter.py::TestFormatValidationResults::test_format_valid_pipeline PASSED [ 25%]
tests/unit/cli/test_validation_formatter.py::TestFormatValidationResults::test_format_invalid_pipeline_with_suggestions PASSED [ 25%]
tests/unit/config/test_env_resolver.py::TestEnvResolverBasic::test_resolve_simple_variable PASSED [ 25%]
tests/unit/config/test_env_resolver.py::TestEnvResolverBasic::test_resolve_with_default PASSED [ 25%]
tests/unit/config/test_env_resolver.py::TestEnvResolverBasic::test_resolve_with_default_when_exists PASSED [ 25%]
tests/unit/config/test_env_resolver.py::TestEnvResolverBasic::test_resolve_required_missing PASSED [ 25%]
tests/unit/config/test_env_resolver.py::TestEnvResolverBasic::test_resolve_with_custom_error PASSED [ 25%]
tests/unit/config/test_env_resolver.py::TestEnvResolverRecursive::test_resolve_in_dict PASSED [ 25%]
tests/unit/config/test_env_resolver.py::TestEnvResolverRecursive::test_resolve_in_list PASSED [ 25%]
tests/unit/config/test_env_resolver.py::TestEnvResolverRecursive::test_resolve_deeply_nested PASSED [ 25%]
tests/unit/config/test_env_resolver.py::TestEnvResolverPartialReplacement::test_partial_string_replacement PASSED [ 25%]
tests/unit/config/test_env_resolver.py::TestEnvResolverPartialReplacement::test_multiple_variables_in_string PASSED [ 25%]
tests/unit/config/test_env_resolver.py::TestEnvResolverPartialReplacement::test_mixed_variables_and_defaults PASSED [ 25%]
tests/unit/config/test_env_resolver.py::TestEnvResolverValidation::test_validate_no_injection_valid PASSED [ 25%]
tests/unit/config/test_env_resolver.py::TestEnvResolverValidation::test_validate_no_injection_invalid PASSED [ 25%]
tests/unit/config/test_env_resolver.py::TestEnvResolverExtraction::test_extract_variable_names_simple PASSED [ 25%]
tests/unit/config/test_env_resolver.py::TestEnvResolverExtraction::test_extract_variable_names_dict PASSED [ 25%]
tests/unit/config/test_env_resolver.py::TestEnvResolverExtraction::test_extract_variable_names_with_defaults PASSED [ 26%]
tests/unit/config/test_env_resolver.py::TestEnvResolverExtraction::test_extract_variable_names_duplicates PASSED [ 26%]
tests/unit/config/test_env_resolver.py::TestEnvResolverExtraction::test_extract_variable_names_nested PASSED [ 26%]
tests/unit/config/test_env_resolver.py::TestEnvResolverEdgeCases::test_resolve_non_string_values PASSED [ 26%]
tests/unit/config/test_env_resolver.py::TestEnvResolverEdgeCases::test_resolve_empty_string PASSED [ 26%]
tests/unit/config/test_env_resolver.py::TestEnvResolverEdgeCases::test_resolve_string_without_variables PASSED [ 26%]
tests/unit/config/test_env_resolver.py::TestEnvResolverEdgeCases::test_resolve_empty_dict PASSED [ 26%]
tests/unit/config/test_env_resolver.py::TestEnvResolverEdgeCases::test_resolve_empty_list PASSED [ 26%]
tests/unit/config/test_env_resolver.py::TestEnvResolverEdgeCases::test_resolve_mixed_types_in_list PASSED [ 26%]
tests/unit/config/test_env_validator.py::TestEnvironmentValidator::test_validate_production_success PASSED [ 26%]
tests/unit/config/test_env_validator.py::TestEnvironmentValidator::test_validate_development_success PASSED [ 26%]
tests/unit/config/test_env_validator.py::TestEnvironmentValidator::test_validate_test_success PASSED [ 26%]
tests/unit/config/test_env_validator.py::TestEnvironmentValidator::test_validate_production_missing PASSED [ 26%]
tests/unit/config/test_env_validator.py::TestEnvironmentValidator::test_validate_test_missing PASSED [ 26%]
tests/unit/config/test_env_validator.py::TestEnvironmentValidator::test_validate_test_with_deprecated_var PASSED [ 26%]
tests/unit/config/test_env_validator.py::TestEnvironmentValidator::test_deprecated_warning PASSED [ 26%]
tests/unit/config/test_env_validator.py::TestEnvironmentValidator::test_no_deprecated_warning_when_not_set PASSED [ 26%]
tests/unit/config/test_env_validator.py::TestEnvironmentValidator::test_get_database_url_main PASSED [ 26%]
tests/unit/config/test_env_validator.py::TestEnvironmentValidator::test_get_database_url_test_new_name PASSED [ 26%]
tests/unit/config/test_env_validator.py::TestEnvironmentValidator::test_get_database_url_backward_compatible PASSED [ 26%]
tests/unit/config/test_env_validator.py::TestEnvironmentValidator::test_get_database_url_prefers_new_name PASSED [ 26%]
tests/unit/config/test_env_validator.py::TestEnvironmentValidator::test_get_database_url_returns_none_when_not_set PASSED [ 27%]
tests/unit/config/test_env_validator.py::TestEnvironmentValidator::test_get_database_url_test_returns_none_when_not_set PASSED [ 27%]
tests/unit/config/test_env_validator.py::TestEnvironmentValidator::test_get_all_database_vars PASSED [ 27%]
tests/unit/config/test_env_validator.py::TestEnvironmentValidator::test_check_required_returns_empty_for_valid_config PASSED [ 27%]
tests/unit/config/test_env_validator.py::TestEnvironmentValidator::test_check_required_returns_missing_vars PASSED [ 27%]
tests/unit/config/test_env_validator.py::TestEnvironmentValidator::test_error_message_includes_documentation_reference PASSED [ 27%]
tests/unit/config/test_env_validator.py::TestEnvironmentValidator::test_deprecation_warning_includes_migration_instructions PASSED [ 27%]
tests/unit/config/test_schemas.py::TestServiceRegistrySchema::test_schema_is_valid_json_schema PASSED [ 27%]
tests/unit/config/test_schemas.py::TestServiceRegistrySchema::test_minimal_valid_config PASSED [ 27%]
tests/unit/config/test_schemas.py::TestServiceRegistrySchema::test_llm_service_valid PASSED [ 27%]
tests/unit/config/test_schemas.py::TestServiceRegistrySchema::test_embedding_service_valid PASSED [ 27%]
tests/unit/config/test_schemas.py::TestServiceRegistrySchema::test_database_service_valid PASSED [ 27%]
tests/unit/config/test_schemas.py::TestServiceRegistrySchema::test_missing_services_invalid PASSED [ 27%]
tests/unit/config/test_schemas.py::TestServiceRegistrySchema::test_invalid_service_name PASSED [ 27%]
tests/unit/config/test_schemas.py::TestServiceRegistrySchema::test_version_format PASSED [ 27%]
tests/unit/config/test_schemas.py::TestStrategyPairSchema::test_schema_is_valid_json_schema PASSED [ 27%]
tests/unit/config/test_schemas.py::TestStrategyPairSchema::test_minimal_valid_config PASSED [ 27%]
tests/unit/config/test_schemas.py::TestStrategyPairSchema::test_service_reference_format PASSED [ 27%]
tests/unit/config/test_schemas.py::TestStrategyPairSchema::test_inline_service_config PASSED [ 27%]
tests/unit/config/test_schemas.py::TestStrategyPairSchema::test_db_config PASSED [ 27%]
tests/unit/config/test_schemas.py::TestStrategyPairSchema::test_migrations_config PASSED [ 27%]
tests/unit/config/test_schemas.py::TestStrategyPairSchema::test_expected_schema_config PASSED [ 28%]
tests/unit/config/test_schemas.py::TestStrategyPairSchema::test_tags PASSED [ 28%]
tests/unit/config/test_schemas.py::TestStrategyPairSchema::test_invalid_strategy_name_format PASSED [ 28%]
tests/unit/config/test_schemas.py::TestStrategyPairSchema::test_missing_required_fields PASSED [ 28%]
tests/unit/config/test_strategy_loader.py::test_load_valid_config PASSED [ 28%]
tests/unit/config/test_strategy_loader.py::test_load_invalid_yaml PASSED [ 28%]
tests/unit/config/test_strategy_loader.py::test_load_missing_file PASSED [ 28%]
tests/unit/config/test_strategy_loader.py::test_schema_validation_error PASSED [ 28%]
tests/unit/config/test_strategy_loader.py::test_schema_validation_types PASSED [ 28%]
tests/unit/config/test_strategy_loader.py::test_schema_pattern_validation PASSED [ 28%]
tests/unit/config/test_strategy_pair_manager.py::test_load_pair_success FAILED [ 28%]
tests/unit/config/test_strategy_pair_manager.py::test_load_pair_compatibility_error PASSED [ 28%]
tests/unit/config/test_strategy_pair_manager.py::test_migration_error PASSED [ 28%]
tests/unit/config/test_strategy_pair_manager.py::test_db_context_creation FAILED [ 28%]
tests/unit/config/test_validator.py::TestServiceRegistryValidation::test_valid_service_registry PASSED [ 28%]
tests/unit/config/test_validator.py::TestServiceRegistryValidation::test_valid_embedding_service PASSED [ 28%]
tests/unit/config/test_validator.py::TestServiceRegistryValidation::test_valid_database_service PASSED [ 28%]
tests/unit/config/test_validator.py::TestServiceRegistryValidation::test_invalid_service_registry_missing_required PASSED [ 28%]
tests/unit/config/test_validator.py::TestServiceRegistryValidation::test_invalid_service_type PASSED [ 28%]
tests/unit/config/test_validator.py::TestServiceRegistryValidation::test_invalid_embedding_provider PASSED [ 28%]
tests/unit/config/test_validator.py::TestServiceRegistryValidation::test_plaintext_secret_warning PASSED [ 28%]
tests/unit/config/test_validator.py::TestServiceRegistryValidation::test_no_warning_for_env_var_secrets PASSED [ 28%]
tests/unit/config/test_validator.py::TestStrategyPairValidation::test_valid_strategy_pair PASSED [ 29%]
tests/unit/config/test_validator.py::TestStrategyPairValidation::test_strategy_pair_with_db_config PASSED [ 29%]
tests/unit/config/test_validator.py::TestStrategyPairValidation::test_strategy_pair_with_migrations PASSED [ 29%]
tests/unit/config/test_validator.py::TestStrategyPairValidation::test_invalid_strategy_name_format PASSED [ 29%]
tests/unit/config/test_validator.py::TestStrategyPairValidation::test_invalid_version_format PASSED [ 29%]
tests/unit/config/test_validator.py::TestStrategyPairValidation::test_missing_required_sections PASSED [ 29%]
tests/unit/config/test_validator.py::TestServiceReferenceValidation::test_invalid_service_reference PASSED [ 29%]
tests/unit/config/test_validator.py::TestServiceReferenceValidation::test_inline_service_config PASSED [ 29%]
tests/unit/config/test_validator.py::TestServiceReferenceValidation::test_validation_without_service_registry PASSED [ 29%]
tests/unit/config/test_validator.py::TestConfigValidationError::test_error_with_all_fields PASSED [ 29%]
tests/unit/config/test_validator.py::TestConfigValidationError::test_error_with_message_only PASSED [ 29%]
tests/unit/config/test_validator.py::TestLoadYamlWithValidation::test_load_valid_services_yaml PASSED [ 29%]
tests/unit/config/test_validator.py::TestLoadYamlWithValidation::test_load_valid_strategy_pair_yaml PASSED [ 29%]
tests/unit/config/test_validator.py::TestLoadYamlWithValidation::test_load_invalid_config_type PASSED [ 29%]
tests/unit/config/test_validator.py::TestLoadYamlWithValidation::test_load_nonexistent_file PASSED [ 29%]
tests/unit/core/test_capabilities.py::TestIndexCapability::test_all_capabilities_defined PASSED [ 29%]
tests/unit/core/test_capabilities.py::TestIndexCapability::test_enum_values_unique PASSED [ 29%]
tests/unit/core/test_capabilities.py::TestIndexCapability::test_enum_members_accessible PASSED [ 29%]
tests/unit/core/test_capabilities.py::TestIndexCapability::test_enum_string_representation PASSED [ 29%]
tests/unit/core/test_capabilities.py::TestIndexCapability::test_enum_comparison PASSED [ 29%]
tests/unit/core/test_capabilities.py::TestIndexCapability::test_enum_in_set PASSED [ 29%]
tests/unit/core/test_capabilities.py::TestIndexingResult::test_has_capability_present PASSED [ 30%]
tests/unit/core/test_capabilities.py::TestIndexingResult::test_has_capability_absent PASSED [ 30%]
tests/unit/core/test_capabilities.py::TestIndexingResult::test_is_compatible_with_satisfied PASSED [ 30%]
tests/unit/core/test_capabilities.py::TestIndexingResult::test_is_compatible_with_unsatisfied PASSED [ 30%]
tests/unit/core/test_capabilities.py::TestIndexingResult::test_is_compatible_with_empty_requirements PASSED [ 30%]
tests/unit/core/test_capabilities.py::TestIndexingResult::test_repr_format PASSED [ 30%]
tests/unit/core/test_capabilities.py::TestIndexingResult::test_repr_sorted_capabilities PASSED [ 30%]
tests/unit/core/test_capabilities.py::TestValidationResult::test_repr_valid PASSED [ 30%]
tests/unit/core/test_capabilities.py::TestValidationResult::test_repr_missing_capabilities_only PASSED [ 30%]
tests/unit/core/test_capabilities.py::TestValidationResult::test_repr_missing_services_only PASSED [ 30%]
tests/unit/core/test_capabilities.py::TestValidationResult::test_repr_missing_both PASSED [ 30%]
tests/unit/core/test_capabilities.py::TestValidationResult::test_repr_empty_missing PASSED [ 30%]
tests/unit/core/test_capabilities.py::TestValidationResult::test_repr_sorted_items PASSED [ 30%]
tests/unit/core/test_factory_validation.py::test_validate_compatibility_success PASSED [ 30%]
tests/unit/core/test_factory_validation.py::test_validate_compatibility_failure PASSED [ 30%]
tests/unit/core/test_factory_validation.py::test_validate_pipeline_success PASSED [ 30%]
tests/unit/core/test_factory_validation.py::test_validate_pipeline_missing_service PASSED [ 30%]
tests/unit/core/test_factory_validation.py::test_auto_select_retrieval PASSED [ 30%]
tests/unit/core/test_factory_validation.py::test_auto_select_retrieval_preference PASSED [ 30%]
tests/unit/core/test_factory_validation.py::test_consistency_checking_called PASSED [ 30%]
tests/unit/core/test_indexing_interface.py::TestIndexingContext::test_initialization_with_database_service PASSED [ 30%]
tests/unit/core/test_indexing_interface.py::TestIndexingContext::test_initialization_with_config PASSED [ 31%]
tests/unit/core/test_indexing_interface.py::TestIndexingContext::test_metrics_tracking PASSED [ 31%]
tests/unit/core/test_indexing_interface.py::TestIndexingContext::test_config_defaults_to_empty_dict PASSED [ 31%]
tests/unit/core/test_indexing_interface.py::TestIIndexingStrategy::test_cannot_instantiate_abstract_class PASSED [ 31%]
tests/unit/core/test_indexing_interface.py::TestIIndexingStrategy::test_requires_produces_implementation PASSED [ 31%]
tests/unit/core/test_indexing_interface.py::TestIIndexingStrategy::test_requires_requires_services_implementation PASSED [ 31%]
tests/unit/core/test_indexing_interface.py::TestIIndexingStrategy::test_requires_process_implementation PASSED [ 31%]
tests/unit/core/test_indexing_interface.py::TestIIndexingStrategy::test_complete_implementation_succeeds PASSED [ 31%]
tests/unit/core/test_indexing_interface.py::TestIIndexingStrategy::test_dependency_validation_on_init PASSED [ 31%]
tests/unit/core/test_indexing_interface.py::TestVectorEmbeddingIndexing::test_produces_correct_capabilities PASSED [ 31%]
tests/unit/core/test_indexing_interface.py::TestVectorEmbeddingIndexing::test_requires_correct_services PASSED [ 31%]
tests/unit/core/test_indexing_interface.py::TestVectorEmbeddingIndexing::test_initialization_fails_without_embedding_service PASSED [ 31%]
tests/unit/core/test_indexing_interface.py::TestVectorEmbeddingIndexing::test_initialization_fails_without_database_service PASSED [ 31%]
tests/unit/core/test_indexing_interface.py::TestVectorEmbeddingIndexing::test_initialization_succeeds_with_all_services PASSED [ 31%]
tests/unit/core/test_indexing_interface.py::TestVectorEmbeddingIndexing::test_process_chunks_documents PASSED [ 31%]
tests/unit/core/test_indexing_interface.py::TestVectorEmbeddingIndexing::test_process_generates_embeddings PASSED [ 31%]
tests/unit/core/test_indexing_interface.py::TestVectorEmbeddingIndexing::test_process_stores_chunks_in_database PASSED [ 31%]
tests/unit/core/test_indexing_interface.py::TestVectorEmbeddingIndexing::test_process_updates_context_metrics PASSED [ 31%]
tests/unit/core/test_indexing_interface.py::TestVectorEmbeddingIndexing::test_process_returns_correct_result PASSED [ 31%]
tests/unit/core/test_indexing_interface.py::TestVectorEmbeddingIndexing::test_chunk_documents_with_default_config PASSED [ 31%]
tests/unit/core/test_indexing_interface.py::TestVectorEmbeddingIndexing::test_chunk_documents_preserves_metadata PASSED [ 31%]
tests/unit/core/test_indexing_interface.py::TestValidateDependencies::test_validation_passes_with_all_services PASSED [ 31%]
tests/unit/core/test_indexing_interface.py::TestValidateDependencies::test_validation_fails_with_missing_service PASSED [ 32%]
tests/unit/core/test_indexing_interface.py::TestValidateDependencies::test_validation_fails_with_multiple_missing_services PASSED [ 32%]
tests/unit/core/test_indexing_interface.py::TestValidateDependencies::test_validation_passes_with_empty_requirements PASSED [ 32%]
tests/unit/core/test_indexing_interface.py::TestValidateDependencies::test_validation_passes_with_extra_services PASSED [ 32%]
tests/unit/core/test_pipeline.py::test_initialization PASSED             [ 32%]
tests/unit/core/test_pipeline.py::test_get_capabilities_before_execution PASSED [ 32%]
tests/unit/core/test_pipeline.py::test_index_sequential_execution PASSED [ 32%]
tests/unit/core/test_pipeline.py::test_get_capabilities_after_execution PASSED [ 32%]
tests/unit/core/test_pipeline.py::test_error_handling PASSED             [ 32%]
tests/unit/core/test_pipeline.py::test_retrieval_initialization PASSED   [ 32%]
tests/unit/core/test_pipeline.py::test_retrieval_requirements PASSED     [ 32%]
tests/unit/core/test_pipeline.py::test_retrieval_sequential_execution PASSED [ 32%]
tests/unit/core/test_pipeline.py::test_retrieval_error_handling PASSED   [ 32%]
tests/unit/core/test_retrieval_interface.py::TestRetrievalContext::test_initialization_with_database_service PASSED [ 32%]
tests/unit/core/test_retrieval_interface.py::TestRetrievalContext::test_initialization_with_config PASSED [ 32%]
tests/unit/core/test_retrieval_interface.py::TestRetrievalContext::test_metrics_tracking PASSED [ 32%]
tests/unit/core/test_retrieval_interface.py::TestIRetrievalStrategy::test_cannot_instantiate_abstract_class PASSED [ 32%]
tests/unit/core/test_retrieval_interface.py::TestIRetrievalStrategy::test_dependency_validation_on_init PASSED [ 32%]
tests/unit/core/test_retrieval_interface.py::TestIRetrievalStrategy::test_successful_initialization_with_all_dependencies PASSED [ 32%]
tests/unit/core/test_retrieval_interface.py::TestIRetrievalStrategy::test_abstract_methods_must_be_implemented PASSED [ 32%]
tests/unit/core/test_retrieval_interface.py::TestRerankingRetrieval::test_requires_capabilities PASSED [ 32%]
tests/unit/core/test_retrieval_interface.py::TestRerankingRetrieval::test_requires_services PASSED [ 33%]
tests/unit/core/test_retrieval_interface.py::TestRerankingRetrieval::test_initialization_validates_dependencies PASSED [ 33%]
tests/unit/core/test_retrieval_interface.py::TestRerankingRetrieval::test_retrieve_with_results PASSED [ 33%]
tests/unit/core/test_retrieval_interface.py::TestRerankingRetrieval::test_retrieve_with_no_candidates PASSED [ 33%]
tests/unit/core/test_retrieval_interface.py::TestRerankingRetrieval::test_retrieve_uses_default_initial_k PASSED [ 33%]
tests/unit/core/test_retrieval_interface.py::TestRerankingRetrieval::test_retrieve_uses_configured_initial_k PASSED [ 33%]
tests/unit/database/test_batch_operations.py::TestBatchOperations::test_batch_vector_insertion PASSED [ 33%]
tests/unit/database/test_batch_operations.py::TestBatchOperations::test_store_chunks_with_hierarchy FAILED [ 33%]
tests/unit/database/test_connection.py::TestDatabaseConnection::test_connection_initialization PASSED [ 33%]
tests/unit/database/test_connection.py::TestDatabaseConnection::test_connection_with_default_config PASSED [ 33%]
tests/unit/database/test_connection.py::TestDatabaseConnection::test_session_context_manager_commit PASSED [ 33%]
tests/unit/database/test_connection.py::TestDatabaseConnection::test_session_context_manager_rollback PASSED [ 33%]
tests/unit/database/test_connection.py::TestDatabaseConnection::test_health_check_success PASSED [ 33%]
tests/unit/database/test_connection.py::TestDatabaseConnection::test_health_check_failure PASSED [ 33%]
tests/unit/database/test_connection.py::TestDatabaseConnection::test_get_pool_status PASSED [ 33%]
tests/unit/database/test_connection.py::TestDatabaseConnection::test_create_tables PASSED [ 33%]
tests/unit/database/test_connection.py::TestDatabaseConnection::test_drop_tables PASSED [ 33%]
tests/unit/database/test_connection.py::TestDatabaseConnection::test_context_manager PASSED [ 33%]
tests/unit/database/test_connection.py::TestDatabaseConnection::test_multiple_sessions PASSED [ 33%]
tests/unit/database/test_connection.py::TestDatabaseConnection::test_pool_configuration PASSED [ 33%]
tests/unit/database/test_connection.py::TestDatabaseConnectionEvents::test_on_connect_event PASSED [ 33%]
tests/unit/database/test_connection.py::TestDatabaseConnectionEvents::test_on_checkout_event PASSED [ 34%]
tests/unit/database/test_migrations.py::TestAlembicMigrations::test_migration_upgrade_to_head FAILED [ 34%]
tests/unit/database/test_migrations.py::TestAlembicMigrations::test_migration_downgrade FAILED [ 34%]
tests/unit/database/test_migrations.py::TestAlembicMigrations::test_migration_history PASSED [ 34%]
tests/unit/database/test_migrations.py::TestAlembicMigrations::test_migration_idempotency FAILED [ 34%]
tests/unit/database/test_migrations.py::TestAlembicMigrations::test_get_current_version FAILED [ 34%]
tests/unit/database/test_migrations.py::TestAlembicMigrations::test_migration_creates_tables FAILED [ 34%]
tests/unit/database/test_migrations.py::TestAlembicMigrations::test_migration_creates_indexes FAILED [ 34%]
tests/unit/database/test_models.py::TestDocumentModel::test_document_model_has_required_columns PASSED [ 34%]
tests/unit/database/test_models.py::TestDocumentModel::test_document_creation PASSED [ 34%]
tests/unit/database/test_models.py::TestDocumentModel::test_document_default_values PASSED [ 34%]
tests/unit/database/test_models.py::TestDocumentModel::test_document_metadata_accepts_json PASSED [ 34%]
tests/unit/database/test_models.py::TestDocumentModel::test_document_status_values PASSED [ 34%]
tests/unit/database/test_models.py::TestDocumentModel::test_document_repr PASSED [ 34%]
tests/unit/database/test_models.py::TestDocumentModel::test_document_persistence FAILED [ 34%]
tests/unit/database/test_models.py::TestChunkModel::test_chunk_model_has_required_columns PASSED [ 34%]
tests/unit/database/test_models.py::TestChunkModel::test_chunk_creation PASSED [ 34%]
tests/unit/database/test_models.py::TestChunkModel::test_chunk_creation_with_embedding PASSED [ 34%]
tests/unit/database/test_models.py::TestChunkModel::test_chunk_default_values PASSED [ 34%]
tests/unit/database/test_models.py::TestChunkModel::test_chunk_metadata_accepts_json PASSED [ 34%]
tests/unit/database/test_models.py::TestChunkModel::test_chunk_repr PASSED [ 34%]
tests/unit/database/test_models.py::TestChunkModel::test_chunk_repr_without_embedding PASSED [ 34%]
tests/unit/database/test_models.py::TestChunkModel::test_chunk_persistence FAILED [ 35%]
tests/unit/database/test_models.py::TestModelRelationships::test_foreign_key_relationship PASSED [ 35%]
tests/unit/database/test_models.py::TestModelRelationships::test_document_chunks_relationship FAILED [ 35%]
tests/unit/database/test_models.py::TestModelRelationships::test_chunk_document_relationship FAILED [ 35%]
tests/unit/database/test_models.py::TestModelRelationships::test_cascade_delete FAILED [ 35%]
tests/unit/database/test_models.py::TestModelIndexes::test_document_indexes PASSED [ 35%]
tests/unit/database/test_models.py::TestModelIndexes::test_chunk_indexes PASSED [ 35%]
tests/unit/database/test_pgvector.py::TestPgVectorIntegration::test_cosine_similarity_search FAILED [ 35%]
tests/unit/database/test_pgvector.py::TestPgVectorIntegration::test_vector_storage_format PASSED [ 35%]
tests/unit/database/test_pgvector.py::TestPgVectorIntegration::test_empty_chunks_storage PASSED [ 35%]
tests/unit/database/test_vector_indexing.py::TestVectorIndexing::test_create_hnsw_index PASSED [ 35%]
tests/unit/database/test_vector_indexing.py::TestVectorIndexing::test_create_ivfflat_index PASSED [ 35%]
tests/unit/database/test_vector_indexing.py::TestVectorIndexing::test_drop_index PASSED [ 35%]
tests/unit/database/test_vector_indexing.py::TestVectorIndexing::test_list_indexes PASSED [ 35%]
tests/unit/documentation/test_code_examples.py::TestCodeExamples::test_all_code_examples_have_valid_syntax FAILED [ 35%]
tests/unit/documentation/test_code_examples.py::TestCodeExamples::test_strategy_examples_have_imports PASSED [ 35%]
tests/unit/documentation/test_code_examples.py::TestCodeExamples::test_configuration_examples_valid SKIPPED [ 35%]
tests/unit/documentation/test_code_examples.py::TestCodeExamples::test_quick_start_example_complete PASSED [ 35%]
tests/unit/documentation/test_code_examples.py::TestCodeExamples::test_no_placeholder_code PASSED [ 35%]
tests/unit/documentation/test_documentation_completeness.py::TestDocumentationCompleteness::test_required_doc_files_exist PASSED [ 35%]
tests/unit/documentation/test_documentation_completeness.py::TestDocumentationCompleteness::test_all_strategies_documented PASSED [ 35%]
tests/unit/documentation/test_documentation_completeness.py::TestDocumentationCompleteness::test_all_public_classes_documented PASSED [ 36%]
tests/unit/documentation/test_documentation_completeness.py::TestDocumentationCompleteness::test_all_public_methods_documented PASSED [ 36%]
tests/unit/documentation/test_documentation_completeness.py::TestDocumentationCompleteness::test_documentation_completeness_score PASSED [ 36%]
tests/unit/documentation/test_documentation_completeness.py::TestDocumentationCompleteness::test_mkdocs_config_valid PASSED [ 36%]
tests/unit/documentation/test_documentation_completeness.py::TestDocumentationCompleteness::test_readme_exists PASSED [ 36%]
tests/unit/documentation/test_documentation_completeness.py::TestDocumentationCompleteness::test_changelog_exists PASSED [ 36%]
tests/unit/documentation/test_links.py::TestDocumentationLinks::test_no_broken_internal_links FAILED [ 36%]
tests/unit/documentation/test_links.py::TestDocumentationLinks::test_all_diagrams_valid PASSED [ 36%]
tests/unit/documentation/test_links.py::TestDocumentationLinks::test_no_todo_links PASSED [ 36%]
tests/unit/documentation/test_links.py::TestDocumentationLinks::test_external_links_valid SKIPPED [ 36%]
tests/unit/evaluation/test_benchmark_suite.py::TestBenchmarkRunner::test_init_with_config PASSED [ 36%]
tests/unit/evaluation/test_benchmark_suite.py::TestBenchmarkRunner::test_init_with_metrics PASSED [ 36%]
tests/unit/evaluation/test_benchmark_suite.py::TestBenchmarkRunner::test_init_without_config_or_metrics PASSED [ 36%]
tests/unit/evaluation/test_benchmark_suite.py::TestBenchmarkRunner::test_run_benchmark_with_dataset PASSED [ 36%]
tests/unit/evaluation/test_benchmark_suite.py::TestBenchmarkRunner::test_run_benchmark_collects_metrics PASSED [ 36%]
tests/unit/evaluation/test_benchmark_suite.py::TestBenchmarkRunner::test_run_benchmark_aggregates_results PASSED [ 36%]
tests/unit/evaluation/test_benchmark_suite.py::TestBenchmarkRunner::test_compare_strategies PASSED [ 36%]
tests/unit/evaluation/test_benchmark_suite.py::TestBenchmarkRunner::test_compare_strategies_name_mismatch PASSED [ 36%]
tests/unit/evaluation/test_benchmark_suite.py::TestBenchmarkRunner::test_benchmark_error_handling PASSED [ 36%]
tests/unit/evaluation/test_benchmark_suite.py::TestBenchmarkRunner::test_save_checkpoint PASSED [ 36%]
tests/unit/evaluation/test_benchmark_suite.py::TestBenchmarkRunner::test_load_checkpoint PASSED [ 36%]
tests/unit/evaluation/test_benchmark_suite.py::TestBenchmarkRunner::test_resume_from_checkpoint PASSED [ 37%]
tests/unit/evaluation/test_benchmark_suite.py::TestBenchmarkResult::test_benchmark_result_to_dict PASSED [ 37%]
tests/unit/evaluation/test_benchmark_suite.py::TestBenchmarkResult::test_benchmark_result_save_load PASSED [ 37%]
tests/unit/evaluation/test_benchmark_suite.py::TestBenchmarkResult::test_empty_dataset_handling PASSED [ 37%]
tests/unit/evaluation/test_comparison.py::TestStrategyComparator::test_init_default_confidence PASSED [ 37%]
tests/unit/evaluation/test_comparison.py::TestStrategyComparator::test_init_custom_confidence PASSED [ 37%]
tests/unit/evaluation/test_comparison.py::TestStrategyComparator::test_compare_strategies PASSED [ 37%]
tests/unit/evaluation/test_comparison.py::TestStrategyComparator::test_compare_metric_specific PASSED [ 37%]
tests/unit/evaluation/test_comparison.py::TestStrategyComparator::test_generate_rankings PASSED [ 37%]
tests/unit/evaluation/test_comparison.py::TestStrategyComparator::test_find_best_strategy PASSED [ 37%]
tests/unit/evaluation/test_comparison.py::TestStrategyComparator::test_generate_report_table_format PASSED [ 37%]
tests/unit/evaluation/test_comparison.py::TestStrategyComparator::test_generate_report_markdown_format PASSED [ 37%]
tests/unit/evaluation/test_comparison.py::TestStrategyComparator::test_generate_report_text_format PASSED [ 37%]
tests/unit/evaluation/test_comparison.py::TestStrategyComparator::test_generate_summary_table PASSED [ 37%]
tests/unit/evaluation/test_comparison.py::TestStrategyComparator::test_comparison_with_statistical_tests PASSED [ 37%]
tests/unit/evaluation/test_comparison.py::TestStrategyComparator::test_comparison_with_baseline PASSED [ 37%]
tests/unit/evaluation/test_comparison.py::TestStrategyComparator::test_comparison_single_strategy PASSED [ 37%]
tests/unit/evaluation/test_comparison.py::TestStrategyComparator::test_comparison_missing_metrics PASSED [ 37%]
tests/unit/evaluation/test_dataset_loader.py::TestDatasetLoader::test_load_json_dataset PASSED [ 37%]
tests/unit/evaluation/test_dataset_loader.py::TestDatasetLoader::test_load_jsonl_dataset PASSED [ 37%]
tests/unit/evaluation/test_dataset_loader.py::TestDatasetLoader::test_load_csv_dataset PASSED [ 37%]
tests/unit/evaluation/test_dataset_loader.py::TestDatasetLoader::test_load_nonexistent_file PASSED [ 37%]
tests/unit/evaluation/test_dataset_loader.py::TestDatasetLoader::test_load_unsupported_format PASSED [ 38%]
tests/unit/evaluation/test_dataset_loader.py::TestDatasetLoader::test_dataset_name_override PASSED [ 38%]
tests/unit/evaluation/test_dataset_loader.py::TestDatasetLoader::test_save_and_load_json PASSED [ 38%]
tests/unit/evaluation/test_dataset_loader.py::TestDatasetLoader::test_save_and_load_jsonl PASSED [ 38%]
tests/unit/evaluation/test_dataset_loader.py::TestDatasetLoader::test_save_and_load_csv PASSED [ 38%]
tests/unit/evaluation/test_dataset_loader.py::TestEvaluationDataset::test_dataset_iteration PASSED [ 38%]
tests/unit/evaluation/test_dataset_loader.py::TestEvaluationDataset::test_dataset_indexing PASSED [ 38%]
tests/unit/evaluation/test_dataset_loader.py::TestEvaluationDataset::test_get_by_id PASSED [ 38%]
tests/unit/evaluation/test_dataset_loader.py::TestEvaluationDataset::test_dataset_split PASSED [ 38%]
tests/unit/evaluation/test_dataset_loader.py::TestEvaluationDataset::test_get_statistics PASSED [ 38%]
tests/unit/evaluation/test_export.py::TestCSVExporter::test_csv_export_summary PASSED [ 38%]
tests/unit/evaluation/test_export.py::TestCSVExporter::test_csv_export_detailed PASSED [ 38%]
tests/unit/evaluation/test_export.py::TestCSVExporter::test_csv_export_comparison PASSED [ 38%]
tests/unit/evaluation/test_export.py::TestCSVExporter::test_csv_export_comparison_custom_metrics PASSED [ 38%]
tests/unit/evaluation/test_export.py::TestCSVExporter::test_csv_export_creates_directories PASSED [ 38%]
tests/unit/evaluation/test_export.py::TestJSONExporter::test_json_export_with_details PASSED [ 38%]
tests/unit/evaluation/test_export.py::TestJSONExporter::test_json_export_without_details PASSED [ 38%]
tests/unit/evaluation/test_export.py::TestJSONExporter::test_json_export_comparison PASSED [ 38%]
tests/unit/evaluation/test_export.py::TestJSONExporter::test_json_export_indentation PASSED [ 38%]
tests/unit/evaluation/test_export.py::TestJSONExporter::test_json_export_creates_directories PASSED [ 38%]
tests/unit/evaluation/test_export.py::TestJSONExporter::test_export_file_content_validity PASSED [ 38%]
tests/unit/evaluation/test_export.py::TestJSONExporter::test_csv_field_selection PASSED [ 39%]
tests/unit/evaluation/test_retrieval_metrics.py::TestPrecisionAtK::test_perfect_precision PASSED [ 39%]
tests/unit/evaluation/test_retrieval_metrics.py::TestPrecisionAtK::test_zero_precision PASSED [ 39%]
tests/unit/evaluation/test_retrieval_metrics.py::TestPrecisionAtK::test_partial_precision PASSED [ 39%]
tests/unit/evaluation/test_retrieval_metrics.py::TestPrecisionAtK::test_fewer_retrieved_than_k PASSED [ 39%]
tests/unit/evaluation/test_retrieval_metrics.py::TestPrecisionAtK::test_invalid_k PASSED [ 39%]
tests/unit/evaluation/test_retrieval_metrics.py::TestRecallAtK::test_perfect_recall PASSED [ 39%]
tests/unit/evaluation/test_retrieval_metrics.py::TestRecallAtK::test_zero_recall PASSED [ 39%]
tests/unit/evaluation/test_retrieval_metrics.py::TestRecallAtK::test_partial_recall PASSED [ 39%]
tests/unit/evaluation/test_retrieval_metrics.py::TestRecallAtK::test_empty_relevant PASSED [ 39%]
tests/unit/evaluation/test_retrieval_metrics.py::TestMeanReciprocalRank::test_first_relevant PASSED [ 39%]
tests/unit/evaluation/test_retrieval_metrics.py::TestMeanReciprocalRank::test_third_relevant PASSED [ 39%]
tests/unit/evaluation/test_retrieval_metrics.py::TestMeanReciprocalRank::test_no_relevant_found PASSED [ 39%]
tests/unit/evaluation/test_retrieval_metrics.py::TestMeanReciprocalRank::test_multiple_relevant PASSED [ 39%]
tests/unit/evaluation/test_retrieval_metrics.py::TestNDCG::test_perfect_ranking PASSED [ 39%]
tests/unit/evaluation/test_retrieval_metrics.py::TestNDCG::test_worst_ranking PASSED [ 39%]
tests/unit/evaluation/test_retrieval_metrics.py::TestNDCG::test_no_relevant_docs PASSED [ 39%]
tests/unit/evaluation/test_retrieval_metrics.py::TestNDCG::test_partial_relevance PASSED [ 39%]
tests/unit/evaluation/test_retrieval_metrics.py::TestHitRateAtK::test_hit PASSED [ 39%]
tests/unit/evaluation/test_retrieval_metrics.py::TestHitRateAtK::test_no_hit PASSED [ 39%]
tests/unit/evaluation/test_retrieval_metrics.py::TestHitRateAtK::test_hit_outside_k PASSED [ 39%]
tests/unit/evaluation/test_retrieval_metrics.py::TestMetricProperties::test_metric_names PASSED [ 40%]
tests/unit/evaluation/test_retrieval_metrics.py::TestMetricProperties::test_higher_is_better PASSED [ 40%]
tests/unit/evaluation/test_statistical_testing.py::TestStatisticalAnalyzer::test_init_default_confidence PASSED [ 40%]
tests/unit/evaluation/test_statistical_testing.py::TestStatisticalAnalyzer::test_init_custom_confidence PASSED [ 40%]
tests/unit/evaluation/test_statistical_testing.py::TestStatisticalAnalyzer::test_init_invalid_confidence PASSED [ 40%]
tests/unit/evaluation/test_statistical_testing.py::TestStatisticalAnalyzer::test_paired_t_test_significant_difference PASSED [ 40%]
tests/unit/evaluation/test_statistical_testing.py::TestStatisticalAnalyzer::test_paired_t_test_no_difference PASSED [ 40%]
tests/unit/evaluation/test_statistical_testing.py::TestStatisticalAnalyzer::test_confidence_interval_contains_mean PASSED [ 40%]
tests/unit/evaluation/test_statistical_testing.py::TestStatisticalAnalyzer::test_confidence_interval_width PASSED [ 40%]
tests/unit/evaluation/test_statistical_testing.py::TestStatisticalAnalyzer::test_confidence_interval_single_value PASSED [ 40%]
tests/unit/evaluation/test_statistical_testing.py::TestStatisticalAnalyzer::test_bootstrap_confidence_interval PASSED [ 40%]
tests/unit/evaluation/test_statistical_testing.py::TestStatisticalAnalyzer::test_cohens_d_calculation PASSED [ 40%]
tests/unit/evaluation/test_statistical_testing.py::TestStatisticalAnalyzer::test_cohens_d_zero_difference PASSED [ 40%]
tests/unit/evaluation/test_statistical_testing.py::TestStatisticalAnalyzer::test_cohens_d_interpretation_small PASSED [ 40%]
tests/unit/evaluation/test_statistical_testing.py::TestStatisticalAnalyzer::test_cohens_d_interpretation_medium PASSED [ 40%]
tests/unit/evaluation/test_statistical_testing.py::TestStatisticalAnalyzer::test_cohens_d_interpretation_large PASSED [ 40%]
tests/unit/evaluation/test_statistical_testing.py::TestStatisticalAnalyzer::test_bonferroni_correction PASSED [ 40%]
tests/unit/evaluation/test_statistical_testing.py::TestStatisticalAnalyzer::test_bonferroni_correction_custom_comparisons PASSED [ 40%]
tests/unit/evaluation/test_statistical_testing.py::TestStatisticalAnalyzer::test_analyze_metric_comprehensive PASSED [ 40%]
tests/unit/evaluation/test_statistical_testing.py::TestStatisticalAnalyzer::test_statistical_test_result_structure PASSED [ 40%]
tests/unit/evaluation/test_statistical_testing.py::TestStatisticalAnalyzer::test_edge_case_equal_distributions PASSED [ 40%]
tests/unit/evaluation/test_statistical_testing.py::TestStatisticalAnalyzer::test_edge_case_high_variance PASSED [ 40%]
tests/unit/evaluation/test_statistical_testing.py::TestStatisticalAnalyzer::test_edge_case_small_sample PASSED [ 41%]
tests/unit/examples/test_examples_imports.py::TestExamplesImports::test_simple_example_imports_rag_factory PASSED [ 41%]
tests/unit/examples/test_examples_imports.py::TestExamplesImports::test_medium_example_imports PASSED [ 41%]
tests/unit/examples/test_examples_imports.py::TestExamplesImports::test_all_examples_import_from_rag_factory PASSED [ 41%]
tests/unit/examples/test_examples_imports.py::TestExamplesImports::test_no_relative_imports_in_examples PASSED [ 41%]
tests/unit/examples/test_examples_imports.py::TestExamplesImports::test_examples_use_absolute_imports PASSED [ 41%]
tests/unit/examples/test_examples_imports.py::TestExamplesImports::test_no_wildcard_imports PASSED [ 41%]
tests/unit/examples/test_examples_imports.py::TestExamplesImports::test_imports_are_organized PASSED [ 41%]
tests/unit/examples/test_examples_syntax.py::TestExamplesSyntax::test_all_examples_valid_syntax PASSED [ 41%]
tests/unit/examples/test_examples_syntax.py::TestExamplesSyntax::test_simple_example_exists PASSED [ 41%]
tests/unit/examples/test_examples_syntax.py::TestExamplesSyntax::test_medium_example_exists PASSED [ 41%]
tests/unit/examples/test_examples_syntax.py::TestExamplesSyntax::test_advanced_example_exists PASSED [ 41%]
tests/unit/examples/test_examples_syntax.py::TestExamplesSyntax::test_all_examples_have_docstrings PASSED [ 41%]
tests/unit/examples/test_examples_syntax.py::TestExamplesSyntax::test_all_examples_have_main_function PASSED [ 41%]
tests/unit/examples/test_examples_syntax.py::TestExamplesSyntax::test_examples_have_proper_encoding PASSED [ 41%]
tests/unit/examples/test_examples_syntax.py::TestExamplesSyntax::test_examples_not_too_long PASSED [ 41%]
tests/unit/examples/test_requirements.py::TestRequirements::test_simple_has_requirements PASSED [ 41%]
tests/unit/examples/test_requirements.py::TestRequirements::test_medium_has_requirements PASSED [ 41%]
tests/unit/examples/test_requirements.py::TestRequirements::test_advanced_has_requirements PASSED [ 41%]
tests/unit/examples/test_requirements.py::TestRequirements::test_all_example_dirs_have_requirements PASSED [ 41%]
tests/unit/examples/test_requirements.py::TestRequirements::test_requirements_have_rag_factory PASSED [ 41%]
tests/unit/examples/test_requirements.py::TestRequirements::test_requirements_are_valid_format PASSED [ 42%]
tests/unit/examples/test_requirements.py::TestRequirements::test_no_duplicate_requirements PASSED [ 42%]
tests/unit/examples/test_requirements.py::TestRequirements::test_requirements_have_versions PASSED [ 42%]
tests/unit/mocks/test_mock_builders.py::TestServiceMocks::test_create_mock_embedding_service PASSED [ 42%]
tests/unit/mocks/test_mock_builders.py::TestServiceMocks::test_create_mock_database_service PASSED [ 42%]
tests/unit/mocks/test_mock_builders.py::TestServiceMocks::test_create_mock_llm_service PASSED [ 42%]
tests/unit/mocks/test_mock_builders.py::TestServiceMocks::test_create_mock_neo4j_service PASSED [ 42%]
tests/unit/mocks/test_mock_builders.py::TestRegistryMocks::test_create_mock_registry_with_services PASSED [ 42%]
tests/unit/mocks/test_mock_builders.py::TestRegistryMocks::test_create_mock_registry_with_graph_services PASSED [ 42%]
tests/unit/mocks/test_mock_builders.py::TestDataMocks::test_create_mock_chunk PASSED [ 42%]
tests/unit/mocks/test_mock_builders.py::TestDataMocks::test_create_mock_document PASSED [ 42%]
tests/unit/mocks/test_mock_builders.py::TestFixtures::test_mock_embedding_service_fixture PASSED [ 42%]
tests/unit/mocks/test_mock_builders.py::TestFixtures::test_mock_database_service_fixture PASSED [ 42%]
tests/unit/mocks/test_mock_builders.py::TestFixtures::test_mock_llm_service_fixture PASSED [ 42%]
tests/unit/mocks/test_mock_builders.py::TestFixtures::test_mock_registry_with_services_fixture PASSED [ 42%]
tests/unit/models/embedding/test_registry.py::test_register_model PASSED [ 42%]
tests/unit/models/embedding/test_registry.py::test_register_model_overwrites_existing PASSED [ 42%]
tests/unit/models/embedding/test_registry.py::test_get_model_not_found PASSED [ 42%]
tests/unit/models/embedding/test_registry.py::test_list_models PASSED    [ 42%]
tests/unit/models/embedding/test_registry.py::test_filter_by_domain PASSED [ 42%]
tests/unit/models/embedding/test_registry.py::test_filter_by_format PASSED [ 42%]
tests/unit/models/embedding/test_registry.py::test_filter_by_tags PASSED [ 42%]
tests/unit/models/embedding/test_registry.py::test_update_metrics PASSED [ 43%]
tests/unit/models/embedding/test_registry.py::test_update_metrics_nonexistent_model PASSED [ 43%]
tests/unit/models/embedding/test_registry.py::test_search_models PASSED  [ 43%]
tests/unit/models/embedding/test_registry.py::test_search_models_by_description PASSED [ 43%]
tests/unit/models/embedding/test_registry.py::test_search_models_case_insensitive PASSED [ 43%]
tests/unit/models/embedding/test_registry.py::test_delete_model PASSED   [ 43%]
tests/unit/models/embedding/test_registry.py::test_delete_nonexistent_model PASSED [ 43%]
tests/unit/models/embedding/test_registry.py::test_registry_persistence PASSED [ 43%]
tests/unit/models/embedding/test_registry.py::test_register_multiple_versions PASSED [ 43%]
tests/unit/models/embedding/test_registry.py::test_list_models_versions PASSED [ 43%]
tests/unit/models/embedding/test_registry.py::test_delete_specific_version PASSED [ 43%]
tests/unit/models/embedding/test_registry.py::test_delete_all_versions PASSED [ 43%]
tests/unit/models/embedding/test_registry.py::test_set_health_status PASSED [ 43%]
tests/unit/models/embedding/test_registry.py::test_registry_persistence_versions PASSED [ 43%]
tests/unit/models/embedding/test_registry.py::test_empty_registry PASSED [ 43%]
tests/unit/models/evaluation/test_ab_testing.py::test_framework_initialization PASSED [ 43%]
tests/unit/models/evaluation/test_ab_testing.py::test_start_test PASSED  [ 43%]
tests/unit/models/evaluation/test_ab_testing.py::test_traffic_splitting PASSED [ 43%]
tests/unit/models/evaluation/test_ab_testing.py::test_traffic_splitting_different_ratios PASSED [ 43%]
tests/unit/models/evaluation/test_ab_testing.py::test_should_use_model_b_inactive_test PASSED [ 43%]
tests/unit/models/evaluation/test_ab_testing.py::test_record_results PASSED [ 43%]
tests/unit/models/evaluation/test_ab_testing.py::test_record_result_inactive_test PASSED [ 44%]
tests/unit/models/evaluation/test_ab_testing.py::test_analyze_test PASSED [ 44%]
tests/unit/models/evaluation/test_ab_testing.py::test_analyze_test_not_found PASSED [ 44%]
tests/unit/models/evaluation/test_ab_testing.py::test_analyze_test_insufficient_samples PASSED [ 44%]
tests/unit/models/evaluation/test_ab_testing.py::test_winner_determination_clear_winner PASSED [ 44%]
tests/unit/models/evaluation/test_ab_testing.py::test_winner_determination_no_difference PASSED [ 44%]
tests/unit/models/evaluation/test_ab_testing.py::test_gradual_rollout PASSED [ 44%]
tests/unit/models/evaluation/test_ab_testing.py::test_gradual_rollout_bounds PASSED [ 44%]
tests/unit/models/evaluation/test_ab_testing.py::test_gradual_rollout_not_found PASSED [ 44%]
tests/unit/models/evaluation/test_ab_testing.py::test_metrics_comparison_calculation PASSED [ 44%]
tests/unit/models/evaluation/test_ab_testing.py::test_confidence_intervals PASSED [ 44%]
tests/unit/observability/test_cost_calculator.py::TestModelPricing::test_model_pricing_creation PASSED [ 44%]
tests/unit/observability/test_cost_calculator.py::TestCostCalculator::test_calculator_initialization PASSED [ 44%]
tests/unit/observability/test_cost_calculator.py::TestCostCalculator::test_calculate_cost_llm PASSED [ 44%]
tests/unit/observability/test_cost_calculator.py::TestCostCalculator::test_calculate_cost_embedding PASSED [ 44%]
tests/unit/observability/test_cost_calculator.py::TestCostCalculator::test_calculate_cost_unknown_model PASSED [ 44%]
tests/unit/observability/test_cost_calculator.py::TestCostCalculator::test_calculate_rerank_cost PASSED [ 44%]
tests/unit/observability/test_cost_calculator.py::TestCostCalculator::test_calculate_rerank_cost_invalid_model PASSED [ 44%]
tests/unit/observability/test_cost_calculator.py::TestCostCalculator::test_add_custom_model PASSED [ 44%]
tests/unit/observability/test_cost_calculator.py::TestCostCalculator::test_get_model_pricing PASSED [ 44%]
tests/unit/observability/test_cost_calculator.py::TestCostCalculator::test_get_model_pricing_nonexistent PASSED [ 44%]
tests/unit/observability/test_cost_calculator.py::TestCostCalculator::test_list_available_models PASSED [ 45%]
tests/unit/observability/test_cost_calculator.py::TestCostCalculator::test_custom_pricing_override PASSED [ 45%]
tests/unit/observability/test_cost_calculator.py::TestCostCalculator::test_zero_cost_models PASSED [ 45%]
tests/unit/observability/test_cost_calculator.py::TestGetCostCalculator::test_get_calculator_singleton PASSED [ 45%]
tests/unit/observability/test_cost_calculator.py::TestGetCostCalculator::test_get_calculator_with_custom_pricing PASSED [ 45%]
tests/unit/observability/test_cost_calculator.py::TestDefaultPricing::test_default_pricing_has_common_models PASSED [ 45%]
tests/unit/observability/test_cost_calculator.py::TestDefaultPricing::test_default_pricing_structure PASSED [ 45%]
tests/unit/observability/test_filters.py::TestPIIFilter::test_filter_email PASSED [ 45%]
tests/unit/observability/test_filters.py::TestPIIFilter::test_filter_multiple_emails PASSED [ 45%]
tests/unit/observability/test_filters.py::TestPIIFilter::test_filter_phone PASSED [ 45%]
tests/unit/observability/test_filters.py::TestPIIFilter::test_filter_ssn PASSED [ 45%]
tests/unit/observability/test_filters.py::TestPIIFilter::test_filter_credit_card PASSED [ 45%]
tests/unit/observability/test_filters.py::TestPIIFilter::test_filter_credit_card_no_dashes PASSED [ 45%]
tests/unit/observability/test_filters.py::TestPIIFilter::test_filter_none_text PASSED [ 45%]
tests/unit/observability/test_filters.py::TestPIIFilter::test_filter_empty_text PASSED [ 45%]
tests/unit/observability/test_filters.py::TestPIIFilter::test_filter_dict PASSED [ 45%]
tests/unit/observability/test_filters.py::TestPIIFilter::test_filter_nested_dict PASSED [ 45%]
tests/unit/observability/test_filters.py::TestPIIFilter::test_filter_dict_with_list PASSED [ 45%]
tests/unit/observability/test_filters.py::TestPIIFilter::test_filter_preserves_non_pii PASSED [ 45%]
tests/unit/observability/test_filters.py::TestPIIFilter::test_filter_mixed_content PASSED [ 45%]
tests/unit/observability/test_filters.py::TestSamplingFilter::test_sampling_filter_initialization PASSED [ 45%]
tests/unit/observability/test_filters.py::TestSamplingFilter::test_sampling_filter_invalid_rate_too_high PASSED [ 45%]
tests/unit/observability/test_filters.py::TestSamplingFilter::test_sampling_filter_invalid_rate_negative PASSED [ 46%]
tests/unit/observability/test_filters.py::TestSamplingFilter::test_sampling_filter_100_percent PASSED [ 46%]
tests/unit/observability/test_filters.py::TestSamplingFilter::test_sampling_filter_0_percent PASSED [ 46%]
tests/unit/observability/test_filters.py::TestSamplingFilter::test_sampling_filter_50_percent PASSED [ 46%]
tests/unit/observability/test_filters.py::TestSamplingFilter::test_sampling_filter_10_percent PASSED [ 46%]
tests/unit/observability/test_logger.py::TestLogContext::test_log_context_creation PASSED [ 46%]
tests/unit/observability/test_logger.py::TestLogContext::test_elapsed_ms PASSED [ 46%]
tests/unit/observability/test_logger.py::TestRAGLogger::test_logger_initialization PASSED [ 46%]
tests/unit/observability/test_logger.py::TestRAGLogger::test_logger_with_config PASSED [ 46%]
tests/unit/observability/test_logger.py::TestRAGLogger::test_logger_with_log_file PASSED [ 46%]
tests/unit/observability/test_logger.py::TestRAGLogger::test_operation_context_success PASSED [ 46%]
tests/unit/observability/test_logger.py::TestRAGLogger::test_operation_context_failure PASSED [ 46%]
tests/unit/observability/test_logger.py::TestRAGLogger::test_operation_context_metadata PASSED [ 46%]
tests/unit/observability/test_logger.py::TestRAGLogger::test_log_query PASSED [ 46%]
tests/unit/observability/test_logger.py::TestRAGLogger::test_log_metrics PASSED [ 46%]
tests/unit/observability/test_logger.py::TestRAGLogger::test_log_error PASSED [ 46%]
tests/unit/observability/test_logger.py::TestRAGLogger::test_convenience_methods PASSED [ 46%]
tests/unit/observability/test_logger.py::TestRAGLogger::test_query_sanitization_truncation PASSED [ 46%]
tests/unit/observability/test_logger.py::TestRAGLogger::test_query_sanitization_email PASSED [ 46%]
tests/unit/observability/test_logger.py::TestRAGLogger::test_query_sanitization_phone PASSED [ 46%]
tests/unit/observability/test_logger.py::TestRAGLogger::test_query_sanitization_ssn PASSED [ 46%]
tests/unit/observability/test_logger.py::TestRAGLogger::test_query_sanitization_none PASSED [ 47%]
tests/unit/observability/test_logger.py::TestGetLogger::test_get_logger_singleton PASSED [ 47%]
tests/unit/observability/test_logger.py::TestGetLogger::test_get_logger_with_config PASSED [ 47%]
tests/unit/observability/test_logger.py::TestLogLevel::test_log_level_values PASSED [ 47%]
tests/unit/observability/test_metrics_collector.py::TestMetricPoint::test_metric_point_creation PASSED [ 47%]
tests/unit/observability/test_metrics_collector.py::TestPerformanceMetrics::test_performance_metrics_creation PASSED [ 47%]
tests/unit/observability/test_metrics_collector.py::TestPerformanceMetrics::test_avg_latency_calculation PASSED [ 47%]
tests/unit/observability/test_metrics_collector.py::TestPerformanceMetrics::test_avg_latency_no_queries PASSED [ 47%]
tests/unit/observability/test_metrics_collector.py::TestPerformanceMetrics::test_success_rate_calculation PASSED [ 47%]
tests/unit/observability/test_metrics_collector.py::TestPerformanceMetrics::test_success_rate_no_queries PASSED [ 47%]
tests/unit/observability/test_metrics_collector.py::TestPerformanceMetrics::test_failure_rate_calculation PASSED [ 47%]
tests/unit/observability/test_metrics_collector.py::TestPerformanceMetrics::test_latency_percentiles PASSED [ 47%]
tests/unit/observability/test_metrics_collector.py::TestPerformanceMetrics::test_percentile_single_value PASSED [ 47%]
tests/unit/observability/test_metrics_collector.py::TestPerformanceMetrics::test_percentile_no_values PASSED [ 47%]
tests/unit/observability/test_metrics_collector.py::TestMetricsCollector::test_collector_initialization PASSED [ 47%]
tests/unit/observability/test_metrics_collector.py::TestMetricsCollector::test_record_successful_query PASSED [ 47%]
tests/unit/observability/test_metrics_collector.py::TestMetricsCollector::test_record_failed_query PASSED [ 47%]
tests/unit/observability/test_metrics_collector.py::TestMetricsCollector::test_multiple_queries PASSED [ 47%]
tests/unit/observability/test_metrics_collector.py::TestMetricsCollector::test_success_rate_calculation PASSED [ 47%]
tests/unit/observability/test_metrics_collector.py::TestMetricsCollector::test_multiple_strategies PASSED [ 47%]
tests/unit/observability/test_metrics_collector.py::TestMetricsCollector::test_get_metrics_nonexistent_strategy PASSED [ 47%]
tests/unit/observability/test_metrics_collector.py::TestMetricsCollector::test_get_summary PASSED [ 48%]
tests/unit/observability/test_metrics_collector.py::TestMetricsCollector::test_get_strategy_names PASSED [ 48%]
tests/unit/observability/test_metrics_collector.py::TestMetricsCollector::test_reset_specific_strategy PASSED [ 48%]
tests/unit/observability/test_metrics_collector.py::TestMetricsCollector::test_reset_all_metrics PASSED [ 48%]
tests/unit/observability/test_metrics_collector.py::TestMetricsCollector::test_time_series_recording PASSED [ 48%]
tests/unit/observability/test_metrics_collector.py::TestMetricsCollector::test_time_series_time_window PASSED [ 48%]
tests/unit/observability/test_metrics_collector.py::TestMetricsCollector::test_time_series_nonexistent_metric PASSED [ 48%]
tests/unit/observability/test_metrics_collector.py::TestMetricsCollector::test_thread_safety PASSED [ 48%]
tests/unit/observability/test_metrics_collector.py::TestMetricsCollector::test_error_tracking PASSED [ 48%]
tests/unit/observability/test_metrics_collector.py::TestGetCollector::test_get_collector_singleton PASSED [ 48%]
tests/unit/observability/test_metrics_collector.py::TestGetCollector::test_get_collector_persistence PASSED [ 48%]
tests/unit/observability/test_performance_monitor.py::TestPerformanceSnapshot::test_performance_snapshot_creation PASSED [ 48%]
tests/unit/observability/test_performance_monitor.py::TestPerformanceMonitor::test_monitor_initialization PASSED [ 48%]
tests/unit/observability/test_performance_monitor.py::TestPerformanceMonitor::test_track_operation PASSED [ 48%]
tests/unit/observability/test_performance_monitor.py::TestPerformanceMonitor::test_track_multiple_executions PASSED [ 48%]
tests/unit/observability/test_performance_monitor.py::TestPerformanceMonitor::test_track_multiple_operations PASSED [ 48%]
tests/unit/observability/test_performance_monitor.py::TestPerformanceMonitor::test_get_stats_nonexistent PASSED [ 48%]
tests/unit/observability/test_performance_monitor.py::TestPerformanceMonitor::test_stats_calculation PASSED [ 48%]
tests/unit/observability/test_performance_monitor.py::TestPerformanceMonitor::test_reset_specific_operation PASSED [ 48%]
tests/unit/observability/test_performance_monitor.py::TestPerformanceMonitor::test_reset_all PASSED [ 48%]
tests/unit/observability/test_performance_monitor.py::TestPerformanceMonitor::test_get_current_system_stats PASSED [ 48%]
tests/unit/observability/test_performance_monitor.py::TestPerformanceMonitor::test_track_with_exception PASSED [ 48%]
tests/unit/observability/test_performance_monitor.py::TestGetPerformanceMonitor::test_get_monitor_singleton PASSED [ 49%]
tests/unit/observability/test_performance_monitor.py::TestGetPerformanceMonitor::test_get_monitor_persistence PASSED [ 49%]
tests/unit/registry/test_exceptions.py::test_service_registry_error PASSED [ 49%]
tests/unit/registry/test_exceptions.py::test_service_not_found_error PASSED [ 49%]
tests/unit/registry/test_exceptions.py::test_service_instantiation_error PASSED [ 49%]
tests/unit/registry/test_service_factory.py::TestServiceTypeDetection::test_is_llm_service PASSED [ 49%]
tests/unit/registry/test_service_factory.py::TestServiceTypeDetection::test_is_llm_service_missing_url PASSED [ 49%]
tests/unit/registry/test_service_factory.py::TestServiceTypeDetection::test_is_llm_service_missing_model PASSED [ 49%]
tests/unit/registry/test_service_factory.py::TestServiceTypeDetection::test_is_embedding_service PASSED [ 49%]
tests/unit/registry/test_service_factory.py::TestServiceTypeDetection::test_is_embedding_service_missing_provider PASSED [ 49%]
tests/unit/registry/test_service_factory.py::TestServiceTypeDetection::test_is_database_service_postgres PASSED [ 49%]
tests/unit/registry/test_service_factory.py::TestServiceTypeDetection::test_is_database_service_neo4j PASSED [ 49%]
tests/unit/registry/test_service_factory.py::TestServiceTypeDetection::test_is_database_service_unknown_type PASSED [ 49%]
tests/unit/registry/test_service_factory.py::TestLLMServiceCreation::test_create_llm_service_openai FAILED [ 49%]
tests/unit/registry/test_service_factory.py::TestLLMServiceCreation::test_create_llm_service_lm_studio PASSED [ 49%]
tests/unit/registry/test_service_factory.py::TestLLMServiceCreation::test_create_llm_service_with_defaults PASSED [ 49%]
tests/unit/registry/test_service_factory.py::TestEmbeddingServiceCreation::test_create_embedding_service_onnx FAILED [ 49%]
tests/unit/registry/test_service_factory.py::TestEmbeddingServiceCreation::test_create_embedding_service_onnx_with_defaults FAILED [ 49%]
tests/unit/registry/test_service_factory.py::TestEmbeddingServiceCreation::test_create_embedding_service_openai FAILED [ 49%]
tests/unit/registry/test_service_factory.py::TestEmbeddingServiceCreation::test_create_embedding_service_cohere_not_implemented PASSED [ 49%]
tests/unit/registry/test_service_factory.py::TestEmbeddingServiceCreation::test_create_embedding_service_unknown_provider PASSED [ 49%]
tests/unit/registry/test_service_factory.py::TestDatabaseServiceCreation::test_create_database_service_postgres_with_connection_string FAILED [ 50%]
tests/unit/registry/test_service_factory.py::TestDatabaseServiceCreation::test_create_database_service_postgres_with_components FAILED [ 50%]
tests/unit/registry/test_service_factory.py::TestDatabaseServiceCreation::test_create_database_service_postgres_with_defaults FAILED [ 50%]
tests/unit/registry/test_service_factory.py::TestDatabaseServiceCreation::test_create_database_service_neo4j FAILED [ 50%]
tests/unit/registry/test_service_factory.py::TestDatabaseServiceCreation::test_create_database_service_neo4j_with_defaults FAILED [ 50%]
tests/unit/registry/test_service_factory.py::TestDatabaseServiceCreation::test_create_database_service_unknown_type PASSED [ 50%]
tests/unit/registry/test_service_factory.py::TestServiceCreation::test_create_service_llm PASSED [ 50%]
tests/unit/registry/test_service_factory.py::TestServiceCreation::test_create_service_embedding PASSED [ 50%]
tests/unit/registry/test_service_factory.py::TestServiceCreation::test_create_service_database PASSED [ 50%]
tests/unit/registry/test_service_factory.py::TestServiceCreation::test_create_service_unknown_type PASSED [ 50%]
tests/unit/registry/test_service_registry.py::TestServiceRegistryInitialization::test_registry_initialization PASSED [ 50%]
tests/unit/registry/test_service_registry.py::TestServiceRegistryInitialization::test_registry_initialization_file_not_found PASSED [ 50%]
tests/unit/registry/test_service_registry.py::TestServiceRegistryInitialization::test_registry_initialization_invalid_yaml PASSED [ 50%]
tests/unit/registry/test_service_registry.py::TestServiceRegistryInitialization::test_registry_loads_and_validates_config PASSED [ 50%]
tests/unit/registry/test_service_registry.py::TestServiceRegistryInitialization::test_registry_resolves_environment_variables PASSED [ 50%]
tests/unit/registry/test_service_registry.py::TestServiceLookup::test_list_services PASSED [ 50%]
tests/unit/registry/test_service_registry.py::TestServiceLookup::test_list_services_empty_registry PASSED [ 50%]
tests/unit/registry/test_service_registry.py::TestServiceLookup::test_get_service_creates_instance PASSED [ 50%]
tests/unit/registry/test_service_registry.py::TestServiceLookup::test_get_service_caches_instance PASSED [ 50%]
tests/unit/registry/test_service_registry.py::TestServiceLookup::test_get_service_with_dollar_prefix PASSED [ 50%]
tests/unit/registry/test_service_registry.py::TestServiceLookup::test_get_service_strips_dollar_prefix PASSED [ 50%]
tests/unit/registry/test_service_registry.py::TestServiceLookup::test_get_nonexistent_service_raises_error PASSED [ 51%]
tests/unit/registry/test_service_registry.py::TestServiceLookup::test_get_service_from_empty_registry PASSED [ 51%]
tests/unit/registry/test_service_registry.py::TestServiceLookup::test_get_service_instantiation_failure PASSED [ 51%]
tests/unit/registry/test_service_registry.py::TestServiceLifecycle::test_reload_service PASSED [ 51%]
tests/unit/registry/test_service_registry.py::TestServiceLifecycle::test_reload_service_without_close_method PASSED [ 51%]
tests/unit/registry/test_service_registry.py::TestServiceLifecycle::test_reload_service_with_dollar_prefix PASSED [ 51%]
tests/unit/registry/test_service_registry.py::TestServiceLifecycle::test_reload_nonexistent_service PASSED [ 51%]
tests/unit/registry/test_service_registry.py::TestServiceLifecycle::test_shutdown_closes_all_services PASSED [ 51%]
tests/unit/registry/test_service_registry.py::TestServiceLifecycle::test_shutdown_handles_close_errors PASSED [ 51%]
tests/unit/registry/test_service_registry.py::TestServiceLifecycle::test_shutdown_skips_services_without_close PASSED [ 51%]
tests/unit/registry/test_service_registry.py::TestContextManager::test_context_manager PASSED [ 51%]
tests/unit/registry/test_service_registry.py::TestContextManager::test_context_manager_with_exception PASSED [ 51%]
tests/unit/registry/test_service_registry.py::TestContextManager::test_context_manager_usage PASSED [ 51%]
tests/unit/registry/test_service_registry.py::TestThreadSafety::test_double_check_locking PASSED [ 51%]
tests/unit/registry/test_service_registry.py::TestThreadSafety::test_per_service_locks PASSED [ 51%]
tests/unit/registry/test_threading.py::TestConcurrentServiceAccess::test_concurrent_service_access_creates_single_instance PASSED [ 51%]
tests/unit/registry/test_threading.py::TestConcurrentServiceAccess::test_concurrent_service_access_returns_same_instance PASSED [ 51%]
tests/unit/registry/test_threading.py::TestConcurrentServiceAccess::test_concurrent_access_with_slow_instantiation PASSED [ 51%]
tests/unit/registry/test_threading.py::TestConcurrentDifferentServices::test_concurrent_different_services PASSED [ 51%]
tests/unit/registry/test_threading.py::TestConcurrentDifferentServices::test_concurrent_different_services_independent_locks PASSED [ 51%]
tests/unit/registry/test_threading.py::TestConcurrentReload::test_reload_while_getting_service PASSED [ 51%]
tests/unit/registry/test_threading.py::TestConcurrentShutdown::test_shutdown_while_getting_services PASSED [ 51%]
tests/unit/registry/test_threading.py::TestRaceConditions::test_no_duplicate_instantiation_race PASSED [ 52%]
tests/unit/registry/test_threading.py::TestRaceConditions::test_cache_consistency_under_load PASSED [ 52%]
tests/unit/repositories/test_chunk_repository.py::TestChunkRepositoryCreate::test_create_chunk_success PASSED [ 52%]
tests/unit/repositories/test_chunk_repository.py::TestChunkRepositoryCreate::test_create_chunk_with_embedding PASSED [ 52%]
tests/unit/repositories/test_chunk_repository.py::TestChunkRepositoryCreate::test_create_chunk_with_metadata PASSED [ 52%]
tests/unit/repositories/test_chunk_repository.py::TestChunkRepositoryCreate::test_create_chunk_database_error PASSED [ 52%]
tests/unit/repositories/test_chunk_repository.py::TestChunkRepositoryCreate::test_bulk_create_chunks PASSED [ 52%]
tests/unit/repositories/test_chunk_repository.py::TestChunkRepositoryCreate::test_bulk_create_database_error PASSED [ 52%]
tests/unit/repositories/test_chunk_repository.py::TestChunkRepositoryRead::test_get_by_id_found PASSED [ 52%]
tests/unit/repositories/test_chunk_repository.py::TestChunkRepositoryRead::test_get_by_id_not_found PASSED [ 52%]
tests/unit/repositories/test_chunk_repository.py::TestChunkRepositoryRead::test_get_by_id_database_error PASSED [ 52%]
tests/unit/repositories/test_chunk_repository.py::TestChunkRepositoryRead::test_get_by_document PASSED [ 52%]
tests/unit/repositories/test_chunk_repository.py::TestChunkRepositoryRead::test_count_by_document PASSED [ 52%]
tests/unit/repositories/test_chunk_repository.py::TestChunkRepositoryUpdate::test_update_chunk_success PASSED [ 52%]
tests/unit/repositories/test_chunk_repository.py::TestChunkRepositoryUpdate::test_update_chunk_not_found PASSED [ 52%]
tests/unit/repositories/test_chunk_repository.py::TestChunkRepositoryUpdate::test_update_embedding PASSED [ 52%]
tests/unit/repositories/test_chunk_repository.py::TestChunkRepositoryUpdate::test_update_embedding_not_found PASSED [ 52%]
tests/unit/repositories/test_chunk_repository.py::TestChunkRepositoryUpdate::test_bulk_update_embeddings PASSED [ 52%]
tests/unit/repositories/test_chunk_repository.py::TestChunkRepositoryUpdate::test_bulk_update_embeddings_database_error PASSED [ 52%]
tests/unit/repositories/test_chunk_repository.py::TestChunkRepositoryDelete::test_delete_chunk_success PASSED [ 52%]
tests/unit/repositories/test_chunk_repository.py::TestChunkRepositoryDelete::test_delete_chunk_not_found PASSED [ 52%]
tests/unit/repositories/test_chunk_repository.py::TestChunkRepositoryDelete::test_delete_by_document PASSED [ 53%]
tests/unit/repositories/test_chunk_repository.py::TestChunkRepositoryDelete::test_delete_database_error PASSED [ 53%]
tests/unit/repositories/test_chunk_repository.py::TestChunkRepositoryVectorSearch::test_search_similar_validation_empty_embedding PASSED [ 53%]
tests/unit/repositories/test_chunk_repository.py::TestChunkRepositoryVectorSearch::test_search_similar_validation_invalid_top_k PASSED [ 53%]
tests/unit/repositories/test_chunk_repository.py::TestChunkRepositoryVectorSearch::test_search_similar_success PASSED [ 53%]
tests/unit/repositories/test_chunk_repository.py::TestChunkRepositoryVectorSearch::test_search_similar_with_threshold PASSED [ 53%]
tests/unit/repositories/test_chunk_repository.py::TestChunkRepositoryVectorSearch::test_search_similar_database_error PASSED [ 53%]
tests/unit/repositories/test_chunk_repository.py::TestChunkRepositoryVectorSearch::test_search_similar_with_filter_validation PASSED [ 53%]
tests/unit/repositories/test_chunk_repository.py::TestChunkRepositoryVectorSearch::test_search_similar_with_filter_success PASSED [ 53%]
tests/unit/repositories/test_chunk_repository.py::TestChunkRepositoryVectorSearch::test_search_similar_with_metadata_success PASSED [ 53%]
tests/unit/repositories/test_chunk_repository.py::TestChunkRepositoryVectorSearch::test_search_similar_with_metadata_validation PASSED [ 53%]
tests/unit/repositories/test_chunk_repository.py::TestChunkRepositoryEdgeCases::test_create_chunk_without_embedding PASSED [ 53%]
tests/unit/repositories/test_chunk_repository.py::TestChunkRepositoryEdgeCases::test_update_with_metadata_attribute PASSED [ 53%]
tests/unit/repositories/test_document_repository.py::TestDocumentRepositoryCreate::test_create_document_success PASSED [ 53%]
tests/unit/repositories/test_document_repository.py::TestDocumentRepositoryCreate::test_create_document_with_metadata PASSED [ 53%]
tests/unit/repositories/test_document_repository.py::TestDocumentRepositoryCreate::test_create_document_duplicate_raises_error PASSED [ 53%]
tests/unit/repositories/test_document_repository.py::TestDocumentRepositoryCreate::test_create_document_database_error PASSED [ 53%]
tests/unit/repositories/test_document_repository.py::TestDocumentRepositoryRead::test_get_by_id_found PASSED [ 53%]
tests/unit/repositories/test_document_repository.py::TestDocumentRepositoryRead::test_get_by_id_not_found PASSED [ 53%]
tests/unit/repositories/test_document_repository.py::TestDocumentRepositoryRead::test_get_by_id_database_error PASSED [ 53%]
tests/unit/repositories/test_document_repository.py::TestDocumentRepositoryRead::test_get_by_content_hash_found PASSED [ 53%]
tests/unit/repositories/test_document_repository.py::TestDocumentRepositoryRead::test_list_all_with_pagination PASSED [ 54%]
tests/unit/repositories/test_document_repository.py::TestDocumentRepositoryRead::test_count_documents PASSED [ 54%]
tests/unit/repositories/test_document_repository.py::TestDocumentRepositoryRead::test_get_by_status PASSED [ 54%]
tests/unit/repositories/test_document_repository.py::TestDocumentRepositoryUpdate::test_update_document_success PASSED [ 54%]
tests/unit/repositories/test_document_repository.py::TestDocumentRepositoryUpdate::test_update_document_not_found PASSED [ 54%]
tests/unit/repositories/test_document_repository.py::TestDocumentRepositoryUpdate::test_update_status PASSED [ 54%]
tests/unit/repositories/test_document_repository.py::TestDocumentRepositoryUpdate::test_update_metadata PASSED [ 54%]
tests/unit/repositories/test_document_repository.py::TestDocumentRepositoryUpdate::test_update_database_error PASSED [ 54%]
tests/unit/repositories/test_document_repository.py::TestDocumentRepositoryDelete::test_delete_document_success PASSED [ 54%]
tests/unit/repositories/test_document_repository.py::TestDocumentRepositoryDelete::test_delete_document_not_found PASSED [ 54%]
tests/unit/repositories/test_document_repository.py::TestDocumentRepositoryDelete::test_delete_database_error PASSED [ 54%]
tests/unit/repositories/test_document_repository.py::TestDocumentRepositoryDelete::test_bulk_delete_documents PASSED [ 54%]
tests/unit/repositories/test_document_repository.py::TestDocumentRepositoryBulkOperations::test_bulk_create_documents PASSED [ 54%]
tests/unit/repositories/test_document_repository.py::TestDocumentRepositoryBulkOperations::test_bulk_create_database_error PASSED [ 54%]
tests/unit/repositories/test_document_repository.py::TestDocumentRepositoryTransactions::test_commit_success PASSED [ 54%]
tests/unit/repositories/test_document_repository.py::TestDocumentRepositoryTransactions::test_commit_failure_triggers_rollback PASSED [ 54%]
tests/unit/repositories/test_document_repository.py::TestDocumentRepositoryTransactions::test_rollback PASSED [ 54%]
tests/unit/repositories/test_exceptions.py::TestRepositoryError::test_repository_error_message PASSED [ 54%]
tests/unit/repositories/test_exceptions.py::TestRepositoryError::test_repository_error_inheritance PASSED [ 54%]
tests/unit/repositories/test_exceptions.py::TestEntityNotFoundError::test_entity_not_found_attributes PASSED [ 54%]
tests/unit/repositories/test_exceptions.py::TestEntityNotFoundError::test_entity_not_found_message PASSED [ 54%]
tests/unit/repositories/test_exceptions.py::TestEntityNotFoundError::test_entity_not_found_inheritance PASSED [ 54%]
tests/unit/repositories/test_exceptions.py::TestDuplicateEntityError::test_duplicate_entity_attributes PASSED [ 55%]
tests/unit/repositories/test_exceptions.py::TestDuplicateEntityError::test_duplicate_entity_message PASSED [ 55%]
tests/unit/repositories/test_exceptions.py::TestDuplicateEntityError::test_duplicate_entity_inheritance PASSED [ 55%]
tests/unit/repositories/test_exceptions.py::TestDatabaseConnectionError::test_database_connection_error_message PASSED [ 55%]
tests/unit/repositories/test_exceptions.py::TestDatabaseConnectionError::test_database_connection_error_inheritance PASSED [ 55%]
tests/unit/repositories/test_exceptions.py::TestInvalidQueryError::test_invalid_query_error_message PASSED [ 55%]
tests/unit/repositories/test_exceptions.py::TestInvalidQueryError::test_invalid_query_error_inheritance PASSED [ 55%]
tests/unit/services/database/test_database_context.py::TestDatabaseContextInitialization::test_initialization_with_all_parameters PASSED [ 55%]
tests/unit/services/database/test_database_context.py::TestDatabaseContextInitialization::test_initialization_without_field_mapping PASSED [ 55%]
tests/unit/services/database/test_database_context.py::TestDatabaseContextInitialization::test_field_mapping_passthrough PASSED [ 55%]
tests/unit/services/database/test_database_context.py::TestTableMapping::test_get_table_unmapped_logical_name_raises_error PASSED [ 55%]
tests/unit/services/database/test_database_context.py::TestTableMapping::test_get_table_caches_reflected_tables PASSED [ 55%]
tests/unit/services/database/test_database_context.py::TestFieldMapping::test_map_field_with_mapping PASSED [ 55%]
tests/unit/services/database/test_database_context.py::TestFieldMapping::test_map_field_without_mapping PASSED [ 55%]
tests/unit/services/database/test_database_context.py::TestFieldMapping::test_map_field_with_empty_mapping PASSED [ 55%]
tests/unit/services/database/test_database_context.py::TestContextIsolation::test_different_contexts_have_different_mappings PASSED [ 55%]
tests/unit/services/database/test_database_context.py::TestContextIsolation::test_contexts_share_same_engine PASSED [ 55%]
tests/unit/services/database/test_database_context.py::TestContextIsolation::test_contexts_have_independent_reflection_cache PASSED [ 55%]
tests/unit/services/database/test_database_context_crud.py::TestInsertOperation::test_insert_with_field_mapping PASSED [ 55%]
tests/unit/services/database/test_database_context_crud.py::TestInsertOperation::test_insert_without_field_mapping PASSED [ 55%]
tests/unit/services/database/test_database_context_crud.py::TestInsertOperation::test_insert_multiple_rows PASSED [ 55%]
tests/unit/services/database/test_database_context_crud.py::TestQueryOperation::test_query_all_rows PASSED [ 56%]
tests/unit/services/database/test_database_context_crud.py::TestQueryOperation::test_query_with_filter PASSED [ 56%]
tests/unit/services/database/test_database_context_crud.py::TestQueryOperation::test_query_with_multiple_filters PASSED [ 56%]
tests/unit/services/database/test_database_context_crud.py::TestQueryOperation::test_query_with_limit PASSED [ 56%]
tests/unit/services/database/test_database_context_crud.py::TestQueryOperation::test_query_empty_result PASSED [ 56%]
tests/unit/services/database/test_database_context_crud.py::TestUpdateOperation::test_update_with_mapping PASSED [ 56%]
tests/unit/services/database/test_database_context_crud.py::TestUpdateOperation::test_update_multiple_rows PASSED [ 56%]
tests/unit/services/database/test_database_context_crud.py::TestUpdateOperation::test_update_multiple_fields PASSED [ 56%]
tests/unit/services/database/test_database_context_crud.py::TestDeleteOperation::test_delete_with_mapping PASSED [ 56%]
tests/unit/services/database/test_database_context_crud.py::TestDeleteOperation::test_delete_multiple_rows PASSED [ 56%]
tests/unit/services/database/test_database_context_crud.py::TestDeleteOperation::test_delete_with_specific_filter PASSED [ 56%]
tests/unit/services/database/test_database_context_crud.py::TestCRUDIntegration::test_full_crud_cycle PASSED [ 56%]
tests/unit/services/database/test_database_context_vector.py::TestVectorSearchErrorHandling::test_invalid_distance_metric_raises_error PASSED [ 56%]
tests/unit/services/database/test_database_context_vector.py::TestVectorSearchWithPostgreSQL::test_vector_search_cosine_distance SKIPPED [ 56%]
tests/unit/services/database/test_database_context_vector.py::TestVectorSearchWithPostgreSQL::test_vector_search_l2_distance SKIPPED [ 56%]
tests/unit/services/database/test_database_context_vector.py::TestVectorSearchWithPostgreSQL::test_vector_search_inner_product SKIPPED [ 56%]
tests/unit/services/database/test_database_context_vector.py::TestVectorSearchWithPostgreSQL::test_vector_search_top_k_limit SKIPPED [ 56%]
tests/unit/services/database/test_database_context_vector.py::TestVectorSearchWithPostgreSQL::test_vector_search_with_field_mapping SKIPPED [ 56%]
tests/unit/services/database/test_database_context_vector.py::TestVectorSearchWithPostgreSQL::test_vector_search_empty_table SKIPPED [ 56%]
tests/unit/services/database/test_database_context_vector.py::TestVectorSearchMocking::test_vector_search_uses_correct_distance_function PASSED [ 56%]
tests/unit/services/database/test_migration_validator.py::TestMigrationValidator::test_init_with_config_path PASSED [ 56%]
tests/unit/services/database/test_migration_validator.py::TestMigrationValidator::test_init_without_config_path PASSED [ 57%]
tests/unit/services/database/test_migration_validator.py::TestMigrationValidator::test_find_alembic_config_success PASSED [ 57%]
tests/unit/services/database/test_migration_validator.py::TestMigrationValidator::test_find_alembic_config_not_found PASSED [ 57%]
tests/unit/services/database/test_migration_validator.py::TestMigrationValidator::test_validate_all_migrations_applied PASSED [ 57%]
tests/unit/services/database/test_migration_validator.py::TestMigrationValidator::test_validate_missing_migrations PASSED [ 57%]
tests/unit/services/database/test_migration_validator.py::TestMigrationValidator::test_validate_no_migrations_applied PASSED [ 57%]
tests/unit/services/database/test_migration_validator.py::TestMigrationValidator::test_validate_or_raise_success PASSED [ 57%]
tests/unit/services/database/test_migration_validator.py::TestMigrationValidator::test_validate_or_raise_failure PASSED [ 57%]
tests/unit/services/database/test_migration_validator.py::TestMigrationValidator::test_build_error_message PASSED [ 57%]
tests/unit/services/database/test_migration_validator.py::TestMigrationValidator::test_build_error_message_empty PASSED [ 57%]
tests/unit/services/database/test_migration_validator.py::TestMigrationValidator::test_get_current_revision_success PASSED [ 57%]
tests/unit/services/database/test_migration_validator.py::TestMigrationValidator::test_get_current_revision_no_table PASSED [ 57%]
tests/unit/services/database/test_migration_validator.py::TestMigrationValidator::test_get_current_revision_programming_error PASSED [ 57%]
tests/unit/services/database/test_migration_validator.py::TestMigrationValidator::test_get_applied_revisions PASSED [ 57%]
tests/unit/services/database/test_migration_validator.py::TestMigrationValidator::test_get_current_revision_public_method PASSED [ 57%]
tests/unit/services/database/test_migration_validator.py::TestMigrationValidator::test_get_all_revisions PASSED [ 57%]
tests/unit/services/database/test_migration_validator.py::TestMigrationValidator::test_get_all_revisions_no_head PASSED [ 57%]
tests/unit/services/database/test_migration_validator.py::TestMigrationValidator::test_is_at_head_true PASSED [ 57%]
tests/unit/services/database/test_migration_validator.py::TestMigrationValidator::test_is_at_head_false PASSED [ 57%]
tests/unit/services/database/test_migration_validator.py::TestMigrationValidator::test_is_at_head_no_migrations PASSED [ 57%]
tests/unit/services/database/test_migration_validator.py::TestMigrationValidator::test_migration_validation_error_attributes PASSED [ 57%]
tests/unit/services/database/test_migration_validator.py::TestMigrationValidatorIntegration::test_full_validation_workflow PASSED [ 57%]
tests/unit/services/database/test_postgres_service_context.py::TestGetContextMethod::test_get_context_creates_context_with_mappings PASSED [ 58%]
tests/unit/services/database/test_postgres_service_context.py::TestGetContextMethod::test_get_context_without_field_mapping PASSED [ 58%]
tests/unit/services/database/test_postgres_service_context.py::TestGetContextMethod::test_get_context_caches_contexts PASSED [ 58%]
tests/unit/services/database/test_postgres_service_context.py::TestGetContextMethod::test_get_context_different_mappings_create_different_contexts PASSED [ 58%]
tests/unit/services/database/test_postgres_service_context.py::TestGetContextMethod::test_get_context_shares_engine_across_contexts PASSED [ 58%]
tests/unit/services/database/test_postgres_service_context.py::TestSyncEngineCreation::test_sync_engine_created_with_correct_connection_string PASSED [ 58%]
tests/unit/services/database/test_postgres_service_context.py::TestSyncEngineCreation::test_sync_engine_created_with_connection_pooling PASSED [ 58%]
tests/unit/services/database/test_postgres_service_context.py::TestSyncEngineCreation::test_sync_engine_created_without_password PASSED [ 58%]
tests/unit/services/database/test_postgres_service_context.py::TestSyncEngineCreation::test_sync_engine_reused_across_calls PASSED [ 58%]
tests/unit/services/database/test_postgres_service_context.py::TestSyncEngineCreation::test_get_context_raises_error_when_sqlalchemy_not_available PASSED [ 58%]
tests/unit/services/database/test_postgres_service_context.py::TestContextCleanup::test_close_disposes_sync_engine PASSED [ 58%]
tests/unit/services/database/test_postgres_service_context.py::TestContextCleanup::test_close_clears_context_cache PASSED [ 58%]
tests/unit/services/database/test_postgres_service_context.py::TestContextCleanup::test_close_handles_no_engine_gracefully PASSED [ 58%]
tests/unit/services/database/test_postgres_service_context.py::TestContextCacheKeyGeneration::test_same_mappings_generate_same_cache_key PASSED [ 58%]
tests/unit/services/database/test_postgres_service_context.py::TestContextCacheKeyGeneration::test_different_table_mappings_generate_different_keys PASSED [ 58%]
tests/unit/services/database/test_postgres_service_context.py::TestContextCacheKeyGeneration::test_different_field_mappings_generate_different_keys PASSED [ 58%]
tests/unit/services/database/test_postgres_service_context.py::TestContextCacheKeyGeneration::test_none_field_mapping_vs_empty_dict PASSED [ 58%]
tests/unit/services/embedding/test_cache.py::test_cache_set_and_get PASSED [ 58%]
tests/unit/services/embedding/test_cache.py::test_cache_miss PASSED      [ 58%]
tests/unit/services/embedding/test_cache.py::test_cache_expiration PASSED [ 58%]
tests/unit/services/embedding/test_cache.py::test_cache_max_size PASSED  [ 58%]
tests/unit/services/embedding/test_cache.py::test_cache_lru_eviction PASSED [ 59%]
tests/unit/services/embedding/test_cache.py::test_cache_clear PASSED     [ 59%]
tests/unit/services/embedding/test_cache.py::test_cache_stats PASSED     [ 59%]
tests/unit/services/embedding/test_cache.py::test_cache_thread_safety PASSED [ 59%]
tests/unit/services/embedding/test_cache.py::test_cache_update_existing_key PASSED [ 59%]
tests/unit/services/embedding/test_cache.py::test_cache_large_embeddings PASSED [ 59%]
tests/unit/services/embedding/test_onnx_local_provider.py::test_provider_not_available_raises_error PASSED [ 59%]
tests/unit/services/embedding/test_onnx_local_provider.py::test_provider_initialization PASSED [ 59%]
tests/unit/services/embedding/test_onnx_local_provider.py::test_get_embeddings PASSED [ 59%]
tests/unit/services/embedding/test_onnx_local_provider.py::test_calculate_cost_is_zero FAILED [ 59%]
tests/unit/services/embedding/test_onnx_local_provider.py::test_known_model_dimensions PASSED [ 59%]
tests/unit/services/embedding/test_onnx_local_provider.py::test_unknown_model_uses_output_shape PASSED [ 59%]
tests/unit/services/embedding/test_onnx_local_provider.py::test_custom_batch_size PASSED [ 59%]
tests/unit/services/embedding/test_onnx_local_provider.py::test_model_loading_failure PASSED [ 59%]
tests/unit/services/embedding/test_onnx_local_provider.py::test_get_model_name PASSED [ 59%]
tests/unit/services/embedding/test_onnx_local_provider.py::test_mean_pooling PASSED [ 59%]
tests/unit/services/embedding/test_openai_provider.py::test_provider_initialization PASSED [ 59%]
tests/unit/services/embedding/test_openai_provider.py::test_provider_invalid_model PASSED [ 59%]
tests/unit/services/embedding/test_openai_provider.py::test_provider_missing_api_key PASSED [ 59%]
tests/unit/services/embedding/test_openai_provider.py::test_get_embeddings PASSED [ 59%]
tests/unit/services/embedding/test_openai_provider.py::test_calculate_cost PASSED [ 59%]
tests/unit/services/embedding/test_openai_provider.py::test_get_max_batch_size PASSED [ 60%]
tests/unit/services/embedding/test_openai_provider.py::test_get_model_name PASSED [ 60%]
tests/unit/services/embedding/test_openai_provider.py::test_different_models PASSED [ 60%]
tests/unit/services/embedding/test_openai_provider.py::test_openai_not_installed PASSED [ 60%]
tests/unit/services/embedding/test_rate_limiter.py::test_rate_limiter_initialization PASSED [ 60%]
tests/unit/services/embedding/test_rate_limiter.py::test_rate_limiter_allows_first_request PASSED [ 60%]
tests/unit/services/embedding/test_rate_limiter.py::test_rate_limiter_enforces_limit PASSED [ 60%]
tests/unit/services/embedding/test_rate_limiter.py::test_rate_limiter_requests_per_minute PASSED [ 60%]
tests/unit/services/embedding/test_rate_limiter.py::test_rate_limiter_multiple_requests PASSED [ 60%]
tests/unit/services/embedding/test_rate_limiter.py::test_rate_limiter_thread_safety PASSED [ 60%]
tests/unit/services/embedding/test_rate_limiter.py::test_rate_limiter_prefers_stricter_limit PASSED [ 60%]
tests/unit/services/embedding/test_service.py::test_service_initialization PASSED [ 60%]
tests/unit/services/embedding/test_service.py::test_embed_single_text PASSED [ 60%]
tests/unit/services/embedding/test_service.py::test_embed_multiple_texts PASSED [ 60%]
tests/unit/services/embedding/test_service.py::test_embed_empty_list_raises_error PASSED [ 60%]
tests/unit/services/embedding/test_service.py::test_cache_hit PASSED     [ 60%]
tests/unit/services/embedding/test_service.py::test_cache_disabled PASSED [ 60%]
tests/unit/services/embedding/test_service.py::test_batch_splitting PASSED [ 60%]
tests/unit/services/embedding/test_service.py::test_get_stats PASSED     [ 60%]
tests/unit/services/embedding/test_service.py::test_clear_cache PASSED   [ 60%]
tests/unit/services/embedding/test_service.py::test_unknown_provider_raises_error PASSED [ 60%]
tests/unit/services/embedding/test_service.py::test_compute_cache_key PASSED [ 60%]
tests/unit/services/embedding/test_service.py::test_cache_different_models PASSED [ 61%]
tests/unit/services/embedding/test_service.py::test_rate_limiter_interaction PASSED [ 61%]
tests/unit/services/embedding/test_service.py::test_provider_error_handling PASSED [ 61%]
tests/unit/services/embeddings/test_onnx_local.py::TestONNXLocalProvider::test_initialization PASSED [ 61%]
tests/unit/services/embeddings/test_onnx_local.py::TestONNXLocalProvider::test_initialization_with_custom_config PASSED [ 61%]
tests/unit/services/embeddings/test_onnx_local.py::TestONNXLocalProvider::test_get_embeddings_single_text PASSED [ 61%]
tests/unit/services/embeddings/test_onnx_local.py::TestONNXLocalProvider::test_get_embeddings_multiple_texts PASSED [ 61%]
tests/unit/services/embeddings/test_onnx_local.py::TestONNXLocalProvider::test_get_embeddings_empty_list PASSED [ 61%]
tests/unit/services/embeddings/test_onnx_local.py::TestONNXLocalProvider::test_embedding_normalization PASSED [ 61%]
tests/unit/services/embeddings/test_onnx_local.py::TestONNXLocalProvider::test_get_dimensions PASSED [ 61%]
tests/unit/services/embeddings/test_onnx_local.py::TestONNXLocalProvider::test_get_max_batch_size PASSED [ 61%]
tests/unit/services/embeddings/test_onnx_local.py::TestONNXLocalProvider::test_get_model_name PASSED [ 61%]
tests/unit/services/embeddings/test_onnx_local.py::TestONNXLocalProvider::test_calculate_cost PASSED [ 61%]
tests/unit/services/embeddings/test_onnx_local.py::TestONNXLocalProvider::test_known_models PASSED [ 61%]
tests/unit/services/embeddings/test_onnx_local.py::TestONNXLocalProvider::test_missing_onnx_runtime PASSED [ 61%]
tests/unit/services/embeddings/test_onnx_local.py::TestONNXLocalProvider::test_model_loading_failure PASSED [ 61%]
tests/unit/services/embeddings/test_onnx_local.py::TestONNXLocalProvider::test_session_creation_failure PASSED [ 61%]
tests/unit/services/llm/test_anthropic_provider.py::test_provider_initialization PASSED [ 61%]
tests/unit/services/llm/test_anthropic_provider.py::test_provider_invalid_model PASSED [ 61%]
tests/unit/services/llm/test_anthropic_provider.py::test_complete PASSED [ 61%]
tests/unit/services/llm/test_anthropic_provider.py::test_complete_with_system_message PASSED [ 61%]
tests/unit/services/llm/test_anthropic_provider.py::test_count_tokens PASSED [ 62%]
tests/unit/services/llm/test_anthropic_provider.py::test_calculate_cost PASSED [ 62%]
tests/unit/services/llm/test_anthropic_provider.py::test_get_model_name PASSED [ 62%]
tests/unit/services/llm/test_anthropic_provider.py::test_get_max_tokens PASSED [ 62%]
tests/unit/services/llm/test_anthropic_provider.py::test_stream PASSED   [ 62%]
tests/unit/services/llm/test_anthropic_provider.py::test_different_models PASSED [ 62%]
tests/unit/services/llm/test_ollama_provider.py::test_provider_initialization PASSED [ 62%]
tests/unit/services/llm/test_ollama_provider.py::test_provider_default_values PASSED [ 62%]
tests/unit/services/llm/test_ollama_provider.py::test_complete PASSED    [ 62%]
tests/unit/services/llm/test_ollama_provider.py::test_complete_with_system_message PASSED [ 62%]
tests/unit/services/llm/test_ollama_provider.py::test_count_tokens PASSED [ 62%]
tests/unit/services/llm/test_ollama_provider.py::test_calculate_cost PASSED [ 62%]
tests/unit/services/llm/test_ollama_provider.py::test_get_model_name PASSED [ 62%]
tests/unit/services/llm/test_ollama_provider.py::test_get_max_tokens PASSED [ 62%]
tests/unit/services/llm/test_ollama_provider.py::test_messages_to_prompt PASSED [ 62%]
tests/unit/services/llm/test_ollama_provider.py::test_stream PASSED      [ 62%]
tests/unit/services/llm/test_openai_provider.py::test_provider_initialization PASSED [ 62%]
tests/unit/services/llm/test_openai_provider.py::test_provider_invalid_model PASSED [ 62%]
tests/unit/services/llm/test_openai_provider.py::test_complete PASSED    [ 62%]
tests/unit/services/llm/test_openai_provider.py::test_complete_with_system_message PASSED [ 62%]
tests/unit/services/llm/test_openai_provider.py::test_count_tokens PASSED [ 62%]
tests/unit/services/llm/test_openai_provider.py::test_calculate_cost PASSED [ 62%]
tests/unit/services/llm/test_openai_provider.py::test_get_model_name PASSED [ 63%]
tests/unit/services/llm/test_openai_provider.py::test_get_max_tokens PASSED [ 63%]
tests/unit/services/llm/test_openai_provider.py::test_stream PASSED      [ 63%]
tests/unit/services/llm/test_openai_provider.py::test_different_models PASSED [ 63%]
tests/unit/services/llm/test_prompt_template.py::test_template_with_system_and_user PASSED [ 63%]
tests/unit/services/llm/test_prompt_template.py::test_template_user_only PASSED [ 63%]
tests/unit/services/llm/test_prompt_template.py::test_template_with_few_shot_examples PASSED [ 63%]
tests/unit/services/llm/test_prompt_template.py::test_template_missing_variable_raises_error PASSED [ 63%]
tests/unit/services/llm/test_prompt_template.py::test_template_validation PASSED [ 63%]
tests/unit/services/llm/test_prompt_template.py::test_common_template_rag_qa PASSED [ 63%]
tests/unit/services/llm/test_prompt_template.py::test_common_template_summarization PASSED [ 63%]
tests/unit/services/llm/test_prompt_template.py::test_template_multiple_variables PASSED [ 63%]
tests/unit/services/llm/test_prompt_template.py::test_template_with_assistant_prefix PASSED [ 63%]
tests/unit/services/llm/test_prompt_template.py::test_common_template_classification PASSED [ 63%]
tests/unit/services/llm/test_prompt_template.py::test_common_template_extraction PASSED [ 63%]
tests/unit/services/llm/test_prompt_template.py::test_empty_template PASSED [ 63%]
tests/unit/services/llm/test_prompt_template.py::test_template_with_special_characters PASSED [ 63%]
tests/unit/services/llm/test_service.py::test_service_initialization PASSED [ 63%]
tests/unit/services/llm/test_service.py::test_complete_single_message PASSED [ 63%]
tests/unit/services/llm/test_service.py::test_complete_with_system_message PASSED [ 63%]
tests/unit/services/llm/test_service.py::test_complete_empty_messages_raises_error PASSED [ 63%]
tests/unit/services/llm/test_service.py::test_complete_with_temperature PASSED [ 64%]
tests/unit/services/llm/test_service.py::test_complete_with_max_tokens PASSED [ 64%]
tests/unit/services/llm/test_service.py::test_stats_tracking PASSED      [ 64%]
tests/unit/services/llm/test_service.py::test_count_tokens PASSED        [ 64%]
tests/unit/services/llm/test_service.py::test_estimate_cost PASSED       [ 64%]
tests/unit/services/llm/test_service.py::test_stream_messages PASSED     [ 64%]
tests/unit/services/llm/test_service.py::test_stream_with_callback PASSED [ 64%]
tests/unit/services/llm/test_service.py::test_stream_empty_messages_raises_error PASSED [ 64%]
tests/unit/services/llm/test_service.py::test_provider_error_handling PASSED [ 64%]
tests/unit/services/llm/test_service.py::test_rate_limiter_interaction PASSED [ 64%]
tests/unit/services/test_consistency.py::TestConsistencyChecker::test_indexing_consistent_vectors PASSED [ 64%]
tests/unit/services/test_consistency.py::TestConsistencyChecker::test_indexing_consistent_graph PASSED [ 64%]
tests/unit/services/test_consistency.py::TestConsistencyChecker::test_indexing_consistent_in_memory PASSED [ 64%]
tests/unit/services/test_consistency.py::TestConsistencyChecker::test_indexing_vectors_without_embedding PASSED [ 64%]
tests/unit/services/test_consistency.py::TestConsistencyChecker::test_indexing_graph_without_graph_service PASSED [ 64%]
tests/unit/services/test_consistency.py::TestConsistencyChecker::test_indexing_database_without_database_service PASSED [ 64%]
tests/unit/services/test_consistency.py::TestConsistencyChecker::test_indexing_in_memory_with_database PASSED [ 64%]
tests/unit/services/test_consistency.py::TestConsistencyChecker::test_indexing_multiple_inconsistencies PASSED [ 64%]
tests/unit/services/test_consistency.py::TestConsistencyChecker::test_retrieval_consistent_vectors PASSED [ 64%]
tests/unit/services/test_consistency.py::TestConsistencyChecker::test_retrieval_consistent_graph PASSED [ 64%]
tests/unit/services/test_consistency.py::TestConsistencyChecker::test_retrieval_consistent_keywords PASSED [ 64%]
tests/unit/services/test_consistency.py::TestConsistencyChecker::test_retrieval_vectors_without_database PASSED [ 65%]
tests/unit/services/test_consistency.py::TestConsistencyChecker::test_retrieval_graph_without_graph_service PASSED [ 65%]
tests/unit/services/test_consistency.py::TestConsistencyChecker::test_retrieval_keywords_without_database PASSED [ 65%]
tests/unit/services/test_consistency.py::TestConsistencyChecker::test_retrieval_multiple_inconsistencies PASSED [ 65%]
tests/unit/services/test_consistency.py::TestConsistencyChecker::test_retrieval_empty_requirements PASSED [ 65%]
tests/unit/services/test_database_service.py::test_service_initialization PASSED [ 65%]
tests/unit/services/test_database_service.py::test_ensure_table PASSED   [ 65%]
tests/unit/services/test_database_service.py::test_store_chunks FAILED   [ 65%]
tests/unit/services/test_database_service.py::test_store_empty_chunks PASSED [ 65%]
tests/unit/services/test_database_service.py::test_search_chunks FAILED  [ 65%]
tests/unit/services/test_database_service.py::test_get_chunk PASSED      [ 65%]
tests/unit/services/test_database_service.py::test_get_chunk_not_found PASSED [ 65%]
tests/unit/services/test_database_service.py::test_get_chunks_for_documents PASSED [ 65%]
tests/unit/services/test_database_service.py::test_close PASSED          [ 65%]
tests/unit/services/test_database_service.py::test_context_manager PASSED [ 65%]
tests/unit/services/test_dependencies.py::TestServiceDependency::test_enum_has_all_service_types PASSED [ 65%]
tests/unit/services/test_dependencies.py::TestServiceDependency::test_enum_values_are_unique PASSED [ 65%]
tests/unit/services/test_dependencies.py::TestServiceDependency::test_enum_count PASSED [ 65%]
tests/unit/services/test_dependencies.py::TestStrategyDependencies::test_instantiation_with_no_services PASSED [ 65%]
tests/unit/services/test_dependencies.py::TestStrategyDependencies::test_instantiation_with_all_services PASSED [ 65%]
tests/unit/services/test_dependencies.py::TestStrategyDependencies::test_instantiation_with_partial_services PASSED [ 65%]
tests/unit/services/test_dependencies.py::TestValidationLogic::test_validation_with_all_required_services_present PASSED [ 65%]
tests/unit/services/test_dependencies.py::TestValidationLogic::test_validation_with_some_services_missing PASSED [ 66%]
tests/unit/services/test_dependencies.py::TestValidationLogic::test_validation_with_empty_requirements PASSED [ 66%]
tests/unit/services/test_dependencies.py::TestValidationLogic::test_validation_with_all_services_missing PASSED [ 66%]
tests/unit/services/test_dependencies.py::TestValidationLogic::test_validation_with_extra_services_present PASSED [ 66%]
tests/unit/services/test_dependencies.py::TestValidationLogic::test_validation_for_each_service_type PASSED [ 66%]
tests/unit/services/test_dependencies.py::TestErrorMessaging::test_message_for_valid_container PASSED [ 66%]
tests/unit/services/test_dependencies.py::TestErrorMessaging::test_message_for_single_missing_service PASSED [ 66%]
tests/unit/services/test_dependencies.py::TestErrorMessaging::test_message_for_multiple_missing_services PASSED [ 66%]
tests/unit/services/test_dependencies.py::TestErrorMessaging::test_message_format PASSED [ 66%]
tests/unit/services/test_dependencies.py::TestErrorMessaging::test_message_with_empty_requirements PASSED [ 66%]
tests/unit/services/test_graph_interface.py::TestIGraphServiceInterface::test_interface_is_abstract PASSED [ 66%]
tests/unit/services/test_graph_interface.py::TestIGraphServiceInterface::test_interface_requires_all_methods PASSED [ 66%]
tests/unit/services/test_graph_interface.py::TestIGraphServiceInterface::test_create_node_signature PASSED [ 66%]
tests/unit/services/test_graph_interface.py::TestIGraphServiceInterface::test_create_relationship_signature PASSED [ 66%]
tests/unit/services/test_graph_interface.py::TestIGraphServiceInterface::test_query_signature PASSED [ 66%]
tests/unit/services/test_graph_interface.py::TestIGraphServiceInterface::test_minimal_concrete_implementation PASSED [ 66%]
tests/unit/services/test_interfaces.py::test_illm_service_requires_implementation PASSED [ 66%]
tests/unit/services/test_interfaces.py::test_illm_service_requires_complete_method PASSED [ 66%]
tests/unit/services/test_interfaces.py::test_illm_service_requires_stream_complete_method PASSED [ 66%]
tests/unit/services/test_interfaces.py::test_illm_service_mock_implementation PASSED [ 66%]
tests/unit/services/test_interfaces.py::test_illm_service_has_docstring PASSED [ 66%]
tests/unit/services/test_interfaces.py::test_iembedding_service_requires_implementation PASSED [ 67%]
tests/unit/services/test_interfaces.py::test_iembedding_service_requires_embed_method PASSED [ 67%]
tests/unit/services/test_interfaces.py::test_iembedding_service_mock_implementation PASSED [ 67%]
tests/unit/services/test_interfaces.py::test_iembedding_service_has_docstring PASSED [ 67%]
tests/unit/services/test_interfaces.py::test_igraph_service_requires_implementation PASSED [ 67%]
tests/unit/services/test_interfaces.py::test_igraph_service_requires_create_node_method PASSED [ 67%]
tests/unit/services/test_interfaces.py::test_igraph_service_mock_implementation PASSED [ 67%]
tests/unit/services/test_interfaces.py::test_igraph_service_has_docstring PASSED [ 67%]
tests/unit/services/test_interfaces.py::test_ireranking_service_requires_implementation PASSED [ 67%]
tests/unit/services/test_interfaces.py::test_ireranking_service_mock_implementation PASSED [ 67%]
tests/unit/services/test_interfaces.py::test_ireranking_service_has_docstring PASSED [ 67%]
tests/unit/services/test_interfaces.py::test_idatabase_service_requires_implementation PASSED [ 67%]
tests/unit/services/test_interfaces.py::test_idatabase_service_requires_store_chunks_method PASSED [ 67%]
tests/unit/services/test_interfaces.py::test_idatabase_service_mock_implementation PASSED [ 67%]
tests/unit/services/test_interfaces.py::test_idatabase_service_has_docstring PASSED [ 67%]
tests/unit/services/test_interfaces.py::test_all_interfaces_have_type_hints PASSED [ 67%]
tests/unit/services/test_reranking_interface.py::TestIRerankingServiceInterface::test_interface_is_abstract PASSED [ 67%]
tests/unit/services/test_reranking_interface.py::TestIRerankingServiceInterface::test_interface_requires_rerank_method PASSED [ 67%]
tests/unit/services/test_reranking_interface.py::TestIRerankingServiceInterface::test_rerank_method_signature PASSED [ 67%]
tests/unit/services/test_reranking_interface.py::TestIRerankingServiceInterface::test_minimal_concrete_implementation PASSED [ 67%]
tests/unit/services/utils/test_onnx_utils.py::TestMeanPooling::test_basic_pooling PASSED [ 67%]
tests/unit/services/utils/test_onnx_utils.py::TestMeanPooling::test_pooling_with_padding PASSED [ 68%]
tests/unit/services/utils/test_onnx_utils.py::TestMeanPooling::test_pooling_single_token PASSED [ 68%]
tests/unit/services/utils/test_onnx_utils.py::TestNormalizeEmbeddings::test_normalize_2d_array PASSED [ 68%]
tests/unit/services/utils/test_onnx_utils.py::TestNormalizeEmbeddings::test_normalize_1d_array PASSED [ 68%]
tests/unit/services/utils/test_onnx_utils.py::TestNormalizeEmbeddings::test_normalize_zero_vector PASSED [ 68%]
tests/unit/services/utils/test_onnx_utils.py::TestNormalizeEmbeddings::test_normalize_already_normalized PASSED [ 68%]
tests/unit/services/utils/test_onnx_utils.py::TestCosineSimilarity::test_identical_vectors PASSED [ 68%]
tests/unit/services/utils/test_onnx_utils.py::TestCosineSimilarity::test_orthogonal_vectors PASSED [ 68%]
tests/unit/services/utils/test_onnx_utils.py::TestCosineSimilarity::test_opposite_vectors PASSED [ 68%]
tests/unit/services/utils/test_onnx_utils.py::TestCosineSimilarity::test_similar_vectors PASSED [ 68%]
tests/unit/services/utils/test_onnx_utils.py::TestCosineSimilarity::test_zero_vector PASSED [ 68%]
tests/unit/services/utils/test_onnx_utils.py::TestCosineSimilarity::test_2d_arrays PASSED [ 68%]
tests/unit/services/utils/test_onnx_utils.py::TestGetModelMetadata::test_metadata_extraction PASSED [ 68%]
tests/unit/services/utils/test_onnx_utils.py::TestGetModelMetadata::test_metadata_with_2d_output PASSED [ 68%]
tests/unit/services/utils/test_onnx_utils.py::TestGetModelMetadata::test_metadata_without_embedding_dim PASSED [ 68%]
tests/unit/services/utils/test_onnx_utils.py::TestGetModelMetadata::test_metadata_with_dynamic_shapes PASSED [ 68%]
tests/unit/strategies/agentic/test_agent.py::test_agent_state_initialization PASSED [ 68%]
tests/unit/strategies/agentic/test_agent.py::test_agent_state_add_tool_call PASSED [ 68%]
tests/unit/strategies/agentic/test_agent.py::test_agent_state_add_tool_result PASSED [ 68%]
tests/unit/strategies/agentic/test_agent.py::test_agent_state_should_continue_max_iterations PASSED [ 68%]
tests/unit/strategies/agentic/test_agent.py::test_agent_state_should_continue_sufficient_results PASSED [ 68%]
tests/unit/strategies/agentic/test_agent.py::test_agent_initialization PASSED [ 68%]
tests/unit/strategies/agentic/test_agent.py::test_agent_run_basic PASSED [ 69%]
tests/unit/strategies/agentic/test_agent.py::test_agent_planning_phase PASSED [ 69%]
tests/unit/strategies/agentic/test_agent.py::test_agent_tool_execution PASSED [ 69%]
tests/unit/strategies/agentic/test_agent.py::test_agent_tool_execution_not_found PASSED [ 69%]
tests/unit/strategies/agentic/test_agent.py::test_agent_synthesize_results PASSED [ 69%]
tests/unit/strategies/agentic/test_agent.py::test_agent_synthesize_results_ignores_failed PASSED [ 69%]
tests/unit/strategies/agentic/test_agent.py::test_agent_max_iterations PASSED [ 69%]
tests/unit/strategies/agentic/test_agent.py::test_agent_parse_tool_calls_structured PASSED [ 69%]
tests/unit/strategies/agentic/test_agent.py::test_agent_parse_tool_calls_done PASSED [ 69%]
tests/unit/strategies/agentic/test_agent.py::test_agent_parse_tool_calls_fallback PASSED [ 69%]
tests/unit/strategies/agentic/test_query_analyzer.py::test_query_analyzer_initialization PASSED [ 69%]
tests/unit/strategies/agentic/test_query_analyzer.py::test_extract_entities PASSED [ 69%]
tests/unit/strategies/agentic/test_query_analyzer.py::test_extract_entities_quoted PASSED [ 69%]
tests/unit/strategies/agentic/test_query_analyzer.py::test_extract_keywords PASSED [ 69%]
tests/unit/strategies/agentic/test_query_analyzer.py::test_assess_complexity_simple PASSED [ 69%]
tests/unit/strategies/agentic/test_query_analyzer.py::test_assess_complexity_complex PASSED [ 69%]
tests/unit/strategies/agentic/test_query_analyzer.py::test_assess_complexity_multiple_questions PASSED [ 69%]
tests/unit/strategies/agentic/test_query_analyzer.py::test_classify_type_factual PASSED [ 69%]
tests/unit/strategies/agentic/test_query_analyzer.py::test_classify_type_exploratory PASSED [ 69%]
tests/unit/strategies/agentic/test_query_analyzer.py::test_classify_type_specific_document PASSED [ 69%]
tests/unit/strategies/agentic/test_query_analyzer.py::test_classify_type_metadata PASSED [ 69%]
tests/unit/strategies/agentic/test_query_analyzer.py::test_recommend_tools_factual PASSED [ 70%]
tests/unit/strategies/agentic/test_query_analyzer.py::test_recommend_tools_specific_document PASSED [ 70%]
tests/unit/strategies/agentic/test_query_analyzer.py::test_recommend_tools_metadata PASSED [ 70%]
tests/unit/strategies/agentic/test_query_analyzer.py::test_recommend_tools_technical_terms PASSED [ 70%]
tests/unit/strategies/agentic/test_query_analyzer.py::test_analyze_full_workflow PASSED [ 70%]
tests/unit/strategies/agentic/test_strategy.py::test_config_defaults PASSED [ 70%]
tests/unit/strategies/agentic/test_strategy.py::test_config_custom_values PASSED [ 70%]
tests/unit/strategies/agentic/test_strategy.py::test_config_validation PASSED [ 70%]
tests/unit/strategies/agentic/test_strategy.py::test_strategy_initialization PASSED [ 70%]
tests/unit/strategies/agentic/test_strategy.py::test_strategy_initialization_with_config PASSED [ 70%]
tests/unit/strategies/agentic/test_strategy.py::test_strategy_retrieve PASSED [ 70%]
tests/unit/strategies/agentic/test_strategy.py::test_strategy_retrieve_with_query_analysis PASSED [ 70%]
tests/unit/strategies/agentic/test_strategy.py::test_strategy_fallback_on_error PASSED [ 70%]
tests/unit/strategies/agentic/test_strategy.py::test_strategy_no_fallback_raises_error PASSED [ 70%]
tests/unit/strategies/agentic/test_strategy.py::test_strategy_get_stats PASSED [ 70%]
tests/unit/strategies/agentic/test_strategy.py::test_strategy_top_k_limit PASSED [ 70%]
tests/unit/strategies/agentic/test_tools.py::test_tool_parameter_creation PASSED [ 70%]
tests/unit/strategies/agentic/test_tools.py::test_tool_result_creation PASSED [ 70%]
tests/unit/strategies/agentic/test_tools.py::test_tool_to_anthropic_format PASSED [ 70%]
tests/unit/strategies/agentic/test_tools.py::test_semantic_search_tool_definition PASSED [ 70%]
tests/unit/strategies/agentic/test_tools.py::test_semantic_search_tool_execute PASSED [ 70%]
tests/unit/strategies/agentic/test_tools.py::test_semantic_search_tool_error_handling PASSED [ 71%]
tests/unit/strategies/agentic/test_tools.py::test_document_reader_tool PASSED [ 71%]
tests/unit/strategies/agentic/test_tools.py::test_document_reader_tool_not_found PASSED [ 71%]
tests/unit/strategies/agentic/test_tools.py::test_document_reader_tool_invalid_id PASSED [ 71%]
tests/unit/strategies/agentic/test_tools.py::test_metadata_search_tool PASSED [ 71%]
tests/unit/strategies/agentic/test_tools.py::test_hybrid_search_tool PASSED [ 71%]
tests/unit/strategies/chunking/test_docling_chunker.py::test_is_docling_available PASSED [ 71%]
tests/unit/strategies/chunking/test_docling_chunker.py::test_get_docling_version PASSED [ 71%]
tests/unit/strategies/chunking/test_docling_chunker.py::test_docling_chunker_import_error_when_not_installed PASSED [ 71%]
tests/unit/strategies/chunking/test_docling_chunker.py::test_docling_chunker_initialization SKIPPED [ 71%]
tests/unit/strategies/chunking/test_docling_chunker.py::test_docling_chunker_placeholder_warning SKIPPED [ 71%]
tests/unit/strategies/chunking/test_docling_chunker.py::test_docling_chunker_module_structure PASSED [ 71%]
tests/unit/strategies/chunking/test_fixed_size_chunker.py::test_fixed_size_chunker_initialization PASSED [ 71%]
tests/unit/strategies/chunking/test_fixed_size_chunker.py::test_chunk_document_basic PASSED [ 71%]
tests/unit/strategies/chunking/test_fixed_size_chunker.py::test_chunk_document_empty PASSED [ 71%]
tests/unit/strategies/chunking/test_fixed_size_chunker.py::test_chunk_size_approximately_target PASSED [ 71%]
tests/unit/strategies/chunking/test_fixed_size_chunker.py::test_chunk_overlap PASSED [ 71%]
tests/unit/strategies/chunking/test_fixed_size_chunker.py::test_no_overlap PASSED [ 71%]
tests/unit/strategies/chunking/test_fixed_size_chunker.py::test_chunk_multiple_documents PASSED [ 71%]
tests/unit/strategies/chunking/test_fixed_size_chunker.py::test_get_overlap_words PASSED [ 71%]
tests/unit/strategies/chunking/test_fixed_size_chunker.py::test_get_overlap_words_zero_overlap PASSED [ 71%]
tests/unit/strategies/chunking/test_fixed_size_chunker.py::test_count_tokens PASSED [ 71%]
tests/unit/strategies/chunking/test_fixed_size_chunker.py::test_single_word_document PASSED [ 72%]
tests/unit/strategies/chunking/test_fixed_size_chunker.py::test_chunk_metadata PASSED [ 72%]
tests/unit/strategies/chunking/test_fixed_size_chunker.py::test_create_chunk_helper PASSED [ 72%]
tests/unit/strategies/chunking/test_hybrid_chunker.py::test_hybrid_chunker_initialization_with_embeddings PASSED [ 72%]
tests/unit/strategies/chunking/test_hybrid_chunker.py::test_hybrid_chunker_initialization_without_embeddings PASSED [ 72%]
tests/unit/strategies/chunking/test_hybrid_chunker.py::test_chunk_markdown_document PASSED [ 72%]
tests/unit/strategies/chunking/test_hybrid_chunker.py::test_chunk_document_empty PASSED [ 72%]
tests/unit/strategies/chunking/test_hybrid_chunker.py::test_structural_only_mode PASSED [ 72%]
tests/unit/strategies/chunking/test_hybrid_chunker.py::test_semantic_refinement_of_large_chunks PASSED [ 72%]
tests/unit/strategies/chunking/test_hybrid_chunker.py::test_hierarchy_preservation PASSED [ 72%]
tests/unit/strategies/chunking/test_hybrid_chunker.py::test_chunk_multiple_documents PASSED [ 72%]
tests/unit/strategies/chunking/test_hybrid_chunker.py::test_atomic_content_not_split PASSED [ 72%]
tests/unit/strategies/chunking/test_hybrid_chunker.py::test_get_stats PASSED [ 72%]
tests/unit/strategies/chunking/test_hybrid_chunker.py::test_chunk_position_reindexing PASSED [ 72%]
tests/unit/strategies/chunking/test_hybrid_chunker.py::test_semantic_chunking_failure_fallback PASSED [ 72%]
tests/unit/strategies/chunking/test_semantic_chunker.py::test_semantic_chunker_initialization PASSED [ 72%]
tests/unit/strategies/chunking/test_semantic_chunker.py::test_semantic_chunker_requires_embeddings PASSED [ 72%]
tests/unit/strategies/chunking/test_semantic_chunker.py::test_chunk_document_basic PASSED [ 72%]
tests/unit/strategies/chunking/test_semantic_chunker.py::test_chunk_document_empty PASSED [ 72%]
tests/unit/strategies/chunking/test_semantic_chunker.py::test_split_into_sentences PASSED [ 72%]
tests/unit/strategies/chunking/test_semantic_chunker.py::test_cosine_similarity PASSED [ 72%]
tests/unit/strategies/chunking/test_semantic_chunker.py::test_detect_boundaries_high_similarity PASSED [ 73%]
tests/unit/strategies/chunking/test_semantic_chunker.py::test_detect_boundaries_low_similarity PASSED [ 73%]
tests/unit/strategies/chunking/test_semantic_chunker.py::test_single_sentence_document PASSED [ 73%]
tests/unit/strategies/chunking/test_semantic_chunker.py::test_fallback_chunking PASSED [ 73%]
tests/unit/strategies/chunking/test_semantic_chunker.py::test_chunk_multiple_documents PASSED [ 73%]
tests/unit/strategies/chunking/test_semantic_chunker.py::test_count_tokens_with_tokenizer PASSED [ 73%]
tests/unit/strategies/chunking/test_semantic_chunker.py::test_create_segments PASSED [ 73%]
tests/unit/strategies/chunking/test_semantic_chunker.py::test_coherence_score_computation PASSED [ 73%]
tests/unit/strategies/chunking/test_structural_chunker.py::test_structural_chunker_initialization PASSED [ 73%]
tests/unit/strategies/chunking/test_structural_chunker.py::test_is_markdown_detection PASSED [ 73%]
tests/unit/strategies/chunking/test_structural_chunker.py::test_chunk_markdown_with_headers PASSED [ 73%]
tests/unit/strategies/chunking/test_structural_chunker.py::test_split_by_headers_hierarchy PASSED [ 73%]
tests/unit/strategies/chunking/test_structural_chunker.py::test_chunk_plain_text_by_paragraphs PASSED [ 73%]
tests/unit/strategies/chunking/test_structural_chunker.py::test_large_section_splitting PASSED [ 73%]
tests/unit/strategies/chunking/test_structural_chunker.py::test_empty_markdown_document PASSED [ 73%]
tests/unit/strategies/chunking/test_structural_chunker.py::test_markdown_with_code_blocks PASSED [ 73%]
tests/unit/strategies/chunking/test_structural_chunker.py::test_multiple_documents_batch PASSED [ 73%]
tests/unit/strategies/chunking/test_structural_chunker.py::test_split_into_paragraphs PASSED [ 73%]
tests/unit/strategies/chunking/test_structural_chunker.py::test_is_atomic_content_code_block PASSED [ 73%]
tests/unit/strategies/chunking/test_structural_chunker.py::test_is_atomic_content_table PASSED [ 73%]
tests/unit/strategies/chunking/test_structural_chunker.py::test_atomic_content_not_split PASSED [ 73%]
tests/unit/strategies/chunking/test_structural_chunker.py::test_respect_headers_disabled PASSED [ 74%]
tests/unit/strategies/chunking/test_structural_chunker.py::test_count_tokens PASSED [ 74%]
tests/unit/strategies/contextual/test_batch_processor.py::test_process_chunks_batching PASSED [ 74%]
tests/unit/strategies/contextual/test_batch_processor.py::test_parallel_batch_processing PASSED [ 74%]
tests/unit/strategies/contextual/test_batch_processor.py::test_cost_tracking_during_batch PASSED [ 74%]
tests/unit/strategies/contextual/test_batch_processor.py::test_error_handling_in_batch PASSED [ 74%]
tests/unit/strategies/contextual/test_batch_processor.py::test_sequential_batch_processing PASSED [ 74%]
tests/unit/strategies/contextual/test_batch_processor.py::test_batch_creation PASSED [ 74%]
tests/unit/strategies/contextual/test_batch_processor.py::test_contextualized_text_format PASSED [ 74%]
tests/unit/strategies/contextual/test_context_generator.py::test_generate_context_basic PASSED [ 74%]
tests/unit/strategies/contextual/test_context_generator.py::test_context_includes_document_metadata PASSED [ 74%]
tests/unit/strategies/contextual/test_context_generator.py::test_skip_short_chunks PASSED [ 74%]
tests/unit/strategies/contextual/test_context_generator.py::test_skip_code_blocks PASSED [ 74%]
tests/unit/strategies/contextual/test_context_generator.py::test_fallback_on_error PASSED [ 74%]
tests/unit/strategies/contextual/test_context_generator.py::test_context_length_validation PASSED [ 74%]
tests/unit/strategies/contextual/test_context_generator.py::test_disabled_contextualization PASSED [ 74%]
tests/unit/strategies/contextual/test_context_generator.py::test_token_counting PASSED [ 74%]
tests/unit/strategies/contextual/test_context_generator.py::test_context_truncation PASSED [ 74%]
tests/unit/strategies/contextual/test_cost_tracker.py::test_calculate_cost PASSED [ 74%]
tests/unit/strategies/contextual/test_cost_tracker.py::test_record_chunk_cost PASSED [ 74%]
tests/unit/strategies/contextual/test_cost_tracker.py::test_cost_summary PASSED [ 74%]
tests/unit/strategies/contextual/test_cost_tracker.py::test_budget_alert FAILED [ 74%]
tests/unit/strategies/contextual/test_cost_tracker.py::test_reset PASSED [ 75%]
tests/unit/strategies/contextual/test_cost_tracker.py::test_check_budget_limit PASSED [ 75%]
tests/unit/strategies/contextual/test_cost_tracker.py::test_multiple_chunk_costs PASSED [ 75%]
tests/unit/strategies/contextual/test_cost_tracker.py::test_cost_per_1k_chunks PASSED [ 75%]
tests/unit/strategies/contextual/test_cost_tracker.py::test_empty_tracker_summary PASSED [ 75%]
tests/unit/strategies/contextual/test_storage.py::test_store_chunks PASSED [ 75%]
tests/unit/strategies/contextual/test_storage.py::test_store_without_context PASSED [ 75%]
tests/unit/strategies/contextual/test_storage.py::test_retrieve_original_format PASSED [ 75%]
tests/unit/strategies/contextual/test_storage.py::test_retrieve_contextualized_format PASSED [ 75%]
tests/unit/strategies/contextual/test_storage.py::test_retrieve_both_format PASSED [ 75%]
tests/unit/strategies/contextual/test_storage.py::test_retrieve_context_only PASSED [ 75%]
tests/unit/strategies/contextual/test_storage.py::test_store_multiple_chunks PASSED [ 75%]
tests/unit/strategies/contextual/test_storage.py::test_config_controls_storage PASSED [ 75%]
tests/unit/strategies/fine_tuned/test_ab_testing.py::TestABTestingFramework::test_start_stop_experiment PASSED [ 75%]
tests/unit/strategies/fine_tuned/test_ab_testing.py::TestABTestingFramework::test_get_model_for_request PASSED [ 75%]
tests/unit/strategies/fine_tuned/test_ab_testing.py::TestABTestingFramework::test_record_and_stats PASSED [ 75%]
tests/unit/strategies/fine_tuned/test_custom_loader.py::TestCustomModelLoader::test_load_model_onnx PASSED [ 75%]
tests/unit/strategies/fine_tuned/test_custom_loader.py::TestCustomModelLoader::test_load_model_pytorch PASSED [ 75%]
tests/unit/strategies/fine_tuned/test_custom_loader.py::TestCustomModelLoader::test_load_model_fallback PASSED [ 75%]
tests/unit/strategies/fine_tuned/test_model_registry.py::TestONNXModelRegistry::test_register_model PASSED [ 75%]
tests/unit/strategies/fine_tuned/test_model_registry.py::TestONNXModelRegistry::test_get_model PASSED [ 75%]
tests/unit/strategies/fine_tuned/test_model_registry.py::TestONNXModelRegistry::test_list_models PASSED [ 76%]
tests/unit/strategies/fine_tuned/test_model_registry.py::TestONNXModelRegistry::test_delete_model PASSED [ 76%]
tests/unit/strategies/fine_tuned/test_model_registry.py::TestONNXModelRegistry::test_get_latest_version PASSED [ 76%]
tests/unit/strategies/hierarchical/test_hierarchy_builder.py::TestHierarchyBuilder::test_build_creates_root_chunk PASSED [ 76%]
tests/unit/strategies/hierarchical/test_hierarchy_builder.py::TestHierarchyBuilder::test_is_markdown_detection PASSED [ 76%]
tests/unit/strategies/hierarchical/test_hierarchy_builder.py::TestHierarchyBuilder::test_markdown_hierarchy_structure PASSED [ 76%]
tests/unit/strategies/hierarchical/test_hierarchy_builder.py::TestHierarchyBuilder::test_split_by_headers PASSED [ 76%]
tests/unit/strategies/hierarchical/test_hierarchy_builder.py::TestHierarchyBuilder::test_paragraph_hierarchy PASSED [ 76%]
tests/unit/strategies/hierarchical/test_hierarchy_builder.py::TestHierarchyBuilder::test_hierarchy_metadata PASSED [ 76%]
tests/unit/strategies/hierarchical/test_hierarchy_builder.py::TestHierarchyBuilder::test_parent_child_relationships PASSED [ 76%]
tests/unit/strategies/hierarchical/test_hierarchy_builder.py::TestHierarchyBuilder::test_min_chunk_size_respected PASSED [ 76%]
tests/unit/strategies/hierarchical/test_hierarchy_builder.py::TestHierarchyBuilder::test_max_hierarchy_depth PASSED [ 76%]
tests/unit/strategies/hierarchical/test_hierarchy_builder.py::TestHierarchyBuilder::test_empty_document PASSED [ 76%]
tests/unit/strategies/hierarchical/test_hierarchy_builder.py::TestHierarchyBuilder::test_document_with_no_structure PASSED [ 76%]
tests/unit/strategies/hierarchical/test_hierarchy_builder.py::TestHierarchyBuilderEdgeCases::test_nested_headers_same_level PASSED [ 76%]
tests/unit/strategies/hierarchical/test_hierarchy_builder.py::TestHierarchyBuilderEdgeCases::test_header_without_content PASSED [ 76%]
tests/unit/strategies/hierarchical/test_hierarchy_builder.py::TestHierarchyBuilderEdgeCases::test_very_long_document PASSED [ 76%]
tests/unit/strategies/hierarchical/test_parent_retriever.py::TestParentRetriever::test_expand_immediate_parent PASSED [ 76%]
tests/unit/strategies/hierarchical/test_parent_retriever.py::TestParentRetriever::test_expand_no_parent PASSED [ 76%]
tests/unit/strategies/hierarchical/test_parent_retriever.py::TestParentRetriever::test_deduplication PASSED [ 76%]
tests/unit/strategies/hierarchical/test_parent_retriever.py::TestParentRetriever::test_adaptive_strategy_small_chunk PASSED [ 76%]
tests/unit/strategies/hierarchical/test_parent_retriever.py::TestParentRetriever::test_adaptive_strategy_paragraph_level PASSED [ 77%]
tests/unit/strategies/hierarchical/test_parent_retriever.py::TestParentRetriever::test_window_expansion PASSED [ 77%]
tests/unit/strategies/hierarchical/test_parent_retriever.py::TestParentRetrieverEdgeCases::test_circular_reference_protection PASSED [ 77%]
tests/unit/strategies/hierarchical/test_parent_retriever.py::TestParentRetrieverEdgeCases::test_missing_parent_handling PASSED [ 77%]
tests/unit/strategies/indexing/test_context_aware.py::test_capabilities FAILED [ 77%]
tests/unit/strategies/indexing/test_context_aware.py::test_requirements PASSED [ 77%]
tests/unit/strategies/indexing/test_context_aware.py::test_split_into_sentences PASSED [ 77%]
tests/unit/strategies/indexing/test_context_aware.py::test_create_windows PASSED [ 77%]
tests/unit/strategies/indexing/test_context_aware.py::test_find_boundaries PASSED [ 77%]
tests/unit/strategies/indexing/test_context_aware.py::test_create_chunks_respects_boundaries PASSED [ 77%]
tests/unit/strategies/indexing/test_context_aware.py::test_create_chunks_respects_min_size PASSED [ 77%]
tests/unit/strategies/indexing/test_context_aware.py::test_create_chunks_respects_max_size PASSED [ 77%]
tests/unit/strategies/indexing/test_context_aware.py::test_process_flow PASSED [ 77%]
tests/unit/strategies/knowledge_graph/test_entity_extractor.py::test_entity_extraction_basic PASSED [ 77%]
tests/unit/strategies/knowledge_graph/test_entity_extractor.py::test_entity_extraction_with_confidence PASSED [ 77%]
tests/unit/strategies/knowledge_graph/test_entity_extractor.py::test_entity_deduplication PASSED [ 77%]
tests/unit/strategies/knowledge_graph/test_entity_extractor.py::test_batch_extraction PASSED [ 77%]
tests/unit/strategies/knowledge_graph/test_entity_extractor.py::test_invalid_json_response PASSED [ 77%]
tests/unit/strategies/knowledge_graph/test_entity_extractor.py::test_confidence_filtering PASSED [ 77%]
tests/unit/strategies/knowledge_graph/test_hybrid_retriever.py::test_hybrid_retrieval PASSED [ 77%]
tests/unit/strategies/knowledge_graph/test_hybrid_retriever.py::test_score_combination PASSED [ 77%]
tests/unit/strategies/knowledge_graph/test_hybrid_retriever.py::test_empty_vector_results PASSED [ 77%]
tests/unit/strategies/knowledge_graph/test_hybrid_retriever.py::test_entities_in_chunks PASSED [ 78%]
tests/unit/strategies/knowledge_graph/test_hybrid_retriever.py::test_graph_expansion PASSED [ 78%]
tests/unit/strategies/knowledge_graph/test_hybrid_retriever.py::test_top_k_limiting PASSED [ 78%]
tests/unit/strategies/knowledge_graph/test_hybrid_retriever.py::test_score_ordering PASSED [ 78%]
tests/unit/strategies/knowledge_graph/test_memory_graph_store.py::test_add_entity PASSED [ 78%]
tests/unit/strategies/knowledge_graph/test_memory_graph_store.py::test_add_relationship PASSED [ 78%]
tests/unit/strategies/knowledge_graph/test_memory_graph_store.py::test_graph_traversal PASSED [ 78%]
tests/unit/strategies/knowledge_graph/test_memory_graph_store.py::test_find_entities_by_name PASSED [ 78%]
tests/unit/strategies/knowledge_graph/test_memory_graph_store.py::test_graph_stats PASSED [ 78%]
tests/unit/strategies/knowledge_graph/test_memory_graph_store.py::test_delete_entity PASSED [ 78%]
tests/unit/strategies/knowledge_graph/test_memory_graph_store.py::test_clear_graph PASSED [ 78%]
tests/unit/strategies/knowledge_graph/test_memory_graph_store.py::test_relationship_type_filtering PASSED [ 78%]
tests/unit/strategies/late_chunking/test_coherence_analyzer.py::test_analyze_chunk_coherence PASSED [ 78%]
tests/unit/strategies/late_chunking/test_coherence_analyzer.py::test_coherence_score_calculation PASSED [ 78%]
tests/unit/strategies/late_chunking/test_coherence_analyzer.py::test_coherence_score_size_penalty PASSED [ 78%]
tests/unit/strategies/late_chunking/test_coherence_analyzer.py::test_compare_with_traditional PASSED [ 78%]
tests/unit/strategies/late_chunking/test_coherence_analyzer.py::test_compare_metrics_types PASSED [ 78%]
tests/unit/strategies/late_chunking/test_coherence_analyzer.py::test_coherence_with_no_scores PASSED [ 78%]
tests/unit/strategies/late_chunking/test_coherence_analyzer.py::test_analyze_preserves_chunk_data PASSED [ 78%]
tests/unit/strategies/late_chunking/test_document_embedder.py::test_document_embedding_basic PASSED [ 78%]
tests/unit/strategies/late_chunking/test_document_embedder.py::test_token_embeddings_extracted PASSED [ 78%]
tests/unit/strategies/late_chunking/test_document_embedder.py::test_mean_pooling PASSED [ 79%]
tests/unit/strategies/late_chunking/test_document_embedder.py::test_mean_pooling_with_mask PASSED [ 79%]
tests/unit/strategies/late_chunking/test_document_embedder.py::test_long_document_truncation PASSED [ 79%]
tests/unit/strategies/late_chunking/test_document_embedder.py::test_batch_processing PASSED [ 79%]
tests/unit/strategies/late_chunking/test_document_embedder.py::test_embedding_dimensions_consistent PASSED [ 79%]
tests/unit/strategies/late_chunking/test_document_embedder.py::test_model_name_stored PASSED [ 79%]
tests/unit/strategies/late_chunking/test_document_embedder.py::test_chunk_embeddings PASSED [ 79%]
tests/unit/strategies/late_chunking/test_document_embedder.py::test_pool_embeddings_mean PASSED [ 79%]
tests/unit/strategies/late_chunking/test_document_embedder.py::test_pool_embeddings_max PASSED [ 79%]
tests/unit/strategies/late_chunking/test_document_embedder.py::test_pool_embeddings_first PASSED [ 79%]
tests/unit/strategies/late_chunking/test_document_embedder.py::test_decode_tokens PASSED [ 79%]
tests/unit/strategies/late_chunking/test_embedding_chunker.py::test_fixed_size_chunking PASSED [ 79%]
tests/unit/strategies/late_chunking/test_embedding_chunker.py::test_semantic_boundary_chunking PASSED [ 79%]
tests/unit/strategies/late_chunking/test_embedding_chunker.py::test_adaptive_chunking PASSED [ 79%]
tests/unit/strategies/late_chunking/test_embedding_chunker.py::test_chunk_text_reconstruction PASSED [ 79%]
tests/unit/strategies/late_chunking/test_embedding_chunker.py::test_chunk_embedding_averaging PASSED [ 79%]
tests/unit/strategies/late_chunking/test_embedding_chunker.py::test_cosine_similarity PASSED [ 79%]
tests/unit/strategies/late_chunking/test_embedding_chunker.py::test_cosine_similarity_zero_vectors PASSED [ 79%]
tests/unit/strategies/late_chunking/test_embedding_chunker.py::test_chunk_overlap PASSED [ 79%]
tests/unit/strategies/late_chunking/test_embedding_chunker.py::test_chunk_ids_unique PASSED [ 79%]
tests/unit/strategies/late_chunking/test_embedding_chunker.py::test_detect_semantic_boundaries PASSED [ 79%]
tests/unit/strategies/late_chunking/test_embedding_chunker.py::test_hierarchical_chunking_fallback PASSED [ 80%]
tests/unit/strategies/late_chunking/test_embedding_chunker.py::test_chunk_metadata PASSED [ 80%]
tests/unit/strategies/multi_query/test_deduplicator.py::test_exact_deduplication PASSED [ 80%]
tests/unit/strategies/multi_query/test_deduplicator.py::test_frequency_tracking PASSED [ 80%]
tests/unit/strategies/multi_query/test_deduplicator.py::test_max_score_retention PASSED [ 80%]
tests/unit/strategies/multi_query/test_deduplicator.py::test_skip_failed_queries PASSED [ 80%]
tests/unit/strategies/multi_query/test_deduplicator.py::test_empty_results PASSED [ 80%]
tests/unit/strategies/multi_query/test_deduplicator.py::test_variant_indices_tracking PASSED [ 80%]
tests/unit/strategies/multi_query/test_deduplicator.py::test_near_duplicate_detection PASSED [ 80%]
tests/unit/strategies/multi_query/test_parallel_executor.py::test_execute_queries_parallel PASSED [ 80%]
tests/unit/strategies/multi_query/test_parallel_executor.py::test_execute_single_query PASSED [ 80%]
tests/unit/strategies/multi_query/test_parallel_executor.py::test_query_timeout_handling PASSED [ 80%]
tests/unit/strategies/multi_query/test_parallel_executor.py::test_partial_failure_handling PASSED [ 80%]
tests/unit/strategies/multi_query/test_parallel_executor.py::test_minimum_successful_queries PASSED [ 80%]
tests/unit/strategies/multi_query/test_parallel_executor.py::test_sync_vector_store_support PASSED [ 80%]
tests/unit/strategies/multi_query/test_ranker.py::test_rank_by_max_score PASSED [ 80%]
tests/unit/strategies/multi_query/test_ranker.py::test_rank_by_frequency_boost PASSED [ 80%]
tests/unit/strategies/multi_query/test_ranker.py::test_rank_by_rrf PASSED [ 80%]
tests/unit/strategies/multi_query/test_ranker.py::test_top_k_selection PASSED [ 80%]
tests/unit/strategies/multi_query/test_ranker.py::test_empty_results PASSED [ 80%]
tests/unit/strategies/multi_query/test_ranker.py::test_hybrid_ranking PASSED [ 80%]
tests/unit/strategies/multi_query/test_ranker.py::test_ranking_preserves_metadata PASSED [ 80%]
tests/unit/strategies/multi_query/test_variant_generator.py::test_generate_variants_basic PASSED [ 81%]
tests/unit/strategies/multi_query/test_variant_generator.py::test_generate_variants_include_original PASSED [ 81%]
tests/unit/strategies/multi_query/test_variant_generator.py::test_generate_variants_exclude_original PASSED [ 81%]
tests/unit/strategies/multi_query/test_variant_generator.py::test_variant_validation PASSED [ 81%]
tests/unit/strategies/multi_query/test_variant_generator.py::test_variant_generation_failure_fallback PASSED [ 81%]
tests/unit/strategies/multi_query/test_variant_generator.py::test_variant_deduplication PASSED [ 81%]
tests/unit/strategies/multi_query/test_variant_generator.py::test_variant_generation_with_complete_method PASSED [ 81%]
tests/unit/strategies/query_expansion/test_base.py::TestExpansionStrategy::test_strategy_values PASSED [ 81%]
tests/unit/strategies/query_expansion/test_base.py::TestExpandedQuery::test_expanded_query_creation PASSED [ 81%]
tests/unit/strategies/query_expansion/test_base.py::TestExpandedQuery::test_expanded_query_with_reasoning PASSED [ 81%]
tests/unit/strategies/query_expansion/test_base.py::TestExpandedQuery::test_expanded_query_with_metadata PASSED [ 81%]
tests/unit/strategies/query_expansion/test_base.py::TestExpansionConfig::test_default_config PASSED [ 81%]
tests/unit/strategies/query_expansion/test_base.py::TestExpansionConfig::test_custom_config PASSED [ 81%]
tests/unit/strategies/query_expansion/test_base.py::TestIQueryExpander::test_validate_query_empty PASSED [ 81%]
tests/unit/strategies/query_expansion/test_base.py::TestIQueryExpander::test_validate_query_whitespace PASSED [ 81%]
tests/unit/strategies/query_expansion/test_base.py::TestIQueryExpander::test_validate_query_too_long PASSED [ 81%]
tests/unit/strategies/query_expansion/test_base.py::TestIQueryExpander::test_validate_query_valid PASSED [ 81%]
tests/unit/strategies/query_expansion/test_base.py::TestIQueryExpander::test_extract_added_terms PASSED [ 81%]
tests/unit/strategies/query_expansion/test_base.py::TestIQueryExpander::test_extract_added_terms_no_additions PASSED [ 81%]
tests/unit/strategies/query_expansion/test_base.py::TestIQueryExpander::test_expand_mock PASSED [ 81%]
tests/unit/strategies/query_expansion/test_expander_service.py::TestQueryExpanderService::test_service_initialization PASSED [ 81%]
tests/unit/strategies/query_expansion/test_expander_service.py::TestQueryExpanderService::test_service_initialization_without_cache PASSED [ 82%]
tests/unit/strategies/query_expansion/test_expander_service.py::TestQueryExpanderService::test_expand_basic PASSED [ 82%]
tests/unit/strategies/query_expansion/test_expander_service.py::TestQueryExpanderService::test_expand_with_cache_hit PASSED [ 82%]
tests/unit/strategies/query_expansion/test_expander_service.py::TestQueryExpanderService::test_expand_disabled PASSED [ 82%]
tests/unit/strategies/query_expansion/test_expander_service.py::TestQueryExpanderService::test_expand_with_error_fallback PASSED [ 82%]
tests/unit/strategies/query_expansion/test_expander_service.py::TestQueryExpanderService::test_multiple_variants PASSED [ 82%]
tests/unit/strategies/query_expansion/test_expander_service.py::TestQueryExpanderService::test_get_stats PASSED [ 82%]
tests/unit/strategies/query_expansion/test_expander_service.py::TestQueryExpanderService::test_clear_cache PASSED [ 82%]
tests/unit/strategies/query_expansion/test_expander_service.py::TestQueryExpanderService::test_execution_time_tracked PASSED [ 82%]
tests/unit/strategies/query_expansion/test_expander_service.py::TestQueryExpanderService::test_stats_average_execution_time PASSED [ 82%]
tests/unit/strategies/query_expansion/test_expander_service.py::TestQueryExpanderService::test_cache_key_computation PASSED [ 82%]
tests/unit/strategies/query_expansion/test_expander_service.py::TestQueryExpanderService::test_passthrough_result_metadata PASSED [ 82%]
tests/unit/strategies/query_expansion/test_expander_service.py::TestQueryExpanderService::test_hyde_expander_used_for_hyde_strategy PASSED [ 82%]
tests/unit/strategies/query_expansion/test_expander_service.py::TestQueryExpanderService::test_llm_expander_used_for_other_strategies PASSED [ 82%]
tests/unit/strategies/query_expansion/test_llm_expander.py::TestLLMQueryExpander::test_initialization PASSED [ 82%]
tests/unit/strategies/query_expansion/test_llm_expander.py::TestLLMQueryExpander::test_expand_query PASSED [ 82%]
tests/unit/strategies/query_expansion/test_llm_expander.py::TestLLMQueryExpander::test_expand_calls_llm_with_correct_params PASSED [ 82%]
tests/unit/strategies/query_expansion/test_llm_expander.py::TestLLMQueryExpander::test_validate_query_empty PASSED [ 82%]
tests/unit/strategies/query_expansion/test_llm_expander.py::TestLLMQueryExpander::test_validate_query_too_long PASSED [ 82%]
tests/unit/strategies/query_expansion/test_llm_expander.py::TestLLMQueryExpander::test_extract_added_terms PASSED [ 82%]
tests/unit/strategies/query_expansion/test_llm_expander.py::TestLLMQueryExpander::test_expand_with_domain_context PASSED [ 82%]
tests/unit/strategies/query_expansion/test_llm_expander.py::TestLLMQueryExpander::test_different_expansion_strategies PASSED [ 82%]
tests/unit/strategies/query_expansion/test_llm_expander.py::TestLLMQueryExpander::test_metadata_includes_token_info PASSED [ 83%]
tests/unit/strategies/query_expansion/test_llm_expander.py::TestLLMQueryExpander::test_llm_response_trimmed PASSED [ 83%]
tests/unit/strategies/query_expansion/test_llm_expander.py::TestLLMQueryExpander::test_confidence_is_one PASSED [ 83%]
tests/unit/strategies/query_expansion/test_prompts.py::TestExpansionPrompts::test_initialization PASSED [ 83%]
tests/unit/strategies/query_expansion/test_prompts.py::TestExpansionPrompts::test_get_system_prompt_keyword PASSED [ 83%]
tests/unit/strategies/query_expansion/test_prompts.py::TestExpansionPrompts::test_get_system_prompt_reformulation PASSED [ 83%]
tests/unit/strategies/query_expansion/test_prompts.py::TestExpansionPrompts::test_get_system_prompt_question_generation PASSED [ 83%]
tests/unit/strategies/query_expansion/test_prompts.py::TestExpansionPrompts::test_get_system_prompt_multi_query PASSED [ 83%]
tests/unit/strategies/query_expansion/test_prompts.py::TestExpansionPrompts::test_get_system_prompt_hyde PASSED [ 83%]
tests/unit/strategies/query_expansion/test_prompts.py::TestExpansionPrompts::test_custom_system_prompt PASSED [ 83%]
tests/unit/strategies/query_expansion/test_prompts.py::TestExpansionPrompts::test_get_user_prompt_keyword PASSED [ 83%]
tests/unit/strategies/query_expansion/test_prompts.py::TestExpansionPrompts::test_get_user_prompt_reformulation PASSED [ 83%]
tests/unit/strategies/query_expansion/test_prompts.py::TestExpansionPrompts::test_get_user_prompt_question_generation PASSED [ 83%]
tests/unit/strategies/query_expansion/test_prompts.py::TestExpansionPrompts::test_get_user_prompt_multi_query PASSED [ 83%]
tests/unit/strategies/query_expansion/test_prompts.py::TestExpansionPrompts::test_get_user_prompt_hyde PASSED [ 83%]
tests/unit/strategies/reranking/test_base.py::TestRerankConfig::test_default_config PASSED [ 83%]
tests/unit/strategies/reranking/test_base.py::TestRerankConfig::test_custom_config PASSED [ 83%]
tests/unit/strategies/reranking/test_base.py::TestRerankResult::test_rerank_result_creation PASSED [ 83%]
tests/unit/strategies/reranking/test_base.py::TestRerankResponse::test_rerank_response_creation PASSED [ 83%]
tests/unit/strategies/reranking/test_base.py::TestRerankResponse::test_rerank_response_with_metadata PASSED [ 83%]
tests/unit/strategies/reranking/test_base.py::TestIReranker::test_normalize_scores_basic PASSED [ 83%]
tests/unit/strategies/reranking/test_base.py::TestIReranker::test_normalize_scores_empty PASSED [ 84%]
tests/unit/strategies/reranking/test_base.py::TestIReranker::test_normalize_scores_all_same PASSED [ 84%]
tests/unit/strategies/reranking/test_base.py::TestIReranker::test_validate_inputs_empty_query PASSED [ 84%]
tests/unit/strategies/reranking/test_base.py::TestIReranker::test_validate_inputs_empty_documents PASSED [ 84%]
tests/unit/strategies/reranking/test_base.py::TestIReranker::test_validate_inputs_too_many_documents PASSED [ 84%]
tests/unit/strategies/reranking/test_base.py::TestIReranker::test_validate_inputs_valid PASSED [ 84%]
tests/unit/strategies/reranking/test_base.py::TestIReranker::test_mock_reranker_rerank PASSED [ 84%]
tests/unit/strategies/reranking/test_base.py::TestIReranker::test_mock_reranker_get_model_name PASSED [ 84%]
tests/unit/strategies/reranking/test_cache.py::TestRerankCache::test_cache_initialization PASSED [ 84%]
tests/unit/strategies/reranking/test_cache.py::TestRerankCache::test_cache_set_and_get PASSED [ 84%]
tests/unit/strategies/reranking/test_cache.py::TestRerankCache::test_cache_miss PASSED [ 84%]
tests/unit/strategies/reranking/test_cache.py::TestRerankCache::test_cache_hit PASSED [ 84%]
tests/unit/strategies/reranking/test_cache.py::TestRerankCache::test_cache_expiration PASSED [ 84%]
tests/unit/strategies/reranking/test_cache.py::TestRerankCache::test_cache_clear PASSED [ 84%]
tests/unit/strategies/reranking/test_cache.py::TestRerankCache::test_evict_expired PASSED [ 84%]
tests/unit/strategies/reranking/test_cache.py::TestRerankCache::test_cache_stats PASSED [ 84%]
tests/unit/strategies/reranking/test_cache.py::TestRerankCache::test_cache_hit_rate PASSED [ 84%]
tests/unit/strategies/reranking/test_cache.py::TestRerankCache::test_compute_key_static PASSED [ 84%]
tests/unit/strategies/reranking/test_cache.py::TestRerankCache::test_compute_key_document_order PASSED [ 84%]
tests/unit/strategies/reranking/test_cache.py::TestRerankCache::test_multiple_entries PASSED [ 84%]
tests/unit/strategies/reranking/test_cache.py::TestRerankCache::test_cache_overwrite PASSED [ 84%]
tests/unit/strategies/reranking/test_cosine_reranker.py::TestCosineRerankerInitialization::test_initialization_success PASSED [ 85%]
tests/unit/strategies/reranking/test_cosine_reranker.py::TestCosineRerankerInitialization::test_initialization_without_embedder PASSED [ 85%]
tests/unit/strategies/reranking/test_cosine_reranker.py::TestCosineRerankerInitialization::test_initialization_invalid_metric PASSED [ 85%]
tests/unit/strategies/reranking/test_cosine_reranker.py::TestCosineRerankerInitialization::test_supported_metrics PASSED [ 85%]
tests/unit/strategies/reranking/test_cosine_reranker.py::TestCosineRerankerReranking::test_rerank_cosine_similarity PASSED [ 85%]
tests/unit/strategies/reranking/test_cosine_reranker.py::TestCosineRerankerReranking::test_rerank_dot_product PASSED [ 85%]
tests/unit/strategies/reranking/test_cosine_reranker.py::TestCosineRerankerReranking::test_rerank_euclidean_similarity PASSED [ 85%]
tests/unit/strategies/reranking/test_cosine_reranker.py::TestCosineRerankerReranking::test_rerank_empty_documents PASSED [ 85%]
tests/unit/strategies/reranking/test_cosine_reranker.py::TestCosineRerankerReranking::test_rerank_empty_query PASSED [ 85%]
tests/unit/strategies/reranking/test_cosine_reranker.py::TestCosineRerankerReranking::test_rerank_with_normalization PASSED [ 85%]
tests/unit/strategies/reranking/test_cosine_reranker.py::TestCosineRerankerNormalization::test_normalize_vector PASSED [ 85%]
tests/unit/strategies/reranking/test_cosine_reranker.py::TestCosineRerankerNormalization::test_normalize_zero_vector PASSED [ 85%]
tests/unit/strategies/reranking/test_cosine_reranker.py::TestCosineRerankerNormalization::test_normalize_batch PASSED [ 85%]
tests/unit/strategies/reranking/test_cosine_reranker.py::TestCosineRerankerModelName::test_get_model_name_cosine PASSED [ 85%]
tests/unit/strategies/reranking/test_cosine_reranker.py::TestCosineRerankerModelName::test_get_model_name_dot PASSED [ 85%]
tests/unit/strategies/reranking/test_cosine_reranker.py::TestCosineRerankerModelName::test_get_model_name_euclidean PASSED [ 85%]
tests/unit/strategies/reranking/test_cosine_reranker.py::TestCosineRerankerPerformance::test_large_batch_processing PASSED [ 85%]
tests/unit/strategies/reranking/test_cross_encoder_reranker.py::TestCrossEncoderReranker::test_initialization SKIPPED [ 85%]
tests/unit/strategies/reranking/test_cross_encoder_reranker.py::TestCrossEncoderReranker::test_initialization_with_cuda SKIPPED [ 85%]
tests/unit/strategies/reranking/test_cross_encoder_reranker.py::TestCrossEncoderReranker::test_rerank_basic SKIPPED [ 85%]
tests/unit/strategies/reranking/test_cross_encoder_reranker.py::TestCrossEncoderReranker::test_rerank_batching SKIPPED [ 85%]
tests/unit/strategies/reranking/test_cross_encoder_reranker.py::TestCrossEncoderReranker::test_validate_empty_query SKIPPED [ 85%]
tests/unit/strategies/reranking/test_cross_encoder_reranker.py::TestCrossEncoderReranker::test_validate_empty_documents SKIPPED [ 86%]
tests/unit/strategies/reranking/test_cross_encoder_reranker.py::TestCrossEncoderReranker::test_validate_too_many_documents SKIPPED [ 86%]
tests/unit/strategies/reranking/test_cross_encoder_reranker.py::TestCrossEncoderReranker::test_get_model_name SKIPPED [ 86%]
tests/unit/strategies/reranking/test_cross_encoder_reranker.py::TestCrossEncoderReranker::test_model_name_shortcut SKIPPED [ 86%]
tests/unit/strategies/reranking/test_cross_encoder_reranker.py::test_import_error_without_dependencies PASSED [ 86%]
tests/unit/strategies/reranking/test_metrics.py::TestDCG::test_dcg_basic PASSED [ 86%]
tests/unit/strategies/reranking/test_metrics.py::TestDCG::test_dcg_empty PASSED [ 86%]
tests/unit/strategies/reranking/test_metrics.py::TestDCG::test_dcg_at_k_limits PASSED [ 86%]
tests/unit/strategies/reranking/test_metrics.py::TestNDCG::test_ndcg_perfect_ranking PASSED [ 86%]
tests/unit/strategies/reranking/test_metrics.py::TestNDCG::test_ndcg_worst_ranking PASSED [ 86%]
tests/unit/strategies/reranking/test_metrics.py::TestNDCG::test_ndcg_empty PASSED [ 86%]
tests/unit/strategies/reranking/test_metrics.py::TestNDCG::test_ndcg_all_zeros PASSED [ 86%]
tests/unit/strategies/reranking/test_metrics.py::TestNDCG::test_ndcg_range PASSED [ 86%]
tests/unit/strategies/reranking/test_metrics.py::TestMRR::test_mrr_first_position PASSED [ 86%]
tests/unit/strategies/reranking/test_metrics.py::TestMRR::test_mrr_second_position PASSED [ 86%]
tests/unit/strategies/reranking/test_metrics.py::TestMRR::test_mrr_third_position PASSED [ 86%]
tests/unit/strategies/reranking/test_metrics.py::TestMRR::test_mrr_multiple_positions PASSED [ 86%]
tests/unit/strategies/reranking/test_metrics.py::TestMRR::test_mrr_empty PASSED [ 86%]
tests/unit/strategies/reranking/test_metrics.py::TestPrecisionAtK::test_precision_all_relevant PASSED [ 86%]
tests/unit/strategies/reranking/test_metrics.py::TestPrecisionAtK::test_precision_none_relevant PASSED [ 86%]
tests/unit/strategies/reranking/test_metrics.py::TestPrecisionAtK::test_precision_half_relevant PASSED [ 86%]
tests/unit/strategies/reranking/test_metrics.py::TestPrecisionAtK::test_precision_at_k_limits PASSED [ 87%]
tests/unit/strategies/reranking/test_metrics.py::TestPrecisionAtK::test_precision_empty PASSED [ 87%]
tests/unit/strategies/reranking/test_metrics.py::TestRecallAtK::test_recall_all_found PASSED [ 87%]
tests/unit/strategies/reranking/test_metrics.py::TestRecallAtK::test_recall_partial_found PASSED [ 87%]
tests/unit/strategies/reranking/test_metrics.py::TestRecallAtK::test_recall_at_k_limits PASSED [ 87%]
tests/unit/strategies/reranking/test_metrics.py::TestRecallAtK::test_recall_empty PASSED [ 87%]
tests/unit/strategies/reranking/test_metrics.py::TestCompareRankings::test_compare_improved_ranking PASSED [ 87%]
tests/unit/strategies/reranking/test_metrics.py::TestCompareRankings::test_compare_same_ranking PASSED [ 87%]
tests/unit/strategies/reranking/test_metrics.py::TestCompareRankings::test_compare_empty PASSED [ 87%]
tests/unit/strategies/reranking/test_metrics.py::TestRankingCorrelation::test_correlation_identical PASSED [ 87%]
tests/unit/strategies/reranking/test_metrics.py::TestRankingCorrelation::test_correlation_reversed PASSED [ 87%]
tests/unit/strategies/reranking/test_metrics.py::TestRankingCorrelation::test_correlation_different_lengths PASSED [ 87%]
tests/unit/strategies/reranking/test_metrics.py::TestRankingCorrelation::test_correlation_empty PASSED [ 87%]
tests/unit/strategies/reranking/test_metrics.py::TestRankingCorrelation::test_correlation_single_item PASSED [ 87%]
tests/unit/strategies/reranking/test_metrics.py::TestRankingAnalyzer::test_analyzer_initialization PASSED [ 87%]
tests/unit/strategies/reranking/test_metrics.py::TestRankingAnalyzer::test_analyzer_add_ranking PASSED [ 87%]
tests/unit/strategies/reranking/test_metrics.py::TestRankingAnalyzer::test_analyzer_multiple_rankings PASSED [ 87%]
tests/unit/strategies/reranking/test_metrics.py::TestRankingAnalyzer::test_analyzer_improvement_rate PASSED [ 87%]
tests/unit/strategies/reranking/test_metrics.py::TestRankingAnalyzer::test_analyzer_clear PASSED [ 87%]
tests/unit/strategies/reranking/test_metrics.py::TestRankingAnalyzer::test_analyzer_average_metrics PASSED [ 87%]
tests/unit/strategies/reranking/test_reranker_selector.py::TestRerankerSelectorAvailability::test_is_cohere_available_with_key_and_package PASSED [ 87%]
tests/unit/strategies/reranking/test_reranker_selector.py::TestRerankerSelectorAvailability::test_is_cohere_available_no_key PASSED [ 88%]
tests/unit/strategies/reranking/test_reranker_selector.py::TestRerankerSelectorAvailability::test_is_cohere_available_with_env_key PASSED [ 88%]
tests/unit/strategies/reranking/test_reranker_selector.py::TestRerankerSelectorAvailability::test_is_torch_available_true PASSED [ 88%]
tests/unit/strategies/reranking/test_reranker_selector.py::TestRerankerSelectorAvailability::test_is_torch_available_false PASSED [ 88%]
tests/unit/strategies/reranking/test_reranker_selector.py::TestRerankerSelectorAvailability::test_get_available_rerankers PASSED [ 88%]
tests/unit/strategies/reranking/test_reranker_selector.py::TestRerankerSelectorAutoSelection::test_auto_select_cohere_when_available PASSED [ 88%]
tests/unit/strategies/reranking/test_reranker_selector.py::TestRerankerSelectorAutoSelection::test_auto_select_cosine_when_cohere_unavailable PASSED [ 88%]
tests/unit/strategies/reranking/test_reranker_selector.py::TestRerankerSelectorAutoSelection::test_auto_select_with_custom_config PASSED [ 88%]
tests/unit/strategies/reranking/test_reranker_selector.py::TestRerankerSelectorManualSelection::test_manual_select_cohere PASSED [ 88%]
tests/unit/strategies/reranking/test_reranker_selector.py::TestRerankerSelectorManualSelection::test_manual_select_cosine PASSED [ 88%]
tests/unit/strategies/reranking/test_reranker_selector.py::TestRerankerSelectorManualSelection::test_manual_select_bge_with_torch PASSED [ 88%]
tests/unit/strategies/reranking/test_reranker_selector.py::TestRerankerSelectorManualSelection::test_manual_select_bge_without_torch PASSED [ 88%]
tests/unit/strategies/reranking/test_reranker_selector.py::TestRerankerSelectorManualSelection::test_manual_select_cross_encoder_with_torch PASSED [ 88%]
tests/unit/strategies/reranking/test_reranker_selector.py::TestRerankerSelectorManualSelection::test_manual_select_cross_encoder_without_torch PASSED [ 88%]
tests/unit/strategies/reranking/test_reranker_selector.py::TestRerankerSelectorManualSelection::test_manual_select_unknown_type PASSED [ 88%]
tests/unit/strategies/reranking/test_reranker_selector.py::TestRerankerSelectorErrorMessages::test_cohere_error_message_suggests_alternatives PASSED [ 88%]
tests/unit/strategies/reranking/test_reranker_selector.py::TestRerankerSelectorErrorMessages::test_bge_error_message_suggests_alternatives PASSED [ 88%]
tests/unit/strategies/reranking/test_reranker_selector.py::TestRerankerSelectorErrorMessages::test_cross_encoder_error_message_suggests_alternatives PASSED [ 88%]
tests/unit/strategies/reranking/test_reranker_selector.py::TestRerankerSelectorConfiguration::test_config_api_key_overrides_env PASSED [ 88%]
tests/unit/strategies/reranking/test_reranker_selector.py::TestRerankerSelectorConfiguration::test_cosine_metric_configuration PASSED [ 88%]
tests/unit/strategies/reranking/test_reranker_service.py::TestCandidateDocument::test_candidate_creation PASSED [ 88%]
tests/unit/strategies/reranking/test_reranker_service.py::TestCandidateDocument::test_candidate_default_metadata PASSED [ 88%]
tests/unit/strategies/reranking/test_reranker_service.py::TestRerankerService::test_service_initialization PASSED [ 89%]
tests/unit/strategies/reranking/test_reranker_service.py::TestRerankerService::test_service_without_cache PASSED [ 89%]
tests/unit/strategies/reranking/test_reranker_service.py::TestRerankerService::test_rerank_basic PASSED [ 89%]
tests/unit/strategies/reranking/test_reranker_service.py::TestRerankerService::test_rerank_empty_candidates PASSED [ 89%]
tests/unit/strategies/reranking/test_reranker_service.py::TestRerankerService::test_rerank_top_k_limit PASSED [ 89%]
tests/unit/strategies/reranking/test_reranker_service.py::TestRerankerService::test_cache_hit PASSED [ 89%]
tests/unit/strategies/reranking/test_reranker_service.py::TestRerankerService::test_cache_disabled PASSED [ 89%]
tests/unit/strategies/reranking/test_reranker_service.py::TestRerankerService::test_score_threshold PASSED [ 89%]
tests/unit/strategies/reranking/test_reranker_service.py::TestRerankerService::test_fallback_on_error PASSED [ 89%]
tests/unit/strategies/reranking/test_reranker_service.py::TestRerankerService::test_no_fallback_raises_error PASSED [ 89%]
tests/unit/strategies/reranking/test_reranker_service.py::TestRerankerService::test_get_stats PASSED [ 89%]
tests/unit/strategies/reranking/test_reranker_service.py::TestRerankerService::test_clear_cache PASSED [ 89%]
tests/unit/strategies/reranking/test_reranker_service.py::TestRerankerService::test_score_normalization PASSED [ 89%]
tests/unit/strategies/reranking/test_reranker_service.py::TestRerankerService::test_cohere_model_initialization PASSED [ 89%]
tests/unit/strategies/self_reflective/test_grader.py::test_grade_results PASSED [ 89%]
tests/unit/strategies/self_reflective/test_grader.py::test_grade_parsing PASSED [ 89%]
tests/unit/strategies/self_reflective/test_grader.py::test_batch_grading PASSED [ 89%]
tests/unit/strategies/self_reflective/test_grader.py::test_grade_fallback_on_parse_error PASSED [ 89%]
tests/unit/strategies/self_reflective/test_grader.py::test_grade_levels PASSED [ 89%]
tests/unit/strategies/self_reflective/test_grader.py::test_empty_results PASSED [ 89%]
tests/unit/strategies/self_reflective/test_grader.py::test_grading_error_handling PASSED [ 89%]
tests/unit/strategies/self_reflective/test_grader.py::test_build_grading_prompt PASSED [ 90%]
tests/unit/strategies/self_reflective/test_refiner.py::test_refine_query PASSED [ 90%]
tests/unit/strategies/self_reflective/test_refiner.py::test_identify_gaps PASSED [ 90%]
tests/unit/strategies/self_reflective/test_refiner.py::test_parse_refinement PASSED [ 90%]
tests/unit/strategies/self_reflective/test_refiner.py::test_refinement_with_previous_attempts PASSED [ 90%]
tests/unit/strategies/self_reflective/test_refiner.py::test_refinement_strategies PASSED [ 90%]
tests/unit/strategies/self_reflective/test_refiner.py::test_empty_grades PASSED [ 90%]
tests/unit/strategies/self_reflective/test_refiner.py::test_refinement_error_handling PASSED [ 90%]
tests/unit/strategies/self_reflective/test_refiner.py::test_build_refinement_prompt PASSED [ 90%]
tests/unit/strategies/self_reflective/test_strategy.py::test_retrieve_good_results_no_retry PASSED [ 90%]
tests/unit/strategies/self_reflective/test_strategy.py::test_retrieve_poor_results_triggers_retry PASSED [ 90%]
tests/unit/strategies/self_reflective/test_strategy.py::test_max_retries_enforced PASSED [ 90%]
tests/unit/strategies/self_reflective/test_strategy.py::test_result_aggregation PASSED [ 90%]
tests/unit/strategies/self_reflective/test_strategy.py::test_timeout_protection PASSED [ 90%]
tests/unit/strategies/self_reflective/test_strategy.py::test_same_query_prevention PASSED [ 90%]
tests/unit/strategies/self_reflective/test_strategy.py::test_normalize_results PASSED [ 90%]
tests/unit/strategies/self_reflective/test_strategy.py::test_strategy_properties PASSED [ 90%]
tests/unit/strategies/test_base.py::test_interface_is_abstract PASSED    [ 90%]
tests/unit/strategies/test_base.py::test_interface_requires_all_abstract_methods PASSED [ 90%]
tests/unit/strategies/test_base.py::test_strategy_config_defaults PASSED [ 90%]
tests/unit/strategies/test_base.py::test_strategy_config_custom_values PASSED [ 90%]
tests/unit/strategies/test_base.py::test_strategy_config_validation PASSED [ 91%]
tests/unit/strategies/test_base.py::test_chunk_creation PASSED           [ 91%]
tests/unit/strategies/test_base.py::test_chunk_serialization PASSED      [ 91%]
tests/unit/strategies/test_base.py::test_prepared_data_creation PASSED   [ 91%]
tests/unit/strategies/test_base.py::test_query_result_creation PASSED    [ 91%]
tests/unit/strategies/test_base.py::test_minimal_concrete_implementation PASSED [ 91%]
tests/unit/strategies/test_base.py::test_concrete_implementation_initialize PASSED [ 91%]
tests/unit/strategies/test_base.py::test_type_hints_present PASSED       [ 91%]
tests/unit/strategies/test_base.py::test_async_method_signature PASSED   [ 91%]
tests/unit/strategies/test_base.py::test_requires_services_type_hints PASSED [ 91%]
tests/unit/strategies/test_base.py::test_prepare_data_type_hints PASSED  [ 91%]
tests/unit/strategies/test_base.py::test_process_query_type_hints PASSED [ 91%]
tests/unit/strategies/test_base_strategy_di.py::TestBaseStrategyDI::test_strategy_with_all_required_services PASSED [ 91%]
tests/unit/strategies/test_base_strategy_di.py::TestBaseStrategyDI::test_strategy_fails_without_required_llm_service PASSED [ 91%]
tests/unit/strategies/test_base_strategy_di.py::TestBaseStrategyDI::test_strategy_fails_without_required_embedding_service PASSED [ 91%]
tests/unit/strategies/test_base_strategy_di.py::TestBaseStrategyDI::test_strategy_fails_with_no_services PASSED [ 91%]
tests/unit/strategies/test_base_strategy_di.py::TestBaseStrategyDI::test_error_message_is_clear_and_helpful PASSED [ 91%]
tests/unit/strategies/test_base_strategy_di.py::TestBaseStrategyDI::test_strategy_with_extra_unused_services PASSED [ 91%]
tests/unit/strategies/test_base_strategy_di.py::TestStrategyWithNoRequirements::test_strategy_with_no_service_requirements PASSED [ 91%]
tests/unit/strategies/test_base_strategy_di.py::TestStrategyWithNoRequirements::test_strategy_with_no_requirements_accepts_services PASSED [ 91%]
tests/unit/strategies/test_base_strategy_di.py::TestDifferentServiceCombinations::test_database_only_strategy PASSED [ 91%]
tests/unit/strategies/test_base_strategy_di.py::TestDifferentServiceCombinations::test_database_only_strategy_fails_without_database PASSED [ 91%]
tests/unit/test_config.py::test_load_from_yaml PASSED                    [ 92%]
tests/unit/test_config.py::test_load_from_json PASSED                    [ 92%]
tests/unit/test_config.py::test_load_from_dict PASSED                    [ 92%]
tests/unit/test_config.py::test_file_not_found_raises_error PASSED       [ 92%]
tests/unit/test_config.py::test_invalid_yaml_raises_error PASSED         [ 92%]
tests/unit/test_config.py::test_invalid_json_raises_error PASSED         [ 92%]
tests/unit/test_config.py::test_unsupported_file_format_raises_error PASSED [ 92%]
tests/unit/test_config.py::test_empty_yaml_loads_as_empty_dict PASSED    [ 92%]
tests/unit/test_config.py::test_validation_enforces_chunk_size_range PASSED [ 92%]
tests/unit/test_config.py::test_validation_enforces_chunk_size_max PASSED [ 92%]
tests/unit/test_config.py::test_validation_enforces_top_k_min PASSED     [ 92%]
tests/unit/test_config.py::test_validation_enforces_log_level PASSED     [ 92%]
tests/unit/test_config.py::test_validation_accepts_valid_log_levels PASSED [ 92%]
tests/unit/test_config.py::test_validation_normalizes_log_level_case PASSED [ 92%]
tests/unit/test_config.py::test_default_config_loaded PASSED             [ 92%]
tests/unit/test_config.py::test_user_config_merged_with_defaults PASSED  [ 92%]
tests/unit/test_config.py::test_get_strategy_config_returns_default PASSED [ 92%]
tests/unit/test_config.py::test_environment_from_env_variable PASSED     [ 92%]
tests/unit/test_config.py::test_environment_override_merges_correctly PASSED [ 92%]
tests/unit/test_config.py::test_environment_override_nonexistent_file PASSED [ 92%]
tests/unit/test_config.py::test_deep_merge_nested_dicts PASSED           [ 92%]
tests/unit/test_config.py::test_get_with_dot_notation PASSED             [ 93%]
tests/unit/test_config.py::test_get_missing_key_returns_default PASSED   [ 93%]
tests/unit/test_config.py::test_get_strategy_config PASSED               [ 93%]
tests/unit/test_config.py::test_get_before_load_raises_error PASSED      [ 93%]
tests/unit/test_config.py::test_to_dict_exports_config PASSED            [ 93%]
tests/unit/test_config.py::test_to_dict_before_load_raises_error PASSED  [ 93%]
tests/unit/test_config.py::test_config_property_returns_schema PASSED    [ 93%]
tests/unit/test_config.py::test_hot_reload_detects_file_changes PASSED   [ 93%]
tests/unit/test_config.py::test_hot_reload_without_config_path_raises_error PASSED [ 93%]
tests/unit/test_config.py::test_disable_hot_reload PASSED                [ 93%]
tests/unit/test_config.py::test_reload_method_reloads_config PASSED      [ 93%]
tests/unit/test_config.py::test_strategy_config_schema_defaults PASSED   [ 93%]
tests/unit/test_config.py::test_global_config_schema_defaults PASSED     [ 93%]
tests/unit/test_config.py::test_pipeline_config_schema_defaults PASSED   [ 93%]
tests/unit/test_config.py::test_rag_config_schema_defaults PASSED        [ 93%]
tests/unit/test_config.py::test_config_manager_singleton PASSED          [ 93%]
tests/unit/test_config.py::test_config_file_handler_initialization PASSED [ 93%]
tests/unit/test_factory.py::test_factory_can_be_created PASSED           [ 93%]
tests/unit/test_factory.py::test_factory_has_empty_registry_initially PASSED [ 93%]
tests/unit/test_factory.py::test_register_strategy_adds_to_registry PASSED [ 93%]
tests/unit/test_factory.py::test_register_duplicate_raises_error PASSED  [ 93%]
tests/unit/test_factory.py::test_register_duplicate_with_override PASSED [ 94%]
tests/unit/test_factory.py::test_unregister_strategy PASSED              [ 94%]
tests/unit/test_factory.py::test_unregister_nonexistent_strategy PASSED  [ 94%]
tests/unit/test_factory.py::test_list_strategies_returns_all_names PASSED [ 94%]
tests/unit/test_factory.py::test_create_strategy_returns_instance PASSED [ 94%]
tests/unit/test_factory.py::test_create_unknown_strategy_raises_error PASSED [ 94%]
tests/unit/test_factory.py::test_create_strategy_with_config PASSED      [ 94%]
tests/unit/test_factory.py::test_strategy_not_found_error_message_includes_available PASSED [ 94%]
tests/unit/test_factory.py::test_create_strategy_without_config PASSED   [ 94%]
tests/unit/test_factory.py::test_invalid_config_raises_error PASSED      [ 94%]
tests/unit/test_factory.py::test_strategy_initialization_error_propagates PASSED [ 94%]
tests/unit/test_factory.py::test_register_decorator_auto_registers PASSED [ 94%]
tests/unit/test_factory.py::test_decorator_returns_class_unchanged PASSED [ 94%]
tests/unit/test_factory.py::test_create_from_yaml_config PASSED          [ 94%]
tests/unit/test_factory.py::test_create_from_json_config PASSED          [ 94%]
tests/unit/test_factory.py::test_create_from_nonexistent_config_file PASSED [ 94%]
tests/unit/test_factory.py::test_create_from_invalid_yaml PASSED         [ 94%]
tests/unit/test_factory.py::test_create_from_config_missing_strategy_name PASSED [ 94%]
tests/unit/test_factory.py::test_set_dependency PASSED                   [ 94%]
tests/unit/test_factory.py::test_get_dependency PASSED                   [ 94%]
tests/unit/test_factory.py::test_get_nonexistent_dependency PASSED       [ 94%]
tests/unit/test_factory.py::test_registry_is_class_level PASSED          [ 94%]
tests/unit/test_factory.py::test_create_from_unsupported_file_format PASSED [ 95%]
tests/unit/test_factory.py::test_clear_registry PASSED                   [ 95%]
tests/unit/test_factory.py::test_clear_dependencies PASSED               [ 95%]
tests/unit/test_factory_di.py::test_factory_initialization_with_no_services PASSED [ 95%]
tests/unit/test_factory_di.py::test_factory_initialization_with_llm_service PASSED [ 95%]
tests/unit/test_factory_di.py::test_factory_initialization_with_all_services PASSED [ 95%]
tests/unit/test_factory_di.py::test_factory_initialization_with_partial_services PASSED [ 95%]
tests/unit/test_factory_di.py::test_create_strategy_with_required_services PASSED [ 95%]
tests/unit/test_factory_di.py::test_create_strategy_without_required_services PASSED [ 95%]
tests/unit/test_factory_di.py::test_create_strategy_with_partial_services PASSED [ 95%]
tests/unit/test_factory_di.py::test_create_strategy_with_no_service_requirements PASSED [ 95%]
tests/unit/test_factory_di.py::test_create_database_only_strategy PASSED [ 95%]
tests/unit/test_factory_di.py::test_create_strategy_with_extra_services PASSED [ 95%]
tests/unit/test_factory_di.py::test_create_strategy_with_override_dependencies PASSED [ 95%]
tests/unit/test_factory_di.py::test_override_dependencies_can_add_missing_services PASSED [ 95%]
tests/unit/test_factory_di.py::test_override_dependencies_still_validates_requirements PASSED [ 95%]
tests/unit/test_factory_di.py::test_error_message_includes_strategy_name PASSED [ 95%]
tests/unit/test_factory_di.py::test_error_message_lists_missing_services PASSED [ 95%]
tests/unit/test_factory_di.py::test_create_strategy_without_config PASSED [ 95%]
tests/unit/test_factory_di.py::test_create_strategy_with_config PASSED   [ 95%]
tests/unit/test_factory_di.py::test_create_from_config_with_dependencies PASSED [ 95%]
tests/unit/test_factory_di.py::test_multiple_strategies_with_same_factory PASSED [ 96%]
tests/unit/test_factory_di.py::test_class_level_dependencies_still_exist PASSED [ 96%]
tests/unit/test_factory_di.py::test_set_and_get_dependency_still_work PASSED [ 96%]
tests/unit/test_factory_di.py::test_legacy_create_strategy_method_exists PASSED [ 96%]
tests/unit/test_package.py::TestImports::test_import_main_package PASSED [ 96%]
tests/unit/test_package.py::TestImports::test_import_factory FAILED      [ 96%]
tests/unit/test_package.py::TestImports::test_import_pipeline FAILED     [ 96%]
tests/unit/test_package.py::TestImports::test_import_config FAILED       [ 96%]
tests/unit/test_package.py::TestImports::test_import_base_strategy PASSED [ 96%]
tests/unit/test_package.py::TestImports::test_import_all_exports PASSED  [ 96%]
tests/unit/test_package.py::TestVersion::test_version_format PASSED      [ 96%]
tests/unit/test_package.py::TestVersion::test_version_accessible PASSED  [ 96%]
tests/unit/test_package.py::TestPackageStructure::test_strategies_subpackage_exists PASSED [ 96%]
tests/unit/test_package.py::TestPackageStructure::test_no_circular_imports FAILED [ 96%]
tests/unit/test_package.py::TestDependencies::test_required_dependencies_installed PASSED [ 96%]
tests/unit/test_package.py::TestDependencies::test_optional_dependencies_handled FAILED [ 96%]
tests/unit/test_pipeline.py::test_pipeline_can_be_created PASSED         [ 96%]
tests/unit/test_pipeline.py::test_pipeline_add_stage PASSED              [ 96%]
tests/unit/test_pipeline.py::test_pipeline_chaining PASSED               [ 96%]
tests/unit/test_pipeline.py::test_sequential_execution_order PASSED      [ 96%]
tests/unit/test_pipeline.py::test_sequential_execution_collects_results PASSED [ 96%]
tests/unit/test_pipeline.py::test_parallel_execution PASSED              [ 97%]
tests/unit/test_pipeline.py::test_strategy_error_caught PASSED           [ 97%]
tests/unit/test_pipeline.py::test_fallback_strategy_executed PASSED      [ 97%]
tests/unit/test_pipeline.py::test_duplicate_results_removed PASSED       [ 97%]
tests/unit/test_pipeline.py::test_results_sorted_by_score PASSED         [ 97%]
tests/unit/test_pipeline.py::test_performance_metrics_collected PASSED   [ 97%]
tests/unit/test_pipeline.py::test_from_config_creates_pipeline PASSED    [ 97%]
tests/unit/test_pipeline.py::test_cascade_mode_not_implemented PASSED    [ 97%]
tests/unit/test_pipeline.py::test_cascade_mode_not_implemented_async PASSED [ 97%]
tests/unit/test_pipeline.py::test_required_stage_failure_raises_exception PASSED [ 97%]
tests/unit/test_pipeline.py::test_required_stage_failure_raises_exception_async PASSED [ 97%]
tests/unit/test_pipeline.py::test_fallback_failure_when_required PASSED  [ 97%]
tests/unit/test_pipeline.py::test_fallback_failure_when_required_async PASSED [ 97%]
tests/unit/test_pipeline.py::test_parallel_required_stage_failure PASSED [ 97%]
tests/unit/test_pipeline.py::test_parallel_required_fallback_failure PASSED [ 97%]
tests/unit/test_pipeline.py::test_non_required_fallback_failure_continues PASSED [ 97%]
tests/unit/test_pipeline.py::test_non_required_fallback_failure_continues_async PASSED [ 97%]
tests/unit/test_pipeline.py::test_parallel_non_required_fallback_success PASSED [ 97%]
tests/unit/test_pipeline.py::test_parallel_non_required_both_fail PASSED [ 97%]
tests/unit/utils/test_token_counter.py::TestTokenCounter::test_initialization PASSED [ 97%]
tests/unit/utils/test_token_counter.py::TestTokenCounter::test_count_messages PASSED [ 97%]
tests/unit/utils/test_token_counter.py::TestTokenCounter::test_count_messages_empty PASSED [ 97%]
tests/unit/utils/test_token_counter.py::TestTokenCounter::test_count_function_call PASSED [ 98%]
tests/unit/utils/test_token_counter.py::TestTokenCounter::test_count_function_call_complex_args PASSED [ 98%]
tests/unit/utils/test_token_counter.py::TestTokenBudget::test_initialization PASSED [ 98%]
tests/unit/utils/test_token_counter.py::TestTokenBudget::test_initialization_with_reserve PASSED [ 98%]
tests/unit/utils/test_token_counter.py::TestTokenBudget::test_add_text_within_budget PASSED [ 98%]
tests/unit/utils/test_token_counter.py::TestTokenBudget::test_add_text_exceeds_budget PASSED [ 98%]
tests/unit/utils/test_token_counter.py::TestTokenBudget::test_add_text_exact_budget PASSED [ 98%]
tests/unit/utils/test_token_counter.py::TestTokenBudget::test_add_texts PASSED [ 98%]
tests/unit/utils/test_token_counter.py::TestTokenBudget::test_add_texts_all_fit PASSED [ 98%]
tests/unit/utils/test_token_counter.py::TestTokenBudget::test_add_texts_none_fit PASSED [ 98%]
tests/unit/utils/test_token_counter.py::TestTokenBudget::test_remaining PASSED [ 98%]
tests/unit/utils/test_token_counter.py::TestTokenBudget::test_reset PASSED [ 98%]
tests/unit/utils/test_token_counter.py::TestTokenBudget::test_multiple_adds_and_reset PASSED [ 98%]
tests/unit/utils/test_token_counter.py::TestTokenBudget::test_budget_with_reserve PASSED [ 98%]
tests/unit/utils/test_token_counter.py::TestTokenBudgetEdgeCases::test_zero_budget PASSED [ 98%]
tests/unit/utils/test_token_counter.py::TestTokenBudgetEdgeCases::test_empty_text PASSED [ 98%]
tests/unit/utils/test_token_counter.py::TestTokenBudgetEdgeCases::test_reserve_equals_max PASSED [ 98%]
tests/unit/utils/test_token_counter.py::TestTokenBudgetEdgeCases::test_reserve_exceeds_max PASSED [ 98%]
tests/unit/utils/test_tokenization.py::TestTokenizer::test_initialization_with_encoding PASSED [ 98%]
tests/unit/utils/test_tokenization.py::TestTokenizer::test_initialization_with_model PASSED [ 98%]
tests/unit/utils/test_tokenization.py::TestTokenizer::test_default_initialization PASSED [ 98%]
tests/unit/utils/test_tokenization.py::TestTokenizer::test_encode_decode PASSED [ 99%]
tests/unit/utils/test_tokenization.py::TestTokenizer::test_count_tokens PASSED [ 99%]
tests/unit/utils/test_tokenization.py::TestTokenizer::test_truncate PASSED [ 99%]
tests/unit/utils/test_tokenization.py::TestTokenizer::test_truncate_no_truncation_needed PASSED [ 99%]
tests/unit/utils/test_tokenization.py::TestTokenizer::test_split_by_tokens PASSED [ 99%]
tests/unit/utils/test_tokenization.py::TestTokenizer::test_split_with_overlap PASSED [ 99%]
tests/unit/utils/test_tokenization.py::TestTokenizer::test_split_short_text PASSED [ 99%]
tests/unit/utils/test_tokenization.py::TestTokenizer::test_fallback_tokenization PASSED [ 99%]
tests/unit/utils/test_tokenization.py::TestTokenizer::test_no_fallback_raises_error PASSED [ 99%]
tests/unit/utils/test_tokenization.py::TestTokenizer::test_different_encodings PASSED [ 99%]
tests/unit/utils/test_tokenization.py::TestTokenizer::test_special_characters PASSED [ 99%]
tests/unit/utils/test_tokenization.py::TestTokenizer::test_empty_text PASSED [ 99%]
tests/unit/utils/test_tokenization.py::TestConvenienceFunctions::test_count_tokens PASSED [ 99%]
tests/unit/utils/test_tokenization.py::TestConvenienceFunctions::test_truncate_text PASSED [ 99%]
tests/unit/utils/test_tokenization.py::TestConvenienceFunctions::test_split_text_by_tokens PASSED [ 99%]
tests/unit/utils/test_tokenization.py::TestEncodingFunctions::test_get_encoding PASSED [ 99%]
tests/unit/utils/test_tokenization.py::TestEncodingFunctions::test_get_encoding_caching PASSED [ 99%]
tests/unit/utils/test_tokenization.py::TestEncodingFunctions::test_get_encoding_invalid PASSED [ 99%]
tests/unit/utils/test_tokenization.py::TestEncodingFunctions::test_get_encoding_for_model PASSED [ 99%]
tests/unit/utils/test_tokenization.py::TestEncodingFunctions::test_get_encoding_for_unknown_model PASSED [ 99%]
tests/unit/utils/test_tokenization.py::TestMultilingualSupport::test_multilingual_text PASSED [ 99%]
tests/unit/utils/test_tokenization.py::TestMultilingualSupport::test_mixed_language_text PASSED [100%]

=================================== FAILURES ===================================
____________ TestMigrationIntegration.test_real_migration_execution ____________

self = <sqlalchemy.engine.base.Connection object at 0x7129963d0c80>
dialect = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7129a8d48d40>
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x7129963753d0>
statement = <sqlalchemy.dialects.postgresql.base.PGCompiler object at 0x712996375490>
parameters = [{}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7129a8d48d40>
cursor = <cursor object at 0x7129a64747c0; closed: -1>
statement = 'DROP EXTENSION IF EXISTS vector', parameters = {}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x7129963753d0>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       psycopg2.errors.DependentObjectsStillExist: cannot drop extension vector because other objects depend on it
E       DETAIL:  column embedding of table test_chunks_real depends on type vector
E       HINT:  Use DROP ... CASCADE to drop the dependent objects too.

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: DependentObjectsStillExist

The above exception was the direct cause of the following exception:

self = <tests.integration.database.test_migration_integration.TestMigrationIntegration object at 0x7129c278e210>
alembic_config = <alembic.config.Config object at 0x7129963a58e0>
test_db_url = 'postgresql://rag_user:rag_password@192.168.56.1:5432/rag_test'

    @pytest.mark.asyncio
    async def test_real_migration_execution(self, alembic_config: Config, test_db_url: str) -> None:
        """Test running migrations against real database."""
        # Start from clean state
>       command.downgrade(alembic_config, "base")

tests/integration/database/test_migration_integration.py:29: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
venv/lib/python3.12/site-packages/alembic/command.py:449: in downgrade
    script.run_env()
venv/lib/python3.12/site-packages/alembic/script/base.py:583: in run_env
    util.load_python_file(self.dir, "env.py")
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:95: in load_python_file
    module = load_module_py(module_id, path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:113: in load_module_py
    spec.loader.exec_module(module)  # type: ignore
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
<frozen importlib._bootstrap_external>:995: in exec_module
    ???
<frozen importlib._bootstrap>:488: in _call_with_frames_removed
    ???
migrations/env.py:93: in <module>
    run_migrations_online()
migrations/env.py:87: in run_migrations_online
    context.run_migrations()
<string>:8: in run_migrations
    ???
venv/lib/python3.12/site-packages/alembic/runtime/environment.py:948: in run_migrations
    self.get_context().run_migrations(**kw)
venv/lib/python3.12/site-packages/alembic/runtime/migration.py:627: in run_migrations
    step.migration_fn(**kw)
migrations/versions/001_initial_schema.py:129: in downgrade
    op.execute("DROP EXTENSION IF EXISTS vector")
<string>:8: in execute
    ???
<string>:3: in execute
    ???
venv/lib/python3.12/site-packages/alembic/operations/ops.py:2537: in execute
    return operations.invoke(op)
           ^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/base.py:445: in invoke
    return fn(self, operation)
           ^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/toimpl.py:224: in execute_sql
    operations.migration_context.impl.execute(
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:214: in execute
    self._exec(sql, execution_options)
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:207: in _exec
    return conn.execute(construct, multiparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1416: in execute
    return meth(
venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py:516: in _execute_on_connection
    return connection._execute_clauseelement(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1639: in _execute_clauseelement
    ret = self._execute_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1848: in _execute_context
    return self._exec_single_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1988: in _exec_single_context
    self._handle_dbapi_exception(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2343: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: in _exec_single_context
    self.dialect.do_execute(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7129a8d48d40>
cursor = <cursor object at 0x7129a64747c0; closed: -1>
statement = 'DROP EXTENSION IF EXISTS vector', parameters = {}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x7129963753d0>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.InternalError: (psycopg2.errors.DependentObjectsStillExist) cannot drop extension vector because other objects depend on it
E       DETAIL:  column embedding of table test_chunks_real depends on type vector
E       HINT:  Use DROP ... CASCADE to drop the dependent objects too.
E       
E       [SQL: DROP EXTENSION IF EXISTS vector]
E       (Background on this error at: https://sqlalche.me/e/20/2j85)

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: InternalError
---------------------------- Captured stderr setup -----------------------------
DEBUG:asyncio:Using selector: EpollSelector
------------------------------ Captured log setup ------------------------------
DEBUG    asyncio:selector_events.py:64 Using selector: EpollSelector
----------------------------- Captured stderr call -----------------------------
INFO  [alembic.runtime.migration] Context impl PostgresqlImpl.
INFO  [alembic.runtime.migration] Will assume transactional DDL.
INFO  [alembic.runtime.migration] Running downgrade 001 -> , Initial schema with documents and chunks tables
__________ TestMigrationIntegration.test_migration_with_existing_data __________

self = <sqlalchemy.engine.base.Connection object at 0x7129a88580e0>
dialect = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7129a87c1640>
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x7129a877fb30>
statement = <sqlalchemy.dialects.postgresql.base.PGCompiler object at 0x7129a877f5f0>
parameters = [{}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7129a87c1640>
cursor = <cursor object at 0x7129a6423100; closed: -1>
statement = 'DROP EXTENSION IF EXISTS vector', parameters = {}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x7129a877fb30>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       psycopg2.errors.DependentObjectsStillExist: cannot drop extension vector because other objects depend on it
E       DETAIL:  column embedding of table test_chunks_real depends on type vector
E       HINT:  Use DROP ... CASCADE to drop the dependent objects too.

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: DependentObjectsStillExist

The above exception was the direct cause of the following exception:

self = <tests.integration.database.test_migration_integration.TestMigrationIntegration object at 0x7129c278f800>
alembic_config = <alembic.config.Config object at 0x7129a8a08200>
test_db_url = 'postgresql://rag_user:rag_password@192.168.56.1:5432/rag_test'

    @pytest.mark.asyncio
    async def test_migration_with_existing_data(self, alembic_config: Config, test_db_url: str) -> None:
        """Test migration with existing data in database."""
        # Start from clean state
>       command.downgrade(alembic_config, "base")

tests/integration/database/test_migration_integration.py:48: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
venv/lib/python3.12/site-packages/alembic/command.py:449: in downgrade
    script.run_env()
venv/lib/python3.12/site-packages/alembic/script/base.py:583: in run_env
    util.load_python_file(self.dir, "env.py")
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:95: in load_python_file
    module = load_module_py(module_id, path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:113: in load_module_py
    spec.loader.exec_module(module)  # type: ignore
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
<frozen importlib._bootstrap_external>:995: in exec_module
    ???
<frozen importlib._bootstrap>:488: in _call_with_frames_removed
    ???
migrations/env.py:93: in <module>
    run_migrations_online()
migrations/env.py:87: in run_migrations_online
    context.run_migrations()
<string>:8: in run_migrations
    ???
venv/lib/python3.12/site-packages/alembic/runtime/environment.py:948: in run_migrations
    self.get_context().run_migrations(**kw)
venv/lib/python3.12/site-packages/alembic/runtime/migration.py:627: in run_migrations
    step.migration_fn(**kw)
migrations/versions/001_initial_schema.py:129: in downgrade
    op.execute("DROP EXTENSION IF EXISTS vector")
<string>:8: in execute
    ???
<string>:3: in execute
    ???
venv/lib/python3.12/site-packages/alembic/operations/ops.py:2537: in execute
    return operations.invoke(op)
           ^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/base.py:445: in invoke
    return fn(self, operation)
           ^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/toimpl.py:224: in execute_sql
    operations.migration_context.impl.execute(
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:214: in execute
    self._exec(sql, execution_options)
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:207: in _exec
    return conn.execute(construct, multiparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1416: in execute
    return meth(
venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py:516: in _execute_on_connection
    return connection._execute_clauseelement(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1639: in _execute_clauseelement
    ret = self._execute_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1848: in _execute_context
    return self._exec_single_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1988: in _exec_single_context
    self._handle_dbapi_exception(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2343: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: in _exec_single_context
    self.dialect.do_execute(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7129a87c1640>
cursor = <cursor object at 0x7129a6423100; closed: -1>
statement = 'DROP EXTENSION IF EXISTS vector', parameters = {}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x7129a877fb30>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.InternalError: (psycopg2.errors.DependentObjectsStillExist) cannot drop extension vector because other objects depend on it
E       DETAIL:  column embedding of table test_chunks_real depends on type vector
E       HINT:  Use DROP ... CASCADE to drop the dependent objects too.
E       
E       [SQL: DROP EXTENSION IF EXISTS vector]
E       (Background on this error at: https://sqlalche.me/e/20/2j85)

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: InternalError
----------------------------- Captured stderr call -----------------------------
INFO  [alembic.runtime.migration] Context impl PostgresqlImpl.
INFO  [alembic.runtime.migration] Will assume transactional DDL.
INFO  [alembic.runtime.migration] Running downgrade 001 -> , Initial schema with documents and chunks tables
_____________ TestMigrationIntegration.test_rollback_functionality _____________

self = <sqlalchemy.engine.base.Connection object at 0x7129a8724b60>
dialect = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7129a87240e0>
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x7129a89f2270>
statement = <sqlalchemy.dialects.postgresql.base.PGCompiler object at 0x7129a89f24b0>
parameters = [{}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7129a87240e0>
cursor = <cursor object at 0x7129a6420310; closed: -1>
statement = 'DROP EXTENSION IF EXISTS vector', parameters = {}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x7129a89f2270>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       psycopg2.errors.DependentObjectsStillExist: cannot drop extension vector because other objects depend on it
E       DETAIL:  column embedding of table test_chunks_real depends on type vector
E       HINT:  Use DROP ... CASCADE to drop the dependent objects too.

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: DependentObjectsStillExist

The above exception was the direct cause of the following exception:

self = <tests.integration.database.test_migration_integration.TestMigrationIntegration object at 0x7129c27b72c0>
alembic_config = <alembic.config.Config object at 0x7129a8724c20>
test_db_url = 'postgresql://rag_user:rag_password@192.168.56.1:5432/rag_test'

    @pytest.mark.asyncio
    async def test_rollback_functionality(self, alembic_config: Config, test_db_url: str) -> None:
        """Test rolling back migrations."""
        # Start from clean state
>       command.downgrade(alembic_config, "base")

tests/integration/database/test_migration_integration.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
venv/lib/python3.12/site-packages/alembic/command.py:449: in downgrade
    script.run_env()
venv/lib/python3.12/site-packages/alembic/script/base.py:583: in run_env
    util.load_python_file(self.dir, "env.py")
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:95: in load_python_file
    module = load_module_py(module_id, path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:113: in load_module_py
    spec.loader.exec_module(module)  # type: ignore
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
<frozen importlib._bootstrap_external>:995: in exec_module
    ???
<frozen importlib._bootstrap>:488: in _call_with_frames_removed
    ???
migrations/env.py:93: in <module>
    run_migrations_online()
migrations/env.py:87: in run_migrations_online
    context.run_migrations()
<string>:8: in run_migrations
    ???
venv/lib/python3.12/site-packages/alembic/runtime/environment.py:948: in run_migrations
    self.get_context().run_migrations(**kw)
venv/lib/python3.12/site-packages/alembic/runtime/migration.py:627: in run_migrations
    step.migration_fn(**kw)
migrations/versions/001_initial_schema.py:129: in downgrade
    op.execute("DROP EXTENSION IF EXISTS vector")
<string>:8: in execute
    ???
<string>:3: in execute
    ???
venv/lib/python3.12/site-packages/alembic/operations/ops.py:2537: in execute
    return operations.invoke(op)
           ^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/base.py:445: in invoke
    return fn(self, operation)
           ^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/toimpl.py:224: in execute_sql
    operations.migration_context.impl.execute(
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:214: in execute
    self._exec(sql, execution_options)
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:207: in _exec
    return conn.execute(construct, multiparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1416: in execute
    return meth(
venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py:516: in _execute_on_connection
    return connection._execute_clauseelement(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1639: in _execute_clauseelement
    ret = self._execute_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1848: in _execute_context
    return self._exec_single_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1988: in _exec_single_context
    self._handle_dbapi_exception(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2343: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: in _exec_single_context
    self.dialect.do_execute(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7129a87240e0>
cursor = <cursor object at 0x7129a6420310; closed: -1>
statement = 'DROP EXTENSION IF EXISTS vector', parameters = {}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x7129a89f2270>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.InternalError: (psycopg2.errors.DependentObjectsStillExist) cannot drop extension vector because other objects depend on it
E       DETAIL:  column embedding of table test_chunks_real depends on type vector
E       HINT:  Use DROP ... CASCADE to drop the dependent objects too.
E       
E       [SQL: DROP EXTENSION IF EXISTS vector]
E       (Background on this error at: https://sqlalche.me/e/20/2j85)

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: InternalError
----------------------------- Captured stderr call -----------------------------
INFO  [alembic.runtime.migration] Context impl PostgresqlImpl.
INFO  [alembic.runtime.migration] Will assume transactional DDL.
INFO  [alembic.runtime.migration] Running downgrade 001 -> , Initial schema with documents and chunks tables
__________ TestMigrationIntegration.test_pgvector_extension_installed __________

self = <sqlalchemy.engine.base.Connection object at 0x7129a87241d0>
dialect = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7129a8a07ce0>
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x7129a8a05880>
statement = <sqlalchemy.dialects.postgresql.base.PGDDLCompiler object at 0x7129a87243e0>
parameters = [immutabledict({})]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7129a8a07ce0>
cursor = <cursor object at 0x7129a88571f0; closed: -1>
statement = 'ALTER TABLE chunks ADD COLUMN parent_chunk_id UUID'
parameters = immutabledict({})
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x7129a8a05880>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       psycopg2.errors.UndefinedTable: relation "chunks" does not exist

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: UndefinedTable

The above exception was the direct cause of the following exception:

self = <tests.integration.database.test_migration_integration.TestMigrationIntegration object at 0x7129c27b6b40>
alembic_config = <alembic.config.Config object at 0x7129a8b146b0>
test_db_url = 'postgresql://rag_user:rag_password@192.168.56.1:5432/rag_test'

    @pytest.mark.asyncio
    async def test_pgvector_extension_installed(self, alembic_config: Config, test_db_url: str) -> None:
        """Test that pgvector extension is installed by migrations."""
        # Upgrade to head
>       command.upgrade(alembic_config, "head")

tests/integration/database/test_migration_integration.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
venv/lib/python3.12/site-packages/alembic/command.py:403: in upgrade
    script.run_env()
venv/lib/python3.12/site-packages/alembic/script/base.py:583: in run_env
    util.load_python_file(self.dir, "env.py")
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:95: in load_python_file
    module = load_module_py(module_id, path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:113: in load_module_py
    spec.loader.exec_module(module)  # type: ignore
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
<frozen importlib._bootstrap_external>:995: in exec_module
    ???
<frozen importlib._bootstrap>:488: in _call_with_frames_removed
    ???
migrations/env.py:93: in <module>
    run_migrations_online()
migrations/env.py:87: in run_migrations_online
    context.run_migrations()
<string>:8: in run_migrations
    ???
venv/lib/python3.12/site-packages/alembic/runtime/environment.py:948: in run_migrations
    self.get_context().run_migrations(**kw)
venv/lib/python3.12/site-packages/alembic/runtime/migration.py:627: in run_migrations
    step.migration_fn(**kw)
migrations/versions/002_add_hierarchy_support.py:26: in upgrade
    op.add_column(
<string>:8: in add_column
    ???
<string>:3: in add_column
    ???
venv/lib/python3.12/site-packages/alembic/operations/ops.py:2142: in add_column
    return operations.invoke(op)
           ^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/base.py:445: in invoke
    return fn(self, operation)
           ^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/toimpl.py:171: in add_column
    operations.impl.add_column(table_name, column, schema=schema, **kw)
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:334: in add_column
    self._exec(base.AddColumn(table_name, column, schema=schema))
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:207: in _exec
    return conn.execute(construct, multiparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1416: in execute
    return meth(
venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:181: in _execute_on_connection
    return connection._execute_ddl(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1528: in _execute_ddl
    ret = self._execute_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1848: in _execute_context
    return self._exec_single_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1988: in _exec_single_context
    self._handle_dbapi_exception(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2343: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: in _exec_single_context
    self.dialect.do_execute(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7129a8a07ce0>
cursor = <cursor object at 0x7129a88571f0; closed: -1>
statement = 'ALTER TABLE chunks ADD COLUMN parent_chunk_id UUID'
parameters = immutabledict({})
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x7129a8a05880>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "chunks" does not exist
E       
E       [SQL: ALTER TABLE chunks ADD COLUMN parent_chunk_id UUID]
E       (Background on this error at: https://sqlalche.me/e/20/f405)

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: ProgrammingError
----------------------------- Captured stderr call -----------------------------
INFO  [alembic.runtime.migration] Context impl PostgresqlImpl.
INFO  [alembic.runtime.migration] Will assume transactional DDL.
INFO  [alembic.runtime.migration] Running upgrade 001 -> 002, Add hierarchy support to chunks table
______ TestMigrationValidatorIntegration.test_validate_with_no_migrations ______

self = <sqlalchemy.engine.base.Connection object at 0x7129a8a058b0>
dialect = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7129a89acef0>
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x7129a89f4e90>
statement = <sqlalchemy.dialects.postgresql.base.PGCompiler object at 0x7129a89f4830>
parameters = [{}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7129a89acef0>
cursor = <cursor object at 0x7129a88df970; closed: -1>
statement = 'DROP EXTENSION IF EXISTS vector', parameters = {}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x7129a89f4e90>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       psycopg2.errors.DependentObjectsStillExist: cannot drop extension vector because other objects depend on it
E       DETAIL:  column embedding of table test_chunks_real depends on type vector
E       HINT:  Use DROP ... CASCADE to drop the dependent objects too.

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: DependentObjectsStillExist

The above exception was the direct cause of the following exception:

self = <tests.integration.database.test_migration_validator_integration.TestMigrationValidatorIntegration object at 0x7129c27e0800>
validator = <rag_factory.services.database.migration_validator.MigrationValidator object at 0x7129a892b290>
alembic_config = <alembic.config.Config object at 0x7129a8c7bb00>

    @pytest.mark.asyncio
    async def test_validate_with_no_migrations(
        self,
        validator: MigrationValidator,
        alembic_config: Config
    ) -> None:
        """Test validation when no migrations are applied."""
        # Start from clean state
>       command.downgrade(alembic_config, "base")

tests/integration/database/test_migration_validator_integration.py:68: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
venv/lib/python3.12/site-packages/alembic/command.py:449: in downgrade
    script.run_env()
venv/lib/python3.12/site-packages/alembic/script/base.py:583: in run_env
    util.load_python_file(self.dir, "env.py")
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:95: in load_python_file
    module = load_module_py(module_id, path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:113: in load_module_py
    spec.loader.exec_module(module)  # type: ignore
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
<frozen importlib._bootstrap_external>:995: in exec_module
    ???
<frozen importlib._bootstrap>:488: in _call_with_frames_removed
    ???
migrations/env.py:93: in <module>
    run_migrations_online()
migrations/env.py:87: in run_migrations_online
    context.run_migrations()
<string>:8: in run_migrations
    ???
venv/lib/python3.12/site-packages/alembic/runtime/environment.py:948: in run_migrations
    self.get_context().run_migrations(**kw)
venv/lib/python3.12/site-packages/alembic/runtime/migration.py:627: in run_migrations
    step.migration_fn(**kw)
migrations/versions/001_initial_schema.py:129: in downgrade
    op.execute("DROP EXTENSION IF EXISTS vector")
<string>:8: in execute
    ???
<string>:3: in execute
    ???
venv/lib/python3.12/site-packages/alembic/operations/ops.py:2537: in execute
    return operations.invoke(op)
           ^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/base.py:445: in invoke
    return fn(self, operation)
           ^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/toimpl.py:224: in execute_sql
    operations.migration_context.impl.execute(
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:214: in execute
    self._exec(sql, execution_options)
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:207: in _exec
    return conn.execute(construct, multiparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1416: in execute
    return meth(
venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py:516: in _execute_on_connection
    return connection._execute_clauseelement(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1639: in _execute_clauseelement
    ret = self._execute_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1848: in _execute_context
    return self._exec_single_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1988: in _exec_single_context
    self._handle_dbapi_exception(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2343: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: in _exec_single_context
    self.dialect.do_execute(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7129a89acef0>
cursor = <cursor object at 0x7129a88df970; closed: -1>
statement = 'DROP EXTENSION IF EXISTS vector', parameters = {}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x7129a89f4e90>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.InternalError: (psycopg2.errors.DependentObjectsStillExist) cannot drop extension vector because other objects depend on it
E       DETAIL:  column embedding of table test_chunks_real depends on type vector
E       HINT:  Use DROP ... CASCADE to drop the dependent objects too.
E       
E       [SQL: DROP EXTENSION IF EXISTS vector]
E       (Background on this error at: https://sqlalche.me/e/20/2j85)

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: InternalError
----------------------------- Captured stderr call -----------------------------
INFO  [alembic.runtime.migration] Context impl PostgresqlImpl.
INFO  [alembic.runtime.migration] Will assume transactional DDL.
INFO  [alembic.runtime.migration] Running downgrade 001 -> , Initial schema with documents and chunks tables
___ TestMigrationValidatorIntegration.test_validate_with_partial_migrations ____

self = <sqlalchemy.engine.base.Connection object at 0x7129a89acc50>
dialect = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x712996374980>
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x712996358c80>
statement = <sqlalchemy.dialects.postgresql.base.PGCompiler object at 0x71299635b800>
parameters = [{}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x712996374980>
cursor = <cursor object at 0x7129a88de3e0; closed: -1>
statement = 'DROP EXTENSION IF EXISTS vector', parameters = {}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x712996358c80>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       psycopg2.errors.DependentObjectsStillExist: cannot drop extension vector because other objects depend on it
E       DETAIL:  column embedding of table test_chunks_real depends on type vector
E       HINT:  Use DROP ... CASCADE to drop the dependent objects too.

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: DependentObjectsStillExist

The above exception was the direct cause of the following exception:

self = <tests.integration.database.test_migration_validator_integration.TestMigrationValidatorIntegration object at 0x7129c27e0ec0>
validator = <rag_factory.services.database.migration_validator.MigrationValidator object at 0x7129a883a090>
alembic_config = <alembic.config.Config object at 0x7129a8970290>

    @pytest.mark.asyncio
    async def test_validate_with_partial_migrations(
        self,
        validator: MigrationValidator,
        alembic_config: Config
    ) -> None:
        """Test validation when only some migrations are applied."""
        # Start from clean state
>       command.downgrade(alembic_config, "base")

tests/integration/database/test_migration_validator_integration.py:85: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
venv/lib/python3.12/site-packages/alembic/command.py:449: in downgrade
    script.run_env()
venv/lib/python3.12/site-packages/alembic/script/base.py:583: in run_env
    util.load_python_file(self.dir, "env.py")
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:95: in load_python_file
    module = load_module_py(module_id, path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:113: in load_module_py
    spec.loader.exec_module(module)  # type: ignore
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
<frozen importlib._bootstrap_external>:995: in exec_module
    ???
<frozen importlib._bootstrap>:488: in _call_with_frames_removed
    ???
migrations/env.py:93: in <module>
    run_migrations_online()
migrations/env.py:87: in run_migrations_online
    context.run_migrations()
<string>:8: in run_migrations
    ???
venv/lib/python3.12/site-packages/alembic/runtime/environment.py:948: in run_migrations
    self.get_context().run_migrations(**kw)
venv/lib/python3.12/site-packages/alembic/runtime/migration.py:627: in run_migrations
    step.migration_fn(**kw)
migrations/versions/001_initial_schema.py:129: in downgrade
    op.execute("DROP EXTENSION IF EXISTS vector")
<string>:8: in execute
    ???
<string>:3: in execute
    ???
venv/lib/python3.12/site-packages/alembic/operations/ops.py:2537: in execute
    return operations.invoke(op)
           ^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/base.py:445: in invoke
    return fn(self, operation)
           ^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/toimpl.py:224: in execute_sql
    operations.migration_context.impl.execute(
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:214: in execute
    self._exec(sql, execution_options)
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:207: in _exec
    return conn.execute(construct, multiparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1416: in execute
    return meth(
venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py:516: in _execute_on_connection
    return connection._execute_clauseelement(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1639: in _execute_clauseelement
    ret = self._execute_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1848: in _execute_context
    return self._exec_single_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1988: in _exec_single_context
    self._handle_dbapi_exception(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2343: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: in _exec_single_context
    self.dialect.do_execute(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x712996374980>
cursor = <cursor object at 0x7129a88de3e0; closed: -1>
statement = 'DROP EXTENSION IF EXISTS vector', parameters = {}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x712996358c80>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.InternalError: (psycopg2.errors.DependentObjectsStillExist) cannot drop extension vector because other objects depend on it
E       DETAIL:  column embedding of table test_chunks_real depends on type vector
E       HINT:  Use DROP ... CASCADE to drop the dependent objects too.
E       
E       [SQL: DROP EXTENSION IF EXISTS vector]
E       (Background on this error at: https://sqlalche.me/e/20/2j85)

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: InternalError
----------------------------- Captured stderr call -----------------------------
INFO  [alembic.runtime.migration] Context impl PostgresqlImpl.
INFO  [alembic.runtime.migration] Will assume transactional DDL.
INFO  [alembic.runtime.migration] Running downgrade 001 -> , Initial schema with documents and chunks tables
_____ TestMigrationValidatorIntegration.test_validate_with_all_migrations ______

self = <sqlalchemy.engine.base.Connection object at 0x7129963a4a40>
dialect = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x712996347cb0>
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x7129a8ae5280>
statement = <sqlalchemy.dialects.postgresql.base.PGDDLCompiler object at 0x7129a8ae5fd0>
parameters = [immutabledict({})]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x712996347cb0>
cursor = <cursor object at 0x7129a88dc6d0; closed: -1>
statement = 'ALTER TABLE chunks ADD COLUMN parent_chunk_id UUID'
parameters = immutabledict({})
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x7129a8ae5280>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       psycopg2.errors.UndefinedTable: relation "chunks" does not exist

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: UndefinedTable

The above exception was the direct cause of the following exception:

self = <tests.integration.database.test_migration_validator_integration.TestMigrationValidatorIntegration object at 0x7129c27e12b0>
validator = <rag_factory.services.database.migration_validator.MigrationValidator object at 0x712996346180>
alembic_config = <alembic.config.Config object at 0x712996345310>

    @pytest.mark.asyncio
    async def test_validate_with_all_migrations(
        self,
        validator: MigrationValidator,
        alembic_config: Config
    ) -> None:
        """Test validation when all required migrations are applied."""
        # Apply all migrations
>       command.upgrade(alembic_config, "head")

tests/integration/database/test_migration_validator_integration.py:105: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
venv/lib/python3.12/site-packages/alembic/command.py:403: in upgrade
    script.run_env()
venv/lib/python3.12/site-packages/alembic/script/base.py:583: in run_env
    util.load_python_file(self.dir, "env.py")
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:95: in load_python_file
    module = load_module_py(module_id, path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:113: in load_module_py
    spec.loader.exec_module(module)  # type: ignore
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
<frozen importlib._bootstrap_external>:995: in exec_module
    ???
<frozen importlib._bootstrap>:488: in _call_with_frames_removed
    ???
migrations/env.py:93: in <module>
    run_migrations_online()
migrations/env.py:87: in run_migrations_online
    context.run_migrations()
<string>:8: in run_migrations
    ???
venv/lib/python3.12/site-packages/alembic/runtime/environment.py:948: in run_migrations
    self.get_context().run_migrations(**kw)
venv/lib/python3.12/site-packages/alembic/runtime/migration.py:627: in run_migrations
    step.migration_fn(**kw)
migrations/versions/002_add_hierarchy_support.py:26: in upgrade
    op.add_column(
<string>:8: in add_column
    ???
<string>:3: in add_column
    ???
venv/lib/python3.12/site-packages/alembic/operations/ops.py:2142: in add_column
    return operations.invoke(op)
           ^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/base.py:445: in invoke
    return fn(self, operation)
           ^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/toimpl.py:171: in add_column
    operations.impl.add_column(table_name, column, schema=schema, **kw)
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:334: in add_column
    self._exec(base.AddColumn(table_name, column, schema=schema))
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:207: in _exec
    return conn.execute(construct, multiparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1416: in execute
    return meth(
venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:181: in _execute_on_connection
    return connection._execute_ddl(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1528: in _execute_ddl
    ret = self._execute_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1848: in _execute_context
    return self._exec_single_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1988: in _exec_single_context
    self._handle_dbapi_exception(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2343: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: in _exec_single_context
    self.dialect.do_execute(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x712996347cb0>
cursor = <cursor object at 0x7129a88dc6d0; closed: -1>
statement = 'ALTER TABLE chunks ADD COLUMN parent_chunk_id UUID'
parameters = immutabledict({})
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x7129a8ae5280>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "chunks" does not exist
E       
E       [SQL: ALTER TABLE chunks ADD COLUMN parent_chunk_id UUID]
E       (Background on this error at: https://sqlalche.me/e/20/f405)

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: ProgrammingError
----------------------------- Captured stderr call -----------------------------
INFO  [alembic.runtime.migration] Context impl PostgresqlImpl.
INFO  [alembic.runtime.migration] Will assume transactional DDL.
INFO  [alembic.runtime.migration] Running upgrade 001 -> 002, Add hierarchy support to chunks table
_______ TestMigrationValidatorIntegration.test_validate_or_raise_success _______

self = <sqlalchemy.engine.base.Connection object at 0x712996346b10>
dialect = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x712995a26b40>
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x712995a27350>
statement = <sqlalchemy.dialects.postgresql.base.PGDDLCompiler object at 0x712995a27680>
parameters = [immutabledict({})]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x712995a26b40>
cursor = <cursor object at 0x7129a64758a0; closed: -1>
statement = 'ALTER TABLE chunks ADD COLUMN parent_chunk_id UUID'
parameters = immutabledict({})
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x712995a27350>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       psycopg2.errors.UndefinedTable: relation "chunks" does not exist

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: UndefinedTable

The above exception was the direct cause of the following exception:

self = <tests.integration.database.test_migration_validator_integration.TestMigrationValidatorIntegration object at 0x7129c27e16a0>
validator = <rag_factory.services.database.migration_validator.MigrationValidator object at 0x7129a88ce930>
alembic_config = <alembic.config.Config object at 0x7129a88ce990>

    @pytest.mark.asyncio
    async def test_validate_or_raise_success(
        self,
        validator: MigrationValidator,
        alembic_config: Config
    ) -> None:
        """Test validate_or_raise when all migrations are applied."""
        # Apply all migrations
>       command.upgrade(alembic_config, "head")

tests/integration/database/test_migration_validator_integration.py:121: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
venv/lib/python3.12/site-packages/alembic/command.py:403: in upgrade
    script.run_env()
venv/lib/python3.12/site-packages/alembic/script/base.py:583: in run_env
    util.load_python_file(self.dir, "env.py")
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:95: in load_python_file
    module = load_module_py(module_id, path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:113: in load_module_py
    spec.loader.exec_module(module)  # type: ignore
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
<frozen importlib._bootstrap_external>:995: in exec_module
    ???
<frozen importlib._bootstrap>:488: in _call_with_frames_removed
    ???
migrations/env.py:93: in <module>
    run_migrations_online()
migrations/env.py:87: in run_migrations_online
    context.run_migrations()
<string>:8: in run_migrations
    ???
venv/lib/python3.12/site-packages/alembic/runtime/environment.py:948: in run_migrations
    self.get_context().run_migrations(**kw)
venv/lib/python3.12/site-packages/alembic/runtime/migration.py:627: in run_migrations
    step.migration_fn(**kw)
migrations/versions/002_add_hierarchy_support.py:26: in upgrade
    op.add_column(
<string>:8: in add_column
    ???
<string>:3: in add_column
    ???
venv/lib/python3.12/site-packages/alembic/operations/ops.py:2142: in add_column
    return operations.invoke(op)
           ^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/base.py:445: in invoke
    return fn(self, operation)
           ^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/toimpl.py:171: in add_column
    operations.impl.add_column(table_name, column, schema=schema, **kw)
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:334: in add_column
    self._exec(base.AddColumn(table_name, column, schema=schema))
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:207: in _exec
    return conn.execute(construct, multiparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1416: in execute
    return meth(
venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:181: in _execute_on_connection
    return connection._execute_ddl(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1528: in _execute_ddl
    ret = self._execute_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1848: in _execute_context
    return self._exec_single_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1988: in _exec_single_context
    self._handle_dbapi_exception(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2343: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: in _exec_single_context
    self.dialect.do_execute(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x712995a26b40>
cursor = <cursor object at 0x7129a64758a0; closed: -1>
statement = 'ALTER TABLE chunks ADD COLUMN parent_chunk_id UUID'
parameters = immutabledict({})
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x712995a27350>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "chunks" does not exist
E       
E       [SQL: ALTER TABLE chunks ADD COLUMN parent_chunk_id UUID]
E       (Background on this error at: https://sqlalche.me/e/20/f405)

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: ProgrammingError
----------------------------- Captured stderr call -----------------------------
INFO  [alembic.runtime.migration] Context impl PostgresqlImpl.
INFO  [alembic.runtime.migration] Will assume transactional DDL.
INFO  [alembic.runtime.migration] Running upgrade 001 -> 002, Add hierarchy support to chunks table
_______ TestMigrationValidatorIntegration.test_validate_or_raise_failure _______

self = <sqlalchemy.engine.base.Connection object at 0x712995a24170>
dialect = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x71299632d7f0>
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x712995c775c0>
statement = <sqlalchemy.dialects.postgresql.base.PGCompiler object at 0x712995c763f0>
parameters = [{}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x71299632d7f0>
cursor = <cursor object at 0x7129a640fc40; closed: -1>
statement = 'DROP EXTENSION IF EXISTS vector', parameters = {}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x712995c775c0>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       psycopg2.errors.DependentObjectsStillExist: cannot drop extension vector because other objects depend on it
E       DETAIL:  column embedding of table test_chunks_real depends on type vector
E       HINT:  Use DROP ... CASCADE to drop the dependent objects too.

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: DependentObjectsStillExist

The above exception was the direct cause of the following exception:

self = <tests.integration.database.test_migration_validator_integration.TestMigrationValidatorIntegration object at 0x7129c27e1a90>
validator = <rag_factory.services.database.migration_validator.MigrationValidator object at 0x71299632d640>
alembic_config = <alembic.config.Config object at 0x71299632fcb0>

    @pytest.mark.asyncio
    async def test_validate_or_raise_failure(
        self,
        validator: MigrationValidator,
        alembic_config: Config
    ) -> None:
        """Test validate_or_raise when migrations are missing."""
        # Start from clean state
>       command.downgrade(alembic_config, "base")

tests/integration/database/test_migration_validator_integration.py:134: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
venv/lib/python3.12/site-packages/alembic/command.py:449: in downgrade
    script.run_env()
venv/lib/python3.12/site-packages/alembic/script/base.py:583: in run_env
    util.load_python_file(self.dir, "env.py")
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:95: in load_python_file
    module = load_module_py(module_id, path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:113: in load_module_py
    spec.loader.exec_module(module)  # type: ignore
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
<frozen importlib._bootstrap_external>:995: in exec_module
    ???
<frozen importlib._bootstrap>:488: in _call_with_frames_removed
    ???
migrations/env.py:93: in <module>
    run_migrations_online()
migrations/env.py:87: in run_migrations_online
    context.run_migrations()
<string>:8: in run_migrations
    ???
venv/lib/python3.12/site-packages/alembic/runtime/environment.py:948: in run_migrations
    self.get_context().run_migrations(**kw)
venv/lib/python3.12/site-packages/alembic/runtime/migration.py:627: in run_migrations
    step.migration_fn(**kw)
migrations/versions/001_initial_schema.py:129: in downgrade
    op.execute("DROP EXTENSION IF EXISTS vector")
<string>:8: in execute
    ???
<string>:3: in execute
    ???
venv/lib/python3.12/site-packages/alembic/operations/ops.py:2537: in execute
    return operations.invoke(op)
           ^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/base.py:445: in invoke
    return fn(self, operation)
           ^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/toimpl.py:224: in execute_sql
    operations.migration_context.impl.execute(
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:214: in execute
    self._exec(sql, execution_options)
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:207: in _exec
    return conn.execute(construct, multiparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1416: in execute
    return meth(
venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py:516: in _execute_on_connection
    return connection._execute_clauseelement(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1639: in _execute_clauseelement
    ret = self._execute_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1848: in _execute_context
    return self._exec_single_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1988: in _exec_single_context
    self._handle_dbapi_exception(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2343: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: in _exec_single_context
    self.dialect.do_execute(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x71299632d7f0>
cursor = <cursor object at 0x7129a640fc40; closed: -1>
statement = 'DROP EXTENSION IF EXISTS vector', parameters = {}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x712995c775c0>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.InternalError: (psycopg2.errors.DependentObjectsStillExist) cannot drop extension vector because other objects depend on it
E       DETAIL:  column embedding of table test_chunks_real depends on type vector
E       HINT:  Use DROP ... CASCADE to drop the dependent objects too.
E       
E       [SQL: DROP EXTENSION IF EXISTS vector]
E       (Background on this error at: https://sqlalche.me/e/20/2j85)

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: InternalError
----------------------------- Captured stderr call -----------------------------
INFO  [alembic.runtime.migration] Context impl PostgresqlImpl.
INFO  [alembic.runtime.migration] Will assume transactional DDL.
INFO  [alembic.runtime.migration] Running downgrade 001 -> , Initial schema with documents and chunks tables
_________ TestMigrationValidatorIntegration.test_get_current_revision __________

self = <sqlalchemy.engine.base.Connection object at 0x712995bca870>
dialect = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7129a88584a0>
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x7129a8816d20>
statement = <sqlalchemy.dialects.postgresql.base.PGCompiler object at 0x7129a8816ff0>
parameters = [{}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7129a88584a0>
cursor = <cursor object at 0x7129a640c130; closed: -1>
statement = 'DROP EXTENSION IF EXISTS vector', parameters = {}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x7129a8816d20>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       psycopg2.errors.DependentObjectsStillExist: cannot drop extension vector because other objects depend on it
E       DETAIL:  column embedding of table test_chunks_real depends on type vector
E       HINT:  Use DROP ... CASCADE to drop the dependent objects too.

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: DependentObjectsStillExist

The above exception was the direct cause of the following exception:

self = <tests.integration.database.test_migration_validator_integration.TestMigrationValidatorIntegration object at 0x7129c27b7ce0>
validator = <rag_factory.services.database.migration_validator.MigrationValidator object at 0x712995bf2330>
alembic_config = <alembic.config.Config object at 0x712995bf1850>

    @pytest.mark.asyncio
    async def test_get_current_revision(
        self,
        validator: MigrationValidator,
        alembic_config: Config
    ) -> None:
        """Test getting current revision from database."""
        # Start from clean state
>       command.downgrade(alembic_config, "base")

tests/integration/database/test_migration_validator_integration.py:153: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
venv/lib/python3.12/site-packages/alembic/command.py:449: in downgrade
    script.run_env()
venv/lib/python3.12/site-packages/alembic/script/base.py:583: in run_env
    util.load_python_file(self.dir, "env.py")
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:95: in load_python_file
    module = load_module_py(module_id, path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:113: in load_module_py
    spec.loader.exec_module(module)  # type: ignore
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
<frozen importlib._bootstrap_external>:995: in exec_module
    ???
<frozen importlib._bootstrap>:488: in _call_with_frames_removed
    ???
migrations/env.py:93: in <module>
    run_migrations_online()
migrations/env.py:87: in run_migrations_online
    context.run_migrations()
<string>:8: in run_migrations
    ???
venv/lib/python3.12/site-packages/alembic/runtime/environment.py:948: in run_migrations
    self.get_context().run_migrations(**kw)
venv/lib/python3.12/site-packages/alembic/runtime/migration.py:627: in run_migrations
    step.migration_fn(**kw)
migrations/versions/001_initial_schema.py:129: in downgrade
    op.execute("DROP EXTENSION IF EXISTS vector")
<string>:8: in execute
    ???
<string>:3: in execute
    ???
venv/lib/python3.12/site-packages/alembic/operations/ops.py:2537: in execute
    return operations.invoke(op)
           ^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/base.py:445: in invoke
    return fn(self, operation)
           ^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/toimpl.py:224: in execute_sql
    operations.migration_context.impl.execute(
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:214: in execute
    self._exec(sql, execution_options)
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:207: in _exec
    return conn.execute(construct, multiparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1416: in execute
    return meth(
venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py:516: in _execute_on_connection
    return connection._execute_clauseelement(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1639: in _execute_clauseelement
    ret = self._execute_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1848: in _execute_context
    return self._exec_single_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1988: in _exec_single_context
    self._handle_dbapi_exception(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2343: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: in _exec_single_context
    self.dialect.do_execute(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7129a88584a0>
cursor = <cursor object at 0x7129a640c130; closed: -1>
statement = 'DROP EXTENSION IF EXISTS vector', parameters = {}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x7129a8816d20>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.InternalError: (psycopg2.errors.DependentObjectsStillExist) cannot drop extension vector because other objects depend on it
E       DETAIL:  column embedding of table test_chunks_real depends on type vector
E       HINT:  Use DROP ... CASCADE to drop the dependent objects too.
E       
E       [SQL: DROP EXTENSION IF EXISTS vector]
E       (Background on this error at: https://sqlalche.me/e/20/2j85)

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: InternalError
----------------------------- Captured stderr call -----------------------------
INFO  [alembic.runtime.migration] Context impl PostgresqlImpl.
INFO  [alembic.runtime.migration] Will assume transactional DDL.
INFO  [alembic.runtime.migration] Running downgrade 001 -> , Initial schema with documents and chunks tables
______________ TestMigrationValidatorIntegration.test_is_at_head _______________

self = <sqlalchemy.engine.base.Connection object at 0x71299632f710>
dialect = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x712996347b00>
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x7129a89af6e0>
statement = <sqlalchemy.dialects.postgresql.base.PGCompiler object at 0x7129a89afaa0>
parameters = [{}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x712996347b00>
cursor = <cursor object at 0x7129a88de5c0; closed: -1>
statement = 'DROP EXTENSION IF EXISTS vector', parameters = {}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x7129a89af6e0>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       psycopg2.errors.DependentObjectsStillExist: cannot drop extension vector because other objects depend on it
E       DETAIL:  column embedding of table test_chunks_real depends on type vector
E       HINT:  Use DROP ... CASCADE to drop the dependent objects too.

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: DependentObjectsStillExist

The above exception was the direct cause of the following exception:

self = <tests.integration.database.test_migration_validator_integration.TestMigrationValidatorIntegration object at 0x7129c27e17f0>
validator = <rag_factory.services.database.migration_validator.MigrationValidator object at 0x7129a88cf560>
alembic_config = <alembic.config.Config object at 0x7129a88cf0e0>

    @pytest.mark.asyncio
    async def test_is_at_head(
        self,
        validator: MigrationValidator,
        alembic_config: Config
    ) -> None:
        """Test checking if database is at head revision."""
        # Start from clean state
>       command.downgrade(alembic_config, "base")

tests/integration/database/test_migration_validator_integration.py:193: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
venv/lib/python3.12/site-packages/alembic/command.py:449: in downgrade
    script.run_env()
venv/lib/python3.12/site-packages/alembic/script/base.py:583: in run_env
    util.load_python_file(self.dir, "env.py")
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:95: in load_python_file
    module = load_module_py(module_id, path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:113: in load_module_py
    spec.loader.exec_module(module)  # type: ignore
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
<frozen importlib._bootstrap_external>:995: in exec_module
    ???
<frozen importlib._bootstrap>:488: in _call_with_frames_removed
    ???
migrations/env.py:93: in <module>
    run_migrations_online()
migrations/env.py:87: in run_migrations_online
    context.run_migrations()
<string>:8: in run_migrations
    ???
venv/lib/python3.12/site-packages/alembic/runtime/environment.py:948: in run_migrations
    self.get_context().run_migrations(**kw)
venv/lib/python3.12/site-packages/alembic/runtime/migration.py:627: in run_migrations
    step.migration_fn(**kw)
migrations/versions/001_initial_schema.py:129: in downgrade
    op.execute("DROP EXTENSION IF EXISTS vector")
<string>:8: in execute
    ???
<string>:3: in execute
    ???
venv/lib/python3.12/site-packages/alembic/operations/ops.py:2537: in execute
    return operations.invoke(op)
           ^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/base.py:445: in invoke
    return fn(self, operation)
           ^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/toimpl.py:224: in execute_sql
    operations.migration_context.impl.execute(
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:214: in execute
    self._exec(sql, execution_options)
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:207: in _exec
    return conn.execute(construct, multiparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1416: in execute
    return meth(
venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py:516: in _execute_on_connection
    return connection._execute_clauseelement(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1639: in _execute_clauseelement
    ret = self._execute_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1848: in _execute_context
    return self._exec_single_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1988: in _exec_single_context
    self._handle_dbapi_exception(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2343: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: in _exec_single_context
    self.dialect.do_execute(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x712996347b00>
cursor = <cursor object at 0x7129a88de5c0; closed: -1>
statement = 'DROP EXTENSION IF EXISTS vector', parameters = {}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x7129a89af6e0>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.InternalError: (psycopg2.errors.DependentObjectsStillExist) cannot drop extension vector because other objects depend on it
E       DETAIL:  column embedding of table test_chunks_real depends on type vector
E       HINT:  Use DROP ... CASCADE to drop the dependent objects too.
E       
E       [SQL: DROP EXTENSION IF EXISTS vector]
E       (Background on this error at: https://sqlalche.me/e/20/2j85)

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: InternalError
----------------------------- Captured stderr call -----------------------------
INFO  [alembic.runtime.migration] Context impl PostgresqlImpl.
INFO  [alembic.runtime.migration] Will assume transactional DDL.
INFO  [alembic.runtime.migration] Running downgrade 001 -> , Initial schema with documents and chunks tables
_________ TestMigrationValidatorIntegration.test_error_message_details _________

self = <sqlalchemy.engine.base.Connection object at 0x712996347f80>
dialect = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7129a877d850>
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x7129a892a450>
statement = <sqlalchemy.dialects.postgresql.base.PGCompiler object at 0x7129a892bda0>
parameters = [{}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7129a877d850>
cursor = <cursor object at 0x7129a88576a0; closed: -1>
statement = 'DROP EXTENSION IF EXISTS vector', parameters = {}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x7129a892a450>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       psycopg2.errors.DependentObjectsStillExist: cannot drop extension vector because other objects depend on it
E       DETAIL:  column embedding of table test_chunks_real depends on type vector
E       HINT:  Use DROP ... CASCADE to drop the dependent objects too.

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: DependentObjectsStillExist

The above exception was the direct cause of the following exception:

self = <tests.integration.database.test_migration_validator_integration.TestMigrationValidatorIntegration object at 0x7129c27e10d0>
validator = <rag_factory.services.database.migration_validator.MigrationValidator object at 0x7129a8b16f30>
alembic_config = <alembic.config.Config object at 0x7129a88cfce0>

    @pytest.mark.asyncio
    async def test_error_message_details(
        self,
        validator: MigrationValidator,
        alembic_config: Config
    ) -> None:
        """Test that error messages include migration details."""
        # Start from clean state
>       command.downgrade(alembic_config, "base")

tests/integration/database/test_migration_validator_integration.py:214: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
venv/lib/python3.12/site-packages/alembic/command.py:449: in downgrade
    script.run_env()
venv/lib/python3.12/site-packages/alembic/script/base.py:583: in run_env
    util.load_python_file(self.dir, "env.py")
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:95: in load_python_file
    module = load_module_py(module_id, path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:113: in load_module_py
    spec.loader.exec_module(module)  # type: ignore
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
<frozen importlib._bootstrap_external>:995: in exec_module
    ???
<frozen importlib._bootstrap>:488: in _call_with_frames_removed
    ???
migrations/env.py:93: in <module>
    run_migrations_online()
migrations/env.py:87: in run_migrations_online
    context.run_migrations()
<string>:8: in run_migrations
    ???
venv/lib/python3.12/site-packages/alembic/runtime/environment.py:948: in run_migrations
    self.get_context().run_migrations(**kw)
venv/lib/python3.12/site-packages/alembic/runtime/migration.py:627: in run_migrations
    step.migration_fn(**kw)
migrations/versions/001_initial_schema.py:129: in downgrade
    op.execute("DROP EXTENSION IF EXISTS vector")
<string>:8: in execute
    ???
<string>:3: in execute
    ???
venv/lib/python3.12/site-packages/alembic/operations/ops.py:2537: in execute
    return operations.invoke(op)
           ^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/base.py:445: in invoke
    return fn(self, operation)
           ^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/toimpl.py:224: in execute_sql
    operations.migration_context.impl.execute(
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:214: in execute
    self._exec(sql, execution_options)
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:207: in _exec
    return conn.execute(construct, multiparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1416: in execute
    return meth(
venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py:516: in _execute_on_connection
    return connection._execute_clauseelement(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1639: in _execute_clauseelement
    ret = self._execute_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1848: in _execute_context
    return self._exec_single_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1988: in _exec_single_context
    self._handle_dbapi_exception(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2343: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: in _exec_single_context
    self.dialect.do_execute(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7129a877d850>
cursor = <cursor object at 0x7129a88576a0; closed: -1>
statement = 'DROP EXTENSION IF EXISTS vector', parameters = {}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x7129a892a450>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.InternalError: (psycopg2.errors.DependentObjectsStillExist) cannot drop extension vector because other objects depend on it
E       DETAIL:  column embedding of table test_chunks_real depends on type vector
E       HINT:  Use DROP ... CASCADE to drop the dependent objects too.
E       
E       [SQL: DROP EXTENSION IF EXISTS vector]
E       (Background on this error at: https://sqlalche.me/e/20/2j85)

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: InternalError
----------------------------- Captured stderr call -----------------------------
INFO  [alembic.runtime.migration] Context impl PostgresqlImpl.
INFO  [alembic.runtime.migration] Will assume transactional DDL.
INFO  [alembic.runtime.migration] Running downgrade 001 -> , Initial schema with documents and chunks tables
_______ TestMigrationValidatorIntegration.test_validate_single_migration _______

self = <sqlalchemy.engine.base.Connection object at 0x7129a877fa10>
dialect = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x712995a26030>
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x71299635a240>
statement = <sqlalchemy.dialects.postgresql.base.PGDDLCompiler object at 0x71299635b170>
parameters = [immutabledict({})]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x712995a26030>
cursor = <cursor object at 0x7129a6475210; closed: -1>
statement = 'ALTER TABLE chunks ADD COLUMN parent_chunk_id UUID'
parameters = immutabledict({})
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x71299635a240>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       psycopg2.errors.UndefinedTable: relation "chunks" does not exist

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: UndefinedTable

The above exception was the direct cause of the following exception:

self = <tests.integration.database.test_migration_validator_integration.TestMigrationValidatorIntegration object at 0x7129c27e0c50>
validator = <rag_factory.services.database.migration_validator.MigrationValidator object at 0x7129963a5d00>
alembic_config = <alembic.config.Config object at 0x7129a8b16ab0>

    @pytest.mark.asyncio
    async def test_validate_single_migration(
        self,
        validator: MigrationValidator,
        alembic_config: Config
    ) -> None:
        """Test validating a single migration requirement."""
        # Apply all migrations
>       command.upgrade(alembic_config, "head")

tests/integration/database/test_migration_validator_integration.py:240: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
venv/lib/python3.12/site-packages/alembic/command.py:403: in upgrade
    script.run_env()
venv/lib/python3.12/site-packages/alembic/script/base.py:583: in run_env
    util.load_python_file(self.dir, "env.py")
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:95: in load_python_file
    module = load_module_py(module_id, path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:113: in load_module_py
    spec.loader.exec_module(module)  # type: ignore
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
<frozen importlib._bootstrap_external>:995: in exec_module
    ???
<frozen importlib._bootstrap>:488: in _call_with_frames_removed
    ???
migrations/env.py:93: in <module>
    run_migrations_online()
migrations/env.py:87: in run_migrations_online
    context.run_migrations()
<string>:8: in run_migrations
    ???
venv/lib/python3.12/site-packages/alembic/runtime/environment.py:948: in run_migrations
    self.get_context().run_migrations(**kw)
venv/lib/python3.12/site-packages/alembic/runtime/migration.py:627: in run_migrations
    step.migration_fn(**kw)
migrations/versions/002_add_hierarchy_support.py:26: in upgrade
    op.add_column(
<string>:8: in add_column
    ???
<string>:3: in add_column
    ???
venv/lib/python3.12/site-packages/alembic/operations/ops.py:2142: in add_column
    return operations.invoke(op)
           ^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/base.py:445: in invoke
    return fn(self, operation)
           ^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/toimpl.py:171: in add_column
    operations.impl.add_column(table_name, column, schema=schema, **kw)
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:334: in add_column
    self._exec(base.AddColumn(table_name, column, schema=schema))
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:207: in _exec
    return conn.execute(construct, multiparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1416: in execute
    return meth(
venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:181: in _execute_on_connection
    return connection._execute_ddl(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1528: in _execute_ddl
    ret = self._execute_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1848: in _execute_context
    return self._exec_single_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1988: in _exec_single_context
    self._handle_dbapi_exception(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2343: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: in _exec_single_context
    self.dialect.do_execute(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x712995a26030>
cursor = <cursor object at 0x7129a6475210; closed: -1>
statement = 'ALTER TABLE chunks ADD COLUMN parent_chunk_id UUID'
parameters = immutabledict({})
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x71299635a240>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "chunks" does not exist
E       
E       [SQL: ALTER TABLE chunks ADD COLUMN parent_chunk_id UUID]
E       (Background on this error at: https://sqlalche.me/e/20/f405)

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: ProgrammingError
----------------------------- Captured stderr call -----------------------------
INFO  [alembic.runtime.migration] Context impl PostgresqlImpl.
INFO  [alembic.runtime.migration] Will assume transactional DDL.
INFO  [alembic.runtime.migration] Running upgrade 001 -> 002, Add hierarchy support to chunks table
____ TestMigrationValidatorIntegration.test_validate_nonexistent_migration _____

self = <sqlalchemy.engine.base.Connection object at 0x712995c755b0>
dialect = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7129a89f6cf0>
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x7129a8a06360>
statement = <sqlalchemy.dialects.postgresql.base.PGDDLCompiler object at 0x7129a8a071d0>
parameters = [immutabledict({})]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7129a89f6cf0>
cursor = <cursor object at 0x7129a6421e40; closed: -1>
statement = 'ALTER TABLE chunks ADD COLUMN parent_chunk_id UUID'
parameters = immutabledict({})
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x7129a8a06360>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       psycopg2.errors.UndefinedTable: relation "chunks" does not exist

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: UndefinedTable

The above exception was the direct cause of the following exception:

self = <tests.integration.database.test_migration_validator_integration.TestMigrationValidatorIntegration object at 0x7129c27e1cd0>
validator = <rag_factory.services.database.migration_validator.MigrationValidator object at 0x712996359d60>
alembic_config = <alembic.config.Config object at 0x7129a8973770>

    @pytest.mark.asyncio
    async def test_validate_nonexistent_migration(
        self,
        validator: MigrationValidator,
        alembic_config: Config
    ) -> None:
        """Test validating a migration that doesn't exist."""
        # Apply all migrations
>       command.upgrade(alembic_config, "head")

tests/integration/database/test_migration_validator_integration.py:256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
venv/lib/python3.12/site-packages/alembic/command.py:403: in upgrade
    script.run_env()
venv/lib/python3.12/site-packages/alembic/script/base.py:583: in run_env
    util.load_python_file(self.dir, "env.py")
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:95: in load_python_file
    module = load_module_py(module_id, path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:113: in load_module_py
    spec.loader.exec_module(module)  # type: ignore
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
<frozen importlib._bootstrap_external>:995: in exec_module
    ???
<frozen importlib._bootstrap>:488: in _call_with_frames_removed
    ???
migrations/env.py:93: in <module>
    run_migrations_online()
migrations/env.py:87: in run_migrations_online
    context.run_migrations()
<string>:8: in run_migrations
    ???
venv/lib/python3.12/site-packages/alembic/runtime/environment.py:948: in run_migrations
    self.get_context().run_migrations(**kw)
venv/lib/python3.12/site-packages/alembic/runtime/migration.py:627: in run_migrations
    step.migration_fn(**kw)
migrations/versions/002_add_hierarchy_support.py:26: in upgrade
    op.add_column(
<string>:8: in add_column
    ???
<string>:3: in add_column
    ???
venv/lib/python3.12/site-packages/alembic/operations/ops.py:2142: in add_column
    return operations.invoke(op)
           ^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/base.py:445: in invoke
    return fn(self, operation)
           ^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/toimpl.py:171: in add_column
    operations.impl.add_column(table_name, column, schema=schema, **kw)
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:334: in add_column
    self._exec(base.AddColumn(table_name, column, schema=schema))
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:207: in _exec
    return conn.execute(construct, multiparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1416: in execute
    return meth(
venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:181: in _execute_on_connection
    return connection._execute_ddl(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1528: in _execute_ddl
    ret = self._execute_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1848: in _execute_context
    return self._exec_single_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1988: in _exec_single_context
    self._handle_dbapi_exception(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2343: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: in _exec_single_context
    self.dialect.do_execute(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7129a89f6cf0>
cursor = <cursor object at 0x7129a6421e40; closed: -1>
statement = 'ALTER TABLE chunks ADD COLUMN parent_chunk_id UUID'
parameters = immutabledict({})
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x7129a8a06360>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "chunks" does not exist
E       
E       [SQL: ALTER TABLE chunks ADD COLUMN parent_chunk_id UUID]
E       (Background on this error at: https://sqlalche.me/e/20/f405)

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: ProgrammingError
----------------------------- Captured stderr call -----------------------------
INFO  [alembic.runtime.migration] Context impl PostgresqlImpl.
INFO  [alembic.runtime.migration] Will assume transactional DDL.
INFO  [alembic.runtime.migration] Running upgrade 001 -> 002, Add hierarchy support to chunks table
_______ TestMigrationValidatorIntegration.test_validate_after_downgrade ________

self = <sqlalchemy.engine.base.Connection object at 0x712996345ee0>
dialect = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7129963757f0>
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x712995bded20>
statement = <sqlalchemy.dialects.postgresql.base.PGDDLCompiler object at 0x712995bde6c0>
parameters = [immutabledict({})]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7129963757f0>
cursor = <cursor object at 0x7129a6421300; closed: -1>
statement = 'ALTER TABLE chunks ADD COLUMN parent_chunk_id UUID'
parameters = immutabledict({})
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x712995bded20>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       psycopg2.errors.UndefinedTable: relation "chunks" does not exist

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: UndefinedTable

The above exception was the direct cause of the following exception:

self = <tests.integration.database.test_migration_validator_integration.TestMigrationValidatorIntegration object at 0x7129c27e20c0>
validator = <rag_factory.services.database.migration_validator.MigrationValidator object at 0x7129a89f05f0>
alembic_config = <alembic.config.Config object at 0x7129a89f20f0>

    @pytest.mark.asyncio
    async def test_validate_after_downgrade(
        self,
        validator: MigrationValidator,
        alembic_config: Config
    ) -> None:
        """Test validation after downgrading migrations."""
        # Apply all migrations
>       command.upgrade(alembic_config, "head")

tests/integration/database/test_migration_validator_integration.py:272: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
venv/lib/python3.12/site-packages/alembic/command.py:403: in upgrade
    script.run_env()
venv/lib/python3.12/site-packages/alembic/script/base.py:583: in run_env
    util.load_python_file(self.dir, "env.py")
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:95: in load_python_file
    module = load_module_py(module_id, path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:113: in load_module_py
    spec.loader.exec_module(module)  # type: ignore
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
<frozen importlib._bootstrap_external>:995: in exec_module
    ???
<frozen importlib._bootstrap>:488: in _call_with_frames_removed
    ???
migrations/env.py:93: in <module>
    run_migrations_online()
migrations/env.py:87: in run_migrations_online
    context.run_migrations()
<string>:8: in run_migrations
    ???
venv/lib/python3.12/site-packages/alembic/runtime/environment.py:948: in run_migrations
    self.get_context().run_migrations(**kw)
venv/lib/python3.12/site-packages/alembic/runtime/migration.py:627: in run_migrations
    step.migration_fn(**kw)
migrations/versions/002_add_hierarchy_support.py:26: in upgrade
    op.add_column(
<string>:8: in add_column
    ???
<string>:3: in add_column
    ???
venv/lib/python3.12/site-packages/alembic/operations/ops.py:2142: in add_column
    return operations.invoke(op)
           ^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/base.py:445: in invoke
    return fn(self, operation)
           ^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/toimpl.py:171: in add_column
    operations.impl.add_column(table_name, column, schema=schema, **kw)
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:334: in add_column
    self._exec(base.AddColumn(table_name, column, schema=schema))
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:207: in _exec
    return conn.execute(construct, multiparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1416: in execute
    return meth(
venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:181: in _execute_on_connection
    return connection._execute_ddl(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1528: in _execute_ddl
    ret = self._execute_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1848: in _execute_context
    return self._exec_single_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1988: in _exec_single_context
    self._handle_dbapi_exception(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2343: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: in _exec_single_context
    self.dialect.do_execute(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7129963757f0>
cursor = <cursor object at 0x7129a6421300; closed: -1>
statement = 'ALTER TABLE chunks ADD COLUMN parent_chunk_id UUID'
parameters = immutabledict({})
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x712995bded20>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "chunks" does not exist
E       
E       [SQL: ALTER TABLE chunks ADD COLUMN parent_chunk_id UUID]
E       (Background on this error at: https://sqlalche.me/e/20/f405)

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: ProgrammingError
----------------------------- Captured stderr call -----------------------------
INFO  [alembic.runtime.migration] Context impl PostgresqlImpl.
INFO  [alembic.runtime.migration] Will assume transactional DDL.
INFO  [alembic.runtime.migration] Running upgrade 001 -> 002, Add hierarchy support to chunks table
___ TestMigrationValidatorIntegration.test_multiple_validators_same_database ___

self = <sqlalchemy.engine.base.Connection object at 0x712996375310>
dialect = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x712995a54a10>
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x712995b753a0>
statement = <sqlalchemy.dialects.postgresql.base.PGDDLCompiler object at 0x712995b76f90>
parameters = [immutabledict({})]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x712995a54a10>
cursor = <cursor object at 0x7129a6421210; closed: -1>
statement = 'ALTER TABLE chunks ADD COLUMN parent_chunk_id UUID'
parameters = immutabledict({})
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x712995b753a0>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       psycopg2.errors.UndefinedTable: relation "chunks" does not exist

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: UndefinedTable

The above exception was the direct cause of the following exception:

self = <tests.integration.database.test_migration_validator_integration.TestMigrationValidatorIntegration object at 0x7129c27e2480>
db_service = <rag_factory.services.database.postgres.PostgresqlDatabaseService object at 0x712995b9fb90>
alembic_config = <alembic.config.Config object at 0x712995b9daf0>

    @pytest.mark.asyncio
    async def test_multiple_validators_same_database(
        self,
        db_service: PostgresqlDatabaseService,
        alembic_config: Config
    ) -> None:
        """Test multiple validators on the same database."""
        # Apply migrations
>       command.upgrade(alembic_config, "head")

tests/integration/database/test_migration_validator_integration.py:295: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
venv/lib/python3.12/site-packages/alembic/command.py:403: in upgrade
    script.run_env()
venv/lib/python3.12/site-packages/alembic/script/base.py:583: in run_env
    util.load_python_file(self.dir, "env.py")
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:95: in load_python_file
    module = load_module_py(module_id, path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:113: in load_module_py
    spec.loader.exec_module(module)  # type: ignore
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
<frozen importlib._bootstrap_external>:995: in exec_module
    ???
<frozen importlib._bootstrap>:488: in _call_with_frames_removed
    ???
migrations/env.py:93: in <module>
    run_migrations_online()
migrations/env.py:87: in run_migrations_online
    context.run_migrations()
<string>:8: in run_migrations
    ???
venv/lib/python3.12/site-packages/alembic/runtime/environment.py:948: in run_migrations
    self.get_context().run_migrations(**kw)
venv/lib/python3.12/site-packages/alembic/runtime/migration.py:627: in run_migrations
    step.migration_fn(**kw)
migrations/versions/002_add_hierarchy_support.py:26: in upgrade
    op.add_column(
<string>:8: in add_column
    ???
<string>:3: in add_column
    ???
venv/lib/python3.12/site-packages/alembic/operations/ops.py:2142: in add_column
    return operations.invoke(op)
           ^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/base.py:445: in invoke
    return fn(self, operation)
           ^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/toimpl.py:171: in add_column
    operations.impl.add_column(table_name, column, schema=schema, **kw)
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:334: in add_column
    self._exec(base.AddColumn(table_name, column, schema=schema))
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:207: in _exec
    return conn.execute(construct, multiparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1416: in execute
    return meth(
venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:181: in _execute_on_connection
    return connection._execute_ddl(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1528: in _execute_ddl
    ret = self._execute_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1848: in _execute_context
    return self._exec_single_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1988: in _exec_single_context
    self._handle_dbapi_exception(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2343: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: in _exec_single_context
    self.dialect.do_execute(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x712995a54a10>
cursor = <cursor object at 0x7129a6421210; closed: -1>
statement = 'ALTER TABLE chunks ADD COLUMN parent_chunk_id UUID'
parameters = immutabledict({})
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x712995b753a0>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "chunks" does not exist
E       
E       [SQL: ALTER TABLE chunks ADD COLUMN parent_chunk_id UUID]
E       (Background on this error at: https://sqlalche.me/e/20/f405)

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: ProgrammingError
----------------------------- Captured stderr call -----------------------------
INFO  [alembic.runtime.migration] Context impl PostgresqlImpl.
INFO  [alembic.runtime.migration] Will assume transactional DDL.
INFO  [alembic.runtime.migration] Running upgrade 001 -> 002, Add hierarchy support to chunks table
_______ TestRealServiceInstantiation.test_multiple_service_instantiation _______

self = <rag_factory.registry.service_registry.ServiceRegistry object at 0x7129964c3c20>
service_ref = 'embedding_local'

    def get(self, service_ref: str) -> Any:
        """Get or create a service instance.
    
        Args:
            service_ref: Service reference like "$llm1" or "llm1"
    
        Returns:
            Service instance implementing appropriate interface
    
        Raises:
            ServiceNotFoundError: If service not found in registry
            ServiceInstantiationError: If service creation fails
        """
        # Strip $ prefix if present
        service_name = service_ref.lstrip('$')
    
        # Return cached instance if exists
        if service_name in self._instances:
            logger.debug(f"Service '{service_name}' returned from cache")
            return self._instances[service_name]
    
        # Thread-safe instantiation
        with self._locks[service_name]:
            # Double-check after acquiring lock
            if service_name in self._instances:
                return self._instances[service_name]
    
            # Validate service exists
            if 'services' not in self.config:
                raise ServiceNotFoundError(
                    f"No services defined in registry configuration"
                )
    
            if service_name not in self.config['services']:
                available = list(self.config['services'].keys())
                raise ServiceNotFoundError(
                    f"Service '{service_name}' not found in registry. "
                    f"Available services: {available}"
                )
    
            # Get service configuration
            service_config = self.config['services'][service_name]
    
            # Create service instance
            logger.info(f"Instantiating service: {service_name}")
            start_time = time.time()
    
            try:
>               service_instance = self._factory.create_service(
                    service_name,
                    service_config
                )

rag_factory/registry/service_registry.py:137: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
rag_factory/registry/service_factory.py:48: in create_service
    return self._create_embedding_service(service_name, config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
rag_factory/registry/service_factory.py:127: in _create_embedding_service
    return ONNXEmbeddingService(
rag_factory/services/onnx/embedding.py:68: in __init__
    self._provider = ONNXLocalProvider(config)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
rag_factory/services/embedding/providers/onnx_local.py:116: in __init__
    self.model_path = get_onnx_model_path(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

model_name = 'Xenova/all-MiniLM-L6-v2', cache_dir = PosixPath('models')
filename = 'model.onnx'

    def get_onnx_model_path(
        model_name: str,
        cache_dir: Optional[Path] = None,
        filename: str = "model.onnx",
    ) -> Path:
        """Get path to local ONNX model.
    
        This function checks:
        1. Local model paths (if model exists locally)
        2. Local cache directory
    
        Args:
            model_name: Model identifier or local path
            cache_dir: Directory for model caching
            filename: Name of the ONNX model file
    
        Returns:
            Path to ONNX model file
    
        Raises:
            FileNotFoundError: If model is not found locally
        """
        import os
    
        check_dependencies()
    
        # Check for environment variable configuration
        env_model_path = os.getenv("EMBEDDING_MODEL_PATH")
        env_model_name = os.getenv("EMBEDDING_MODEL_NAME")
    
        # Use environment variable for cache_dir if not specified
        if cache_dir is None:
            if env_model_path:
                cache_dir = Path(env_model_path)
            elif Path("models/embeddings").exists():
                cache_dir = Path("models/embeddings").resolve()
                logger.info(f"Using local project cache: {cache_dir}")
            else:
                # Default to standard location, but don't create it if we're not downloading
                cache_dir = Path.home() / ".cache" / "rag_factory" / "onnx_models"
    
        cache_dir = Path(cache_dir)
    
        # Use environment variable for model_name if it matches default
        if env_model_name and model_name == "Xenova/all-MiniLM-L6-v2":
            logger.info(f"Using model from EMBEDDING_MODEL_NAME env: {env_model_name}")
            model_name = env_model_name
    
        # Check if model_name is a local path
        potential_local_path = Path(model_name)
        if potential_local_path.exists() and potential_local_path.is_file():
            logger.info(f"Using local ONNX model: {potential_local_path}")
            return potential_local_path
    
        # Check if model exists in cache directory
        # Try both naming conventions: underscore (old) and double-dash (HF standard)
        model_dir_name_underscore = model_name.replace("/", "_")
        model_dir_name_dash = model_name.replace("/", "--")
    
        for model_dir_name in [model_dir_name_dash, model_dir_name_underscore]:
            local_model_dir = cache_dir / model_dir_name
    
            if local_model_dir.exists():
                # Look for ONNX files in the directory (recursively, Xenova models have onnx/ subdirectory)
                onnx_files = list(local_model_dir.rglob("*.onnx"))
                if onnx_files:
                    # Prefer the main model.onnx if available, otherwise use first one
                    main_model = next((f for f in onnx_files if f.name == "model.onnx"), onnx_files[0])
                    logger.info(f"Using cached ONNX model: {main_model}")
                    return main_model
    
        # Model not found locally
        error_msg = (
            f"ONNX model '{model_name}' not found locally.\n"
            f"Checked path: {cache_dir}\n"
            f"Automatic downloading is disabled. Please ensure the model is available directly in the infrastructure.\n"
            f"Set EMBEDDING_MODEL_PATH environment variable to the directory containing the model."
        )
>       raise FileNotFoundError(error_msg)
E       FileNotFoundError: ONNX model 'Xenova/all-MiniLM-L6-v2' not found locally.
E       Checked path: models
E       Automatic downloading is disabled. Please ensure the model is available directly in the infrastructure.
E       Set EMBEDDING_MODEL_PATH environment variable to the directory containing the model.

rag_factory/services/utils/onnx_utils.py:123: FileNotFoundError

During handling of the above exception, another exception occurred:

self = <tests.integration.registry.test_registry_integration.TestRealServiceInstantiation object at 0x7129ae73de80>
test_services_yaml_with_env = '/tmp/pytest-of-admindevmac/pytest-54/test_multiple_service_instanti0/services.yaml'

    def test_multiple_service_instantiation(self, test_services_yaml_with_env):
        """Test instantiating multiple services."""
        registry = ServiceRegistry(test_services_yaml_with_env)
    
        # Get both services
>       embedding = registry.get("embedding_local")
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/integration/registry/test_registry_integration.py:95: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <rag_factory.registry.service_registry.ServiceRegistry object at 0x7129964c3c20>
service_ref = 'embedding_local'

    def get(self, service_ref: str) -> Any:
        """Get or create a service instance.
    
        Args:
            service_ref: Service reference like "$llm1" or "llm1"
    
        Returns:
            Service instance implementing appropriate interface
    
        Raises:
            ServiceNotFoundError: If service not found in registry
            ServiceInstantiationError: If service creation fails
        """
        # Strip $ prefix if present
        service_name = service_ref.lstrip('$')
    
        # Return cached instance if exists
        if service_name in self._instances:
            logger.debug(f"Service '{service_name}' returned from cache")
            return self._instances[service_name]
    
        # Thread-safe instantiation
        with self._locks[service_name]:
            # Double-check after acquiring lock
            if service_name in self._instances:
                return self._instances[service_name]
    
            # Validate service exists
            if 'services' not in self.config:
                raise ServiceNotFoundError(
                    f"No services defined in registry configuration"
                )
    
            if service_name not in self.config['services']:
                available = list(self.config['services'].keys())
                raise ServiceNotFoundError(
                    f"Service '{service_name}' not found in registry. "
                    f"Available services: {available}"
                )
    
            # Get service configuration
            service_config = self.config['services'][service_name]
    
            # Create service instance
            logger.info(f"Instantiating service: {service_name}")
            start_time = time.time()
    
            try:
                service_instance = self._factory.create_service(
                    service_name,
                    service_config
                )
                instantiation_time = time.time() - start_time
    
                logger.info(
                    f"Service '{service_name}' instantiated successfully "
                    f"in {instantiation_time:.2f}s"
                )
    
            except Exception as e:
                logger.error(f"Failed to instantiate service '{service_name}': {e}")
>               raise ServiceInstantiationError(
                    f"Service instantiation failed for '{service_name}': {e}"
                )
E               rag_factory.registry.exceptions.ServiceInstantiationError: Service instantiation failed for 'embedding_local': ONNX model 'Xenova/all-MiniLM-L6-v2' not found locally.
E               Checked path: models
E               Automatic downloading is disabled. Please ensure the model is available directly in the infrastructure.
E               Set EMBEDDING_MODEL_PATH environment variable to the directory containing the model.

rag_factory/registry/service_registry.py:150: ServiceInstantiationError
________________ TestErrorHandling.test_invalid_service_config _________________

self = <rag_factory.config.validator.ConfigValidator object at 0x7129a8838d70>
config = {'services': {'invalid_service': {'unknown_field': 'value'}}}
file_path = '/tmp/pytest-of-admindevmac/pytest-54/test_invalid_service_config0/services.yaml'

    def validate_services_yaml(
        self,
        config: Dict[str, Any],
        file_path: Optional[str] = None
    ) -> List[str]:
        """
        Validate services.yaml configuration.
    
        Args:
            config: Parsed YAML configuration
            file_path: Path to YAML file (for error messages)
    
        Returns:
            List of warning messages (empty if no warnings)
    
        Raises:
            ConfigValidationError: If validation fails
    
        Examples:
            >>> validator = ConfigValidator()
            >>> config = {
            ...     "services": {
            ...         "llm1": {
            ...             "name": "test-llm",
            ...             "type": "llm",
            ...             "url": "http://localhost:1234/v1",
            ...             "api_key": "${API_KEY}",
            ...             "model": "test-model"
            ...         }
            ...     }
            ... }
            >>> warnings = validator.validate_services_yaml(config)
            >>> len(warnings)
            0
        """
        try:
            # JSON Schema validation
>           jsonschema.validate(
                instance=config,
                schema=self._schemas["service_registry"]
            )

rag_factory/config/validator.py:113: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

instance = {'services': {'invalid_service': {'unknown_field': 'value'}}}
schema = {'$schema': 'http://json-schema.org/draft-07/schema#', 'definitions': {'database_service': {'properties': {'connection...tion': 'Schema version (semver)', 'pattern': '^\\d+\\.\\d+\\.\\d+$', 'type': 'string'}}, 'required': ['services'], ...}
cls = <class 'jsonschema.validators.Draft7Validator'>, args = (), kwargs = {}
validator = Draft7Validator(schema={'$schema': 'http://json-...ft-07/schema#', 'definitions': {'database_service': {'properties': ... (semver)', 'pattern': '^\\d+\\.\\d+\\.\\d+$', 'type': 'string'}}, 'required': ['services'], ...}, format_checker=None)
error = <ValidationError: "{'unknown_field': 'value'} is not valid under any of the given schemas">

    def validate(instance, schema, cls=None, *args, **kwargs):  # noqa: D417
        """
        Validate an instance under the given schema.
    
            >>> validate([2, 3, 4], {"maxItems": 2})
            Traceback (most recent call last):
                ...
            ValidationError: [2, 3, 4] is too long
    
        :func:`~jsonschema.validators.validate` will first verify that the
        provided schema is itself valid, since not doing so can lead to less
        obvious error messages and fail in less obvious or consistent ways.
    
        If you know you have a valid schema already, especially
        if you intend to validate multiple instances with
        the same schema, you likely would prefer using the
        `jsonschema.protocols.Validator.validate` method directly on a
        specific validator (e.g. ``Draft202012Validator.validate``).
    
    
        Arguments:
    
            instance:
    
                The instance to validate
    
            schema:
    
                The schema to validate with
    
            cls (jsonschema.protocols.Validator):
    
                The class that will be used to validate the instance.
    
        If the ``cls`` argument is not provided, two things will happen
        in accordance with the specification. First, if the schema has a
        :kw:`$schema` keyword containing a known meta-schema [#]_ then the
        proper validator will be used. The specification recommends that
        all schemas contain :kw:`$schema` properties for this reason. If no
        :kw:`$schema` property is found, the default validator class is the
        latest released draft.
    
        Any other provided positional and keyword arguments will be passed
        on when instantiating the ``cls``.
    
        Raises:
    
            `jsonschema.exceptions.ValidationError`:
    
                if the instance is invalid
    
            `jsonschema.exceptions.SchemaError`:
    
                if the schema itself is invalid
    
        .. rubric:: Footnotes
        .. [#] known by a validator registered with
            `jsonschema.validators.validates`
    
        """
        if cls is None:
            cls = validator_for(schema)
    
        cls.check_schema(schema)
        validator = cls(schema, *args, **kwargs)
        error = exceptions.best_match(validator.iter_errors(instance))
        if error is not None:
>           raise error
E           jsonschema.exceptions.ValidationError: {'unknown_field': 'value'} is not valid under any of the given schemas
E           
E           Failed validating 'oneOf' in schema['properties']['services']['patternProperties']['^[a-zA-Z0-9_]+$']:
E               {'oneOf': [{'$ref': '#/definitions/llm_service'},
E                          {'$ref': '#/definitions/embedding_service'},
E                          {'$ref': '#/definitions/database_service'}]}
E           
E           On instance['services']['invalid_service']:
E               {'unknown_field': 'value'}

venv/lib/python3.12/site-packages/jsonschema/validators.py:1332: ValidationError

During handling of the above exception, another exception occurred:

self = <rag_factory.registry.service_registry.ServiceRegistry object at 0x7129a8839160>

    def _load_config(self) -> None:
        """Load and validate services.yaml configuration."""
        logger.info(f"Loading service registry from: {self.config_path}")
    
        try:
            # Load YAML
            with open(self.config_path, 'r') as f:
                raw_config = yaml.safe_load(f)
    
            # Validate schema
>           warnings = self._validator.validate_services_yaml(
                raw_config,
                file_path=self.config_path
            )

rag_factory/registry/service_registry.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <rag_factory.config.validator.ConfigValidator object at 0x7129a8838d70>
config = {'services': {'invalid_service': {'unknown_field': 'value'}}}
file_path = '/tmp/pytest-of-admindevmac/pytest-54/test_invalid_service_config0/services.yaml'

    def validate_services_yaml(
        self,
        config: Dict[str, Any],
        file_path: Optional[str] = None
    ) -> List[str]:
        """
        Validate services.yaml configuration.
    
        Args:
            config: Parsed YAML configuration
            file_path: Path to YAML file (for error messages)
    
        Returns:
            List of warning messages (empty if no warnings)
    
        Raises:
            ConfigValidationError: If validation fails
    
        Examples:
            >>> validator = ConfigValidator()
            >>> config = {
            ...     "services": {
            ...         "llm1": {
            ...             "name": "test-llm",
            ...             "type": "llm",
            ...             "url": "http://localhost:1234/v1",
            ...             "api_key": "${API_KEY}",
            ...             "model": "test-model"
            ...         }
            ...     }
            ... }
            >>> warnings = validator.validate_services_yaml(config)
            >>> len(warnings)
            0
        """
        try:
            # JSON Schema validation
            jsonschema.validate(
                instance=config,
                schema=self._schemas["service_registry"]
            )
        except jsonschema.ValidationError as e:
>           raise ConfigValidationError(
                message=f"Schema validation failed: {e.message}",
                file_path=file_path,
                field=".".join(str(p) for p in e.path)
            )
E           rag_factory.config.validator.ConfigValidationError: Schema validation failed: {'unknown_field': 'value'} is not valid under any of the given schemas
E           File: /tmp/pytest-of-admindevmac/pytest-54/test_invalid_service_config0/services.yaml
E           Field: services.invalid_service

rag_factory/config/validator.py:118: ConfigValidationError

During handling of the above exception, another exception occurred:

self = <tests.integration.registry.test_registry_integration.TestErrorHandling object at 0x7129ae73f3e0>
tmp_path = PosixPath('/tmp/pytest-of-admindevmac/pytest-54/test_invalid_service_config0')

        def test_invalid_service_config(self, tmp_path):
            """Test handling of invalid service configuration."""
            content = """
    services:
      invalid_service:
        unknown_field: "value"
    """
            services_file = tmp_path / "services.yaml"
            services_file.write_text(content)
    
>           registry = ServiceRegistry(str(services_file))
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/integration/registry/test_registry_integration.py:230: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
rag_factory/registry/service_registry.py:51: in __init__
    self._load_config()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <rag_factory.registry.service_registry.ServiceRegistry object at 0x7129a8839160>

    def _load_config(self) -> None:
        """Load and validate services.yaml configuration."""
        logger.info(f"Loading service registry from: {self.config_path}")
    
        try:
            # Load YAML
            with open(self.config_path, 'r') as f:
                raw_config = yaml.safe_load(f)
    
            # Validate schema
            warnings = self._validator.validate_services_yaml(
                raw_config,
                file_path=self.config_path
            )
    
            # Print warnings
            for warning in warnings:
                logger.warning(warning)
    
            # Resolve environment variables
            self.config = EnvResolver.resolve(raw_config)
    
            logger.info(
                f"Service registry loaded: "
                f"{len(self.config.get('services', {}))} services available"
            )
    
        except FileNotFoundError:
            raise ServiceInstantiationError(
                f"Service registry configuration not found: {self.config_path}"
            )
        except Exception as e:
>           raise ServiceInstantiationError(
                f"Failed to load service registry: {e}"
            )
E           rag_factory.registry.exceptions.ServiceInstantiationError: Failed to load service registry: Schema validation failed: {'unknown_field': 'value'} is not valid under any of the given schemas
E           File: /tmp/pytest-of-admindevmac/pytest-54/test_invalid_service_config0/services.yaml
E           Field: services.invalid_service

rag_factory/registry/service_registry.py:85: ServiceInstantiationError
___________ TestConfigurationValidation.test_configuration_warnings ____________

self = <rag_factory.config.validator.ConfigValidator object at 0x71299632c710>
config = {'services': {'test_service': {'api_key': 'plaintext-secret', 'model': 'test-model', 'provider': 'onnx'}}}
file_path = '/tmp/pytest-of-admindevmac/pytest-54/test_configuration_warnings0/services.yaml'

    def validate_services_yaml(
        self,
        config: Dict[str, Any],
        file_path: Optional[str] = None
    ) -> List[str]:
        """
        Validate services.yaml configuration.
    
        Args:
            config: Parsed YAML configuration
            file_path: Path to YAML file (for error messages)
    
        Returns:
            List of warning messages (empty if no warnings)
    
        Raises:
            ConfigValidationError: If validation fails
    
        Examples:
            >>> validator = ConfigValidator()
            >>> config = {
            ...     "services": {
            ...         "llm1": {
            ...             "name": "test-llm",
            ...             "type": "llm",
            ...             "url": "http://localhost:1234/v1",
            ...             "api_key": "${API_KEY}",
            ...             "model": "test-model"
            ...         }
            ...     }
            ... }
            >>> warnings = validator.validate_services_yaml(config)
            >>> len(warnings)
            0
        """
        try:
            # JSON Schema validation
>           jsonschema.validate(
                instance=config,
                schema=self._schemas["service_registry"]
            )

rag_factory/config/validator.py:113: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

instance = {'services': {'test_service': {'api_key': 'plaintext-secret', 'model': 'test-model', 'provider': 'onnx'}}}
schema = {'$schema': 'http://json-schema.org/draft-07/schema#', 'definitions': {'database_service': {'properties': {'connection...tion': 'Schema version (semver)', 'pattern': '^\\d+\\.\\d+\\.\\d+$', 'type': 'string'}}, 'required': ['services'], ...}
cls = <class 'jsonschema.validators.Draft7Validator'>, args = (), kwargs = {}
validator = Draft7Validator(schema={'$schema': 'http://json-...ft-07/schema#', 'definitions': {'database_service': {'properties': ... (semver)', 'pattern': '^\\d+\\.\\d+\\.\\d+$', 'type': 'string'}}, 'required': ['services'], ...}, format_checker=None)
error = <ValidationError: "{'provider': 'onnx', 'model': 'test-model', 'api_key': 'plaintext-secret'} is not valid under any of the given schemas">

    def validate(instance, schema, cls=None, *args, **kwargs):  # noqa: D417
        """
        Validate an instance under the given schema.
    
            >>> validate([2, 3, 4], {"maxItems": 2})
            Traceback (most recent call last):
                ...
            ValidationError: [2, 3, 4] is too long
    
        :func:`~jsonschema.validators.validate` will first verify that the
        provided schema is itself valid, since not doing so can lead to less
        obvious error messages and fail in less obvious or consistent ways.
    
        If you know you have a valid schema already, especially
        if you intend to validate multiple instances with
        the same schema, you likely would prefer using the
        `jsonschema.protocols.Validator.validate` method directly on a
        specific validator (e.g. ``Draft202012Validator.validate``).
    
    
        Arguments:
    
            instance:
    
                The instance to validate
    
            schema:
    
                The schema to validate with
    
            cls (jsonschema.protocols.Validator):
    
                The class that will be used to validate the instance.
    
        If the ``cls`` argument is not provided, two things will happen
        in accordance with the specification. First, if the schema has a
        :kw:`$schema` keyword containing a known meta-schema [#]_ then the
        proper validator will be used. The specification recommends that
        all schemas contain :kw:`$schema` properties for this reason. If no
        :kw:`$schema` property is found, the default validator class is the
        latest released draft.
    
        Any other provided positional and keyword arguments will be passed
        on when instantiating the ``cls``.
    
        Raises:
    
            `jsonschema.exceptions.ValidationError`:
    
                if the instance is invalid
    
            `jsonschema.exceptions.SchemaError`:
    
                if the schema itself is invalid
    
        .. rubric:: Footnotes
        .. [#] known by a validator registered with
            `jsonschema.validators.validates`
    
        """
        if cls is None:
            cls = validator_for(schema)
    
        cls.check_schema(schema)
        validator = cls(schema, *args, **kwargs)
        error = exceptions.best_match(validator.iter_errors(instance))
        if error is not None:
>           raise error
E           jsonschema.exceptions.ValidationError: {'provider': 'onnx', 'model': 'test-model', 'api_key': 'plaintext-secret'} is not valid under any of the given schemas
E           
E           Failed validating 'oneOf' in schema['properties']['services']['patternProperties']['^[a-zA-Z0-9_]+$']:
E               {'oneOf': [{'$ref': '#/definitions/llm_service'},
E                          {'$ref': '#/definitions/embedding_service'},
E                          {'$ref': '#/definitions/database_service'}]}
E           
E           On instance['services']['test_service']:
E               {'provider': 'onnx',
E                'model': 'test-model',
E                'api_key': 'plaintext-secret'}

venv/lib/python3.12/site-packages/jsonschema/validators.py:1332: ValidationError

During handling of the above exception, another exception occurred:

self = <rag_factory.registry.service_registry.ServiceRegistry object at 0x7129a88e6c30>

    def _load_config(self) -> None:
        """Load and validate services.yaml configuration."""
        logger.info(f"Loading service registry from: {self.config_path}")
    
        try:
            # Load YAML
            with open(self.config_path, 'r') as f:
                raw_config = yaml.safe_load(f)
    
            # Validate schema
>           warnings = self._validator.validate_services_yaml(
                raw_config,
                file_path=self.config_path
            )

rag_factory/registry/service_registry.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <rag_factory.config.validator.ConfigValidator object at 0x71299632c710>
config = {'services': {'test_service': {'api_key': 'plaintext-secret', 'model': 'test-model', 'provider': 'onnx'}}}
file_path = '/tmp/pytest-of-admindevmac/pytest-54/test_configuration_warnings0/services.yaml'

    def validate_services_yaml(
        self,
        config: Dict[str, Any],
        file_path: Optional[str] = None
    ) -> List[str]:
        """
        Validate services.yaml configuration.
    
        Args:
            config: Parsed YAML configuration
            file_path: Path to YAML file (for error messages)
    
        Returns:
            List of warning messages (empty if no warnings)
    
        Raises:
            ConfigValidationError: If validation fails
    
        Examples:
            >>> validator = ConfigValidator()
            >>> config = {
            ...     "services": {
            ...         "llm1": {
            ...             "name": "test-llm",
            ...             "type": "llm",
            ...             "url": "http://localhost:1234/v1",
            ...             "api_key": "${API_KEY}",
            ...             "model": "test-model"
            ...         }
            ...     }
            ... }
            >>> warnings = validator.validate_services_yaml(config)
            >>> len(warnings)
            0
        """
        try:
            # JSON Schema validation
            jsonschema.validate(
                instance=config,
                schema=self._schemas["service_registry"]
            )
        except jsonschema.ValidationError as e:
>           raise ConfigValidationError(
                message=f"Schema validation failed: {e.message}",
                file_path=file_path,
                field=".".join(str(p) for p in e.path)
            )
E           rag_factory.config.validator.ConfigValidationError: Schema validation failed: {'provider': 'onnx', 'model': 'test-model', 'api_key': 'plaintext-secret'} is not valid under any of the given schemas
E           File: /tmp/pytest-of-admindevmac/pytest-54/test_configuration_warnings0/services.yaml
E           Field: services.test_service

rag_factory/config/validator.py:118: ConfigValidationError

During handling of the above exception, another exception occurred:

self = <tests.integration.registry.test_registry_integration.TestConfigurationValidation object at 0x7129ae760500>
tmp_path = PosixPath('/tmp/pytest-of-admindevmac/pytest-54/test_configuration_warnings0')
caplog = <_pytest.logging.LogCaptureFixture object at 0x7129a88cf980>

        def test_configuration_warnings(self, tmp_path, caplog):
            """Test that configuration warnings are logged."""
            import logging
            caplog.set_level(logging.WARNING)
    
            content = """
    services:
      test_service:
        provider: "onnx"
        model: "test-model"
        api_key: "plaintext-secret"  # Should trigger warning
    """
            services_file = tmp_path / "services.yaml"
            services_file.write_text(content)
    
>           registry = ServiceRegistry(str(services_file))
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/integration/registry/test_registry_integration.py:332: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
rag_factory/registry/service_registry.py:51: in __init__
    self._load_config()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <rag_factory.registry.service_registry.ServiceRegistry object at 0x7129a88e6c30>

    def _load_config(self) -> None:
        """Load and validate services.yaml configuration."""
        logger.info(f"Loading service registry from: {self.config_path}")
    
        try:
            # Load YAML
            with open(self.config_path, 'r') as f:
                raw_config = yaml.safe_load(f)
    
            # Validate schema
            warnings = self._validator.validate_services_yaml(
                raw_config,
                file_path=self.config_path
            )
    
            # Print warnings
            for warning in warnings:
                logger.warning(warning)
    
            # Resolve environment variables
            self.config = EnvResolver.resolve(raw_config)
    
            logger.info(
                f"Service registry loaded: "
                f"{len(self.config.get('services', {}))} services available"
            )
    
        except FileNotFoundError:
            raise ServiceInstantiationError(
                f"Service registry configuration not found: {self.config_path}"
            )
        except Exception as e:
>           raise ServiceInstantiationError(
                f"Failed to load service registry: {e}"
            )
E           rag_factory.registry.exceptions.ServiceInstantiationError: Failed to load service registry: Schema validation failed: {'provider': 'onnx', 'model': 'test-model', 'api_key': 'plaintext-secret'} is not valid under any of the given schemas
E           File: /tmp/pytest-of-admindevmac/pytest-54/test_configuration_warnings0/services.yaml
E           Field: services.test_service

rag_factory/registry/service_registry.py:85: ServiceInstantiationError
______________________________ test_rag_workflow _______________________________

embedding_service = <rag_factory.services.embedding.service.EmbeddingService object at 0x7129a66c4890>
llm_service = <rag_factory.services.llm.service.LLMService object at 0x7129a747cf80>
database_service = (<rag_factory.services.database.postgres.PostgresqlDatabaseService object at 0x7129a7493380>, <AsyncMock name='mock.__aenter__()' id='124423714154320'>)

    @pytest.mark.asyncio
    async def test_rag_workflow(embedding_service, llm_service, database_service):
        """Test full RAG workflow integration."""
        db_service, db_conn = database_service
    
        # 1. Embed document
        text = "Important document content"
        embedding_result = embedding_service.embed([text])
        embedding = embedding_result.embeddings[0]
    
        assert len(embedding) == 3
    
        # 2. Store in database
        chunk = {
            "chunk_id": "doc1",
            "text": text,
            "embedding": embedding,
            "metadata": {"source": "test"}
        }
        await db_service.store_chunks([chunk])
    
        db_conn.execute.assert_called()
    
        # 3. Retrieve relevant chunks (mock search)
        db_conn.fetch.return_value = [
            {
                "chunk_id": "doc1",
                "text": text,
                "metadata": '{"source": "test"}',
                "similarity": 0.95
            }
        ]
    
        query = "What is important?"
        query_embedding = embedding_service.embed([query]).embeddings[0]
        results = await db_service.search_chunks(query_embedding)
    
        assert len(results) == 1
>       assert results[0]["text"] == text
               ^^^^^^^^^^^^^^^^^^
E       TypeError: 'Chunk' object is not subscriptable

tests/integration/services/test_service_integration.py:136: TypeError
_____________________ test_embedding_database_consistency ______________________

embedding_service = <rag_factory.services.embedding.service.EmbeddingService object at 0x7129a6606c00>
database_service = (<rag_factory.services.database.postgres.PostgresqlDatabaseService object at 0x7129a74b2930>, <AsyncMock name='mock.__aenter__()' id='124423714364864'>)

    @pytest.mark.asyncio
    async def test_embedding_database_consistency(embedding_service, database_service):
        """Test consistency between embedding dimensions and database storage."""
        db_service, db_conn = database_service
    
        # Get embedding dimension
        dim = embedding_service.provider.get_dimensions()
    
        # Create chunk with correct dimension
        embedding = [0.1] * dim
        chunk = {
            "chunk_id": "1",
            "text": "test",
            "embedding": embedding
        }
    
        await db_service.store_chunks([chunk])
    
        # Verify database received correct dimension vector
        call_args = db_conn.execute.call_args
        embedding_str = call_args[0][3] # 4th argument is embedding_str
        stored_dim = embedding_str.count(",") + 1
    
>       assert stored_dim == dim
E       assert 1 == 3

tests/integration/services/test_service_integration.py:171: AssertionError
____________ TestSelfReflectiveIntegration.test_end_to_end_workflow ____________

self = <tests.integration.strategies.test_self_reflective_integration.TestSelfReflectiveIntegration object at 0x7129a97b7740>
mock_base_strategy = <Mock id='124423711365248'>
mock_llm_service = <Mock id='124423711365440'>

    def test_end_to_end_workflow(self, mock_base_strategy, mock_llm_service):
        """Test complete self-reflective retrieval workflow."""
        # Create strategy
>       strategy = SelfReflectiveRAGStrategy(
            base_retrieval_strategy=mock_base_strategy,
            llm_service=mock_llm_service,
            config={"grade_threshold": 4.0, "max_retries": 2}
        )
E       TypeError: SelfReflectiveRAGStrategy.__init__() got an unexpected keyword argument 'base_retrieval_strategy'

tests/integration/strategies/test_self_reflective_integration.py:80: TypeError
__________ TestSelfReflectiveIntegration.test_retry_with_poor_results __________

self = <tests.integration.strategies.test_self_reflective_integration.TestSelfReflectiveIntegration object at 0x7129a97b7620>
mock_base_strategy = <Mock id='124423711368656'>
mock_llm_service = <Mock id='124423711363808'>

    def test_retry_with_poor_results(self, mock_base_strategy, mock_llm_service):
        """Test that retry is triggered for poor results."""
>       strategy = SelfReflectiveRAGStrategy(
            base_retrieval_strategy=mock_base_strategy,
            llm_service=mock_llm_service,
            config={"grade_threshold": 4.0, "max_retries": 2}
        )
E       TypeError: SelfReflectiveRAGStrategy.__init__() got an unexpected keyword argument 'base_retrieval_strategy'

tests/integration/strategies/test_self_reflective_integration.py:100: TypeError
_________ TestSelfReflectiveIntegration.test_performance_within_limits _________

self = <tests.integration.strategies.test_self_reflective_integration.TestSelfReflectiveIntegration object at 0x7129a97b7c20>
mock_base_strategy = <Mock id='124423711373504'>
mock_llm_service = <Mock id='124423711375328'>

    def test_performance_within_limits(self, mock_base_strategy, mock_llm_service):
        """Test that self-reflective retrieval completes within timeout."""
        import time
    
>       strategy = SelfReflectiveRAGStrategy(
            base_retrieval_strategy=mock_base_strategy,
            llm_service=mock_llm_service,
            config={"grade_threshold": 4.0, "max_retries": 2, "timeout_seconds": 10}
        )
E       TypeError: SelfReflectiveRAGStrategy.__init__() got an unexpected keyword argument 'base_retrieval_strategy'

tests/integration/strategies/test_self_reflective_integration.py:119: TypeError
______________ TestSelfReflectiveWithLMStudio.test_with_real_llm _______________

self = <tests.integration.strategies.test_self_reflective_integration.TestSelfReflectiveWithLMStudio object at 0x7129a97f4080>
llm_service_from_env = <rag_factory.services.llm.service.LLMService object at 0x7129a71dc4a0>

    def test_with_real_llm(self, llm_service_from_env):
        """Test with real LLM service from environment (LM Studio)."""
        from unittest.mock import Mock
    
        # Mock base strategy
        base_strategy = Mock()
        base_strategy.retrieve.return_value = [
            {"chunk_id": "c1", "text": "Sample result", "score": 0.9}
        ]
    
        # Create self-reflective strategy
>       strategy = SelfReflectiveRAGStrategy(
            base_retrieval_strategy=base_strategy,
            llm_service=llm_service_from_env,
            config={"grade_threshold": 4.0, "max_retries": 1}
        )
E       TypeError: SelfReflectiveRAGStrategy.__init__() got an unexpected keyword argument 'base_retrieval_strategy'

tests/integration/strategies/test_self_reflective_integration.py:149: TypeError
_ TestFactoryConsistencyIntegration.test_inconsistent_indexing_strategy_logs_warnings _

self = <tests.integration.test_factory_consistency.TestFactoryConsistencyIntegration object at 0x7129a9657020>
mock_services = StrategyDependencies(llm_service=<MagicMock id='124423709440096'>, embedding_service=<MagicMock id='124423709656992'>, graph_service=<MagicMock id='124423709660736'>, database_service=<MagicMock id='124423709664480'>, reranker_service=None)
caplog = <_pytest.logging.LogCaptureFixture object at 0x7129a7043470>

    def test_inconsistent_indexing_strategy_logs_warnings(self, mock_services, caplog):
        """Test that inconsistent indexing strategy logs warnings."""
        factory = RAGFactory()
        factory.register_strategy("inconsistent_indexing", InconsistentIndexingStrategy)
    
        with caplog.at_level(logging.WARNING):
            strategy = factory.create_strategy("inconsistent_indexing", {})
    
        # Should have warnings for missing EMBEDDING and GRAPH services
>       assert len(caplog.records) == 2
E       assert 0 == 2
E        +  where 0 = len([])
E        +    where [] = <_pytest.logging.LogCaptureFixture object at 0x7129a7043470>.records

tests/integration/test_factory_consistency.py:185: AssertionError
_ TestFactoryConsistencyIntegration.test_inconsistent_retrieval_strategy_logs_warnings _

self = <tests.integration.test_factory_consistency.TestFactoryConsistencyIntegration object at 0x7129a9657740>
mock_services = StrategyDependencies(llm_service=<MagicMock id='124423709891888'>, embedding_service=<MagicMock id='124423709753664'>, graph_service=<MagicMock id='124423709757456'>, database_service=<MagicMock id='124423709761200'>, reranker_service=None)
caplog = <_pytest.logging.LogCaptureFixture object at 0x7129a705aea0>

    def test_inconsistent_retrieval_strategy_logs_warnings(self, mock_services, caplog):
        """Test that inconsistent retrieval strategy logs warnings."""
        factory = RAGFactory(
            llm_service=mock_services.llm_service,
        )
        factory.register_strategy("inconsistent_retrieval", InconsistentRetrievalStrategy)
    
        with caplog.at_level(logging.WARNING):
            strategy = factory.create_strategy("inconsistent_retrieval", {})
    
        # Should have warnings for missing DATABASE and GRAPH services
>       assert len(caplog.records) == 2
E       assert 0 == 2
E        +  where 0 = len([])
E        +    where [] = <_pytest.logging.LogCaptureFixture object at 0x7129a705aea0>.records

tests/integration/test_factory_consistency.py:219: AssertionError
___________________ test_fine_tuned_embeddings_pair_loading ____________________

self = <rag_factory.config.strategy_pair_manager.StrategyPairManager object at 0x7129a7001790>
config = {'config': {'chunk_size': 512, 'min_chunk_size': 100, 'overlap': 50}, 'db_config': {'fields': {'chunk_id': 'chunk_id',..._vectors'}}, 'services': {'db': '$db_main', 'embedding': '$embedding_finetuned'}, 'strategy': 'VectorEmbeddingIndexer'}
is_indexing = True

    def _create_strategy(self, config: Dict[str, Any], is_indexing: bool) -> Any:
        """
        Instantiate strategy with all dependencies.
    
        Args:
            config: Strategy configuration dictionary.
            is_indexing: True if creating indexing strategy, False for retrieval.
    
        Returns:
            Instantiated strategy object.
        """
        # Resolve service references
        # Config['services'] maps abstract service names (llm, db) to registry keys (openai_gpt4, postgres_main)
        # Service references may have $ prefix (e.g., "$embedding_local") which needs to be stripped
        services_map = config.get('services', {})
        resolved_services = {}
    
        for service_type, service_ref in services_map.items():
            try:
                # Strip $ prefix if present
                clean_ref = service_ref.lstrip('$') if isinstance(service_ref, str) else service_ref
                resolved_services[service_type] = self.registry.get(clean_ref)
            except Exception as e:
                 raise ConfigurationError(f"Failed to resolve service '{service_ref}' for type '{service_type}': {e}")
    
        # Handle DatabaseContext if db_config present
        # This allows mapping specific tables/fields for this strategy
        if 'db_config' in config and 'db' in resolved_services:
            db_service = resolved_services['db']
            # Check if db_service supports get_context
            if hasattr(db_service, 'get_context'):
                resolved_services['db'] = db_service.get_context(
                    table_mapping=config['db_config'].get('tables', {}),
                    field_mapping=config['db_config'].get('fields', {})
                )
    
        # Construct StrategyDependencies
        deps = self._build_dependencies(resolved_services)
    
        # Use RAGFactory to create strategy
        factory = RAGFactory()
        strategy_name = config['strategy']
        strategy_config = config.get('config', {})
    
        try:
>           strategy = factory.create_strategy(
                strategy_name,
                config=strategy_config,
                override_deps=deps
            )

rag_factory/config/strategy_pair_manager.py:179: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <rag_factory.factory.RAGFactory object at 0x7129a7001cd0>
name = 'VectorEmbeddingIndexer'
config = {'chunk_size': 512, 'min_chunk_size': 100, 'overlap': 50}
override_deps = StrategyDependencies(llm_service=None, embedding_service=<Mock id='124423709898848'>, graph_service=None, database_service=<Mock id='124423710074848'>, reranker_service=None)

    def create_strategy(
        self,
        name: str,
        config: Optional[Dict[str, Any]] = None,
        override_deps: Optional[StrategyDependencies] = None,
    ) -> IRAGStrategy:
        """
        Create and initialize a strategy instance with dependency injection.
    
        Args:
            name: Name of the registered strategy to create
            config: Optional configuration dictionary for the strategy
            override_deps: Optional dependencies to override factory defaults
    
        Returns:
            IRAGStrategy: Initialized strategy instance
    
        Raises:
            StrategyNotFoundError: If strategy name not in registry
            ValueError: If required services are missing or config is invalid
    
        Example:
            >>> factory = RAGFactory(llm_service=my_llm)
            >>> config = {"chunk_size": 1024, "top_k": 10}
            >>> strategy = factory.create_strategy("my_strategy", config)
            >>>
            >>> # Or with override dependencies
            >>> override = StrategyDependencies(llm_service=different_llm)
            >>> strategy = factory.create_strategy("my_strategy", config, override)
        """
        if name not in self._registry:
            available = list(self._registry.keys())
>           raise StrategyNotFoundError(
                f"Strategy '{name}' not found. "
                f"Available strategies: {available}"
            )
E           rag_factory.exceptions.StrategyNotFoundError: Strategy 'VectorEmbeddingIndexer' not found. Available strategies: ['dummy']

rag_factory/factory.py:204: StrategyNotFoundError

During handling of the above exception, another exception occurred:

self = <rag_factory.config.strategy_pair_manager.StrategyPairManager object at 0x7129a7001790>
class_path = 'VectorEmbeddingIndexer'

    def _import_strategy_class(self, class_path: str) -> Type:
        """
        Import a class dynamically.
    
        Args:
            class_path: Dot-separated path to the class (module.ClassName).
    
        Returns:
            The class object.
        """
        try:
>           module_path, class_name = class_path.rsplit('.', 1)
            ^^^^^^^^^^^^^^^^^^^^^^^
E           ValueError: not enough values to unpack (expected 2, got 1)

rag_factory/config/strategy_pair_manager.py:211: ValueError

During handling of the above exception, another exception occurred:

self = <rag_factory.config.strategy_pair_manager.StrategyPairManager object at 0x7129a7001790>
config = {'config': {'chunk_size': 512, 'min_chunk_size': 100, 'overlap': 50}, 'db_config': {'fields': {'chunk_id': 'chunk_id',..._vectors'}}, 'services': {'db': '$db_main', 'embedding': '$embedding_finetuned'}, 'strategy': 'VectorEmbeddingIndexer'}
is_indexing = True

    def _create_strategy(self, config: Dict[str, Any], is_indexing: bool) -> Any:
        """
        Instantiate strategy with all dependencies.
    
        Args:
            config: Strategy configuration dictionary.
            is_indexing: True if creating indexing strategy, False for retrieval.
    
        Returns:
            Instantiated strategy object.
        """
        # Resolve service references
        # Config['services'] maps abstract service names (llm, db) to registry keys (openai_gpt4, postgres_main)
        # Service references may have $ prefix (e.g., "$embedding_local") which needs to be stripped
        services_map = config.get('services', {})
        resolved_services = {}
    
        for service_type, service_ref in services_map.items():
            try:
                # Strip $ prefix if present
                clean_ref = service_ref.lstrip('$') if isinstance(service_ref, str) else service_ref
                resolved_services[service_type] = self.registry.get(clean_ref)
            except Exception as e:
                 raise ConfigurationError(f"Failed to resolve service '{service_ref}' for type '{service_type}': {e}")
    
        # Handle DatabaseContext if db_config present
        # This allows mapping specific tables/fields for this strategy
        if 'db_config' in config and 'db' in resolved_services:
            db_service = resolved_services['db']
            # Check if db_service supports get_context
            if hasattr(db_service, 'get_context'):
                resolved_services['db'] = db_service.get_context(
                    table_mapping=config['db_config'].get('tables', {}),
                    field_mapping=config['db_config'].get('fields', {})
                )
    
        # Construct StrategyDependencies
        deps = self._build_dependencies(resolved_services)
    
        # Use RAGFactory to create strategy
        factory = RAGFactory()
        strategy_name = config['strategy']
        strategy_config = config.get('config', {})
    
        try:
            strategy = factory.create_strategy(
                strategy_name,
                config=strategy_config,
                override_deps=deps
            )
        except StrategyNotFoundError:
            # Fallback: try to treat it as a class path
            try:
>               strategy_class = self._import_strategy_class(strategy_name)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

rag_factory/config/strategy_pair_manager.py:187: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <rag_factory.config.strategy_pair_manager.StrategyPairManager object at 0x7129a7001790>
class_path = 'VectorEmbeddingIndexer'

    def _import_strategy_class(self, class_path: str) -> Type:
        """
        Import a class dynamically.
    
        Args:
            class_path: Dot-separated path to the class (module.ClassName).
    
        Returns:
            The class object.
        """
        try:
            module_path, class_name = class_path.rsplit('.', 1)
            module = importlib.import_module(module_path)
            return getattr(module, class_name)
        except (ValueError, ImportError, AttributeError) as e:
>           raise ConfigurationError(f"Could not import strategy class '{class_path}': {e}")
E           rag_factory.config.strategy_loader.ConfigurationError: Could not import strategy class 'VectorEmbeddingIndexer': not enough values to unpack (expected 2, got 1)

rag_factory/config/strategy_pair_manager.py:215: ConfigurationError

During handling of the above exception, another exception occurred:

mock_registry_with_services = <Mock id='124423709661552'>

    @pytest.mark.asyncio
    async def test_fine_tuned_embeddings_pair_loading(mock_registry_with_services):
        """Test loading and basic functionality of fine-tuned-embeddings-pair."""
        with patch('rag_factory.config.strategy_pair_manager.MigrationValidator') as MockValidator:
            mock_validator_instance = MockValidator.return_value
            mock_validator_instance.validate.return_value = (True, [])
    
            project_root = Path(__file__).parent.parent.parent
            config_dir = project_root / "strategies"
    
            manager = StrategyPairManager(
                service_registry=mock_registry_with_services,
                config_dir=str(config_dir)
            )
    
            # Load pair
>           indexing, retrieval = manager.load_pair("fine-tuned-embeddings-pair")
                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/integration/test_fine_tuned_embeddings_pair.py:36: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
rag_factory/config/strategy_pair_manager.py:117: in load_pair
    indexing = self._create_strategy(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <rag_factory.config.strategy_pair_manager.StrategyPairManager object at 0x7129a7001790>
config = {'config': {'chunk_size': 512, 'min_chunk_size': 100, 'overlap': 50}, 'db_config': {'fields': {'chunk_id': 'chunk_id',..._vectors'}}, 'services': {'db': '$db_main', 'embedding': '$embedding_finetuned'}, 'strategy': 'VectorEmbeddingIndexer'}
is_indexing = True

    def _create_strategy(self, config: Dict[str, Any], is_indexing: bool) -> Any:
        """
        Instantiate strategy with all dependencies.
    
        Args:
            config: Strategy configuration dictionary.
            is_indexing: True if creating indexing strategy, False for retrieval.
    
        Returns:
            Instantiated strategy object.
        """
        # Resolve service references
        # Config['services'] maps abstract service names (llm, db) to registry keys (openai_gpt4, postgres_main)
        # Service references may have $ prefix (e.g., "$embedding_local") which needs to be stripped
        services_map = config.get('services', {})
        resolved_services = {}
    
        for service_type, service_ref in services_map.items():
            try:
                # Strip $ prefix if present
                clean_ref = service_ref.lstrip('$') if isinstance(service_ref, str) else service_ref
                resolved_services[service_type] = self.registry.get(clean_ref)
            except Exception as e:
                 raise ConfigurationError(f"Failed to resolve service '{service_ref}' for type '{service_type}': {e}")
    
        # Handle DatabaseContext if db_config present
        # This allows mapping specific tables/fields for this strategy
        if 'db_config' in config and 'db' in resolved_services:
            db_service = resolved_services['db']
            # Check if db_service supports get_context
            if hasattr(db_service, 'get_context'):
                resolved_services['db'] = db_service.get_context(
                    table_mapping=config['db_config'].get('tables', {}),
                    field_mapping=config['db_config'].get('fields', {})
                )
    
        # Construct StrategyDependencies
        deps = self._build_dependencies(resolved_services)
    
        # Use RAGFactory to create strategy
        factory = RAGFactory()
        strategy_name = config['strategy']
        strategy_config = config.get('config', {})
    
        try:
            strategy = factory.create_strategy(
                strategy_name,
                config=strategy_config,
                override_deps=deps
            )
        except StrategyNotFoundError:
            # Fallback: try to treat it as a class path
            try:
                strategy_class = self._import_strategy_class(strategy_name)
                 # Manually verify dependencies if not using factory?
                 # Or just instantiate.
                strategy = strategy_class(config=strategy_config, dependencies=deps)
            except Exception as e:
>               raise ConfigurationError(
                    f"Strategy '{strategy_name}' not found in registry and could not be imported as a class: {e}"
                )
E               rag_factory.config.strategy_loader.ConfigurationError: Strategy 'VectorEmbeddingIndexer' not found in registry and could not be imported as a class: Could not import strategy class 'VectorEmbeddingIndexer': not enough values to unpack (expected 2, got 1)

rag_factory/config/strategy_pair_manager.py:192: ConfigurationError
______________________ test_hierarchical_rag_pair_loading ______________________

self = <rag_factory.config.strategy_pair_manager.StrategyPairManager object at 0x7129a7002360>
config = {'config': {'max_depth': 2, 'min_chunk_size': 100}, 'db_config': {'fields': {'chunk_id': 'chunk_id', 'doc_id': 'docume...chical_vectors'}}, 'services': {'db': '$db_main', 'embedding': '$embedding_local'}, 'strategy': 'HierarchicalIndexing'}
is_indexing = True

    def _create_strategy(self, config: Dict[str, Any], is_indexing: bool) -> Any:
        """
        Instantiate strategy with all dependencies.
    
        Args:
            config: Strategy configuration dictionary.
            is_indexing: True if creating indexing strategy, False for retrieval.
    
        Returns:
            Instantiated strategy object.
        """
        # Resolve service references
        # Config['services'] maps abstract service names (llm, db) to registry keys (openai_gpt4, postgres_main)
        # Service references may have $ prefix (e.g., "$embedding_local") which needs to be stripped
        services_map = config.get('services', {})
        resolved_services = {}
    
        for service_type, service_ref in services_map.items():
            try:
                # Strip $ prefix if present
                clean_ref = service_ref.lstrip('$') if isinstance(service_ref, str) else service_ref
                resolved_services[service_type] = self.registry.get(clean_ref)
            except Exception as e:
                 raise ConfigurationError(f"Failed to resolve service '{service_ref}' for type '{service_type}': {e}")
    
        # Handle DatabaseContext if db_config present
        # This allows mapping specific tables/fields for this strategy
        if 'db_config' in config and 'db' in resolved_services:
            db_service = resolved_services['db']
            # Check if db_service supports get_context
            if hasattr(db_service, 'get_context'):
                resolved_services['db'] = db_service.get_context(
                    table_mapping=config['db_config'].get('tables', {}),
                    field_mapping=config['db_config'].get('fields', {})
                )
    
        # Construct StrategyDependencies
        deps = self._build_dependencies(resolved_services)
    
        # Use RAGFactory to create strategy
        factory = RAGFactory()
        strategy_name = config['strategy']
        strategy_config = config.get('config', {})
    
        try:
>           strategy = factory.create_strategy(
                strategy_name,
                config=strategy_config,
                override_deps=deps
            )

rag_factory/config/strategy_pair_manager.py:179: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <rag_factory.factory.RAGFactory object at 0x7129a747f440>
name = 'HierarchicalIndexing', config = {'max_depth': 2, 'min_chunk_size': 100}
override_deps = StrategyDependencies(llm_service=None, embedding_service=<Mock id='124423710537104'>, graph_service=None, database_service=<Mock id='124423709401856'>, reranker_service=None)

    def create_strategy(
        self,
        name: str,
        config: Optional[Dict[str, Any]] = None,
        override_deps: Optional[StrategyDependencies] = None,
    ) -> IRAGStrategy:
        """
        Create and initialize a strategy instance with dependency injection.
    
        Args:
            name: Name of the registered strategy to create
            config: Optional configuration dictionary for the strategy
            override_deps: Optional dependencies to override factory defaults
    
        Returns:
            IRAGStrategy: Initialized strategy instance
    
        Raises:
            StrategyNotFoundError: If strategy name not in registry
            ValueError: If required services are missing or config is invalid
    
        Example:
            >>> factory = RAGFactory(llm_service=my_llm)
            >>> config = {"chunk_size": 1024, "top_k": 10}
            >>> strategy = factory.create_strategy("my_strategy", config)
            >>>
            >>> # Or with override dependencies
            >>> override = StrategyDependencies(llm_service=different_llm)
            >>> strategy = factory.create_strategy("my_strategy", config, override)
        """
        if name not in self._registry:
            available = list(self._registry.keys())
>           raise StrategyNotFoundError(
                f"Strategy '{name}' not found. "
                f"Available strategies: {available}"
            )
E           rag_factory.exceptions.StrategyNotFoundError: Strategy 'HierarchicalIndexing' not found. Available strategies: ['dummy']

rag_factory/factory.py:204: StrategyNotFoundError

During handling of the above exception, another exception occurred:

self = <rag_factory.config.strategy_pair_manager.StrategyPairManager object at 0x7129a7002360>
class_path = 'HierarchicalIndexing'

    def _import_strategy_class(self, class_path: str) -> Type:
        """
        Import a class dynamically.
    
        Args:
            class_path: Dot-separated path to the class (module.ClassName).
    
        Returns:
            The class object.
        """
        try:
>           module_path, class_name = class_path.rsplit('.', 1)
            ^^^^^^^^^^^^^^^^^^^^^^^
E           ValueError: not enough values to unpack (expected 2, got 1)

rag_factory/config/strategy_pair_manager.py:211: ValueError

During handling of the above exception, another exception occurred:

self = <rag_factory.config.strategy_pair_manager.StrategyPairManager object at 0x7129a7002360>
config = {'config': {'max_depth': 2, 'min_chunk_size': 100}, 'db_config': {'fields': {'chunk_id': 'chunk_id', 'doc_id': 'docume...chical_vectors'}}, 'services': {'db': '$db_main', 'embedding': '$embedding_local'}, 'strategy': 'HierarchicalIndexing'}
is_indexing = True

    def _create_strategy(self, config: Dict[str, Any], is_indexing: bool) -> Any:
        """
        Instantiate strategy with all dependencies.
    
        Args:
            config: Strategy configuration dictionary.
            is_indexing: True if creating indexing strategy, False for retrieval.
    
        Returns:
            Instantiated strategy object.
        """
        # Resolve service references
        # Config['services'] maps abstract service names (llm, db) to registry keys (openai_gpt4, postgres_main)
        # Service references may have $ prefix (e.g., "$embedding_local") which needs to be stripped
        services_map = config.get('services', {})
        resolved_services = {}
    
        for service_type, service_ref in services_map.items():
            try:
                # Strip $ prefix if present
                clean_ref = service_ref.lstrip('$') if isinstance(service_ref, str) else service_ref
                resolved_services[service_type] = self.registry.get(clean_ref)
            except Exception as e:
                 raise ConfigurationError(f"Failed to resolve service '{service_ref}' for type '{service_type}': {e}")
    
        # Handle DatabaseContext if db_config present
        # This allows mapping specific tables/fields for this strategy
        if 'db_config' in config and 'db' in resolved_services:
            db_service = resolved_services['db']
            # Check if db_service supports get_context
            if hasattr(db_service, 'get_context'):
                resolved_services['db'] = db_service.get_context(
                    table_mapping=config['db_config'].get('tables', {}),
                    field_mapping=config['db_config'].get('fields', {})
                )
    
        # Construct StrategyDependencies
        deps = self._build_dependencies(resolved_services)
    
        # Use RAGFactory to create strategy
        factory = RAGFactory()
        strategy_name = config['strategy']
        strategy_config = config.get('config', {})
    
        try:
            strategy = factory.create_strategy(
                strategy_name,
                config=strategy_config,
                override_deps=deps
            )
        except StrategyNotFoundError:
            # Fallback: try to treat it as a class path
            try:
>               strategy_class = self._import_strategy_class(strategy_name)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

rag_factory/config/strategy_pair_manager.py:187: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <rag_factory.config.strategy_pair_manager.StrategyPairManager object at 0x7129a7002360>
class_path = 'HierarchicalIndexing'

    def _import_strategy_class(self, class_path: str) -> Type:
        """
        Import a class dynamically.
    
        Args:
            class_path: Dot-separated path to the class (module.ClassName).
    
        Returns:
            The class object.
        """
        try:
            module_path, class_name = class_path.rsplit('.', 1)
            module = importlib.import_module(module_path)
            return getattr(module, class_name)
        except (ValueError, ImportError, AttributeError) as e:
>           raise ConfigurationError(f"Could not import strategy class '{class_path}': {e}")
E           rag_factory.config.strategy_loader.ConfigurationError: Could not import strategy class 'HierarchicalIndexing': not enough values to unpack (expected 2, got 1)

rag_factory/config/strategy_pair_manager.py:215: ConfigurationError

During handling of the above exception, another exception occurred:

mock_registry_with_services = <Mock id='124423709441536'>

    @pytest.mark.asyncio
    async def test_hierarchical_rag_pair_loading(mock_registry_with_services):
        """Test loading and basic functionality of hierarchical-rag-pair."""
        with patch('rag_factory.config.strategy_pair_manager.MigrationValidator') as MockValidator:
            mock_validator_instance = MockValidator.return_value
            mock_validator_instance.validate.return_value = (True, [])
    
            project_root = Path(__file__).parent.parent.parent
            config_dir = project_root / "strategies"
    
            manager = StrategyPairManager(
                service_registry=mock_registry_with_services,
                config_dir=str(config_dir)
            )
    
            # Load pair
>           indexing, retrieval = manager.load_pair("hierarchical-rag-pair")
                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/integration/test_hierarchical_rag_pair.py:35: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
rag_factory/config/strategy_pair_manager.py:117: in load_pair
    indexing = self._create_strategy(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <rag_factory.config.strategy_pair_manager.StrategyPairManager object at 0x7129a7002360>
config = {'config': {'max_depth': 2, 'min_chunk_size': 100}, 'db_config': {'fields': {'chunk_id': 'chunk_id', 'doc_id': 'docume...chical_vectors'}}, 'services': {'db': '$db_main', 'embedding': '$embedding_local'}, 'strategy': 'HierarchicalIndexing'}
is_indexing = True

    def _create_strategy(self, config: Dict[str, Any], is_indexing: bool) -> Any:
        """
        Instantiate strategy with all dependencies.
    
        Args:
            config: Strategy configuration dictionary.
            is_indexing: True if creating indexing strategy, False for retrieval.
    
        Returns:
            Instantiated strategy object.
        """
        # Resolve service references
        # Config['services'] maps abstract service names (llm, db) to registry keys (openai_gpt4, postgres_main)
        # Service references may have $ prefix (e.g., "$embedding_local") which needs to be stripped
        services_map = config.get('services', {})
        resolved_services = {}
    
        for service_type, service_ref in services_map.items():
            try:
                # Strip $ prefix if present
                clean_ref = service_ref.lstrip('$') if isinstance(service_ref, str) else service_ref
                resolved_services[service_type] = self.registry.get(clean_ref)
            except Exception as e:
                 raise ConfigurationError(f"Failed to resolve service '{service_ref}' for type '{service_type}': {e}")
    
        # Handle DatabaseContext if db_config present
        # This allows mapping specific tables/fields for this strategy
        if 'db_config' in config and 'db' in resolved_services:
            db_service = resolved_services['db']
            # Check if db_service supports get_context
            if hasattr(db_service, 'get_context'):
                resolved_services['db'] = db_service.get_context(
                    table_mapping=config['db_config'].get('tables', {}),
                    field_mapping=config['db_config'].get('fields', {})
                )
    
        # Construct StrategyDependencies
        deps = self._build_dependencies(resolved_services)
    
        # Use RAGFactory to create strategy
        factory = RAGFactory()
        strategy_name = config['strategy']
        strategy_config = config.get('config', {})
    
        try:
            strategy = factory.create_strategy(
                strategy_name,
                config=strategy_config,
                override_deps=deps
            )
        except StrategyNotFoundError:
            # Fallback: try to treat it as a class path
            try:
                strategy_class = self._import_strategy_class(strategy_name)
                 # Manually verify dependencies if not using factory?
                 # Or just instantiate.
                strategy = strategy_class(config=strategy_config, dependencies=deps)
            except Exception as e:
>               raise ConfigurationError(
                    f"Strategy '{strategy_name}' not found in registry and could not be imported as a class: {e}"
                )
E               rag_factory.config.strategy_loader.ConfigurationError: Strategy 'HierarchicalIndexing' not found in registry and could not be imported as a class: Could not import strategy class 'HierarchicalIndexing': not enough values to unpack (expected 2, got 1)

rag_factory/config/strategy_pair_manager.py:192: ConfigurationError
_______________________ test_hybrid_search_pair_loading ________________________

self = <rag_factory.config.strategy_pair_manager.StrategyPairManager object at 0x7129a71f81a0>
config = {'config': {'batch_size': 32, 'chunk_overlap': 50, 'chunk_size': 512}, 'db_config': {'fields': {'chunk_id': 'id', 'con... 'documents'}}, 'services': {'db': '$db_main', 'embedding': '$embedding_openai'}, 'strategy': 'VectorEmbeddingIndexer'}
is_indexing = True

    def _create_strategy(self, config: Dict[str, Any], is_indexing: bool) -> Any:
        """
        Instantiate strategy with all dependencies.
    
        Args:
            config: Strategy configuration dictionary.
            is_indexing: True if creating indexing strategy, False for retrieval.
    
        Returns:
            Instantiated strategy object.
        """
        # Resolve service references
        # Config['services'] maps abstract service names (llm, db) to registry keys (openai_gpt4, postgres_main)
        # Service references may have $ prefix (e.g., "$embedding_local") which needs to be stripped
        services_map = config.get('services', {})
        resolved_services = {}
    
        for service_type, service_ref in services_map.items():
            try:
                # Strip $ prefix if present
                clean_ref = service_ref.lstrip('$') if isinstance(service_ref, str) else service_ref
                resolved_services[service_type] = self.registry.get(clean_ref)
            except Exception as e:
                 raise ConfigurationError(f"Failed to resolve service '{service_ref}' for type '{service_type}': {e}")
    
        # Handle DatabaseContext if db_config present
        # This allows mapping specific tables/fields for this strategy
        if 'db_config' in config and 'db' in resolved_services:
            db_service = resolved_services['db']
            # Check if db_service supports get_context
            if hasattr(db_service, 'get_context'):
                resolved_services['db'] = db_service.get_context(
                    table_mapping=config['db_config'].get('tables', {}),
                    field_mapping=config['db_config'].get('fields', {})
                )
    
        # Construct StrategyDependencies
        deps = self._build_dependencies(resolved_services)
    
        # Use RAGFactory to create strategy
        factory = RAGFactory()
        strategy_name = config['strategy']
        strategy_config = config.get('config', {})
    
        try:
>           strategy = factory.create_strategy(
                strategy_name,
                config=strategy_config,
                override_deps=deps
            )

rag_factory/config/strategy_pair_manager.py:179: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <rag_factory.factory.RAGFactory object at 0x7129a97b4d40>
name = 'VectorEmbeddingIndexer'
config = {'batch_size': 32, 'chunk_overlap': 50, 'chunk_size': 512}
override_deps = StrategyDependencies(llm_service=None, embedding_service=<Mock id='124423714096576'>, graph_service=None, database_service=<Mock id='124423711345744'>, reranker_service=None)

    def create_strategy(
        self,
        name: str,
        config: Optional[Dict[str, Any]] = None,
        override_deps: Optional[StrategyDependencies] = None,
    ) -> IRAGStrategy:
        """
        Create and initialize a strategy instance with dependency injection.
    
        Args:
            name: Name of the registered strategy to create
            config: Optional configuration dictionary for the strategy
            override_deps: Optional dependencies to override factory defaults
    
        Returns:
            IRAGStrategy: Initialized strategy instance
    
        Raises:
            StrategyNotFoundError: If strategy name not in registry
            ValueError: If required services are missing or config is invalid
    
        Example:
            >>> factory = RAGFactory(llm_service=my_llm)
            >>> config = {"chunk_size": 1024, "top_k": 10}
            >>> strategy = factory.create_strategy("my_strategy", config)
            >>>
            >>> # Or with override dependencies
            >>> override = StrategyDependencies(llm_service=different_llm)
            >>> strategy = factory.create_strategy("my_strategy", config, override)
        """
        if name not in self._registry:
            available = list(self._registry.keys())
>           raise StrategyNotFoundError(
                f"Strategy '{name}' not found. "
                f"Available strategies: {available}"
            )
E           rag_factory.exceptions.StrategyNotFoundError: Strategy 'VectorEmbeddingIndexer' not found. Available strategies: ['dummy']

rag_factory/factory.py:204: StrategyNotFoundError

During handling of the above exception, another exception occurred:

self = <rag_factory.config.strategy_pair_manager.StrategyPairManager object at 0x7129a71f81a0>
class_path = 'VectorEmbeddingIndexer'

    def _import_strategy_class(self, class_path: str) -> Type:
        """
        Import a class dynamically.
    
        Args:
            class_path: Dot-separated path to the class (module.ClassName).
    
        Returns:
            The class object.
        """
        try:
>           module_path, class_name = class_path.rsplit('.', 1)
            ^^^^^^^^^^^^^^^^^^^^^^^
E           ValueError: not enough values to unpack (expected 2, got 1)

rag_factory/config/strategy_pair_manager.py:211: ValueError

During handling of the above exception, another exception occurred:

self = <rag_factory.config.strategy_pair_manager.StrategyPairManager object at 0x7129a71f81a0>
config = {'config': {'batch_size': 32, 'chunk_overlap': 50, 'chunk_size': 512}, 'db_config': {'fields': {'chunk_id': 'id', 'con... 'documents'}}, 'services': {'db': '$db_main', 'embedding': '$embedding_openai'}, 'strategy': 'VectorEmbeddingIndexer'}
is_indexing = True

    def _create_strategy(self, config: Dict[str, Any], is_indexing: bool) -> Any:
        """
        Instantiate strategy with all dependencies.
    
        Args:
            config: Strategy configuration dictionary.
            is_indexing: True if creating indexing strategy, False for retrieval.
    
        Returns:
            Instantiated strategy object.
        """
        # Resolve service references
        # Config['services'] maps abstract service names (llm, db) to registry keys (openai_gpt4, postgres_main)
        # Service references may have $ prefix (e.g., "$embedding_local") which needs to be stripped
        services_map = config.get('services', {})
        resolved_services = {}
    
        for service_type, service_ref in services_map.items():
            try:
                # Strip $ prefix if present
                clean_ref = service_ref.lstrip('$') if isinstance(service_ref, str) else service_ref
                resolved_services[service_type] = self.registry.get(clean_ref)
            except Exception as e:
                 raise ConfigurationError(f"Failed to resolve service '{service_ref}' for type '{service_type}': {e}")
    
        # Handle DatabaseContext if db_config present
        # This allows mapping specific tables/fields for this strategy
        if 'db_config' in config and 'db' in resolved_services:
            db_service = resolved_services['db']
            # Check if db_service supports get_context
            if hasattr(db_service, 'get_context'):
                resolved_services['db'] = db_service.get_context(
                    table_mapping=config['db_config'].get('tables', {}),
                    field_mapping=config['db_config'].get('fields', {})
                )
    
        # Construct StrategyDependencies
        deps = self._build_dependencies(resolved_services)
    
        # Use RAGFactory to create strategy
        factory = RAGFactory()
        strategy_name = config['strategy']
        strategy_config = config.get('config', {})
    
        try:
            strategy = factory.create_strategy(
                strategy_name,
                config=strategy_config,
                override_deps=deps
            )
        except StrategyNotFoundError:
            # Fallback: try to treat it as a class path
            try:
>               strategy_class = self._import_strategy_class(strategy_name)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

rag_factory/config/strategy_pair_manager.py:187: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <rag_factory.config.strategy_pair_manager.StrategyPairManager object at 0x7129a71f81a0>
class_path = 'VectorEmbeddingIndexer'

    def _import_strategy_class(self, class_path: str) -> Type:
        """
        Import a class dynamically.
    
        Args:
            class_path: Dot-separated path to the class (module.ClassName).
    
        Returns:
            The class object.
        """
        try:
            module_path, class_name = class_path.rsplit('.', 1)
            module = importlib.import_module(module_path)
            return getattr(module, class_name)
        except (ValueError, ImportError, AttributeError) as e:
>           raise ConfigurationError(f"Could not import strategy class '{class_path}': {e}")
E           rag_factory.config.strategy_loader.ConfigurationError: Could not import strategy class 'VectorEmbeddingIndexer': not enough values to unpack (expected 2, got 1)

rag_factory/config/strategy_pair_manager.py:215: ConfigurationError

During handling of the above exception, another exception occurred:

mock_registry_with_services = <Mock id='124423711471328'>

    @pytest.mark.asyncio
    async def test_hybrid_search_pair_loading(mock_registry_with_services):
        """Test loading and basic functionality of hybrid-search-pair."""
        with patch('rag_factory.config.strategy_pair_manager.MigrationValidator') as MockValidator:
            mock_validator_instance = MockValidator.return_value
            mock_validator_instance.validate.return_value = (True, [])
    
            project_root = Path(__file__).parent.parent.parent
            config_dir = project_root / "strategies"
    
            manager = StrategyPairManager(
                service_registry=mock_registry_with_services,
                config_dir=str(config_dir)
            )
    
            # Load pair
>           indexing, retrieval = manager.load_pair("hybrid-search-pair")
                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/integration/test_hybrid_search_pair.py:36: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
rag_factory/config/strategy_pair_manager.py:117: in load_pair
    indexing = self._create_strategy(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <rag_factory.config.strategy_pair_manager.StrategyPairManager object at 0x7129a71f81a0>
config = {'config': {'batch_size': 32, 'chunk_overlap': 50, 'chunk_size': 512}, 'db_config': {'fields': {'chunk_id': 'id', 'con... 'documents'}}, 'services': {'db': '$db_main', 'embedding': '$embedding_openai'}, 'strategy': 'VectorEmbeddingIndexer'}
is_indexing = True

    def _create_strategy(self, config: Dict[str, Any], is_indexing: bool) -> Any:
        """
        Instantiate strategy with all dependencies.
    
        Args:
            config: Strategy configuration dictionary.
            is_indexing: True if creating indexing strategy, False for retrieval.
    
        Returns:
            Instantiated strategy object.
        """
        # Resolve service references
        # Config['services'] maps abstract service names (llm, db) to registry keys (openai_gpt4, postgres_main)
        # Service references may have $ prefix (e.g., "$embedding_local") which needs to be stripped
        services_map = config.get('services', {})
        resolved_services = {}
    
        for service_type, service_ref in services_map.items():
            try:
                # Strip $ prefix if present
                clean_ref = service_ref.lstrip('$') if isinstance(service_ref, str) else service_ref
                resolved_services[service_type] = self.registry.get(clean_ref)
            except Exception as e:
                 raise ConfigurationError(f"Failed to resolve service '{service_ref}' for type '{service_type}': {e}")
    
        # Handle DatabaseContext if db_config present
        # This allows mapping specific tables/fields for this strategy
        if 'db_config' in config and 'db' in resolved_services:
            db_service = resolved_services['db']
            # Check if db_service supports get_context
            if hasattr(db_service, 'get_context'):
                resolved_services['db'] = db_service.get_context(
                    table_mapping=config['db_config'].get('tables', {}),
                    field_mapping=config['db_config'].get('fields', {})
                )
    
        # Construct StrategyDependencies
        deps = self._build_dependencies(resolved_services)
    
        # Use RAGFactory to create strategy
        factory = RAGFactory()
        strategy_name = config['strategy']
        strategy_config = config.get('config', {})
    
        try:
            strategy = factory.create_strategy(
                strategy_name,
                config=strategy_config,
                override_deps=deps
            )
        except StrategyNotFoundError:
            # Fallback: try to treat it as a class path
            try:
                strategy_class = self._import_strategy_class(strategy_name)
                 # Manually verify dependencies if not using factory?
                 # Or just instantiate.
                strategy = strategy_class(config=strategy_config, dependencies=deps)
            except Exception as e:
>               raise ConfigurationError(
                    f"Strategy '{strategy_name}' not found in registry and could not be imported as a class: {e}"
                )
E               rag_factory.config.strategy_loader.ConfigurationError: Strategy 'VectorEmbeddingIndexer' not found in registry and could not be imported as a class: Could not import strategy class 'VectorEmbeddingIndexer': not enough values to unpack (expected 2, got 1)

rag_factory/config/strategy_pair_manager.py:192: ConfigurationError
__________________________ test_keyword_pair_loading ___________________________

self = <rag_factory.config.strategy_pair_manager.StrategyPairManager object at 0x7129a7114e00>
config = {'config': {'chunk_size': 512, 'language': 'english', 'min_chunk_size': 100, 'overlap': 50, ...}, 'db_config': {'field...eyword_inverted_index', 'metadata': 'keyword_metadata'}}, 'services': {'db': '$db_main'}, 'strategy': 'KeywordIndexer'}
is_indexing = True

    def _create_strategy(self, config: Dict[str, Any], is_indexing: bool) -> Any:
        """
        Instantiate strategy with all dependencies.
    
        Args:
            config: Strategy configuration dictionary.
            is_indexing: True if creating indexing strategy, False for retrieval.
    
        Returns:
            Instantiated strategy object.
        """
        # Resolve service references
        # Config['services'] maps abstract service names (llm, db) to registry keys (openai_gpt4, postgres_main)
        # Service references may have $ prefix (e.g., "$embedding_local") which needs to be stripped
        services_map = config.get('services', {})
        resolved_services = {}
    
        for service_type, service_ref in services_map.items():
            try:
                # Strip $ prefix if present
                clean_ref = service_ref.lstrip('$') if isinstance(service_ref, str) else service_ref
                resolved_services[service_type] = self.registry.get(clean_ref)
            except Exception as e:
                 raise ConfigurationError(f"Failed to resolve service '{service_ref}' for type '{service_type}': {e}")
    
        # Handle DatabaseContext if db_config present
        # This allows mapping specific tables/fields for this strategy
        if 'db_config' in config and 'db' in resolved_services:
            db_service = resolved_services['db']
            # Check if db_service supports get_context
            if hasattr(db_service, 'get_context'):
                resolved_services['db'] = db_service.get_context(
                    table_mapping=config['db_config'].get('tables', {}),
                    field_mapping=config['db_config'].get('fields', {})
                )
    
        # Construct StrategyDependencies
        deps = self._build_dependencies(resolved_services)
    
        # Use RAGFactory to create strategy
        factory = RAGFactory()
        strategy_name = config['strategy']
        strategy_config = config.get('config', {})
    
        try:
>           strategy = factory.create_strategy(
                strategy_name,
                config=strategy_config,
                override_deps=deps
            )

rag_factory/config/strategy_pair_manager.py:179: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <rag_factory.factory.RAGFactory object at 0x7129a71fbec0>
name = 'KeywordIndexer'
config = {'chunk_size': 512, 'language': 'english', 'min_chunk_size': 100, 'overlap': 50, ...}
override_deps = StrategyDependencies(llm_service=None, embedding_service=None, graph_service=None, database_service=<Mock id='124423709593328'>, reranker_service=None)

    def create_strategy(
        self,
        name: str,
        config: Optional[Dict[str, Any]] = None,
        override_deps: Optional[StrategyDependencies] = None,
    ) -> IRAGStrategy:
        """
        Create and initialize a strategy instance with dependency injection.
    
        Args:
            name: Name of the registered strategy to create
            config: Optional configuration dictionary for the strategy
            override_deps: Optional dependencies to override factory defaults
    
        Returns:
            IRAGStrategy: Initialized strategy instance
    
        Raises:
            StrategyNotFoundError: If strategy name not in registry
            ValueError: If required services are missing or config is invalid
    
        Example:
            >>> factory = RAGFactory(llm_service=my_llm)
            >>> config = {"chunk_size": 1024, "top_k": 10}
            >>> strategy = factory.create_strategy("my_strategy", config)
            >>>
            >>> # Or with override dependencies
            >>> override = StrategyDependencies(llm_service=different_llm)
            >>> strategy = factory.create_strategy("my_strategy", config, override)
        """
        if name not in self._registry:
            available = list(self._registry.keys())
>           raise StrategyNotFoundError(
                f"Strategy '{name}' not found. "
                f"Available strategies: {available}"
            )
E           rag_factory.exceptions.StrategyNotFoundError: Strategy 'KeywordIndexer' not found. Available strategies: ['dummy']

rag_factory/factory.py:204: StrategyNotFoundError

During handling of the above exception, another exception occurred:

self = <rag_factory.config.strategy_pair_manager.StrategyPairManager object at 0x7129a7114e00>
class_path = 'KeywordIndexer'

    def _import_strategy_class(self, class_path: str) -> Type:
        """
        Import a class dynamically.
    
        Args:
            class_path: Dot-separated path to the class (module.ClassName).
    
        Returns:
            The class object.
        """
        try:
>           module_path, class_name = class_path.rsplit('.', 1)
            ^^^^^^^^^^^^^^^^^^^^^^^
E           ValueError: not enough values to unpack (expected 2, got 1)

rag_factory/config/strategy_pair_manager.py:211: ValueError

During handling of the above exception, another exception occurred:

self = <rag_factory.config.strategy_pair_manager.StrategyPairManager object at 0x7129a7114e00>
config = {'config': {'chunk_size': 512, 'language': 'english', 'min_chunk_size': 100, 'overlap': 50, ...}, 'db_config': {'field...eyword_inverted_index', 'metadata': 'keyword_metadata'}}, 'services': {'db': '$db_main'}, 'strategy': 'KeywordIndexer'}
is_indexing = True

    def _create_strategy(self, config: Dict[str, Any], is_indexing: bool) -> Any:
        """
        Instantiate strategy with all dependencies.
    
        Args:
            config: Strategy configuration dictionary.
            is_indexing: True if creating indexing strategy, False for retrieval.
    
        Returns:
            Instantiated strategy object.
        """
        # Resolve service references
        # Config['services'] maps abstract service names (llm, db) to registry keys (openai_gpt4, postgres_main)
        # Service references may have $ prefix (e.g., "$embedding_local") which needs to be stripped
        services_map = config.get('services', {})
        resolved_services = {}
    
        for service_type, service_ref in services_map.items():
            try:
                # Strip $ prefix if present
                clean_ref = service_ref.lstrip('$') if isinstance(service_ref, str) else service_ref
                resolved_services[service_type] = self.registry.get(clean_ref)
            except Exception as e:
                 raise ConfigurationError(f"Failed to resolve service '{service_ref}' for type '{service_type}': {e}")
    
        # Handle DatabaseContext if db_config present
        # This allows mapping specific tables/fields for this strategy
        if 'db_config' in config and 'db' in resolved_services:
            db_service = resolved_services['db']
            # Check if db_service supports get_context
            if hasattr(db_service, 'get_context'):
                resolved_services['db'] = db_service.get_context(
                    table_mapping=config['db_config'].get('tables', {}),
                    field_mapping=config['db_config'].get('fields', {})
                )
    
        # Construct StrategyDependencies
        deps = self._build_dependencies(resolved_services)
    
        # Use RAGFactory to create strategy
        factory = RAGFactory()
        strategy_name = config['strategy']
        strategy_config = config.get('config', {})
    
        try:
            strategy = factory.create_strategy(
                strategy_name,
                config=strategy_config,
                override_deps=deps
            )
        except StrategyNotFoundError:
            # Fallback: try to treat it as a class path
            try:
>               strategy_class = self._import_strategy_class(strategy_name)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

rag_factory/config/strategy_pair_manager.py:187: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <rag_factory.config.strategy_pair_manager.StrategyPairManager object at 0x7129a7114e00>
class_path = 'KeywordIndexer'

    def _import_strategy_class(self, class_path: str) -> Type:
        """
        Import a class dynamically.
    
        Args:
            class_path: Dot-separated path to the class (module.ClassName).
    
        Returns:
            The class object.
        """
        try:
            module_path, class_name = class_path.rsplit('.', 1)
            module = importlib.import_module(module_path)
            return getattr(module, class_name)
        except (ValueError, ImportError, AttributeError) as e:
>           raise ConfigurationError(f"Could not import strategy class '{class_path}': {e}")
E           rag_factory.config.strategy_loader.ConfigurationError: Could not import strategy class 'KeywordIndexer': not enough values to unpack (expected 2, got 1)

rag_factory/config/strategy_pair_manager.py:215: ConfigurationError

During handling of the above exception, another exception occurred:

mock_registry_with_services = <Mock id='124423709418528'>

    @pytest.mark.asyncio
    async def test_keyword_pair_loading(mock_registry_with_services):
        """Test loading and basic functionality of keyword-pair."""
        with patch('rag_factory.config.strategy_pair_manager.MigrationValidator') as MockValidator:
            mock_validator_instance = MockValidator.return_value
            mock_validator_instance.validate.return_value = (True, [])
    
            project_root = Path(__file__).parent.parent.parent
            config_dir = project_root / "strategies"
    
            manager = StrategyPairManager(
                service_registry=mock_registry_with_services,
                config_dir=str(config_dir)
            )
    
            # Load pair
>           indexing, retrieval = manager.load_pair("keyword-pair")
                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/integration/test_keyword_pair.py:35: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
rag_factory/config/strategy_pair_manager.py:117: in load_pair
    indexing = self._create_strategy(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <rag_factory.config.strategy_pair_manager.StrategyPairManager object at 0x7129a7114e00>
config = {'config': {'chunk_size': 512, 'language': 'english', 'min_chunk_size': 100, 'overlap': 50, ...}, 'db_config': {'field...eyword_inverted_index', 'metadata': 'keyword_metadata'}}, 'services': {'db': '$db_main'}, 'strategy': 'KeywordIndexer'}
is_indexing = True

    def _create_strategy(self, config: Dict[str, Any], is_indexing: bool) -> Any:
        """
        Instantiate strategy with all dependencies.
    
        Args:
            config: Strategy configuration dictionary.
            is_indexing: True if creating indexing strategy, False for retrieval.
    
        Returns:
            Instantiated strategy object.
        """
        # Resolve service references
        # Config['services'] maps abstract service names (llm, db) to registry keys (openai_gpt4, postgres_main)
        # Service references may have $ prefix (e.g., "$embedding_local") which needs to be stripped
        services_map = config.get('services', {})
        resolved_services = {}
    
        for service_type, service_ref in services_map.items():
            try:
                # Strip $ prefix if present
                clean_ref = service_ref.lstrip('$') if isinstance(service_ref, str) else service_ref
                resolved_services[service_type] = self.registry.get(clean_ref)
            except Exception as e:
                 raise ConfigurationError(f"Failed to resolve service '{service_ref}' for type '{service_type}': {e}")
    
        # Handle DatabaseContext if db_config present
        # This allows mapping specific tables/fields for this strategy
        if 'db_config' in config and 'db' in resolved_services:
            db_service = resolved_services['db']
            # Check if db_service supports get_context
            if hasattr(db_service, 'get_context'):
                resolved_services['db'] = db_service.get_context(
                    table_mapping=config['db_config'].get('tables', {}),
                    field_mapping=config['db_config'].get('fields', {})
                )
    
        # Construct StrategyDependencies
        deps = self._build_dependencies(resolved_services)
    
        # Use RAGFactory to create strategy
        factory = RAGFactory()
        strategy_name = config['strategy']
        strategy_config = config.get('config', {})
    
        try:
            strategy = factory.create_strategy(
                strategy_name,
                config=strategy_config,
                override_deps=deps
            )
        except StrategyNotFoundError:
            # Fallback: try to treat it as a class path
            try:
                strategy_class = self._import_strategy_class(strategy_name)
                 # Manually verify dependencies if not using factory?
                 # Or just instantiate.
                strategy = strategy_class(config=strategy_config, dependencies=deps)
            except Exception as e:
>               raise ConfigurationError(
                    f"Strategy '{strategy_name}' not found in registry and could not be imported as a class: {e}"
                )
E               rag_factory.config.strategy_loader.ConfigurationError: Strategy 'KeywordIndexer' not found in registry and could not be imported as a class: Could not import strategy class 'KeywordIndexer': not enough values to unpack (expected 2, got 1)

rag_factory/config/strategy_pair_manager.py:192: ConfigurationError
______________________ test_knowledge_graph_pair_loading _______________________

self = <rag_factory.config.strategy_pair_manager.StrategyPairManager object at 0x7129a70aaf60>
config = {'config': {'chunk_size': 512, 'entity_types': ['person', 'organization', 'place', 'concept'], 'extract_entities': Tru...', 'embedding': '$embedding_local', 'graph_db': '$db_neo4j', 'llm': '$llm_local'}, 'strategy': 'KnowledgeGraphIndexer'}
is_indexing = True

    def _create_strategy(self, config: Dict[str, Any], is_indexing: bool) -> Any:
        """
        Instantiate strategy with all dependencies.
    
        Args:
            config: Strategy configuration dictionary.
            is_indexing: True if creating indexing strategy, False for retrieval.
    
        Returns:
            Instantiated strategy object.
        """
        # Resolve service references
        # Config['services'] maps abstract service names (llm, db) to registry keys (openai_gpt4, postgres_main)
        # Service references may have $ prefix (e.g., "$embedding_local") which needs to be stripped
        services_map = config.get('services', {})
        resolved_services = {}
    
        for service_type, service_ref in services_map.items():
            try:
                # Strip $ prefix if present
                clean_ref = service_ref.lstrip('$') if isinstance(service_ref, str) else service_ref
                resolved_services[service_type] = self.registry.get(clean_ref)
            except Exception as e:
                 raise ConfigurationError(f"Failed to resolve service '{service_ref}' for type '{service_type}': {e}")
    
        # Handle DatabaseContext if db_config present
        # This allows mapping specific tables/fields for this strategy
        if 'db_config' in config and 'db' in resolved_services:
            db_service = resolved_services['db']
            # Check if db_service supports get_context
            if hasattr(db_service, 'get_context'):
                resolved_services['db'] = db_service.get_context(
                    table_mapping=config['db_config'].get('tables', {}),
                    field_mapping=config['db_config'].get('fields', {})
                )
    
        # Construct StrategyDependencies
        deps = self._build_dependencies(resolved_services)
    
        # Use RAGFactory to create strategy
        factory = RAGFactory()
        strategy_name = config['strategy']
        strategy_config = config.get('config', {})
    
        try:
>           strategy = factory.create_strategy(
                strategy_name,
                config=strategy_config,
                override_deps=deps
            )

rag_factory/config/strategy_pair_manager.py:179: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <rag_factory.factory.RAGFactory object at 0x7129a70313d0>
name = 'KnowledgeGraphIndexer'
config = {'chunk_size': 512, 'entity_types': ['person', 'organization', 'place', 'concept'], 'extract_entities': True, 'extract_relationships': True, ...}
override_deps = StrategyDependencies(llm_service=<Mock id='124423710032480'>, embedding_service=<Mock id='124423709399312'>, graph_service=<Mock id='124423710530720'>, database_service=<Mock id='124423709656464'>, reranker_service=None)

    def create_strategy(
        self,
        name: str,
        config: Optional[Dict[str, Any]] = None,
        override_deps: Optional[StrategyDependencies] = None,
    ) -> IRAGStrategy:
        """
        Create and initialize a strategy instance with dependency injection.
    
        Args:
            name: Name of the registered strategy to create
            config: Optional configuration dictionary for the strategy
            override_deps: Optional dependencies to override factory defaults
    
        Returns:
            IRAGStrategy: Initialized strategy instance
    
        Raises:
            StrategyNotFoundError: If strategy name not in registry
            ValueError: If required services are missing or config is invalid
    
        Example:
            >>> factory = RAGFactory(llm_service=my_llm)
            >>> config = {"chunk_size": 1024, "top_k": 10}
            >>> strategy = factory.create_strategy("my_strategy", config)
            >>>
            >>> # Or with override dependencies
            >>> override = StrategyDependencies(llm_service=different_llm)
            >>> strategy = factory.create_strategy("my_strategy", config, override)
        """
        if name not in self._registry:
            available = list(self._registry.keys())
>           raise StrategyNotFoundError(
                f"Strategy '{name}' not found. "
                f"Available strategies: {available}"
            )
E           rag_factory.exceptions.StrategyNotFoundError: Strategy 'KnowledgeGraphIndexer' not found. Available strategies: ['dummy']

rag_factory/factory.py:204: StrategyNotFoundError

During handling of the above exception, another exception occurred:

self = <rag_factory.config.strategy_pair_manager.StrategyPairManager object at 0x7129a70aaf60>
class_path = 'KnowledgeGraphIndexer'

    def _import_strategy_class(self, class_path: str) -> Type:
        """
        Import a class dynamically.
    
        Args:
            class_path: Dot-separated path to the class (module.ClassName).
    
        Returns:
            The class object.
        """
        try:
>           module_path, class_name = class_path.rsplit('.', 1)
            ^^^^^^^^^^^^^^^^^^^^^^^
E           ValueError: not enough values to unpack (expected 2, got 1)

rag_factory/config/strategy_pair_manager.py:211: ValueError

During handling of the above exception, another exception occurred:

self = <rag_factory.config.strategy_pair_manager.StrategyPairManager object at 0x7129a70aaf60>
config = {'config': {'chunk_size': 512, 'entity_types': ['person', 'organization', 'place', 'concept'], 'extract_entities': Tru...', 'embedding': '$embedding_local', 'graph_db': '$db_neo4j', 'llm': '$llm_local'}, 'strategy': 'KnowledgeGraphIndexer'}
is_indexing = True

    def _create_strategy(self, config: Dict[str, Any], is_indexing: bool) -> Any:
        """
        Instantiate strategy with all dependencies.
    
        Args:
            config: Strategy configuration dictionary.
            is_indexing: True if creating indexing strategy, False for retrieval.
    
        Returns:
            Instantiated strategy object.
        """
        # Resolve service references
        # Config['services'] maps abstract service names (llm, db) to registry keys (openai_gpt4, postgres_main)
        # Service references may have $ prefix (e.g., "$embedding_local") which needs to be stripped
        services_map = config.get('services', {})
        resolved_services = {}
    
        for service_type, service_ref in services_map.items():
            try:
                # Strip $ prefix if present
                clean_ref = service_ref.lstrip('$') if isinstance(service_ref, str) else service_ref
                resolved_services[service_type] = self.registry.get(clean_ref)
            except Exception as e:
                 raise ConfigurationError(f"Failed to resolve service '{service_ref}' for type '{service_type}': {e}")
    
        # Handle DatabaseContext if db_config present
        # This allows mapping specific tables/fields for this strategy
        if 'db_config' in config and 'db' in resolved_services:
            db_service = resolved_services['db']
            # Check if db_service supports get_context
            if hasattr(db_service, 'get_context'):
                resolved_services['db'] = db_service.get_context(
                    table_mapping=config['db_config'].get('tables', {}),
                    field_mapping=config['db_config'].get('fields', {})
                )
    
        # Construct StrategyDependencies
        deps = self._build_dependencies(resolved_services)
    
        # Use RAGFactory to create strategy
        factory = RAGFactory()
        strategy_name = config['strategy']
        strategy_config = config.get('config', {})
    
        try:
            strategy = factory.create_strategy(
                strategy_name,
                config=strategy_config,
                override_deps=deps
            )
        except StrategyNotFoundError:
            # Fallback: try to treat it as a class path
            try:
>               strategy_class = self._import_strategy_class(strategy_name)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

rag_factory/config/strategy_pair_manager.py:187: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <rag_factory.config.strategy_pair_manager.StrategyPairManager object at 0x7129a70aaf60>
class_path = 'KnowledgeGraphIndexer'

    def _import_strategy_class(self, class_path: str) -> Type:
        """
        Import a class dynamically.
    
        Args:
            class_path: Dot-separated path to the class (module.ClassName).
    
        Returns:
            The class object.
        """
        try:
            module_path, class_name = class_path.rsplit('.', 1)
            module = importlib.import_module(module_path)
            return getattr(module, class_name)
        except (ValueError, ImportError, AttributeError) as e:
>           raise ConfigurationError(f"Could not import strategy class '{class_path}': {e}")
E           rag_factory.config.strategy_loader.ConfigurationError: Could not import strategy class 'KnowledgeGraphIndexer': not enough values to unpack (expected 2, got 1)

rag_factory/config/strategy_pair_manager.py:215: ConfigurationError

During handling of the above exception, another exception occurred:

mock_registry_with_graph_services = <Mock id='124423709523600'>

    @pytest.mark.asyncio
    async def test_knowledge_graph_pair_loading(mock_registry_with_graph_services):
        """Test loading and basic functionality of knowledge-graph-pair.
    
        Uses centralized mock_registry_with_graph_services fixture which provides:
        - Mock embedding service (384 dimensions)
        - Mock LLM service for entity extraction
        - Mock database service
        - Mock Neo4j graph database service
        - Mock migration validator
    
        This test verifies:
        1. Strategy pair loads correctly with all required services
        2. Indexing strategy can process documents with graph extraction
        3. Retrieval strategy can query the knowledge graph
        4. All dependencies are properly injected
        """
        with patch('rag_factory.config.strategy_pair_manager.MigrationValidator') as MockValidator:
            mock_validator_instance = MockValidator.return_value
            mock_validator_instance.validate.return_value = (True, [])
    
            project_root = Path(__file__).parent.parent.parent
            config_dir = project_root / "strategies"
    
            manager = StrategyPairManager(
                service_registry=mock_registry_with_graph_services,
                config_dir=str(config_dir)
            )
    
            # Load pair
>           indexing, retrieval = manager.load_pair("knowledge-graph-pair")
                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/integration/test_knowledge_graph_pair.py:51: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
rag_factory/config/strategy_pair_manager.py:117: in load_pair
    indexing = self._create_strategy(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <rag_factory.config.strategy_pair_manager.StrategyPairManager object at 0x7129a70aaf60>
config = {'config': {'chunk_size': 512, 'entity_types': ['person', 'organization', 'place', 'concept'], 'extract_entities': Tru...', 'embedding': '$embedding_local', 'graph_db': '$db_neo4j', 'llm': '$llm_local'}, 'strategy': 'KnowledgeGraphIndexer'}
is_indexing = True

    def _create_strategy(self, config: Dict[str, Any], is_indexing: bool) -> Any:
        """
        Instantiate strategy with all dependencies.
    
        Args:
            config: Strategy configuration dictionary.
            is_indexing: True if creating indexing strategy, False for retrieval.
    
        Returns:
            Instantiated strategy object.
        """
        # Resolve service references
        # Config['services'] maps abstract service names (llm, db) to registry keys (openai_gpt4, postgres_main)
        # Service references may have $ prefix (e.g., "$embedding_local") which needs to be stripped
        services_map = config.get('services', {})
        resolved_services = {}
    
        for service_type, service_ref in services_map.items():
            try:
                # Strip $ prefix if present
                clean_ref = service_ref.lstrip('$') if isinstance(service_ref, str) else service_ref
                resolved_services[service_type] = self.registry.get(clean_ref)
            except Exception as e:
                 raise ConfigurationError(f"Failed to resolve service '{service_ref}' for type '{service_type}': {e}")
    
        # Handle DatabaseContext if db_config present
        # This allows mapping specific tables/fields for this strategy
        if 'db_config' in config and 'db' in resolved_services:
            db_service = resolved_services['db']
            # Check if db_service supports get_context
            if hasattr(db_service, 'get_context'):
                resolved_services['db'] = db_service.get_context(
                    table_mapping=config['db_config'].get('tables', {}),
                    field_mapping=config['db_config'].get('fields', {})
                )
    
        # Construct StrategyDependencies
        deps = self._build_dependencies(resolved_services)
    
        # Use RAGFactory to create strategy
        factory = RAGFactory()
        strategy_name = config['strategy']
        strategy_config = config.get('config', {})
    
        try:
            strategy = factory.create_strategy(
                strategy_name,
                config=strategy_config,
                override_deps=deps
            )
        except StrategyNotFoundError:
            # Fallback: try to treat it as a class path
            try:
                strategy_class = self._import_strategy_class(strategy_name)
                 # Manually verify dependencies if not using factory?
                 # Or just instantiate.
                strategy = strategy_class(config=strategy_config, dependencies=deps)
            except Exception as e:
>               raise ConfigurationError(
                    f"Strategy '{strategy_name}' not found in registry and could not be imported as a class: {e}"
                )
E               rag_factory.config.strategy_loader.ConfigurationError: Strategy 'KnowledgeGraphIndexer' not found in registry and could not be imported as a class: Could not import strategy class 'KnowledgeGraphIndexer': not enough values to unpack (expected 2, got 1)

rag_factory/config/strategy_pair_manager.py:192: ConfigurationError
_______________________ test_late_chunking_pair_loading ________________________

self = <rag_factory.config.strategy_pair_manager.StrategyPairManager object at 0x7129a70ee600>
config = {'config': {'chunk_size': 512, 'embed_full_document': True, 'min_chunk_size': 100, 'overlap': 50, ...}, 'db_config': {...unking_vectors'}}, 'services': {'db': '$db_main', 'embedding': '$embedding_local'}, 'strategy': 'LateChunkingStrategy'}
is_indexing = True

    def _create_strategy(self, config: Dict[str, Any], is_indexing: bool) -> Any:
        """
        Instantiate strategy with all dependencies.
    
        Args:
            config: Strategy configuration dictionary.
            is_indexing: True if creating indexing strategy, False for retrieval.
    
        Returns:
            Instantiated strategy object.
        """
        # Resolve service references
        # Config['services'] maps abstract service names (llm, db) to registry keys (openai_gpt4, postgres_main)
        # Service references may have $ prefix (e.g., "$embedding_local") which needs to be stripped
        services_map = config.get('services', {})
        resolved_services = {}
    
        for service_type, service_ref in services_map.items():
            try:
                # Strip $ prefix if present
                clean_ref = service_ref.lstrip('$') if isinstance(service_ref, str) else service_ref
                resolved_services[service_type] = self.registry.get(clean_ref)
            except Exception as e:
                 raise ConfigurationError(f"Failed to resolve service '{service_ref}' for type '{service_type}': {e}")
    
        # Handle DatabaseContext if db_config present
        # This allows mapping specific tables/fields for this strategy
        if 'db_config' in config and 'db' in resolved_services:
            db_service = resolved_services['db']
            # Check if db_service supports get_context
            if hasattr(db_service, 'get_context'):
                resolved_services['db'] = db_service.get_context(
                    table_mapping=config['db_config'].get('tables', {}),
                    field_mapping=config['db_config'].get('fields', {})
                )
    
        # Construct StrategyDependencies
        deps = self._build_dependencies(resolved_services)
    
        # Use RAGFactory to create strategy
        factory = RAGFactory()
        strategy_name = config['strategy']
        strategy_config = config.get('config', {})
    
        try:
>           strategy = factory.create_strategy(
                strategy_name,
                config=strategy_config,
                override_deps=deps
            )

rag_factory/config/strategy_pair_manager.py:179: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <rag_factory.factory.RAGFactory object at 0x7129a70322a0>
name = 'LateChunkingStrategy'
config = {'chunk_size': 512, 'embed_full_document': True, 'min_chunk_size': 100, 'overlap': 50, ...}
override_deps = StrategyDependencies(llm_service=None, embedding_service=<Mock id='124423709439664'>, graph_service=None, database_service=<Mock id='124423709426464'>, reranker_service=None)

    def create_strategy(
        self,
        name: str,
        config: Optional[Dict[str, Any]] = None,
        override_deps: Optional[StrategyDependencies] = None,
    ) -> IRAGStrategy:
        """
        Create and initialize a strategy instance with dependency injection.
    
        Args:
            name: Name of the registered strategy to create
            config: Optional configuration dictionary for the strategy
            override_deps: Optional dependencies to override factory defaults
    
        Returns:
            IRAGStrategy: Initialized strategy instance
    
        Raises:
            StrategyNotFoundError: If strategy name not in registry
            ValueError: If required services are missing or config is invalid
    
        Example:
            >>> factory = RAGFactory(llm_service=my_llm)
            >>> config = {"chunk_size": 1024, "top_k": 10}
            >>> strategy = factory.create_strategy("my_strategy", config)
            >>>
            >>> # Or with override dependencies
            >>> override = StrategyDependencies(llm_service=different_llm)
            >>> strategy = factory.create_strategy("my_strategy", config, override)
        """
        if name not in self._registry:
            available = list(self._registry.keys())
>           raise StrategyNotFoundError(
                f"Strategy '{name}' not found. "
                f"Available strategies: {available}"
            )
E           rag_factory.exceptions.StrategyNotFoundError: Strategy 'LateChunkingStrategy' not found. Available strategies: ['dummy']

rag_factory/factory.py:204: StrategyNotFoundError

During handling of the above exception, another exception occurred:

self = <rag_factory.config.strategy_pair_manager.StrategyPairManager object at 0x7129a70ee600>
class_path = 'LateChunkingStrategy'

    def _import_strategy_class(self, class_path: str) -> Type:
        """
        Import a class dynamically.
    
        Args:
            class_path: Dot-separated path to the class (module.ClassName).
    
        Returns:
            The class object.
        """
        try:
>           module_path, class_name = class_path.rsplit('.', 1)
            ^^^^^^^^^^^^^^^^^^^^^^^
E           ValueError: not enough values to unpack (expected 2, got 1)

rag_factory/config/strategy_pair_manager.py:211: ValueError

During handling of the above exception, another exception occurred:

self = <rag_factory.config.strategy_pair_manager.StrategyPairManager object at 0x7129a70ee600>
config = {'config': {'chunk_size': 512, 'embed_full_document': True, 'min_chunk_size': 100, 'overlap': 50, ...}, 'db_config': {...unking_vectors'}}, 'services': {'db': '$db_main', 'embedding': '$embedding_local'}, 'strategy': 'LateChunkingStrategy'}
is_indexing = True

    def _create_strategy(self, config: Dict[str, Any], is_indexing: bool) -> Any:
        """
        Instantiate strategy with all dependencies.
    
        Args:
            config: Strategy configuration dictionary.
            is_indexing: True if creating indexing strategy, False for retrieval.
    
        Returns:
            Instantiated strategy object.
        """
        # Resolve service references
        # Config['services'] maps abstract service names (llm, db) to registry keys (openai_gpt4, postgres_main)
        # Service references may have $ prefix (e.g., "$embedding_local") which needs to be stripped
        services_map = config.get('services', {})
        resolved_services = {}
    
        for service_type, service_ref in services_map.items():
            try:
                # Strip $ prefix if present
                clean_ref = service_ref.lstrip('$') if isinstance(service_ref, str) else service_ref
                resolved_services[service_type] = self.registry.get(clean_ref)
            except Exception as e:
                 raise ConfigurationError(f"Failed to resolve service '{service_ref}' for type '{service_type}': {e}")
    
        # Handle DatabaseContext if db_config present
        # This allows mapping specific tables/fields for this strategy
        if 'db_config' in config and 'db' in resolved_services:
            db_service = resolved_services['db']
            # Check if db_service supports get_context
            if hasattr(db_service, 'get_context'):
                resolved_services['db'] = db_service.get_context(
                    table_mapping=config['db_config'].get('tables', {}),
                    field_mapping=config['db_config'].get('fields', {})
                )
    
        # Construct StrategyDependencies
        deps = self._build_dependencies(resolved_services)
    
        # Use RAGFactory to create strategy
        factory = RAGFactory()
        strategy_name = config['strategy']
        strategy_config = config.get('config', {})
    
        try:
            strategy = factory.create_strategy(
                strategy_name,
                config=strategy_config,
                override_deps=deps
            )
        except StrategyNotFoundError:
            # Fallback: try to treat it as a class path
            try:
>               strategy_class = self._import_strategy_class(strategy_name)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

rag_factory/config/strategy_pair_manager.py:187: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <rag_factory.config.strategy_pair_manager.StrategyPairManager object at 0x7129a70ee600>
class_path = 'LateChunkingStrategy'

    def _import_strategy_class(self, class_path: str) -> Type:
        """
        Import a class dynamically.
    
        Args:
            class_path: Dot-separated path to the class (module.ClassName).
    
        Returns:
            The class object.
        """
        try:
            module_path, class_name = class_path.rsplit('.', 1)
            module = importlib.import_module(module_path)
            return getattr(module, class_name)
        except (ValueError, ImportError, AttributeError) as e:
>           raise ConfigurationError(f"Could not import strategy class '{class_path}': {e}")
E           rag_factory.config.strategy_loader.ConfigurationError: Could not import strategy class 'LateChunkingStrategy': not enough values to unpack (expected 2, got 1)

rag_factory/config/strategy_pair_manager.py:215: ConfigurationError

During handling of the above exception, another exception occurred:

mock_registry_with_services = <Mock id='124423709591408'>

    @pytest.mark.asyncio
    async def test_late_chunking_pair_loading(mock_registry_with_services):
        """Test loading and basic functionality of late-chunking-pair."""
        with patch('rag_factory.config.strategy_pair_manager.MigrationValidator') as MockValidator:
            mock_validator_instance = MockValidator.return_value
            mock_validator_instance.validate.return_value = (True, [])
    
            project_root = Path(__file__).parent.parent.parent
            config_dir = project_root / "strategies"
    
            manager = StrategyPairManager(
                service_registry=mock_registry_with_services,
                config_dir=str(config_dir)
            )
    
            # Load pair
>           indexing, retrieval = manager.load_pair("late-chunking-pair")
                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/integration/test_late_chunking_pair.py:36: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
rag_factory/config/strategy_pair_manager.py:117: in load_pair
    indexing = self._create_strategy(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <rag_factory.config.strategy_pair_manager.StrategyPairManager object at 0x7129a70ee600>
config = {'config': {'chunk_size': 512, 'embed_full_document': True, 'min_chunk_size': 100, 'overlap': 50, ...}, 'db_config': {...unking_vectors'}}, 'services': {'db': '$db_main', 'embedding': '$embedding_local'}, 'strategy': 'LateChunkingStrategy'}
is_indexing = True

    def _create_strategy(self, config: Dict[str, Any], is_indexing: bool) -> Any:
        """
        Instantiate strategy with all dependencies.
    
        Args:
            config: Strategy configuration dictionary.
            is_indexing: True if creating indexing strategy, False for retrieval.
    
        Returns:
            Instantiated strategy object.
        """
        # Resolve service references
        # Config['services'] maps abstract service names (llm, db) to registry keys (openai_gpt4, postgres_main)
        # Service references may have $ prefix (e.g., "$embedding_local") which needs to be stripped
        services_map = config.get('services', {})
        resolved_services = {}
    
        for service_type, service_ref in services_map.items():
            try:
                # Strip $ prefix if present
                clean_ref = service_ref.lstrip('$') if isinstance(service_ref, str) else service_ref
                resolved_services[service_type] = self.registry.get(clean_ref)
            except Exception as e:
                 raise ConfigurationError(f"Failed to resolve service '{service_ref}' for type '{service_type}': {e}")
    
        # Handle DatabaseContext if db_config present
        # This allows mapping specific tables/fields for this strategy
        if 'db_config' in config and 'db' in resolved_services:
            db_service = resolved_services['db']
            # Check if db_service supports get_context
            if hasattr(db_service, 'get_context'):
                resolved_services['db'] = db_service.get_context(
                    table_mapping=config['db_config'].get('tables', {}),
                    field_mapping=config['db_config'].get('fields', {})
                )
    
        # Construct StrategyDependencies
        deps = self._build_dependencies(resolved_services)
    
        # Use RAGFactory to create strategy
        factory = RAGFactory()
        strategy_name = config['strategy']
        strategy_config = config.get('config', {})
    
        try:
            strategy = factory.create_strategy(
                strategy_name,
                config=strategy_config,
                override_deps=deps
            )
        except StrategyNotFoundError:
            # Fallback: try to treat it as a class path
            try:
                strategy_class = self._import_strategy_class(strategy_name)
                 # Manually verify dependencies if not using factory?
                 # Or just instantiate.
                strategy = strategy_class(config=strategy_config, dependencies=deps)
            except Exception as e:
>               raise ConfigurationError(
                    f"Strategy '{strategy_name}' not found in registry and could not be imported as a class: {e}"
                )
E               rag_factory.config.strategy_loader.ConfigurationError: Strategy 'LateChunkingStrategy' not found in registry and could not be imported as a class: Could not import strategy class 'LateChunkingStrategy': not enough values to unpack (expected 2, got 1)

rag_factory/config/strategy_pair_manager.py:192: ConfigurationError
________________________ test_multi_query_pair_loading _________________________

self = <rag_factory.config.strategy_pair_manager.StrategyPairManager object at 0x7129a711bc50>
config = {'config': {'chunk_size': 512, 'min_chunk_size': 100, 'overlap': 50}, 'db_config': {'fields': {'chunk_id': 'chunk_id',...uery_vectors'}}, 'services': {'db': '$db_main', 'embedding': '$embedding_local'}, 'strategy': 'VectorEmbeddingIndexer'}
is_indexing = True

    def _create_strategy(self, config: Dict[str, Any], is_indexing: bool) -> Any:
        """
        Instantiate strategy with all dependencies.
    
        Args:
            config: Strategy configuration dictionary.
            is_indexing: True if creating indexing strategy, False for retrieval.
    
        Returns:
            Instantiated strategy object.
        """
        # Resolve service references
        # Config['services'] maps abstract service names (llm, db) to registry keys (openai_gpt4, postgres_main)
        # Service references may have $ prefix (e.g., "$embedding_local") which needs to be stripped
        services_map = config.get('services', {})
        resolved_services = {}
    
        for service_type, service_ref in services_map.items():
            try:
                # Strip $ prefix if present
                clean_ref = service_ref.lstrip('$') if isinstance(service_ref, str) else service_ref
                resolved_services[service_type] = self.registry.get(clean_ref)
            except Exception as e:
                 raise ConfigurationError(f"Failed to resolve service '{service_ref}' for type '{service_type}': {e}")
    
        # Handle DatabaseContext if db_config present
        # This allows mapping specific tables/fields for this strategy
        if 'db_config' in config and 'db' in resolved_services:
            db_service = resolved_services['db']
            # Check if db_service supports get_context
            if hasattr(db_service, 'get_context'):
                resolved_services['db'] = db_service.get_context(
                    table_mapping=config['db_config'].get('tables', {}),
                    field_mapping=config['db_config'].get('fields', {})
                )
    
        # Construct StrategyDependencies
        deps = self._build_dependencies(resolved_services)
    
        # Use RAGFactory to create strategy
        factory = RAGFactory()
        strategy_name = config['strategy']
        strategy_config = config.get('config', {})
    
        try:
>           strategy = factory.create_strategy(
                strategy_name,
                config=strategy_config,
                override_deps=deps
            )

rag_factory/config/strategy_pair_manager.py:179: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <rag_factory.factory.RAGFactory object at 0x7129a710dfa0>
name = 'VectorEmbeddingIndexer'
config = {'chunk_size': 512, 'min_chunk_size': 100, 'overlap': 50}
override_deps = StrategyDependencies(llm_service=None, embedding_service=<Mock id='124423710375232'>, graph_service=None, database_service=<Mock id='124423710349584'>, reranker_service=None)

    def create_strategy(
        self,
        name: str,
        config: Optional[Dict[str, Any]] = None,
        override_deps: Optional[StrategyDependencies] = None,
    ) -> IRAGStrategy:
        """
        Create and initialize a strategy instance with dependency injection.
    
        Args:
            name: Name of the registered strategy to create
            config: Optional configuration dictionary for the strategy
            override_deps: Optional dependencies to override factory defaults
    
        Returns:
            IRAGStrategy: Initialized strategy instance
    
        Raises:
            StrategyNotFoundError: If strategy name not in registry
            ValueError: If required services are missing or config is invalid
    
        Example:
            >>> factory = RAGFactory(llm_service=my_llm)
            >>> config = {"chunk_size": 1024, "top_k": 10}
            >>> strategy = factory.create_strategy("my_strategy", config)
            >>>
            >>> # Or with override dependencies
            >>> override = StrategyDependencies(llm_service=different_llm)
            >>> strategy = factory.create_strategy("my_strategy", config, override)
        """
        if name not in self._registry:
            available = list(self._registry.keys())
>           raise StrategyNotFoundError(
                f"Strategy '{name}' not found. "
                f"Available strategies: {available}"
            )
E           rag_factory.exceptions.StrategyNotFoundError: Strategy 'VectorEmbeddingIndexer' not found. Available strategies: ['dummy']

rag_factory/factory.py:204: StrategyNotFoundError

During handling of the above exception, another exception occurred:

self = <rag_factory.config.strategy_pair_manager.StrategyPairManager object at 0x7129a711bc50>
class_path = 'VectorEmbeddingIndexer'

    def _import_strategy_class(self, class_path: str) -> Type:
        """
        Import a class dynamically.
    
        Args:
            class_path: Dot-separated path to the class (module.ClassName).
    
        Returns:
            The class object.
        """
        try:
>           module_path, class_name = class_path.rsplit('.', 1)
            ^^^^^^^^^^^^^^^^^^^^^^^
E           ValueError: not enough values to unpack (expected 2, got 1)

rag_factory/config/strategy_pair_manager.py:211: ValueError

During handling of the above exception, another exception occurred:

self = <rag_factory.config.strategy_pair_manager.StrategyPairManager object at 0x7129a711bc50>
config = {'config': {'chunk_size': 512, 'min_chunk_size': 100, 'overlap': 50}, 'db_config': {'fields': {'chunk_id': 'chunk_id',...uery_vectors'}}, 'services': {'db': '$db_main', 'embedding': '$embedding_local'}, 'strategy': 'VectorEmbeddingIndexer'}
is_indexing = True

    def _create_strategy(self, config: Dict[str, Any], is_indexing: bool) -> Any:
        """
        Instantiate strategy with all dependencies.
    
        Args:
            config: Strategy configuration dictionary.
            is_indexing: True if creating indexing strategy, False for retrieval.
    
        Returns:
            Instantiated strategy object.
        """
        # Resolve service references
        # Config['services'] maps abstract service names (llm, db) to registry keys (openai_gpt4, postgres_main)
        # Service references may have $ prefix (e.g., "$embedding_local") which needs to be stripped
        services_map = config.get('services', {})
        resolved_services = {}
    
        for service_type, service_ref in services_map.items():
            try:
                # Strip $ prefix if present
                clean_ref = service_ref.lstrip('$') if isinstance(service_ref, str) else service_ref
                resolved_services[service_type] = self.registry.get(clean_ref)
            except Exception as e:
                 raise ConfigurationError(f"Failed to resolve service '{service_ref}' for type '{service_type}': {e}")
    
        # Handle DatabaseContext if db_config present
        # This allows mapping specific tables/fields for this strategy
        if 'db_config' in config and 'db' in resolved_services:
            db_service = resolved_services['db']
            # Check if db_service supports get_context
            if hasattr(db_service, 'get_context'):
                resolved_services['db'] = db_service.get_context(
                    table_mapping=config['db_config'].get('tables', {}),
                    field_mapping=config['db_config'].get('fields', {})
                )
    
        # Construct StrategyDependencies
        deps = self._build_dependencies(resolved_services)
    
        # Use RAGFactory to create strategy
        factory = RAGFactory()
        strategy_name = config['strategy']
        strategy_config = config.get('config', {})
    
        try:
            strategy = factory.create_strategy(
                strategy_name,
                config=strategy_config,
                override_deps=deps
            )
        except StrategyNotFoundError:
            # Fallback: try to treat it as a class path
            try:
>               strategy_class = self._import_strategy_class(strategy_name)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

rag_factory/config/strategy_pair_manager.py:187: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <rag_factory.config.strategy_pair_manager.StrategyPairManager object at 0x7129a711bc50>
class_path = 'VectorEmbeddingIndexer'

    def _import_strategy_class(self, class_path: str) -> Type:
        """
        Import a class dynamically.
    
        Args:
            class_path: Dot-separated path to the class (module.ClassName).
    
        Returns:
            The class object.
        """
        try:
            module_path, class_name = class_path.rsplit('.', 1)
            module = importlib.import_module(module_path)
            return getattr(module, class_name)
        except (ValueError, ImportError, AttributeError) as e:
>           raise ConfigurationError(f"Could not import strategy class '{class_path}': {e}")
E           rag_factory.config.strategy_loader.ConfigurationError: Could not import strategy class 'VectorEmbeddingIndexer': not enough values to unpack (expected 2, got 1)

rag_factory/config/strategy_pair_manager.py:215: ConfigurationError

During handling of the above exception, another exception occurred:

mock_registry_with_llm_services = <Mock id='124423710542688'>

    @pytest.mark.asyncio
    async def test_multi_query_pair_loading(mock_registry_with_llm_services):
        """Test loading and basic functionality of multi-query-pair."""
        with patch('rag_factory.config.strategy_pair_manager.MigrationValidator') as MockValidator:
            mock_validator_instance = MockValidator.return_value
            mock_validator_instance.validate.return_value = (True, [])
    
            project_root = Path(__file__).parent.parent.parent
            config_dir = project_root / "strategies"
    
            manager = StrategyPairManager(
                service_registry=mock_registry_with_llm_services,
                config_dir=str(config_dir)
            )
    
            # Load pair
>           indexing, retrieval = manager.load_pair("multi-query-pair")
                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/integration/test_multi_query_pair.py:36: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
rag_factory/config/strategy_pair_manager.py:117: in load_pair
    indexing = self._create_strategy(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <rag_factory.config.strategy_pair_manager.StrategyPairManager object at 0x7129a711bc50>
config = {'config': {'chunk_size': 512, 'min_chunk_size': 100, 'overlap': 50}, 'db_config': {'fields': {'chunk_id': 'chunk_id',...uery_vectors'}}, 'services': {'db': '$db_main', 'embedding': '$embedding_local'}, 'strategy': 'VectorEmbeddingIndexer'}
is_indexing = True

    def _create_strategy(self, config: Dict[str, Any], is_indexing: bool) -> Any:
        """
        Instantiate strategy with all dependencies.
    
        Args:
            config: Strategy configuration dictionary.
            is_indexing: True if creating indexing strategy, False for retrieval.
    
        Returns:
            Instantiated strategy object.
        """
        # Resolve service references
        # Config['services'] maps abstract service names (llm, db) to registry keys (openai_gpt4, postgres_main)
        # Service references may have $ prefix (e.g., "$embedding_local") which needs to be stripped
        services_map = config.get('services', {})
        resolved_services = {}
    
        for service_type, service_ref in services_map.items():
            try:
                # Strip $ prefix if present
                clean_ref = service_ref.lstrip('$') if isinstance(service_ref, str) else service_ref
                resolved_services[service_type] = self.registry.get(clean_ref)
            except Exception as e:
                 raise ConfigurationError(f"Failed to resolve service '{service_ref}' for type '{service_type}': {e}")
    
        # Handle DatabaseContext if db_config present
        # This allows mapping specific tables/fields for this strategy
        if 'db_config' in config and 'db' in resolved_services:
            db_service = resolved_services['db']
            # Check if db_service supports get_context
            if hasattr(db_service, 'get_context'):
                resolved_services['db'] = db_service.get_context(
                    table_mapping=config['db_config'].get('tables', {}),
                    field_mapping=config['db_config'].get('fields', {})
                )
    
        # Construct StrategyDependencies
        deps = self._build_dependencies(resolved_services)
    
        # Use RAGFactory to create strategy
        factory = RAGFactory()
        strategy_name = config['strategy']
        strategy_config = config.get('config', {})
    
        try:
            strategy = factory.create_strategy(
                strategy_name,
                config=strategy_config,
                override_deps=deps
            )
        except StrategyNotFoundError:
            # Fallback: try to treat it as a class path
            try:
                strategy_class = self._import_strategy_class(strategy_name)
                 # Manually verify dependencies if not using factory?
                 # Or just instantiate.
                strategy = strategy_class(config=strategy_config, dependencies=deps)
            except Exception as e:
>               raise ConfigurationError(
                    f"Strategy '{strategy_name}' not found in registry and could not be imported as a class: {e}"
                )
E               rag_factory.config.strategy_loader.ConfigurationError: Strategy 'VectorEmbeddingIndexer' not found in registry and could not be imported as a class: Could not import strategy class 'VectorEmbeddingIndexer': not enough values to unpack (expected 2, got 1)

rag_factory/config/strategy_pair_manager.py:192: ConfigurationError
__________________ TestSmokeTest.test_basic_usage_smoke_test ___________________

self = <tests.integration.test_package_integration.TestSmokeTest object at 0x7129a96b0320>

    def test_basic_usage_smoke_test(self) -> None:
        """Test basic usage works after import."""
>       from rag_factory import RAGFactory, StrategyPipeline, ConfigManager
E       ImportError: cannot import name 'RAGFactory' from 'rag_factory' (/mnt/MCPProyects/ragTools/rag_factory/__init__.py)

tests/integration/test_package_integration.py:60: ImportError
__________ TestFullWorkflow.test_full_workflow_with_installed_package __________

self = <tests.integration.test_package_integration.TestFullWorkflow object at 0x7129a96b0680>

    def test_full_workflow_with_installed_package(self) -> None:
        """Test complete workflow using installed package."""
>       from rag_factory import RAGFactory, StrategyPipeline
E       ImportError: cannot import name 'RAGFactory' from 'rag_factory' (/mnt/MCPProyects/ragTools/rag_factory/__init__.py)

tests/integration/test_package_integration.py:90: ImportError
______________________ test_query_expansion_pair_loading _______________________

self = <rag_factory.config.strategy_pair_manager.StrategyPairManager object at 0x7129a715cce0>
config = {'config': {'chunk_size': 512, 'min_chunk_size': 100, 'overlap': 50}, 'db_config': {'fields': {'chunk_id': 'chunk_id',...sion_vectors'}}, 'services': {'db': '$db_main', 'embedding': '$embedding_local'}, 'strategy': 'VectorEmbeddingIndexer'}
is_indexing = True

    def _create_strategy(self, config: Dict[str, Any], is_indexing: bool) -> Any:
        """
        Instantiate strategy with all dependencies.
    
        Args:
            config: Strategy configuration dictionary.
            is_indexing: True if creating indexing strategy, False for retrieval.
    
        Returns:
            Instantiated strategy object.
        """
        # Resolve service references
        # Config['services'] maps abstract service names (llm, db) to registry keys (openai_gpt4, postgres_main)
        # Service references may have $ prefix (e.g., "$embedding_local") which needs to be stripped
        services_map = config.get('services', {})
        resolved_services = {}
    
        for service_type, service_ref in services_map.items():
            try:
                # Strip $ prefix if present
                clean_ref = service_ref.lstrip('$') if isinstance(service_ref, str) else service_ref
                resolved_services[service_type] = self.registry.get(clean_ref)
            except Exception as e:
                 raise ConfigurationError(f"Failed to resolve service '{service_ref}' for type '{service_type}': {e}")
    
        # Handle DatabaseContext if db_config present
        # This allows mapping specific tables/fields for this strategy
        if 'db_config' in config and 'db' in resolved_services:
            db_service = resolved_services['db']
            # Check if db_service supports get_context
            if hasattr(db_service, 'get_context'):
                resolved_services['db'] = db_service.get_context(
                    table_mapping=config['db_config'].get('tables', {}),
                    field_mapping=config['db_config'].get('fields', {})
                )
    
        # Construct StrategyDependencies
        deps = self._build_dependencies(resolved_services)
    
        # Use RAGFactory to create strategy
        factory = RAGFactory()
        strategy_name = config['strategy']
        strategy_config = config.get('config', {})
    
        try:
>           strategy = factory.create_strategy(
                strategy_name,
                config=strategy_config,
                override_deps=deps
            )

rag_factory/config/strategy_pair_manager.py:179: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <rag_factory.factory.RAGFactory object at 0x7129a715eb10>
name = 'VectorEmbeddingIndexer'
config = {'chunk_size': 512, 'min_chunk_size': 100, 'overlap': 50}
override_deps = StrategyDependencies(llm_service=None, embedding_service=<Mock id='124423710369760'>, graph_service=None, database_service=<Mock id='124423709420640'>, reranker_service=None)

    def create_strategy(
        self,
        name: str,
        config: Optional[Dict[str, Any]] = None,
        override_deps: Optional[StrategyDependencies] = None,
    ) -> IRAGStrategy:
        """
        Create and initialize a strategy instance with dependency injection.
    
        Args:
            name: Name of the registered strategy to create
            config: Optional configuration dictionary for the strategy
            override_deps: Optional dependencies to override factory defaults
    
        Returns:
            IRAGStrategy: Initialized strategy instance
    
        Raises:
            StrategyNotFoundError: If strategy name not in registry
            ValueError: If required services are missing or config is invalid
    
        Example:
            >>> factory = RAGFactory(llm_service=my_llm)
            >>> config = {"chunk_size": 1024, "top_k": 10}
            >>> strategy = factory.create_strategy("my_strategy", config)
            >>>
            >>> # Or with override dependencies
            >>> override = StrategyDependencies(llm_service=different_llm)
            >>> strategy = factory.create_strategy("my_strategy", config, override)
        """
        if name not in self._registry:
            available = list(self._registry.keys())
>           raise StrategyNotFoundError(
                f"Strategy '{name}' not found. "
                f"Available strategies: {available}"
            )
E           rag_factory.exceptions.StrategyNotFoundError: Strategy 'VectorEmbeddingIndexer' not found. Available strategies: ['dummy', 'strategy_a', 'strategy_b']

rag_factory/factory.py:204: StrategyNotFoundError

During handling of the above exception, another exception occurred:

self = <rag_factory.config.strategy_pair_manager.StrategyPairManager object at 0x7129a715cce0>
class_path = 'VectorEmbeddingIndexer'

    def _import_strategy_class(self, class_path: str) -> Type:
        """
        Import a class dynamically.
    
        Args:
            class_path: Dot-separated path to the class (module.ClassName).
    
        Returns:
            The class object.
        """
        try:
>           module_path, class_name = class_path.rsplit('.', 1)
            ^^^^^^^^^^^^^^^^^^^^^^^
E           ValueError: not enough values to unpack (expected 2, got 1)

rag_factory/config/strategy_pair_manager.py:211: ValueError

During handling of the above exception, another exception occurred:

self = <rag_factory.config.strategy_pair_manager.StrategyPairManager object at 0x7129a715cce0>
config = {'config': {'chunk_size': 512, 'min_chunk_size': 100, 'overlap': 50}, 'db_config': {'fields': {'chunk_id': 'chunk_id',...sion_vectors'}}, 'services': {'db': '$db_main', 'embedding': '$embedding_local'}, 'strategy': 'VectorEmbeddingIndexer'}
is_indexing = True

    def _create_strategy(self, config: Dict[str, Any], is_indexing: bool) -> Any:
        """
        Instantiate strategy with all dependencies.
    
        Args:
            config: Strategy configuration dictionary.
            is_indexing: True if creating indexing strategy, False for retrieval.
    
        Returns:
            Instantiated strategy object.
        """
        # Resolve service references
        # Config['services'] maps abstract service names (llm, db) to registry keys (openai_gpt4, postgres_main)
        # Service references may have $ prefix (e.g., "$embedding_local") which needs to be stripped
        services_map = config.get('services', {})
        resolved_services = {}
    
        for service_type, service_ref in services_map.items():
            try:
                # Strip $ prefix if present
                clean_ref = service_ref.lstrip('$') if isinstance(service_ref, str) else service_ref
                resolved_services[service_type] = self.registry.get(clean_ref)
            except Exception as e:
                 raise ConfigurationError(f"Failed to resolve service '{service_ref}' for type '{service_type}': {e}")
    
        # Handle DatabaseContext if db_config present
        # This allows mapping specific tables/fields for this strategy
        if 'db_config' in config and 'db' in resolved_services:
            db_service = resolved_services['db']
            # Check if db_service supports get_context
            if hasattr(db_service, 'get_context'):
                resolved_services['db'] = db_service.get_context(
                    table_mapping=config['db_config'].get('tables', {}),
                    field_mapping=config['db_config'].get('fields', {})
                )
    
        # Construct StrategyDependencies
        deps = self._build_dependencies(resolved_services)
    
        # Use RAGFactory to create strategy
        factory = RAGFactory()
        strategy_name = config['strategy']
        strategy_config = config.get('config', {})
    
        try:
            strategy = factory.create_strategy(
                strategy_name,
                config=strategy_config,
                override_deps=deps
            )
        except StrategyNotFoundError:
            # Fallback: try to treat it as a class path
            try:
>               strategy_class = self._import_strategy_class(strategy_name)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

rag_factory/config/strategy_pair_manager.py:187: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <rag_factory.config.strategy_pair_manager.StrategyPairManager object at 0x7129a715cce0>
class_path = 'VectorEmbeddingIndexer'

    def _import_strategy_class(self, class_path: str) -> Type:
        """
        Import a class dynamically.
    
        Args:
            class_path: Dot-separated path to the class (module.ClassName).
    
        Returns:
            The class object.
        """
        try:
            module_path, class_name = class_path.rsplit('.', 1)
            module = importlib.import_module(module_path)
            return getattr(module, class_name)
        except (ValueError, ImportError, AttributeError) as e:
>           raise ConfigurationError(f"Could not import strategy class '{class_path}': {e}")
E           rag_factory.config.strategy_loader.ConfigurationError: Could not import strategy class 'VectorEmbeddingIndexer': not enough values to unpack (expected 2, got 1)

rag_factory/config/strategy_pair_manager.py:215: ConfigurationError

During handling of the above exception, another exception occurred:

mock_registry_with_llm_services = <Mock id='124423714106176'>

    @pytest.mark.asyncio
    async def test_query_expansion_pair_loading(mock_registry_with_llm_services):
        """Test loading and basic functionality of query-expansion-pair."""
        with patch('rag_factory.config.strategy_pair_manager.MigrationValidator') as MockValidator:
            mock_validator_instance = MockValidator.return_value
            mock_validator_instance.validate.return_value = (True, [])
    
            project_root = Path(__file__).parent.parent.parent
            config_dir = project_root / "strategies"
    
            manager = StrategyPairManager(
                service_registry=mock_registry_with_llm_services,
                config_dir=str(config_dir)
            )
    
            # Load pair
>           indexing, retrieval = manager.load_pair("query-expansion-pair")
                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/integration/test_query_expansion_pair.py:35: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
rag_factory/config/strategy_pair_manager.py:117: in load_pair
    indexing = self._create_strategy(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <rag_factory.config.strategy_pair_manager.StrategyPairManager object at 0x7129a715cce0>
config = {'config': {'chunk_size': 512, 'min_chunk_size': 100, 'overlap': 50}, 'db_config': {'fields': {'chunk_id': 'chunk_id',...sion_vectors'}}, 'services': {'db': '$db_main', 'embedding': '$embedding_local'}, 'strategy': 'VectorEmbeddingIndexer'}
is_indexing = True

    def _create_strategy(self, config: Dict[str, Any], is_indexing: bool) -> Any:
        """
        Instantiate strategy with all dependencies.
    
        Args:
            config: Strategy configuration dictionary.
            is_indexing: True if creating indexing strategy, False for retrieval.
    
        Returns:
            Instantiated strategy object.
        """
        # Resolve service references
        # Config['services'] maps abstract service names (llm, db) to registry keys (openai_gpt4, postgres_main)
        # Service references may have $ prefix (e.g., "$embedding_local") which needs to be stripped
        services_map = config.get('services', {})
        resolved_services = {}
    
        for service_type, service_ref in services_map.items():
            try:
                # Strip $ prefix if present
                clean_ref = service_ref.lstrip('$') if isinstance(service_ref, str) else service_ref
                resolved_services[service_type] = self.registry.get(clean_ref)
            except Exception as e:
                 raise ConfigurationError(f"Failed to resolve service '{service_ref}' for type '{service_type}': {e}")
    
        # Handle DatabaseContext if db_config present
        # This allows mapping specific tables/fields for this strategy
        if 'db_config' in config and 'db' in resolved_services:
            db_service = resolved_services['db']
            # Check if db_service supports get_context
            if hasattr(db_service, 'get_context'):
                resolved_services['db'] = db_service.get_context(
                    table_mapping=config['db_config'].get('tables', {}),
                    field_mapping=config['db_config'].get('fields', {})
                )
    
        # Construct StrategyDependencies
        deps = self._build_dependencies(resolved_services)
    
        # Use RAGFactory to create strategy
        factory = RAGFactory()
        strategy_name = config['strategy']
        strategy_config = config.get('config', {})
    
        try:
            strategy = factory.create_strategy(
                strategy_name,
                config=strategy_config,
                override_deps=deps
            )
        except StrategyNotFoundError:
            # Fallback: try to treat it as a class path
            try:
                strategy_class = self._import_strategy_class(strategy_name)
                 # Manually verify dependencies if not using factory?
                 # Or just instantiate.
                strategy = strategy_class(config=strategy_config, dependencies=deps)
            except Exception as e:
>               raise ConfigurationError(
                    f"Strategy '{strategy_name}' not found in registry and could not be imported as a class: {e}"
                )
E               rag_factory.config.strategy_loader.ConfigurationError: Strategy 'VectorEmbeddingIndexer' not found in registry and could not be imported as a class: Could not import strategy class 'VectorEmbeddingIndexer': not enough values to unpack (expected 2, got 1)

rag_factory/config/strategy_pair_manager.py:192: ConfigurationError
_________________________ test_reranking_pair_loading __________________________

self = <rag_factory.config.strategy_pair_manager.StrategyPairManager object at 0x7129a713ff50>
config = {'config': {'chunk_size': 512, 'min_chunk_size': 100, 'overlap': 50}, 'db_config': {'fields': {'chunk_id': 'chunk_id',...king_vectors'}}, 'services': {'db': '$db_main', 'embedding': '$embedding_local'}, 'strategy': 'VectorEmbeddingIndexer'}
is_indexing = True

    def _create_strategy(self, config: Dict[str, Any], is_indexing: bool) -> Any:
        """
        Instantiate strategy with all dependencies.
    
        Args:
            config: Strategy configuration dictionary.
            is_indexing: True if creating indexing strategy, False for retrieval.
    
        Returns:
            Instantiated strategy object.
        """
        # Resolve service references
        # Config['services'] maps abstract service names (llm, db) to registry keys (openai_gpt4, postgres_main)
        # Service references may have $ prefix (e.g., "$embedding_local") which needs to be stripped
        services_map = config.get('services', {})
        resolved_services = {}
    
        for service_type, service_ref in services_map.items():
            try:
                # Strip $ prefix if present
                clean_ref = service_ref.lstrip('$') if isinstance(service_ref, str) else service_ref
                resolved_services[service_type] = self.registry.get(clean_ref)
            except Exception as e:
                 raise ConfigurationError(f"Failed to resolve service '{service_ref}' for type '{service_type}': {e}")
    
        # Handle DatabaseContext if db_config present
        # This allows mapping specific tables/fields for this strategy
        if 'db_config' in config and 'db' in resolved_services:
            db_service = resolved_services['db']
            # Check if db_service supports get_context
            if hasattr(db_service, 'get_context'):
                resolved_services['db'] = db_service.get_context(
                    table_mapping=config['db_config'].get('tables', {}),
                    field_mapping=config['db_config'].get('fields', {})
                )
    
        # Construct StrategyDependencies
        deps = self._build_dependencies(resolved_services)
    
        # Use RAGFactory to create strategy
        factory = RAGFactory()
        strategy_name = config['strategy']
        strategy_config = config.get('config', {})
    
        try:
>           strategy = factory.create_strategy(
                strategy_name,
                config=strategy_config,
                override_deps=deps
            )

rag_factory/config/strategy_pair_manager.py:179: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <rag_factory.factory.RAGFactory object at 0x7129a718b1a0>
name = 'VectorEmbeddingIndexer'
config = {'chunk_size': 512, 'min_chunk_size': 100, 'overlap': 50}
override_deps = StrategyDependencies(llm_service=None, embedding_service=<Mock id='124423711288896'>, graph_service=None, database_service=<Mock id='124423710528032'>, reranker_service=None)

    def create_strategy(
        self,
        name: str,
        config: Optional[Dict[str, Any]] = None,
        override_deps: Optional[StrategyDependencies] = None,
    ) -> IRAGStrategy:
        """
        Create and initialize a strategy instance with dependency injection.
    
        Args:
            name: Name of the registered strategy to create
            config: Optional configuration dictionary for the strategy
            override_deps: Optional dependencies to override factory defaults
    
        Returns:
            IRAGStrategy: Initialized strategy instance
    
        Raises:
            StrategyNotFoundError: If strategy name not in registry
            ValueError: If required services are missing or config is invalid
    
        Example:
            >>> factory = RAGFactory(llm_service=my_llm)
            >>> config = {"chunk_size": 1024, "top_k": 10}
            >>> strategy = factory.create_strategy("my_strategy", config)
            >>>
            >>> # Or with override dependencies
            >>> override = StrategyDependencies(llm_service=different_llm)
            >>> strategy = factory.create_strategy("my_strategy", config, override)
        """
        if name not in self._registry:
            available = list(self._registry.keys())
>           raise StrategyNotFoundError(
                f"Strategy '{name}' not found. "
                f"Available strategies: {available}"
            )
E           rag_factory.exceptions.StrategyNotFoundError: Strategy 'VectorEmbeddingIndexer' not found. Available strategies: ['dummy', 'strategy_a', 'strategy_b']

rag_factory/factory.py:204: StrategyNotFoundError

During handling of the above exception, another exception occurred:

self = <rag_factory.config.strategy_pair_manager.StrategyPairManager object at 0x7129a713ff50>
class_path = 'VectorEmbeddingIndexer'

    def _import_strategy_class(self, class_path: str) -> Type:
        """
        Import a class dynamically.
    
        Args:
            class_path: Dot-separated path to the class (module.ClassName).
    
        Returns:
            The class object.
        """
        try:
>           module_path, class_name = class_path.rsplit('.', 1)
            ^^^^^^^^^^^^^^^^^^^^^^^
E           ValueError: not enough values to unpack (expected 2, got 1)

rag_factory/config/strategy_pair_manager.py:211: ValueError

During handling of the above exception, another exception occurred:

self = <rag_factory.config.strategy_pair_manager.StrategyPairManager object at 0x7129a713ff50>
config = {'config': {'chunk_size': 512, 'min_chunk_size': 100, 'overlap': 50}, 'db_config': {'fields': {'chunk_id': 'chunk_id',...king_vectors'}}, 'services': {'db': '$db_main', 'embedding': '$embedding_local'}, 'strategy': 'VectorEmbeddingIndexer'}
is_indexing = True

    def _create_strategy(self, config: Dict[str, Any], is_indexing: bool) -> Any:
        """
        Instantiate strategy with all dependencies.
    
        Args:
            config: Strategy configuration dictionary.
            is_indexing: True if creating indexing strategy, False for retrieval.
    
        Returns:
            Instantiated strategy object.
        """
        # Resolve service references
        # Config['services'] maps abstract service names (llm, db) to registry keys (openai_gpt4, postgres_main)
        # Service references may have $ prefix (e.g., "$embedding_local") which needs to be stripped
        services_map = config.get('services', {})
        resolved_services = {}
    
        for service_type, service_ref in services_map.items():
            try:
                # Strip $ prefix if present
                clean_ref = service_ref.lstrip('$') if isinstance(service_ref, str) else service_ref
                resolved_services[service_type] = self.registry.get(clean_ref)
            except Exception as e:
                 raise ConfigurationError(f"Failed to resolve service '{service_ref}' for type '{service_type}': {e}")
    
        # Handle DatabaseContext if db_config present
        # This allows mapping specific tables/fields for this strategy
        if 'db_config' in config and 'db' in resolved_services:
            db_service = resolved_services['db']
            # Check if db_service supports get_context
            if hasattr(db_service, 'get_context'):
                resolved_services['db'] = db_service.get_context(
                    table_mapping=config['db_config'].get('tables', {}),
                    field_mapping=config['db_config'].get('fields', {})
                )
    
        # Construct StrategyDependencies
        deps = self._build_dependencies(resolved_services)
    
        # Use RAGFactory to create strategy
        factory = RAGFactory()
        strategy_name = config['strategy']
        strategy_config = config.get('config', {})
    
        try:
            strategy = factory.create_strategy(
                strategy_name,
                config=strategy_config,
                override_deps=deps
            )
        except StrategyNotFoundError:
            # Fallback: try to treat it as a class path
            try:
>               strategy_class = self._import_strategy_class(strategy_name)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

rag_factory/config/strategy_pair_manager.py:187: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <rag_factory.config.strategy_pair_manager.StrategyPairManager object at 0x7129a713ff50>
class_path = 'VectorEmbeddingIndexer'

    def _import_strategy_class(self, class_path: str) -> Type:
        """
        Import a class dynamically.
    
        Args:
            class_path: Dot-separated path to the class (module.ClassName).
    
        Returns:
            The class object.
        """
        try:
            module_path, class_name = class_path.rsplit('.', 1)
            module = importlib.import_module(module_path)
            return getattr(module, class_name)
        except (ValueError, ImportError, AttributeError) as e:
>           raise ConfigurationError(f"Could not import strategy class '{class_path}': {e}")
E           rag_factory.config.strategy_loader.ConfigurationError: Could not import strategy class 'VectorEmbeddingIndexer': not enough values to unpack (expected 2, got 1)

rag_factory/config/strategy_pair_manager.py:215: ConfigurationError

During handling of the above exception, another exception occurred:

mock_registry_with_reranker_services = <Mock id='124423710689856'>

    @pytest.mark.asyncio
    async def test_reranking_pair_loading(mock_registry_with_reranker_services):
        """Test loading and basic functionality of reranking-pair."""
        with patch('rag_factory.config.strategy_pair_manager.MigrationValidator') as MockValidator:
            mock_validator_instance = MockValidator.return_value
            mock_validator_instance.validate.return_value = (True, [])
    
            project_root = Path(__file__).parent.parent.parent
            config_dir = project_root / "strategies"
    
            manager = StrategyPairManager(
                service_registry=mock_registry_with_reranker_services,
                config_dir=str(config_dir)
            )
    
            # Load pair
>           indexing, retrieval = manager.load_pair("reranking-pair")
                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/integration/test_reranking_pair.py:35: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
rag_factory/config/strategy_pair_manager.py:117: in load_pair
    indexing = self._create_strategy(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <rag_factory.config.strategy_pair_manager.StrategyPairManager object at 0x7129a713ff50>
config = {'config': {'chunk_size': 512, 'min_chunk_size': 100, 'overlap': 50}, 'db_config': {'fields': {'chunk_id': 'chunk_id',...king_vectors'}}, 'services': {'db': '$db_main', 'embedding': '$embedding_local'}, 'strategy': 'VectorEmbeddingIndexer'}
is_indexing = True

    def _create_strategy(self, config: Dict[str, Any], is_indexing: bool) -> Any:
        """
        Instantiate strategy with all dependencies.
    
        Args:
            config: Strategy configuration dictionary.
            is_indexing: True if creating indexing strategy, False for retrieval.
    
        Returns:
            Instantiated strategy object.
        """
        # Resolve service references
        # Config['services'] maps abstract service names (llm, db) to registry keys (openai_gpt4, postgres_main)
        # Service references may have $ prefix (e.g., "$embedding_local") which needs to be stripped
        services_map = config.get('services', {})
        resolved_services = {}
    
        for service_type, service_ref in services_map.items():
            try:
                # Strip $ prefix if present
                clean_ref = service_ref.lstrip('$') if isinstance(service_ref, str) else service_ref
                resolved_services[service_type] = self.registry.get(clean_ref)
            except Exception as e:
                 raise ConfigurationError(f"Failed to resolve service '{service_ref}' for type '{service_type}': {e}")
    
        # Handle DatabaseContext if db_config present
        # This allows mapping specific tables/fields for this strategy
        if 'db_config' in config and 'db' in resolved_services:
            db_service = resolved_services['db']
            # Check if db_service supports get_context
            if hasattr(db_service, 'get_context'):
                resolved_services['db'] = db_service.get_context(
                    table_mapping=config['db_config'].get('tables', {}),
                    field_mapping=config['db_config'].get('fields', {})
                )
    
        # Construct StrategyDependencies
        deps = self._build_dependencies(resolved_services)
    
        # Use RAGFactory to create strategy
        factory = RAGFactory()
        strategy_name = config['strategy']
        strategy_config = config.get('config', {})
    
        try:
            strategy = factory.create_strategy(
                strategy_name,
                config=strategy_config,
                override_deps=deps
            )
        except StrategyNotFoundError:
            # Fallback: try to treat it as a class path
            try:
                strategy_class = self._import_strategy_class(strategy_name)
                 # Manually verify dependencies if not using factory?
                 # Or just instantiate.
                strategy = strategy_class(config=strategy_config, dependencies=deps)
            except Exception as e:
>               raise ConfigurationError(
                    f"Strategy '{strategy_name}' not found in registry and could not be imported as a class: {e}"
                )
E               rag_factory.config.strategy_loader.ConfigurationError: Strategy 'VectorEmbeddingIndexer' not found in registry and could not be imported as a class: Could not import strategy class 'VectorEmbeddingIndexer': not enough values to unpack (expected 2, got 1)

rag_factory/config/strategy_pair_manager.py:192: ConfigurationError
______________________ test_self_reflective_pair_loading _______________________

self = <rag_factory.config.strategy_pair_manager.StrategyPairManager object at 0x7129a7004260>
config = {'config': {'chunk_size': 512, 'min_chunk_size': 100, 'overlap': 50}, 'db_config': {'fields': {'chunk_id': 'chunk_id',...tive_vectors'}}, 'services': {'db': '$db_main', 'embedding': '$embedding_local'}, 'strategy': 'VectorEmbeddingIndexer'}
is_indexing = True

    def _create_strategy(self, config: Dict[str, Any], is_indexing: bool) -> Any:
        """
        Instantiate strategy with all dependencies.
    
        Args:
            config: Strategy configuration dictionary.
            is_indexing: True if creating indexing strategy, False for retrieval.
    
        Returns:
            Instantiated strategy object.
        """
        # Resolve service references
        # Config['services'] maps abstract service names (llm, db) to registry keys (openai_gpt4, postgres_main)
        # Service references may have $ prefix (e.g., "$embedding_local") which needs to be stripped
        services_map = config.get('services', {})
        resolved_services = {}
    
        for service_type, service_ref in services_map.items():
            try:
                # Strip $ prefix if present
                clean_ref = service_ref.lstrip('$') if isinstance(service_ref, str) else service_ref
                resolved_services[service_type] = self.registry.get(clean_ref)
            except Exception as e:
                 raise ConfigurationError(f"Failed to resolve service '{service_ref}' for type '{service_type}': {e}")
    
        # Handle DatabaseContext if db_config present
        # This allows mapping specific tables/fields for this strategy
        if 'db_config' in config and 'db' in resolved_services:
            db_service = resolved_services['db']
            # Check if db_service supports get_context
            if hasattr(db_service, 'get_context'):
                resolved_services['db'] = db_service.get_context(
                    table_mapping=config['db_config'].get('tables', {}),
                    field_mapping=config['db_config'].get('fields', {})
                )
    
        # Construct StrategyDependencies
        deps = self._build_dependencies(resolved_services)
    
        # Use RAGFactory to create strategy
        factory = RAGFactory()
        strategy_name = config['strategy']
        strategy_config = config.get('config', {})
    
        try:
>           strategy = factory.create_strategy(
                strategy_name,
                config=strategy_config,
                override_deps=deps
            )

rag_factory/config/strategy_pair_manager.py:179: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <rag_factory.factory.RAGFactory object at 0x7129a71df4d0>
name = 'VectorEmbeddingIndexer'
config = {'chunk_size': 512, 'min_chunk_size': 100, 'overlap': 50}
override_deps = StrategyDependencies(llm_service=None, embedding_service=<Mock id='124423710826880'>, graph_service=None, database_service=<Mock id='124423710501072'>, reranker_service=None)

    def create_strategy(
        self,
        name: str,
        config: Optional[Dict[str, Any]] = None,
        override_deps: Optional[StrategyDependencies] = None,
    ) -> IRAGStrategy:
        """
        Create and initialize a strategy instance with dependency injection.
    
        Args:
            name: Name of the registered strategy to create
            config: Optional configuration dictionary for the strategy
            override_deps: Optional dependencies to override factory defaults
    
        Returns:
            IRAGStrategy: Initialized strategy instance
    
        Raises:
            StrategyNotFoundError: If strategy name not in registry
            ValueError: If required services are missing or config is invalid
    
        Example:
            >>> factory = RAGFactory(llm_service=my_llm)
            >>> config = {"chunk_size": 1024, "top_k": 10}
            >>> strategy = factory.create_strategy("my_strategy", config)
            >>>
            >>> # Or with override dependencies
            >>> override = StrategyDependencies(llm_service=different_llm)
            >>> strategy = factory.create_strategy("my_strategy", config, override)
        """
        if name not in self._registry:
            available = list(self._registry.keys())
>           raise StrategyNotFoundError(
                f"Strategy '{name}' not found. "
                f"Available strategies: {available}"
            )
E           rag_factory.exceptions.StrategyNotFoundError: Strategy 'VectorEmbeddingIndexer' not found. Available strategies: ['dummy', 'strategy_a', 'strategy_b']

rag_factory/factory.py:204: StrategyNotFoundError

During handling of the above exception, another exception occurred:

self = <rag_factory.config.strategy_pair_manager.StrategyPairManager object at 0x7129a7004260>
class_path = 'VectorEmbeddingIndexer'

    def _import_strategy_class(self, class_path: str) -> Type:
        """
        Import a class dynamically.
    
        Args:
            class_path: Dot-separated path to the class (module.ClassName).
    
        Returns:
            The class object.
        """
        try:
>           module_path, class_name = class_path.rsplit('.', 1)
            ^^^^^^^^^^^^^^^^^^^^^^^
E           ValueError: not enough values to unpack (expected 2, got 1)

rag_factory/config/strategy_pair_manager.py:211: ValueError

During handling of the above exception, another exception occurred:

self = <rag_factory.config.strategy_pair_manager.StrategyPairManager object at 0x7129a7004260>
config = {'config': {'chunk_size': 512, 'min_chunk_size': 100, 'overlap': 50}, 'db_config': {'fields': {'chunk_id': 'chunk_id',...tive_vectors'}}, 'services': {'db': '$db_main', 'embedding': '$embedding_local'}, 'strategy': 'VectorEmbeddingIndexer'}
is_indexing = True

    def _create_strategy(self, config: Dict[str, Any], is_indexing: bool) -> Any:
        """
        Instantiate strategy with all dependencies.
    
        Args:
            config: Strategy configuration dictionary.
            is_indexing: True if creating indexing strategy, False for retrieval.
    
        Returns:
            Instantiated strategy object.
        """
        # Resolve service references
        # Config['services'] maps abstract service names (llm, db) to registry keys (openai_gpt4, postgres_main)
        # Service references may have $ prefix (e.g., "$embedding_local") which needs to be stripped
        services_map = config.get('services', {})
        resolved_services = {}
    
        for service_type, service_ref in services_map.items():
            try:
                # Strip $ prefix if present
                clean_ref = service_ref.lstrip('$') if isinstance(service_ref, str) else service_ref
                resolved_services[service_type] = self.registry.get(clean_ref)
            except Exception as e:
                 raise ConfigurationError(f"Failed to resolve service '{service_ref}' for type '{service_type}': {e}")
    
        # Handle DatabaseContext if db_config present
        # This allows mapping specific tables/fields for this strategy
        if 'db_config' in config and 'db' in resolved_services:
            db_service = resolved_services['db']
            # Check if db_service supports get_context
            if hasattr(db_service, 'get_context'):
                resolved_services['db'] = db_service.get_context(
                    table_mapping=config['db_config'].get('tables', {}),
                    field_mapping=config['db_config'].get('fields', {})
                )
    
        # Construct StrategyDependencies
        deps = self._build_dependencies(resolved_services)
    
        # Use RAGFactory to create strategy
        factory = RAGFactory()
        strategy_name = config['strategy']
        strategy_config = config.get('config', {})
    
        try:
            strategy = factory.create_strategy(
                strategy_name,
                config=strategy_config,
                override_deps=deps
            )
        except StrategyNotFoundError:
            # Fallback: try to treat it as a class path
            try:
>               strategy_class = self._import_strategy_class(strategy_name)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

rag_factory/config/strategy_pair_manager.py:187: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <rag_factory.config.strategy_pair_manager.StrategyPairManager object at 0x7129a7004260>
class_path = 'VectorEmbeddingIndexer'

    def _import_strategy_class(self, class_path: str) -> Type:
        """
        Import a class dynamically.
    
        Args:
            class_path: Dot-separated path to the class (module.ClassName).
    
        Returns:
            The class object.
        """
        try:
            module_path, class_name = class_path.rsplit('.', 1)
            module = importlib.import_module(module_path)
            return getattr(module, class_name)
        except (ValueError, ImportError, AttributeError) as e:
>           raise ConfigurationError(f"Could not import strategy class '{class_path}': {e}")
E           rag_factory.config.strategy_loader.ConfigurationError: Could not import strategy class 'VectorEmbeddingIndexer': not enough values to unpack (expected 2, got 1)

rag_factory/config/strategy_pair_manager.py:215: ConfigurationError

During handling of the above exception, another exception occurred:

mock_registry_with_llm_services = <Mock id='124423714104352'>

    @pytest.mark.asyncio
    async def test_self_reflective_pair_loading(mock_registry_with_llm_services):
        """Test loading and basic functionality of self-reflective-pair."""
        with patch('rag_factory.config.strategy_pair_manager.MigrationValidator') as MockValidator:
            mock_validator_instance = MockValidator.return_value
            mock_validator_instance.validate.return_value = (True, [])
    
            project_root = Path(__file__).parent.parent.parent
            config_dir = project_root / "strategies"
    
            manager = StrategyPairManager(
                service_registry=mock_registry_with_llm_services,
                config_dir=str(config_dir)
            )
    
            # Load pair
>           indexing, retrieval = manager.load_pair("self-reflective-pair")
                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/integration/test_self_reflective_pair.py:36: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
rag_factory/config/strategy_pair_manager.py:117: in load_pair
    indexing = self._create_strategy(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <rag_factory.config.strategy_pair_manager.StrategyPairManager object at 0x7129a7004260>
config = {'config': {'chunk_size': 512, 'min_chunk_size': 100, 'overlap': 50}, 'db_config': {'fields': {'chunk_id': 'chunk_id',...tive_vectors'}}, 'services': {'db': '$db_main', 'embedding': '$embedding_local'}, 'strategy': 'VectorEmbeddingIndexer'}
is_indexing = True

    def _create_strategy(self, config: Dict[str, Any], is_indexing: bool) -> Any:
        """
        Instantiate strategy with all dependencies.
    
        Args:
            config: Strategy configuration dictionary.
            is_indexing: True if creating indexing strategy, False for retrieval.
    
        Returns:
            Instantiated strategy object.
        """
        # Resolve service references
        # Config['services'] maps abstract service names (llm, db) to registry keys (openai_gpt4, postgres_main)
        # Service references may have $ prefix (e.g., "$embedding_local") which needs to be stripped
        services_map = config.get('services', {})
        resolved_services = {}
    
        for service_type, service_ref in services_map.items():
            try:
                # Strip $ prefix if present
                clean_ref = service_ref.lstrip('$') if isinstance(service_ref, str) else service_ref
                resolved_services[service_type] = self.registry.get(clean_ref)
            except Exception as e:
                 raise ConfigurationError(f"Failed to resolve service '{service_ref}' for type '{service_type}': {e}")
    
        # Handle DatabaseContext if db_config present
        # This allows mapping specific tables/fields for this strategy
        if 'db_config' in config and 'db' in resolved_services:
            db_service = resolved_services['db']
            # Check if db_service supports get_context
            if hasattr(db_service, 'get_context'):
                resolved_services['db'] = db_service.get_context(
                    table_mapping=config['db_config'].get('tables', {}),
                    field_mapping=config['db_config'].get('fields', {})
                )
    
        # Construct StrategyDependencies
        deps = self._build_dependencies(resolved_services)
    
        # Use RAGFactory to create strategy
        factory = RAGFactory()
        strategy_name = config['strategy']
        strategy_config = config.get('config', {})
    
        try:
            strategy = factory.create_strategy(
                strategy_name,
                config=strategy_config,
                override_deps=deps
            )
        except StrategyNotFoundError:
            # Fallback: try to treat it as a class path
            try:
                strategy_class = self._import_strategy_class(strategy_name)
                 # Manually verify dependencies if not using factory?
                 # Or just instantiate.
                strategy = strategy_class(config=strategy_config, dependencies=deps)
            except Exception as e:
>               raise ConfigurationError(
                    f"Strategy '{strategy_name}' not found in registry and could not be imported as a class: {e}"
                )
E               rag_factory.config.strategy_loader.ConfigurationError: Strategy 'VectorEmbeddingIndexer' not found in registry and could not be imported as a class: Could not import strategy class 'VectorEmbeddingIndexer': not enough values to unpack (expected 2, got 1)

rag_factory/config/strategy_pair_manager.py:192: ConfigurationError
________________________ test_semantic_api_pair_loading ________________________

self = <rag_factory.config.strategy_pair_manager.StrategyPairManager object at 0x7129a7225910>
config = {'config': {'chunk_size': 512, 'min_chunk_size': 100, 'overlap': 50}, 'db_config': {'fields': {'chunk_id': 'chunk_id',...api_vectors'}}, 'services': {'db': '$db_main', 'embedding': '$embedding_openai'}, 'strategy': 'VectorEmbeddingIndexer'}
is_indexing = True

    def _create_strategy(self, config: Dict[str, Any], is_indexing: bool) -> Any:
        """
        Instantiate strategy with all dependencies.
    
        Args:
            config: Strategy configuration dictionary.
            is_indexing: True if creating indexing strategy, False for retrieval.
    
        Returns:
            Instantiated strategy object.
        """
        # Resolve service references
        # Config['services'] maps abstract service names (llm, db) to registry keys (openai_gpt4, postgres_main)
        # Service references may have $ prefix (e.g., "$embedding_local") which needs to be stripped
        services_map = config.get('services', {})
        resolved_services = {}
    
        for service_type, service_ref in services_map.items():
            try:
                # Strip $ prefix if present
                clean_ref = service_ref.lstrip('$') if isinstance(service_ref, str) else service_ref
                resolved_services[service_type] = self.registry.get(clean_ref)
            except Exception as e:
                 raise ConfigurationError(f"Failed to resolve service '{service_ref}' for type '{service_type}': {e}")
    
        # Handle DatabaseContext if db_config present
        # This allows mapping specific tables/fields for this strategy
        if 'db_config' in config and 'db' in resolved_services:
            db_service = resolved_services['db']
            # Check if db_service supports get_context
            if hasattr(db_service, 'get_context'):
                resolved_services['db'] = db_service.get_context(
                    table_mapping=config['db_config'].get('tables', {}),
                    field_mapping=config['db_config'].get('fields', {})
                )
    
        # Construct StrategyDependencies
        deps = self._build_dependencies(resolved_services)
    
        # Use RAGFactory to create strategy
        factory = RAGFactory()
        strategy_name = config['strategy']
        strategy_config = config.get('config', {})
    
        try:
>           strategy = factory.create_strategy(
                strategy_name,
                config=strategy_config,
                override_deps=deps
            )

rag_factory/config/strategy_pair_manager.py:179: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <rag_factory.factory.RAGFactory object at 0x7129a7227440>
name = 'VectorEmbeddingIndexer'
config = {'chunk_size': 512, 'min_chunk_size': 100, 'overlap': 50}
override_deps = StrategyDependencies(llm_service=None, embedding_service=<Mock id='124423709415792'>, graph_service=None, database_service=<Mock id='124423711006624'>, reranker_service=None)

    def create_strategy(
        self,
        name: str,
        config: Optional[Dict[str, Any]] = None,
        override_deps: Optional[StrategyDependencies] = None,
    ) -> IRAGStrategy:
        """
        Create and initialize a strategy instance with dependency injection.
    
        Args:
            name: Name of the registered strategy to create
            config: Optional configuration dictionary for the strategy
            override_deps: Optional dependencies to override factory defaults
    
        Returns:
            IRAGStrategy: Initialized strategy instance
    
        Raises:
            StrategyNotFoundError: If strategy name not in registry
            ValueError: If required services are missing or config is invalid
    
        Example:
            >>> factory = RAGFactory(llm_service=my_llm)
            >>> config = {"chunk_size": 1024, "top_k": 10}
            >>> strategy = factory.create_strategy("my_strategy", config)
            >>>
            >>> # Or with override dependencies
            >>> override = StrategyDependencies(llm_service=different_llm)
            >>> strategy = factory.create_strategy("my_strategy", config, override)
        """
        if name not in self._registry:
            available = list(self._registry.keys())
>           raise StrategyNotFoundError(
                f"Strategy '{name}' not found. "
                f"Available strategies: {available}"
            )
E           rag_factory.exceptions.StrategyNotFoundError: Strategy 'VectorEmbeddingIndexer' not found. Available strategies: ['dummy', 'strategy_a', 'strategy_b']

rag_factory/factory.py:204: StrategyNotFoundError

During handling of the above exception, another exception occurred:

self = <rag_factory.config.strategy_pair_manager.StrategyPairManager object at 0x7129a7225910>
class_path = 'VectorEmbeddingIndexer'

    def _import_strategy_class(self, class_path: str) -> Type:
        """
        Import a class dynamically.
    
        Args:
            class_path: Dot-separated path to the class (module.ClassName).
    
        Returns:
            The class object.
        """
        try:
>           module_path, class_name = class_path.rsplit('.', 1)
            ^^^^^^^^^^^^^^^^^^^^^^^
E           ValueError: not enough values to unpack (expected 2, got 1)

rag_factory/config/strategy_pair_manager.py:211: ValueError

During handling of the above exception, another exception occurred:

self = <rag_factory.config.strategy_pair_manager.StrategyPairManager object at 0x7129a7225910>
config = {'config': {'chunk_size': 512, 'min_chunk_size': 100, 'overlap': 50}, 'db_config': {'fields': {'chunk_id': 'chunk_id',...api_vectors'}}, 'services': {'db': '$db_main', 'embedding': '$embedding_openai'}, 'strategy': 'VectorEmbeddingIndexer'}
is_indexing = True

    def _create_strategy(self, config: Dict[str, Any], is_indexing: bool) -> Any:
        """
        Instantiate strategy with all dependencies.
    
        Args:
            config: Strategy configuration dictionary.
            is_indexing: True if creating indexing strategy, False for retrieval.
    
        Returns:
            Instantiated strategy object.
        """
        # Resolve service references
        # Config['services'] maps abstract service names (llm, db) to registry keys (openai_gpt4, postgres_main)
        # Service references may have $ prefix (e.g., "$embedding_local") which needs to be stripped
        services_map = config.get('services', {})
        resolved_services = {}
    
        for service_type, service_ref in services_map.items():
            try:
                # Strip $ prefix if present
                clean_ref = service_ref.lstrip('$') if isinstance(service_ref, str) else service_ref
                resolved_services[service_type] = self.registry.get(clean_ref)
            except Exception as e:
                 raise ConfigurationError(f"Failed to resolve service '{service_ref}' for type '{service_type}': {e}")
    
        # Handle DatabaseContext if db_config present
        # This allows mapping specific tables/fields for this strategy
        if 'db_config' in config and 'db' in resolved_services:
            db_service = resolved_services['db']
            # Check if db_service supports get_context
            if hasattr(db_service, 'get_context'):
                resolved_services['db'] = db_service.get_context(
                    table_mapping=config['db_config'].get('tables', {}),
                    field_mapping=config['db_config'].get('fields', {})
                )
    
        # Construct StrategyDependencies
        deps = self._build_dependencies(resolved_services)
    
        # Use RAGFactory to create strategy
        factory = RAGFactory()
        strategy_name = config['strategy']
        strategy_config = config.get('config', {})
    
        try:
            strategy = factory.create_strategy(
                strategy_name,
                config=strategy_config,
                override_deps=deps
            )
        except StrategyNotFoundError:
            # Fallback: try to treat it as a class path
            try:
>               strategy_class = self._import_strategy_class(strategy_name)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

rag_factory/config/strategy_pair_manager.py:187: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <rag_factory.config.strategy_pair_manager.StrategyPairManager object at 0x7129a7225910>
class_path = 'VectorEmbeddingIndexer'

    def _import_strategy_class(self, class_path: str) -> Type:
        """
        Import a class dynamically.
    
        Args:
            class_path: Dot-separated path to the class (module.ClassName).
    
        Returns:
            The class object.
        """
        try:
            module_path, class_name = class_path.rsplit('.', 1)
            module = importlib.import_module(module_path)
            return getattr(module, class_name)
        except (ValueError, ImportError, AttributeError) as e:
>           raise ConfigurationError(f"Could not import strategy class '{class_path}': {e}")
E           rag_factory.config.strategy_loader.ConfigurationError: Could not import strategy class 'VectorEmbeddingIndexer': not enough values to unpack (expected 2, got 1)

rag_factory/config/strategy_pair_manager.py:215: ConfigurationError

During handling of the above exception, another exception occurred:

mock_registry_with_services = <Mock id='124423711303888'>

    @pytest.mark.asyncio
    async def test_semantic_api_pair_loading(mock_registry_with_services):
        """Test loading and basic functionality of semantic-api-pair."""
        with patch('rag_factory.config.strategy_pair_manager.MigrationValidator') as MockValidator:
            mock_validator_instance = MockValidator.return_value
            mock_validator_instance.validate.return_value = (True, [])
    
            project_root = Path(__file__).parent.parent.parent
            config_dir = project_root / "strategies"
    
            manager = StrategyPairManager(
                service_registry=mock_registry_with_services,
                config_dir=str(config_dir)
            )
    
            # Load pair
>           indexing, retrieval = manager.load_pair("semantic-api-pair")
                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/integration/test_semantic_api_pair.py:36: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
rag_factory/config/strategy_pair_manager.py:117: in load_pair
    indexing = self._create_strategy(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <rag_factory.config.strategy_pair_manager.StrategyPairManager object at 0x7129a7225910>
config = {'config': {'chunk_size': 512, 'min_chunk_size': 100, 'overlap': 50}, 'db_config': {'fields': {'chunk_id': 'chunk_id',...api_vectors'}}, 'services': {'db': '$db_main', 'embedding': '$embedding_openai'}, 'strategy': 'VectorEmbeddingIndexer'}
is_indexing = True

    def _create_strategy(self, config: Dict[str, Any], is_indexing: bool) -> Any:
        """
        Instantiate strategy with all dependencies.
    
        Args:
            config: Strategy configuration dictionary.
            is_indexing: True if creating indexing strategy, False for retrieval.
    
        Returns:
            Instantiated strategy object.
        """
        # Resolve service references
        # Config['services'] maps abstract service names (llm, db) to registry keys (openai_gpt4, postgres_main)
        # Service references may have $ prefix (e.g., "$embedding_local") which needs to be stripped
        services_map = config.get('services', {})
        resolved_services = {}
    
        for service_type, service_ref in services_map.items():
            try:
                # Strip $ prefix if present
                clean_ref = service_ref.lstrip('$') if isinstance(service_ref, str) else service_ref
                resolved_services[service_type] = self.registry.get(clean_ref)
            except Exception as e:
                 raise ConfigurationError(f"Failed to resolve service '{service_ref}' for type '{service_type}': {e}")
    
        # Handle DatabaseContext if db_config present
        # This allows mapping specific tables/fields for this strategy
        if 'db_config' in config and 'db' in resolved_services:
            db_service = resolved_services['db']
            # Check if db_service supports get_context
            if hasattr(db_service, 'get_context'):
                resolved_services['db'] = db_service.get_context(
                    table_mapping=config['db_config'].get('tables', {}),
                    field_mapping=config['db_config'].get('fields', {})
                )
    
        # Construct StrategyDependencies
        deps = self._build_dependencies(resolved_services)
    
        # Use RAGFactory to create strategy
        factory = RAGFactory()
        strategy_name = config['strategy']
        strategy_config = config.get('config', {})
    
        try:
            strategy = factory.create_strategy(
                strategy_name,
                config=strategy_config,
                override_deps=deps
            )
        except StrategyNotFoundError:
            # Fallback: try to treat it as a class path
            try:
                strategy_class = self._import_strategy_class(strategy_name)
                 # Manually verify dependencies if not using factory?
                 # Or just instantiate.
                strategy = strategy_class(config=strategy_config, dependencies=deps)
            except Exception as e:
>               raise ConfigurationError(
                    f"Strategy '{strategy_name}' not found in registry and could not be imported as a class: {e}"
                )
E               rag_factory.config.strategy_loader.ConfigurationError: Strategy 'VectorEmbeddingIndexer' not found in registry and could not be imported as a class: Could not import strategy class 'VectorEmbeddingIndexer': not enough values to unpack (expected 2, got 1)

rag_factory/config/strategy_pair_manager.py:192: ConfigurationError
_______________________ test_semantic_local_pair_loading _______________________

self = <rag_factory.config.strategy_pair_manager.StrategyPairManager object at 0x7129a71891f0>
config = {'config': {'chunk_size': 512, 'min_chunk_size': 100, 'overlap': 50}, 'db_config': {'fields': {'chunk_id': 'chunk_id',...ocal_vectors'}}, 'services': {'db': '$db_main', 'embedding': '$embedding_local'}, 'strategy': 'VectorEmbeddingIndexer'}
is_indexing = True

    def _create_strategy(self, config: Dict[str, Any], is_indexing: bool) -> Any:
        """
        Instantiate strategy with all dependencies.
    
        Args:
            config: Strategy configuration dictionary.
            is_indexing: True if creating indexing strategy, False for retrieval.
    
        Returns:
            Instantiated strategy object.
        """
        # Resolve service references
        # Config['services'] maps abstract service names (llm, db) to registry keys (openai_gpt4, postgres_main)
        # Service references may have $ prefix (e.g., "$embedding_local") which needs to be stripped
        services_map = config.get('services', {})
        resolved_services = {}
    
        for service_type, service_ref in services_map.items():
            try:
                # Strip $ prefix if present
                clean_ref = service_ref.lstrip('$') if isinstance(service_ref, str) else service_ref
                resolved_services[service_type] = self.registry.get(clean_ref)
            except Exception as e:
                 raise ConfigurationError(f"Failed to resolve service '{service_ref}' for type '{service_type}': {e}")
    
        # Handle DatabaseContext if db_config present
        # This allows mapping specific tables/fields for this strategy
        if 'db_config' in config and 'db' in resolved_services:
            db_service = resolved_services['db']
            # Check if db_service supports get_context
            if hasattr(db_service, 'get_context'):
                resolved_services['db'] = db_service.get_context(
                    table_mapping=config['db_config'].get('tables', {}),
                    field_mapping=config['db_config'].get('fields', {})
                )
    
        # Construct StrategyDependencies
        deps = self._build_dependencies(resolved_services)
    
        # Use RAGFactory to create strategy
        factory = RAGFactory()
        strategy_name = config['strategy']
        strategy_config = config.get('config', {})
    
        try:
>           strategy = factory.create_strategy(
                strategy_name,
                config=strategy_config,
                override_deps=deps
            )

rag_factory/config/strategy_pair_manager.py:179: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <rag_factory.factory.RAGFactory object at 0x7129a70339b0>
name = 'VectorEmbeddingIndexer'
config = {'chunk_size': 512, 'min_chunk_size': 100, 'overlap': 50}
override_deps = StrategyDependencies(llm_service=None, embedding_service=<Mock id='124423710537968'>, graph_service=None, database_service=<Mock id='124423709419296'>, reranker_service=None)

    def create_strategy(
        self,
        name: str,
        config: Optional[Dict[str, Any]] = None,
        override_deps: Optional[StrategyDependencies] = None,
    ) -> IRAGStrategy:
        """
        Create and initialize a strategy instance with dependency injection.
    
        Args:
            name: Name of the registered strategy to create
            config: Optional configuration dictionary for the strategy
            override_deps: Optional dependencies to override factory defaults
    
        Returns:
            IRAGStrategy: Initialized strategy instance
    
        Raises:
            StrategyNotFoundError: If strategy name not in registry
            ValueError: If required services are missing or config is invalid
    
        Example:
            >>> factory = RAGFactory(llm_service=my_llm)
            >>> config = {"chunk_size": 1024, "top_k": 10}
            >>> strategy = factory.create_strategy("my_strategy", config)
            >>>
            >>> # Or with override dependencies
            >>> override = StrategyDependencies(llm_service=different_llm)
            >>> strategy = factory.create_strategy("my_strategy", config, override)
        """
        if name not in self._registry:
            available = list(self._registry.keys())
>           raise StrategyNotFoundError(
                f"Strategy '{name}' not found. "
                f"Available strategies: {available}"
            )
E           rag_factory.exceptions.StrategyNotFoundError: Strategy 'VectorEmbeddingIndexer' not found. Available strategies: ['dummy', 'strategy_a', 'strategy_b']

rag_factory/factory.py:204: StrategyNotFoundError

During handling of the above exception, another exception occurred:

self = <rag_factory.config.strategy_pair_manager.StrategyPairManager object at 0x7129a71891f0>
class_path = 'VectorEmbeddingIndexer'

    def _import_strategy_class(self, class_path: str) -> Type:
        """
        Import a class dynamically.
    
        Args:
            class_path: Dot-separated path to the class (module.ClassName).
    
        Returns:
            The class object.
        """
        try:
>           module_path, class_name = class_path.rsplit('.', 1)
            ^^^^^^^^^^^^^^^^^^^^^^^
E           ValueError: not enough values to unpack (expected 2, got 1)

rag_factory/config/strategy_pair_manager.py:211: ValueError

During handling of the above exception, another exception occurred:

self = <rag_factory.config.strategy_pair_manager.StrategyPairManager object at 0x7129a71891f0>
config = {'config': {'chunk_size': 512, 'min_chunk_size': 100, 'overlap': 50}, 'db_config': {'fields': {'chunk_id': 'chunk_id',...ocal_vectors'}}, 'services': {'db': '$db_main', 'embedding': '$embedding_local'}, 'strategy': 'VectorEmbeddingIndexer'}
is_indexing = True

    def _create_strategy(self, config: Dict[str, Any], is_indexing: bool) -> Any:
        """
        Instantiate strategy with all dependencies.
    
        Args:
            config: Strategy configuration dictionary.
            is_indexing: True if creating indexing strategy, False for retrieval.
    
        Returns:
            Instantiated strategy object.
        """
        # Resolve service references
        # Config['services'] maps abstract service names (llm, db) to registry keys (openai_gpt4, postgres_main)
        # Service references may have $ prefix (e.g., "$embedding_local") which needs to be stripped
        services_map = config.get('services', {})
        resolved_services = {}
    
        for service_type, service_ref in services_map.items():
            try:
                # Strip $ prefix if present
                clean_ref = service_ref.lstrip('$') if isinstance(service_ref, str) else service_ref
                resolved_services[service_type] = self.registry.get(clean_ref)
            except Exception as e:
                 raise ConfigurationError(f"Failed to resolve service '{service_ref}' for type '{service_type}': {e}")
    
        # Handle DatabaseContext if db_config present
        # This allows mapping specific tables/fields for this strategy
        if 'db_config' in config and 'db' in resolved_services:
            db_service = resolved_services['db']
            # Check if db_service supports get_context
            if hasattr(db_service, 'get_context'):
                resolved_services['db'] = db_service.get_context(
                    table_mapping=config['db_config'].get('tables', {}),
                    field_mapping=config['db_config'].get('fields', {})
                )
    
        # Construct StrategyDependencies
        deps = self._build_dependencies(resolved_services)
    
        # Use RAGFactory to create strategy
        factory = RAGFactory()
        strategy_name = config['strategy']
        strategy_config = config.get('config', {})
    
        try:
            strategy = factory.create_strategy(
                strategy_name,
                config=strategy_config,
                override_deps=deps
            )
        except StrategyNotFoundError:
            # Fallback: try to treat it as a class path
            try:
>               strategy_class = self._import_strategy_class(strategy_name)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

rag_factory/config/strategy_pair_manager.py:187: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <rag_factory.config.strategy_pair_manager.StrategyPairManager object at 0x7129a71891f0>
class_path = 'VectorEmbeddingIndexer'

    def _import_strategy_class(self, class_path: str) -> Type:
        """
        Import a class dynamically.
    
        Args:
            class_path: Dot-separated path to the class (module.ClassName).
    
        Returns:
            The class object.
        """
        try:
            module_path, class_name = class_path.rsplit('.', 1)
            module = importlib.import_module(module_path)
            return getattr(module, class_name)
        except (ValueError, ImportError, AttributeError) as e:
>           raise ConfigurationError(f"Could not import strategy class '{class_path}': {e}")
E           rag_factory.config.strategy_loader.ConfigurationError: Could not import strategy class 'VectorEmbeddingIndexer': not enough values to unpack (expected 2, got 1)

rag_factory/config/strategy_pair_manager.py:215: ConfigurationError

During handling of the above exception, another exception occurred:

mock_registry_with_services = <Mock id='124423709436640'>

    @pytest.mark.asyncio
    async def test_semantic_local_pair_loading(mock_registry_with_services):
        """Test loading and execution of semantic-local-pair strategy.
    
        Uses centralized mock_registry_with_services fixture which provides:
        - Mock embedding service (384 dimensions)
        - Mock database service with CRUD operations
        - Mock migration validator
    
        This test verifies:
        1. Strategy pair loads correctly
        2. Indexing strategy processes documents
        3. Retrieval strategy retrieves chunks
        4. Dependencies are properly injected
        """
        # Patch MigrationValidator to avoid DB interaction
        with patch('rag_factory.config.strategy_pair_manager.MigrationValidator') as MockValidator:
            # Configure mock validator instance
            mock_validator_instance = MockValidator.return_value
            mock_validator_instance.validate.return_value = (True, [])
    
            # Setup paths
            project_root = Path(__file__).parent.parent.parent
            config_dir = project_root / "strategies"
    
            # Initialize manager with centralized mock registry
            manager = StrategyPairManager(
                service_registry=mock_registry_with_services,
                config_dir=str(config_dir)
            )
    
            # Check that validator was initialized
            assert manager.migration_validator is not None
    
            # Load strategy pair
>           indexing, retrieval = manager.load_pair("semantic-local-pair")
                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/integration/test_semantic_local_pair.py:52: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
rag_factory/config/strategy_pair_manager.py:117: in load_pair
    indexing = self._create_strategy(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <rag_factory.config.strategy_pair_manager.StrategyPairManager object at 0x7129a71891f0>
config = {'config': {'chunk_size': 512, 'min_chunk_size': 100, 'overlap': 50}, 'db_config': {'fields': {'chunk_id': 'chunk_id',...ocal_vectors'}}, 'services': {'db': '$db_main', 'embedding': '$embedding_local'}, 'strategy': 'VectorEmbeddingIndexer'}
is_indexing = True

    def _create_strategy(self, config: Dict[str, Any], is_indexing: bool) -> Any:
        """
        Instantiate strategy with all dependencies.
    
        Args:
            config: Strategy configuration dictionary.
            is_indexing: True if creating indexing strategy, False for retrieval.
    
        Returns:
            Instantiated strategy object.
        """
        # Resolve service references
        # Config['services'] maps abstract service names (llm, db) to registry keys (openai_gpt4, postgres_main)
        # Service references may have $ prefix (e.g., "$embedding_local") which needs to be stripped
        services_map = config.get('services', {})
        resolved_services = {}
    
        for service_type, service_ref in services_map.items():
            try:
                # Strip $ prefix if present
                clean_ref = service_ref.lstrip('$') if isinstance(service_ref, str) else service_ref
                resolved_services[service_type] = self.registry.get(clean_ref)
            except Exception as e:
                 raise ConfigurationError(f"Failed to resolve service '{service_ref}' for type '{service_type}': {e}")
    
        # Handle DatabaseContext if db_config present
        # This allows mapping specific tables/fields for this strategy
        if 'db_config' in config and 'db' in resolved_services:
            db_service = resolved_services['db']
            # Check if db_service supports get_context
            if hasattr(db_service, 'get_context'):
                resolved_services['db'] = db_service.get_context(
                    table_mapping=config['db_config'].get('tables', {}),
                    field_mapping=config['db_config'].get('fields', {})
                )
    
        # Construct StrategyDependencies
        deps = self._build_dependencies(resolved_services)
    
        # Use RAGFactory to create strategy
        factory = RAGFactory()
        strategy_name = config['strategy']
        strategy_config = config.get('config', {})
    
        try:
            strategy = factory.create_strategy(
                strategy_name,
                config=strategy_config,
                override_deps=deps
            )
        except StrategyNotFoundError:
            # Fallback: try to treat it as a class path
            try:
                strategy_class = self._import_strategy_class(strategy_name)
                 # Manually verify dependencies if not using factory?
                 # Or just instantiate.
                strategy = strategy_class(config=strategy_config, dependencies=deps)
            except Exception as e:
>               raise ConfigurationError(
                    f"Strategy '{strategy_name}' not found in registry and could not be imported as a class: {e}"
                )
E               rag_factory.config.strategy_loader.ConfigurationError: Strategy 'VectorEmbeddingIndexer' not found in registry and could not be imported as a class: Could not import strategy class 'VectorEmbeddingIndexer': not enough values to unpack (expected 2, got 1)

rag_factory/config/strategy_pair_manager.py:192: ConfigurationError
______________________________ test_llm_streaming ______________________________

real_llm_service = <rag_factory.services.llm.service.LLMService object at 0x7129a715d670>

    @pytest.mark.real_integration
    @pytest.mark.requires_llm
    @pytest.mark.asyncio
    async def test_llm_streaming(real_llm_service):
        """Test LLM streaming responses."""
        from rag_factory.services.llm.base import Message, MessageRole
    
        messages = [
            Message(
                role=MessageRole.USER,
                content="Count from 1 to 5."
            )
        ]
    
        # Check if service supports streaming
        if hasattr(real_llm_service, 'stream'):
            chunks = []
>           async for chunk in real_llm_service.stream(messages):
E           TypeError: 'async for' requires an object with __aiter__ method, got generator

tests/integration_real/test_llm_real.py:197: TypeError
____________________________ test_load_pair_success ____________________________

manager = <rag_factory.config.strategy_pair_manager.StrategyPairManager object at 0x7129966d69f0>
mock_loader = <MagicMock name='StrategyPairLoader()' id='124423714209040'>
mock_registry = <MagicMock spec='ServiceRegistry' id='124423431018240'>

    def test_load_pair_success(manager, mock_loader, mock_registry):
        # Setup Loader return
        mock_config = {
            "strategy_name": "test-pair",
            "indexer": {
                "strategy": "indexer.module.Class",
                "services": {"llm": "$gpt4", "db": "$db1"},
                "config": {"some": "param"}
            },
            "retriever": {
                "strategy": "retriever.module.Class",
                "services": {"embedding": "$embed1"},
                "config": {"top_k": 5}
            },
            "migrations": {
                "required_revisions": ["1234"]
            }
        }
        mock_loader.load_config.return_value = mock_config
    
        # Mock _import_strategy_class
        with patch.object(manager, "_import_strategy_class") as mock_import:
            mock_import.side_effect = lambda x: MockIndexingStrategy if "indexer" in x else MockRetrievalStrategy
    
            # Run
            idx, ret = manager.load_pair("test-pair")
    
            # Assertions
            assert isinstance(idx, MockIndexingStrategy)
            assert isinstance(ret, MockRetrievalStrategy)
    
            # Verify loader usage
            mock_loader.load_config.assert_called_with(Path("/tmp/strategies/test-pair.yaml"))
    
            # Verify Migration Validation
            manager.migration_validator.validate.assert_called_with(["1234"])
    
            # Verify Service Resolution
>           mock_registry.get.assert_any_call("$gpt4")

tests/unit/config/test_strategy_pair_manager.py:100: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MagicMock name='mock.get' id='124423747193072'>, args = ('$gpt4',)
kwargs = {}, expected = call('$gpt4'), cause = None
actual = [call('db_main'), call('gpt4'), call('db1'), call('embed1')]
expected_string = "get('$gpt4')"

    def assert_any_call(self, /, *args, **kwargs):
        """assert the mock has been called with the specified arguments.
    
        The assert passes if the mock has *ever* been called, unlike
        `assert_called_with` and `assert_called_once_with` that only pass if
        the call is the most recent one."""
        expected = self._call_matcher(_Call((args, kwargs), two=True))
        cause = expected if isinstance(expected, Exception) else None
        actual = [self._call_matcher(c) for c in self.call_args_list]
        if cause or expected not in _AnyComparer(actual):
            expected_string = self._format_mock_call_signature(args, kwargs)
>           raise AssertionError(
                '%s call not found' % expected_string
            ) from cause
E           AssertionError: get('$gpt4') call not found

/usr/lib/python3.12/unittest/mock.py:1015: AssertionError
___________________________ test_db_context_creation ___________________________

manager = <rag_factory.config.strategy_pair_manager.StrategyPairManager object at 0x7129a4c6d190>
mock_loader = <MagicMock name='StrategyPairLoader()' id='124423711007824'>
mock_registry = <MagicMock spec='ServiceRegistry' id='124423708761296'>

    def test_db_context_creation(manager, mock_loader, mock_registry):
        mock_config = {
            "strategy_name": "db-context-pair",
            "indexer": {
                "strategy": "indexer.module.Class",
                "services": {"db": "$db1"},
                "db_config": {
                    "tables": {"logical": "physical"},
                    "fields": {"f1": "col1"}
                }
            },
            "retriever": { "strategy": "retriever.module.Class" }
        }
        mock_loader.load_config.return_value = mock_config
    
        # Mock DB service with get_context
        mock_db = MagicMock()
        mock_context = MagicMock()
        mock_db.get_context.return_value = mock_context
    
        # Configure registry to return mock_db
        def get_service(ref):
            if ref == "$db1": return mock_db
            return MagicMock()
        mock_registry.get.side_effect = get_service
    
        with patch.object(manager, "_import_strategy_class") as mock_import:
            mock_import.return_value = MagicMock() # Generic mock strategy
    
            manager.load_pair("db-context-pair")
    
            # Verify get_context called
>           mock_db.get_context.assert_called_with(
                table_mapping={"logical": "physical"},
                field_mapping={"f1": "col1"}
            )

tests/unit/config/test_strategy_pair_manager.py:172: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MagicMock name='mock.get_context' id='124423708774224'>, args = ()
kwargs = {'field_mapping': {'f1': 'col1'}, 'table_mapping': {'logical': 'physical'}}
expected = "get_context(table_mapping={'logical': 'physical'}, field_mapping={'f1': 'col1'})"
actual = 'not called.'
error_message = "expected call not found.\nExpected: get_context(table_mapping={'logical': 'physical'}, field_mapping={'f1': 'col1'})\n  Actual: not called."

    def assert_called_with(self, /, *args, **kwargs):
        """assert that the last call was made with the specified arguments.
    
        Raises an AssertionError if the args and keyword args passed in are
        different to the last call to the mock."""
        if self.call_args is None:
            expected = self._format_mock_call_signature(args, kwargs)
            actual = 'not called.'
            error_message = ('expected call not found.\nExpected: %s\n  Actual: %s'
                    % (expected, actual))
>           raise AssertionError(error_message)
E           AssertionError: expected call not found.
E           Expected: get_context(table_mapping={'logical': 'physical'}, field_mapping={'f1': 'col1'})
E             Actual: not called.

/usr/lib/python3.12/unittest/mock.py:935: AssertionError
_____________ TestBatchOperations.test_store_chunks_with_hierarchy _____________

self = <tests.unit.database.test_batch_operations.TestBatchOperations object at 0x7129a94d7080>
mock_pool = (<MagicMock id='124423708730832'>, <AsyncMock name='mock.acquire().__aenter__()' id='124423430779344'>)

    @pytest.mark.asyncio
    async def test_store_chunks_with_hierarchy(self, mock_pool):
        """Test storing chunks with hierarchy metadata."""
        pool, conn = mock_pool
        with patch('rag_factory.services.database.postgres.ASYNCPG_AVAILABLE', True):
            service = PostgresqlDatabaseService(password="test")
            service._pool = pool
    
            chunks = [{
                "id": "child_1",
                "text": "child text",
                "embedding": [0.1] * 384,
                "level": 1,
                "parent_id": "root_1",
                "path": [0, 1],
                "document_id": "doc_1"
            }]
    
            await service.store_chunks_with_hierarchy(chunks)
    
            # Verify metadata enrichment
            call_args = conn.execute.call_args
            # Query is 0, chunk_id is 1, text is 2, embedding is 3, metadata is 4
>           metadata_json = call_args[0][4]
                            ^^^^^^^^^^^^^^^
E           IndexError: tuple index out of range

tests/unit/database/test_batch_operations.py:70: IndexError
_____________ TestAlembicMigrations.test_migration_upgrade_to_head _____________

self = <sqlalchemy.engine.base.Connection object at 0x712995a56c90>
dialect = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x712995a55be0>
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x7129a4cbe0c0>
statement = <sqlalchemy.dialects.postgresql.base.PGCompiler object at 0x7129a4cbe870>
parameters = [{}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x712995a55be0>
cursor = <cursor object at 0x7129a727c130; closed: -1>
statement = 'DROP EXTENSION IF EXISTS vector', parameters = {}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x7129a4cbe0c0>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       psycopg2.errors.DependentObjectsStillExist: cannot drop extension vector because other objects depend on it
E       DETAIL:  column embedding of table test_chunks_real depends on type vector
E       HINT:  Use DROP ... CASCADE to drop the dependent objects too.

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: DependentObjectsStillExist

The above exception was the direct cause of the following exception:

self = <tests.unit.database.test_migrations.TestAlembicMigrations object at 0x7129a94eed80>
alembic_config = <alembic.config.Config object at 0x7129a4cc4680>
test_db_url = 'postgresql://rag_user:rag_password@192.168.56.1:5432/rag_test'

    def test_migration_upgrade_to_head(self, alembic_config: Config, test_db_url: str) -> None:
        """Test upgrading migrations to head."""
        # Start from clean state
>       command.downgrade(alembic_config, "base")

tests/unit/database/test_migrations.py:39: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
venv/lib/python3.12/site-packages/alembic/command.py:449: in downgrade
    script.run_env()
venv/lib/python3.12/site-packages/alembic/script/base.py:583: in run_env
    util.load_python_file(self.dir, "env.py")
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:95: in load_python_file
    module = load_module_py(module_id, path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:113: in load_module_py
    spec.loader.exec_module(module)  # type: ignore
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
<frozen importlib._bootstrap_external>:995: in exec_module
    ???
<frozen importlib._bootstrap>:488: in _call_with_frames_removed
    ???
migrations/env.py:93: in <module>
    run_migrations_online()
migrations/env.py:87: in run_migrations_online
    context.run_migrations()
<string>:8: in run_migrations
    ???
venv/lib/python3.12/site-packages/alembic/runtime/environment.py:948: in run_migrations
    self.get_context().run_migrations(**kw)
venv/lib/python3.12/site-packages/alembic/runtime/migration.py:627: in run_migrations
    step.migration_fn(**kw)
migrations/versions/001_initial_schema.py:129: in downgrade
    op.execute("DROP EXTENSION IF EXISTS vector")
<string>:8: in execute
    ???
<string>:3: in execute
    ???
venv/lib/python3.12/site-packages/alembic/operations/ops.py:2537: in execute
    return operations.invoke(op)
           ^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/base.py:445: in invoke
    return fn(self, operation)
           ^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/toimpl.py:224: in execute_sql
    operations.migration_context.impl.execute(
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:214: in execute
    self._exec(sql, execution_options)
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:207: in _exec
    return conn.execute(construct, multiparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1416: in execute
    return meth(
venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py:516: in _execute_on_connection
    return connection._execute_clauseelement(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1639: in _execute_clauseelement
    ret = self._execute_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1848: in _execute_context
    return self._exec_single_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1988: in _exec_single_context
    self._handle_dbapi_exception(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2343: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: in _exec_single_context
    self.dialect.do_execute(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x712995a55be0>
cursor = <cursor object at 0x7129a727c130; closed: -1>
statement = 'DROP EXTENSION IF EXISTS vector', parameters = {}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x7129a4cbe0c0>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.InternalError: (psycopg2.errors.DependentObjectsStillExist) cannot drop extension vector because other objects depend on it
E       DETAIL:  column embedding of table test_chunks_real depends on type vector
E       HINT:  Use DROP ... CASCADE to drop the dependent objects too.
E       
E       [SQL: DROP EXTENSION IF EXISTS vector]
E       (Background on this error at: https://sqlalche.me/e/20/2j85)

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: InternalError
----------------------------- Captured stderr call -----------------------------
INFO  [alembic.runtime.migration] Context impl PostgresqlImpl.
INFO  [alembic.runtime.migration] Will assume transactional DDL.
INFO  [alembic.runtime.migration] Running downgrade 001 -> , Initial schema with documents and chunks tables
________________ TestAlembicMigrations.test_migration_downgrade ________________

self = <sqlalchemy.engine.base.Connection object at 0x7129a4c83650>
dialect = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7129a4c83620>
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x7129a4c437a0>
statement = <sqlalchemy.dialects.postgresql.base.PGCompiler object at 0x7129a4c436e0>
parameters = [{}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7129a4c83620>
cursor = <cursor object at 0x7129a6f8d210; closed: -1>
statement = 'DROP EXTENSION IF EXISTS vector', parameters = {}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x7129a4c437a0>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       psycopg2.errors.DependentObjectsStillExist: cannot drop extension vector because other objects depend on it
E       DETAIL:  column embedding of table test_chunks_real depends on type vector
E       HINT:  Use DROP ... CASCADE to drop the dependent objects too.

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: DependentObjectsStillExist

The above exception was the direct cause of the following exception:

self = <tests.unit.database.test_migrations.TestAlembicMigrations object at 0x7129a94d57c0>
alembic_config = <alembic.config.Config object at 0x7129a4c80890>
test_db_url = 'postgresql://rag_user:rag_password@192.168.56.1:5432/rag_test'

    def test_migration_downgrade(self, alembic_config: Config, test_db_url: str) -> None:
        """Test downgrading migrations."""
        # Start from clean state
>       command.downgrade(alembic_config, "base")

tests/unit/database/test_migrations.py:60: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
venv/lib/python3.12/site-packages/alembic/command.py:449: in downgrade
    script.run_env()
venv/lib/python3.12/site-packages/alembic/script/base.py:583: in run_env
    util.load_python_file(self.dir, "env.py")
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:95: in load_python_file
    module = load_module_py(module_id, path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:113: in load_module_py
    spec.loader.exec_module(module)  # type: ignore
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
<frozen importlib._bootstrap_external>:995: in exec_module
    ???
<frozen importlib._bootstrap>:488: in _call_with_frames_removed
    ???
migrations/env.py:93: in <module>
    run_migrations_online()
migrations/env.py:87: in run_migrations_online
    context.run_migrations()
<string>:8: in run_migrations
    ???
venv/lib/python3.12/site-packages/alembic/runtime/environment.py:948: in run_migrations
    self.get_context().run_migrations(**kw)
venv/lib/python3.12/site-packages/alembic/runtime/migration.py:627: in run_migrations
    step.migration_fn(**kw)
migrations/versions/001_initial_schema.py:129: in downgrade
    op.execute("DROP EXTENSION IF EXISTS vector")
<string>:8: in execute
    ???
<string>:3: in execute
    ???
venv/lib/python3.12/site-packages/alembic/operations/ops.py:2537: in execute
    return operations.invoke(op)
           ^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/base.py:445: in invoke
    return fn(self, operation)
           ^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/toimpl.py:224: in execute_sql
    operations.migration_context.impl.execute(
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:214: in execute
    self._exec(sql, execution_options)
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:207: in _exec
    return conn.execute(construct, multiparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1416: in execute
    return meth(
venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py:516: in _execute_on_connection
    return connection._execute_clauseelement(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1639: in _execute_clauseelement
    ret = self._execute_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1848: in _execute_context
    return self._exec_single_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1988: in _exec_single_context
    self._handle_dbapi_exception(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2343: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: in _exec_single_context
    self.dialect.do_execute(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7129a4c83620>
cursor = <cursor object at 0x7129a6f8d210; closed: -1>
statement = 'DROP EXTENSION IF EXISTS vector', parameters = {}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x7129a4c437a0>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.InternalError: (psycopg2.errors.DependentObjectsStillExist) cannot drop extension vector because other objects depend on it
E       DETAIL:  column embedding of table test_chunks_real depends on type vector
E       HINT:  Use DROP ... CASCADE to drop the dependent objects too.
E       
E       [SQL: DROP EXTENSION IF EXISTS vector]
E       (Background on this error at: https://sqlalche.me/e/20/2j85)

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: InternalError
----------------------------- Captured stderr call -----------------------------
INFO  [alembic.runtime.migration] Context impl PostgresqlImpl.
INFO  [alembic.runtime.migration] Will assume transactional DDL.
INFO  [alembic.runtime.migration] Running downgrade 001 -> , Initial schema with documents and chunks tables
_______________ TestAlembicMigrations.test_migration_idempotency _______________

self = <sqlalchemy.engine.base.Connection object at 0x7129a4c425d0>
dialect = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7129a4c4b590>
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x7129966f2f30>
statement = <sqlalchemy.dialects.postgresql.base.PGCompiler object at 0x7129966f30b0>
parameters = [{}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7129a4c4b590>
cursor = <cursor object at 0x7129a6f8d4e0; closed: -1>
statement = 'DROP EXTENSION IF EXISTS vector', parameters = {}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x7129966f2f30>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       psycopg2.errors.DependentObjectsStillExist: cannot drop extension vector because other objects depend on it
E       DETAIL:  column embedding of table test_chunks_real depends on type vector
E       HINT:  Use DROP ... CASCADE to drop the dependent objects too.

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: DependentObjectsStillExist

The above exception was the direct cause of the following exception:

self = <tests.unit.database.test_migrations.TestAlembicMigrations object at 0x7129a93284d0>
alembic_config = <alembic.config.Config object at 0x7129a4c49a30>
test_db_url = 'postgresql://rag_user:rag_password@192.168.56.1:5432/rag_test'

    def test_migration_idempotency(self, alembic_config: Config, test_db_url: str) -> None:
        """Test that running migrations twice doesn't cause errors."""
        # Start from clean state
>       command.downgrade(alembic_config, "base")

tests/unit/database/test_migrations.py:102: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
venv/lib/python3.12/site-packages/alembic/command.py:449: in downgrade
    script.run_env()
venv/lib/python3.12/site-packages/alembic/script/base.py:583: in run_env
    util.load_python_file(self.dir, "env.py")
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:95: in load_python_file
    module = load_module_py(module_id, path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:113: in load_module_py
    spec.loader.exec_module(module)  # type: ignore
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
<frozen importlib._bootstrap_external>:995: in exec_module
    ???
<frozen importlib._bootstrap>:488: in _call_with_frames_removed
    ???
migrations/env.py:93: in <module>
    run_migrations_online()
migrations/env.py:87: in run_migrations_online
    context.run_migrations()
<string>:8: in run_migrations
    ???
venv/lib/python3.12/site-packages/alembic/runtime/environment.py:948: in run_migrations
    self.get_context().run_migrations(**kw)
venv/lib/python3.12/site-packages/alembic/runtime/migration.py:627: in run_migrations
    step.migration_fn(**kw)
migrations/versions/001_initial_schema.py:129: in downgrade
    op.execute("DROP EXTENSION IF EXISTS vector")
<string>:8: in execute
    ???
<string>:3: in execute
    ???
venv/lib/python3.12/site-packages/alembic/operations/ops.py:2537: in execute
    return operations.invoke(op)
           ^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/base.py:445: in invoke
    return fn(self, operation)
           ^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/toimpl.py:224: in execute_sql
    operations.migration_context.impl.execute(
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:214: in execute
    self._exec(sql, execution_options)
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:207: in _exec
    return conn.execute(construct, multiparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1416: in execute
    return meth(
venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py:516: in _execute_on_connection
    return connection._execute_clauseelement(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1639: in _execute_clauseelement
    ret = self._execute_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1848: in _execute_context
    return self._exec_single_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1988: in _exec_single_context
    self._handle_dbapi_exception(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2343: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: in _exec_single_context
    self.dialect.do_execute(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7129a4c4b590>
cursor = <cursor object at 0x7129a6f8d4e0; closed: -1>
statement = 'DROP EXTENSION IF EXISTS vector', parameters = {}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x7129966f2f30>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.InternalError: (psycopg2.errors.DependentObjectsStillExist) cannot drop extension vector because other objects depend on it
E       DETAIL:  column embedding of table test_chunks_real depends on type vector
E       HINT:  Use DROP ... CASCADE to drop the dependent objects too.
E       
E       [SQL: DROP EXTENSION IF EXISTS vector]
E       (Background on this error at: https://sqlalche.me/e/20/2j85)

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: InternalError
----------------------------- Captured stderr call -----------------------------
INFO  [alembic.runtime.migration] Context impl PostgresqlImpl.
INFO  [alembic.runtime.migration] Will assume transactional DDL.
INFO  [alembic.runtime.migration] Running downgrade 001 -> , Initial schema with documents and chunks tables
________________ TestAlembicMigrations.test_get_current_version ________________

self = <sqlalchemy.engine.base.Connection object at 0x7129a4c4a8a0>
dialect = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7129a4c4bcb0>
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x7129966e9010>
statement = <sqlalchemy.dialects.postgresql.base.PGCompiler object at 0x7129966ebcb0>
parameters = [{}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7129a4c4bcb0>
cursor = <cursor object at 0x7129a6f8fd30; closed: -1>
statement = 'DROP EXTENSION IF EXISTS vector', parameters = {}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x7129966e9010>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       psycopg2.errors.DependentObjectsStillExist: cannot drop extension vector because other objects depend on it
E       DETAIL:  column embedding of table test_chunks_real depends on type vector
E       HINT:  Use DROP ... CASCADE to drop the dependent objects too.

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: DependentObjectsStillExist

The above exception was the direct cause of the following exception:

self = <tests.unit.database.test_migrations.TestAlembicMigrations object at 0x7129a9328800>
alembic_config = <alembic.config.Config object at 0x7129966f39b0>
test_db_url = 'postgresql://rag_user:rag_password@192.168.56.1:5432/rag_test'

    def test_get_current_version(self, alembic_config: Config, test_db_url: str) -> None:
        """Test retrieving current schema version."""
        # Start from clean state
>       command.downgrade(alembic_config, "base")

tests/unit/database/test_migrations.py:129: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
venv/lib/python3.12/site-packages/alembic/command.py:449: in downgrade
    script.run_env()
venv/lib/python3.12/site-packages/alembic/script/base.py:583: in run_env
    util.load_python_file(self.dir, "env.py")
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:95: in load_python_file
    module = load_module_py(module_id, path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:113: in load_module_py
    spec.loader.exec_module(module)  # type: ignore
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
<frozen importlib._bootstrap_external>:995: in exec_module
    ???
<frozen importlib._bootstrap>:488: in _call_with_frames_removed
    ???
migrations/env.py:93: in <module>
    run_migrations_online()
migrations/env.py:87: in run_migrations_online
    context.run_migrations()
<string>:8: in run_migrations
    ???
venv/lib/python3.12/site-packages/alembic/runtime/environment.py:948: in run_migrations
    self.get_context().run_migrations(**kw)
venv/lib/python3.12/site-packages/alembic/runtime/migration.py:627: in run_migrations
    step.migration_fn(**kw)
migrations/versions/001_initial_schema.py:129: in downgrade
    op.execute("DROP EXTENSION IF EXISTS vector")
<string>:8: in execute
    ???
<string>:3: in execute
    ???
venv/lib/python3.12/site-packages/alembic/operations/ops.py:2537: in execute
    return operations.invoke(op)
           ^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/base.py:445: in invoke
    return fn(self, operation)
           ^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/toimpl.py:224: in execute_sql
    operations.migration_context.impl.execute(
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:214: in execute
    self._exec(sql, execution_options)
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:207: in _exec
    return conn.execute(construct, multiparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1416: in execute
    return meth(
venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py:516: in _execute_on_connection
    return connection._execute_clauseelement(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1639: in _execute_clauseelement
    ret = self._execute_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1848: in _execute_context
    return self._exec_single_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1988: in _exec_single_context
    self._handle_dbapi_exception(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2343: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: in _exec_single_context
    self.dialect.do_execute(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7129a4c4bcb0>
cursor = <cursor object at 0x7129a6f8fd30; closed: -1>
statement = 'DROP EXTENSION IF EXISTS vector', parameters = {}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x7129966e9010>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.InternalError: (psycopg2.errors.DependentObjectsStillExist) cannot drop extension vector because other objects depend on it
E       DETAIL:  column embedding of table test_chunks_real depends on type vector
E       HINT:  Use DROP ... CASCADE to drop the dependent objects too.
E       
E       [SQL: DROP EXTENSION IF EXISTS vector]
E       (Background on this error at: https://sqlalche.me/e/20/2j85)

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: InternalError
----------------------------- Captured stderr call -----------------------------
INFO  [alembic.runtime.migration] Context impl PostgresqlImpl.
INFO  [alembic.runtime.migration] Will assume transactional DDL.
INFO  [alembic.runtime.migration] Running downgrade 001 -> , Initial schema with documents and chunks tables
_____________ TestAlembicMigrations.test_migration_creates_tables ______________

self = <sqlalchemy.engine.base.Connection object at 0x7129966ebc50>
dialect = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7129966d5c10>
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x7129966d5130>
statement = <sqlalchemy.dialects.postgresql.base.PGCompiler object at 0x7129966d5280>
parameters = [{}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7129966d5c10>
cursor = <cursor object at 0x7129a6f8d300; closed: -1>
statement = 'DROP EXTENSION IF EXISTS vector', parameters = {}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x7129966d5130>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       psycopg2.errors.DependentObjectsStillExist: cannot drop extension vector because other objects depend on it
E       DETAIL:  column embedding of table test_chunks_real depends on type vector
E       HINT:  Use DROP ... CASCADE to drop the dependent objects too.

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: DependentObjectsStillExist

The above exception was the direct cause of the following exception:

self = <tests.unit.database.test_migrations.TestAlembicMigrations object at 0x7129a9328b30>
alembic_config = <alembic.config.Config object at 0x7129966d5070>
test_db_url = 'postgresql://rag_user:rag_password@192.168.56.1:5432/rag_test'

    def test_migration_creates_tables(self, alembic_config: Config, test_db_url: str) -> None:
        """Test that migrations create expected tables."""
        # Start from clean state
>       command.downgrade(alembic_config, "base")

tests/unit/database/test_migrations.py:147: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
venv/lib/python3.12/site-packages/alembic/command.py:449: in downgrade
    script.run_env()
venv/lib/python3.12/site-packages/alembic/script/base.py:583: in run_env
    util.load_python_file(self.dir, "env.py")
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:95: in load_python_file
    module = load_module_py(module_id, path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:113: in load_module_py
    spec.loader.exec_module(module)  # type: ignore
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
<frozen importlib._bootstrap_external>:995: in exec_module
    ???
<frozen importlib._bootstrap>:488: in _call_with_frames_removed
    ???
migrations/env.py:93: in <module>
    run_migrations_online()
migrations/env.py:87: in run_migrations_online
    context.run_migrations()
<string>:8: in run_migrations
    ???
venv/lib/python3.12/site-packages/alembic/runtime/environment.py:948: in run_migrations
    self.get_context().run_migrations(**kw)
venv/lib/python3.12/site-packages/alembic/runtime/migration.py:627: in run_migrations
    step.migration_fn(**kw)
migrations/versions/001_initial_schema.py:129: in downgrade
    op.execute("DROP EXTENSION IF EXISTS vector")
<string>:8: in execute
    ???
<string>:3: in execute
    ???
venv/lib/python3.12/site-packages/alembic/operations/ops.py:2537: in execute
    return operations.invoke(op)
           ^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/base.py:445: in invoke
    return fn(self, operation)
           ^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/toimpl.py:224: in execute_sql
    operations.migration_context.impl.execute(
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:214: in execute
    self._exec(sql, execution_options)
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:207: in _exec
    return conn.execute(construct, multiparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1416: in execute
    return meth(
venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py:516: in _execute_on_connection
    return connection._execute_clauseelement(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1639: in _execute_clauseelement
    ret = self._execute_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1848: in _execute_context
    return self._exec_single_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1988: in _exec_single_context
    self._handle_dbapi_exception(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2343: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: in _exec_single_context
    self.dialect.do_execute(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7129966d5c10>
cursor = <cursor object at 0x7129a6f8d300; closed: -1>
statement = 'DROP EXTENSION IF EXISTS vector', parameters = {}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x7129966d5130>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.InternalError: (psycopg2.errors.DependentObjectsStillExist) cannot drop extension vector because other objects depend on it
E       DETAIL:  column embedding of table test_chunks_real depends on type vector
E       HINT:  Use DROP ... CASCADE to drop the dependent objects too.
E       
E       [SQL: DROP EXTENSION IF EXISTS vector]
E       (Background on this error at: https://sqlalche.me/e/20/2j85)

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: InternalError
----------------------------- Captured stderr call -----------------------------
INFO  [alembic.runtime.migration] Context impl PostgresqlImpl.
INFO  [alembic.runtime.migration] Will assume transactional DDL.
INFO  [alembic.runtime.migration] Running downgrade 001 -> , Initial schema with documents and chunks tables
_____________ TestAlembicMigrations.test_migration_creates_indexes _____________

self = <sqlalchemy.engine.base.Connection object at 0x712996653b60>
dialect = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x712996653bf0>
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x712996687b90>
statement = <sqlalchemy.dialects.postgresql.base.PGCompiler object at 0x712996686f30>
parameters = [{}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x712996653bf0>
cursor = <cursor object at 0x7129a6f8f880; closed: -1>
statement = 'DROP EXTENSION IF EXISTS vector', parameters = {}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x712996687b90>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       psycopg2.errors.DependentObjectsStillExist: cannot drop extension vector because other objects depend on it
E       DETAIL:  column embedding of table test_chunks_real depends on type vector
E       HINT:  Use DROP ... CASCADE to drop the dependent objects too.

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: DependentObjectsStillExist

The above exception was the direct cause of the following exception:

self = <tests.unit.database.test_migrations.TestAlembicMigrations object at 0x7129a9328e60>
alembic_config = <alembic.config.Config object at 0x712996652960>
test_db_url = 'postgresql://rag_user:rag_password@192.168.56.1:5432/rag_test'

    def test_migration_creates_indexes(self, alembic_config: Config, test_db_url: str) -> None:
        """Test that migrations create expected indexes."""
        # Start from clean state
>       command.downgrade(alembic_config, "base")

tests/unit/database/test_migrations.py:167: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
venv/lib/python3.12/site-packages/alembic/command.py:449: in downgrade
    script.run_env()
venv/lib/python3.12/site-packages/alembic/script/base.py:583: in run_env
    util.load_python_file(self.dir, "env.py")
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:95: in load_python_file
    module = load_module_py(module_id, path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:113: in load_module_py
    spec.loader.exec_module(module)  # type: ignore
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
<frozen importlib._bootstrap_external>:995: in exec_module
    ???
<frozen importlib._bootstrap>:488: in _call_with_frames_removed
    ???
migrations/env.py:93: in <module>
    run_migrations_online()
migrations/env.py:87: in run_migrations_online
    context.run_migrations()
<string>:8: in run_migrations
    ???
venv/lib/python3.12/site-packages/alembic/runtime/environment.py:948: in run_migrations
    self.get_context().run_migrations(**kw)
venv/lib/python3.12/site-packages/alembic/runtime/migration.py:627: in run_migrations
    step.migration_fn(**kw)
migrations/versions/001_initial_schema.py:129: in downgrade
    op.execute("DROP EXTENSION IF EXISTS vector")
<string>:8: in execute
    ???
<string>:3: in execute
    ???
venv/lib/python3.12/site-packages/alembic/operations/ops.py:2537: in execute
    return operations.invoke(op)
           ^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/base.py:445: in invoke
    return fn(self, operation)
           ^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/toimpl.py:224: in execute_sql
    operations.migration_context.impl.execute(
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:214: in execute
    self._exec(sql, execution_options)
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:207: in _exec
    return conn.execute(construct, multiparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1416: in execute
    return meth(
venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py:516: in _execute_on_connection
    return connection._execute_clauseelement(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1639: in _execute_clauseelement
    ret = self._execute_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1848: in _execute_context
    return self._exec_single_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1988: in _exec_single_context
    self._handle_dbapi_exception(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2343: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: in _exec_single_context
    self.dialect.do_execute(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x712996653bf0>
cursor = <cursor object at 0x7129a6f8f880; closed: -1>
statement = 'DROP EXTENSION IF EXISTS vector', parameters = {}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x712996687b90>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.InternalError: (psycopg2.errors.DependentObjectsStillExist) cannot drop extension vector because other objects depend on it
E       DETAIL:  column embedding of table test_chunks_real depends on type vector
E       HINT:  Use DROP ... CASCADE to drop the dependent objects too.
E       
E       [SQL: DROP EXTENSION IF EXISTS vector]
E       (Background on this error at: https://sqlalche.me/e/20/2j85)

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: InternalError
----------------------------- Captured stderr call -----------------------------
INFO  [alembic.runtime.migration] Context impl PostgresqlImpl.
INFO  [alembic.runtime.migration] Will assume transactional DDL.
INFO  [alembic.runtime.migration] Running downgrade 001 -> , Initial schema with documents and chunks tables
_________________ TestDocumentModel.test_document_persistence __________________

self = <sqlalchemy.engine.base.Connection object at 0x7129a6fbcbc0>
dialect = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7129a8973620>
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x712996652c00>
statement = <sqlalchemy.dialects.postgresql.base.PGCompiler object at 0x7129a6fbeb40>
parameters = [{'content_hash': 'abc123', 'created_at': datetime.datetime(2025, 12, 18, 3, 19, 35, 717615), 'document_id': UUID('1f6c89bd-7e1a-4d60-8da8-a0d1a38186a8'), 'filename': 'test.txt', ...}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7129a8973620>
cursor = <cursor object at 0x7129a6f8d030; closed: -1>
statement = 'INSERT INTO documents (document_id, filename, source_path, content_hash, total_chunks, metadata, status, created_at, ...name)s, %(source_path)s, %(content_hash)s, %(total_chunks)s, %(metadata)s, %(status)s, %(created_at)s, %(updated_at)s)'
parameters = {'content_hash': 'abc123', 'created_at': datetime.datetime(2025, 12, 18, 3, 19, 35, 717615), 'document_id': UUID('1f6c89bd-7e1a-4d60-8da8-a0d1a38186a8'), 'filename': 'test.txt', ...}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x712996652c00>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       psycopg2.errors.UndefinedTable: relation "documents" does not exist
E       LINE 1: INSERT INTO documents (document_id, filename, source_path, c...
E                           ^

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: UndefinedTable

The above exception was the direct cause of the following exception:

self = <tests.unit.database.test_models.TestDocumentModel object at 0x7129a9328350>
db_session = <sqlalchemy.orm.session.Session object at 0x7129a6fbda60>

    def test_document_persistence(self, db_session):
        """Test Document can be persisted to database."""
        doc = Document(
            filename="test.txt",
            source_path="/path/to/test.txt",
            content_hash="abc123",
            total_chunks=5
        )
    
        db_session.add(doc)
>       db_session.flush()

tests/unit/database/test_models.py:118: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py:4312: in flush
    self._flush(objects)
venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py:4447: in _flush
    with util.safe_reraise():
venv/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py:146: in __exit__
    raise exc_value.with_traceback(exc_tb)
venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py:4408: in _flush
    flush_context.execute()
venv/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py:466: in execute
    rec.execute(self)
venv/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py:642: in execute
    util.preloaded.orm_persistence.save_obj(
venv/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py:93: in save_obj
    _emit_insert_statements(
venv/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py:1226: in _emit_insert_statements
    result = connection.execute(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1416: in execute
    return meth(
venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py:516: in _execute_on_connection
    return connection._execute_clauseelement(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1639: in _execute_clauseelement
    ret = self._execute_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1848: in _execute_context
    return self._exec_single_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1988: in _exec_single_context
    self._handle_dbapi_exception(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2343: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: in _exec_single_context
    self.dialect.do_execute(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7129a8973620>
cursor = <cursor object at 0x7129a6f8d030; closed: -1>
statement = 'INSERT INTO documents (document_id, filename, source_path, content_hash, total_chunks, metadata, status, created_at, ...name)s, %(source_path)s, %(content_hash)s, %(total_chunks)s, %(metadata)s, %(status)s, %(created_at)s, %(updated_at)s)'
parameters = {'content_hash': 'abc123', 'created_at': datetime.datetime(2025, 12, 18, 3, 19, 35, 717615), 'document_id': UUID('1f6c89bd-7e1a-4d60-8da8-a0d1a38186a8'), 'filename': 'test.txt', ...}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x712996652c00>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "documents" does not exist
E       LINE 1: INSERT INTO documents (document_id, filename, source_path, c...
E                           ^
E       
E       [SQL: INSERT INTO documents (document_id, filename, source_path, content_hash, total_chunks, metadata, status, created_at, updated_at) VALUES (%(document_id)s::UUID, %(filename)s, %(source_path)s, %(content_hash)s, %(total_chunks)s, %(metadata)s, %(status)s, %(created_at)s, %(updated_at)s)]
E       [parameters: {'document_id': UUID('1f6c89bd-7e1a-4d60-8da8-a0d1a38186a8'), 'filename': 'test.txt', 'source_path': '/path/to/test.txt', 'content_hash': 'abc123', 'total_chunks': 5, 'metadata': '{}', 'status': 'pending', 'created_at': datetime.datetime(2025, 12, 18, 3, 19, 35, 717615), 'updated_at': datetime.datetime(2025, 12, 18, 3, 19, 35, 717628)}]
E       (Background on this error at: https://sqlalche.me/e/20/f405)

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: ProgrammingError
____________________ TestChunkModel.test_chunk_persistence _____________________

self = <sqlalchemy.engine.base.Connection object at 0x7129a72d29c0>
dialect = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7129a8973620>
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x7129a6f664b0>
statement = <sqlalchemy.dialects.postgresql.base.PGCompiler object at 0x7129a72d22d0>
parameters = [{'content_hash': 'abc', 'created_at': datetime.datetime(2025, 12, 18, 3, 19, 37, 924537), 'document_id': UUID('c7496e78-ea78-495c-abe6-654acf6bc559'), 'filename': 'test.txt', ...}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7129a8973620>
cursor = <cursor object at 0x712996673f10; closed: -1>
statement = 'INSERT INTO documents (document_id, filename, source_path, content_hash, total_chunks, metadata, status, created_at, ...name)s, %(source_path)s, %(content_hash)s, %(total_chunks)s, %(metadata)s, %(status)s, %(created_at)s, %(updated_at)s)'
parameters = {'content_hash': 'abc', 'created_at': datetime.datetime(2025, 12, 18, 3, 19, 37, 924537), 'document_id': UUID('c7496e78-ea78-495c-abe6-654acf6bc559'), 'filename': 'test.txt', ...}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x7129a6f664b0>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       psycopg2.errors.UndefinedTable: relation "documents" does not exist
E       LINE 1: INSERT INTO documents (document_id, filename, source_path, c...
E                           ^

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: UndefinedTable

The above exception was the direct cause of the following exception:

self = <tests.unit.database.test_models.TestChunkModel object at 0x7129a932b410>
db_session = <sqlalchemy.orm.session.Session object at 0x7129a95b4920>

    def test_chunk_persistence(self, db_session):
        """Test Chunk can be persisted to database."""
        # First create a document
        doc = Document(
            filename="test.txt",
            source_path="/path/test.txt",
            content_hash="abc"
        )
        db_session.add(doc)
>       db_session.flush()

tests/unit/database/test_models.py:246: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py:4312: in flush
    self._flush(objects)
venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py:4447: in _flush
    with util.safe_reraise():
venv/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py:146: in __exit__
    raise exc_value.with_traceback(exc_tb)
venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py:4408: in _flush
    flush_context.execute()
venv/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py:466: in execute
    rec.execute(self)
venv/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py:642: in execute
    util.preloaded.orm_persistence.save_obj(
venv/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py:93: in save_obj
    _emit_insert_statements(
venv/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py:1226: in _emit_insert_statements
    result = connection.execute(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1416: in execute
    return meth(
venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py:516: in _execute_on_connection
    return connection._execute_clauseelement(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1639: in _execute_clauseelement
    ret = self._execute_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1848: in _execute_context
    return self._exec_single_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1988: in _exec_single_context
    self._handle_dbapi_exception(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2343: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: in _exec_single_context
    self.dialect.do_execute(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7129a8973620>
cursor = <cursor object at 0x712996673f10; closed: -1>
statement = 'INSERT INTO documents (document_id, filename, source_path, content_hash, total_chunks, metadata, status, created_at, ...name)s, %(source_path)s, %(content_hash)s, %(total_chunks)s, %(metadata)s, %(status)s, %(created_at)s, %(updated_at)s)'
parameters = {'content_hash': 'abc', 'created_at': datetime.datetime(2025, 12, 18, 3, 19, 37, 924537), 'document_id': UUID('c7496e78-ea78-495c-abe6-654acf6bc559'), 'filename': 'test.txt', ...}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x7129a6f664b0>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "documents" does not exist
E       LINE 1: INSERT INTO documents (document_id, filename, source_path, c...
E                           ^
E       
E       [SQL: INSERT INTO documents (document_id, filename, source_path, content_hash, total_chunks, metadata, status, created_at, updated_at) VALUES (%(document_id)s::UUID, %(filename)s, %(source_path)s, %(content_hash)s, %(total_chunks)s, %(metadata)s, %(status)s, %(created_at)s, %(updated_at)s)]
E       [parameters: {'document_id': UUID('c7496e78-ea78-495c-abe6-654acf6bc559'), 'filename': 'test.txt', 'source_path': '/path/test.txt', 'content_hash': 'abc', 'total_chunks': 0, 'metadata': '{}', 'status': 'pending', 'created_at': datetime.datetime(2025, 12, 18, 3, 19, 37, 924537), 'updated_at': datetime.datetime(2025, 12, 18, 3, 19, 37, 924559)}]
E       (Background on this error at: https://sqlalche.me/e/20/f405)

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: ProgrammingError
___________ TestModelRelationships.test_document_chunks_relationship ___________

self = <sqlalchemy.engine.base.Connection object at 0x7129a6f64080>
dialect = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7129a8973620>
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x7129a6f67c20>
statement = <sqlalchemy.dialects.postgresql.base.PGCompiler object at 0x7129a72d22d0>
parameters = [{'content_hash': 'abc', 'created_at': datetime.datetime(2025, 12, 18, 3, 19, 39, 590272), 'document_id': UUID('e532a885-ea2f-45ed-9c91-3ab6ed037503'), 'filename': 'test.txt', ...}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7129a8973620>
cursor = <cursor object at 0x712996671e40; closed: -1>
statement = 'INSERT INTO documents (document_id, filename, source_path, content_hash, total_chunks, metadata, status, created_at, ...name)s, %(source_path)s, %(content_hash)s, %(total_chunks)s, %(metadata)s, %(status)s, %(created_at)s, %(updated_at)s)'
parameters = {'content_hash': 'abc', 'created_at': datetime.datetime(2025, 12, 18, 3, 19, 39, 590272), 'document_id': UUID('e532a885-ea2f-45ed-9c91-3ab6ed037503'), 'filename': 'test.txt', ...}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x7129a6f67c20>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       psycopg2.errors.UndefinedTable: relation "documents" does not exist
E       LINE 1: INSERT INTO documents (document_id, filename, source_path, c...
E                           ^

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: UndefinedTable

The above exception was the direct cause of the following exception:

self = <tests.unit.database.test_models.TestModelRelationships object at 0x7129a932bb00>
db_session = <sqlalchemy.orm.session.Session object at 0x7129a6f64dd0>

    def test_document_chunks_relationship(self, db_session):
        """Test Document.chunks relationship."""
        # Create document
        doc = Document(
            filename="test.txt",
            source_path="/path/test.txt",
            content_hash="abc"
        )
        db_session.add(doc)
>       db_session.flush()

tests/unit/database/test_models.py:294: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py:4312: in flush
    self._flush(objects)
venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py:4447: in _flush
    with util.safe_reraise():
venv/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py:146: in __exit__
    raise exc_value.with_traceback(exc_tb)
venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py:4408: in _flush
    flush_context.execute()
venv/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py:466: in execute
    rec.execute(self)
venv/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py:642: in execute
    util.preloaded.orm_persistence.save_obj(
venv/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py:93: in save_obj
    _emit_insert_statements(
venv/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py:1226: in _emit_insert_statements
    result = connection.execute(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1416: in execute
    return meth(
venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py:516: in _execute_on_connection
    return connection._execute_clauseelement(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1639: in _execute_clauseelement
    ret = self._execute_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1848: in _execute_context
    return self._exec_single_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1988: in _exec_single_context
    self._handle_dbapi_exception(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2343: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: in _exec_single_context
    self.dialect.do_execute(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7129a8973620>
cursor = <cursor object at 0x712996671e40; closed: -1>
statement = 'INSERT INTO documents (document_id, filename, source_path, content_hash, total_chunks, metadata, status, created_at, ...name)s, %(source_path)s, %(content_hash)s, %(total_chunks)s, %(metadata)s, %(status)s, %(created_at)s, %(updated_at)s)'
parameters = {'content_hash': 'abc', 'created_at': datetime.datetime(2025, 12, 18, 3, 19, 39, 590272), 'document_id': UUID('e532a885-ea2f-45ed-9c91-3ab6ed037503'), 'filename': 'test.txt', ...}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x7129a6f67c20>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "documents" does not exist
E       LINE 1: INSERT INTO documents (document_id, filename, source_path, c...
E                           ^
E       
E       [SQL: INSERT INTO documents (document_id, filename, source_path, content_hash, total_chunks, metadata, status, created_at, updated_at) VALUES (%(document_id)s::UUID, %(filename)s, %(source_path)s, %(content_hash)s, %(total_chunks)s, %(metadata)s, %(status)s, %(created_at)s, %(updated_at)s)]
E       [parameters: {'document_id': UUID('e532a885-ea2f-45ed-9c91-3ab6ed037503'), 'filename': 'test.txt', 'source_path': '/path/test.txt', 'content_hash': 'abc', 'total_chunks': 0, 'metadata': '{}', 'status': 'pending', 'created_at': datetime.datetime(2025, 12, 18, 3, 19, 39, 590272), 'updated_at': datetime.datetime(2025, 12, 18, 3, 19, 39, 590282)}]
E       (Background on this error at: https://sqlalche.me/e/20/f405)

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: ProgrammingError
___________ TestModelRelationships.test_chunk_document_relationship ____________

self = <sqlalchemy.engine.base.Connection object at 0x7129a6f67d40>
dialect = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7129a8973620>
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x7129a932b4d0>
statement = <sqlalchemy.dialects.postgresql.base.PGCompiler object at 0x7129a72d22d0>
parameters = [{'content_hash': 'abc', 'created_at': datetime.datetime(2025, 12, 18, 3, 19, 41, 816674), 'document_id': UUID('0974be98-1735-43d3-a2a8-ef68f28b0d70'), 'filename': 'test.txt', ...}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7129a8973620>
cursor = <cursor object at 0x7129966726b0; closed: -1>
statement = 'INSERT INTO documents (document_id, filename, source_path, content_hash, total_chunks, metadata, status, created_at, ...name)s, %(source_path)s, %(content_hash)s, %(total_chunks)s, %(metadata)s, %(status)s, %(created_at)s, %(updated_at)s)'
parameters = {'content_hash': 'abc', 'created_at': datetime.datetime(2025, 12, 18, 3, 19, 41, 816674), 'document_id': UUID('0974be98-1735-43d3-a2a8-ef68f28b0d70'), 'filename': 'test.txt', ...}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x7129a932b4d0>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       psycopg2.errors.UndefinedTable: relation "documents" does not exist
E       LINE 1: INSERT INTO documents (document_id, filename, source_path, c...
E                           ^

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: UndefinedTable

The above exception was the direct cause of the following exception:

self = <tests.unit.database.test_models.TestModelRelationships object at 0x7129a932bf80>
db_session = <sqlalchemy.orm.session.Session object at 0x7129a6f66360>

    def test_chunk_document_relationship(self, db_session):
        """Test Chunk.document relationship."""
        # Create document
        doc = Document(
            filename="test.txt",
            source_path="/path/test.txt",
            content_hash="abc"
        )
        db_session.add(doc)
>       db_session.flush()

tests/unit/database/test_models.py:323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py:4312: in flush
    self._flush(objects)
venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py:4447: in _flush
    with util.safe_reraise():
venv/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py:146: in __exit__
    raise exc_value.with_traceback(exc_tb)
venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py:4408: in _flush
    flush_context.execute()
venv/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py:466: in execute
    rec.execute(self)
venv/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py:642: in execute
    util.preloaded.orm_persistence.save_obj(
venv/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py:93: in save_obj
    _emit_insert_statements(
venv/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py:1226: in _emit_insert_statements
    result = connection.execute(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1416: in execute
    return meth(
venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py:516: in _execute_on_connection
    return connection._execute_clauseelement(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1639: in _execute_clauseelement
    ret = self._execute_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1848: in _execute_context
    return self._exec_single_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1988: in _exec_single_context
    self._handle_dbapi_exception(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2343: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: in _exec_single_context
    self.dialect.do_execute(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7129a8973620>
cursor = <cursor object at 0x7129966726b0; closed: -1>
statement = 'INSERT INTO documents (document_id, filename, source_path, content_hash, total_chunks, metadata, status, created_at, ...name)s, %(source_path)s, %(content_hash)s, %(total_chunks)s, %(metadata)s, %(status)s, %(created_at)s, %(updated_at)s)'
parameters = {'content_hash': 'abc', 'created_at': datetime.datetime(2025, 12, 18, 3, 19, 41, 816674), 'document_id': UUID('0974be98-1735-43d3-a2a8-ef68f28b0d70'), 'filename': 'test.txt', ...}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x7129a932b4d0>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "documents" does not exist
E       LINE 1: INSERT INTO documents (document_id, filename, source_path, c...
E                           ^
E       
E       [SQL: INSERT INTO documents (document_id, filename, source_path, content_hash, total_chunks, metadata, status, created_at, updated_at) VALUES (%(document_id)s::UUID, %(filename)s, %(source_path)s, %(content_hash)s, %(total_chunks)s, %(metadata)s, %(status)s, %(created_at)s, %(updated_at)s)]
E       [parameters: {'document_id': UUID('0974be98-1735-43d3-a2a8-ef68f28b0d70'), 'filename': 'test.txt', 'source_path': '/path/test.txt', 'content_hash': 'abc', 'total_chunks': 0, 'metadata': '{}', 'status': 'pending', 'created_at': datetime.datetime(2025, 12, 18, 3, 19, 41, 816674), 'updated_at': datetime.datetime(2025, 12, 18, 3, 19, 41, 816844)}]
E       (Background on this error at: https://sqlalche.me/e/20/f405)

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: ProgrammingError
__________________ TestModelRelationships.test_cascade_delete __________________

self = <sqlalchemy.engine.base.Connection object at 0x7129a6fa9e20>
dialect = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7129a8973620>
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x7129a6fab740>
statement = <sqlalchemy.dialects.postgresql.base.PGCompiler object at 0x7129a72d22d0>
parameters = [{'content_hash': 'abc', 'created_at': datetime.datetime(2025, 12, 18, 3, 19, 44, 58033), 'document_id': UUID('8ae0df36-d946-4427-9fe5-2fd9b24de39d'), 'filename': 'test.txt', ...}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7129a8973620>
cursor = <cursor object at 0x7129a727f6a0; closed: -1>
statement = 'INSERT INTO documents (document_id, filename, source_path, content_hash, total_chunks, metadata, status, created_at, ...name)s, %(source_path)s, %(content_hash)s, %(total_chunks)s, %(metadata)s, %(status)s, %(created_at)s, %(updated_at)s)'
parameters = {'content_hash': 'abc', 'created_at': datetime.datetime(2025, 12, 18, 3, 19, 44, 58033), 'document_id': UUID('8ae0df36-d946-4427-9fe5-2fd9b24de39d'), 'filename': 'test.txt', ...}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x7129a6fab740>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       psycopg2.errors.UndefinedTable: relation "documents" does not exist
E       LINE 1: INSERT INTO documents (document_id, filename, source_path, c...
E                           ^

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: UndefinedTable

The above exception was the direct cause of the following exception:

self = <tests.unit.database.test_models.TestModelRelationships object at 0x7129a932be30>
db_session = <sqlalchemy.orm.session.Session object at 0x7129a6fab860>

    def test_cascade_delete(self, db_session):
        """Test cascade delete removes chunks when document is deleted."""
        # Create document
        doc = Document(
            filename="test.txt",
            source_path="/path/test.txt",
            content_hash="abc"
        )
        db_session.add(doc)
>       db_session.flush()

tests/unit/database/test_models.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py:4312: in flush
    self._flush(objects)
venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py:4447: in _flush
    with util.safe_reraise():
venv/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py:146: in __exit__
    raise exc_value.with_traceback(exc_tb)
venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py:4408: in _flush
    flush_context.execute()
venv/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py:466: in execute
    rec.execute(self)
venv/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py:642: in execute
    util.preloaded.orm_persistence.save_obj(
venv/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py:93: in save_obj
    _emit_insert_statements(
venv/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py:1226: in _emit_insert_statements
    result = connection.execute(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1416: in execute
    return meth(
venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py:516: in _execute_on_connection
    return connection._execute_clauseelement(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1639: in _execute_clauseelement
    ret = self._execute_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1848: in _execute_context
    return self._exec_single_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1988: in _exec_single_context
    self._handle_dbapi_exception(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2343: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: in _exec_single_context
    self.dialect.do_execute(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7129a8973620>
cursor = <cursor object at 0x7129a727f6a0; closed: -1>
statement = 'INSERT INTO documents (document_id, filename, source_path, content_hash, total_chunks, metadata, status, created_at, ...name)s, %(source_path)s, %(content_hash)s, %(total_chunks)s, %(metadata)s, %(status)s, %(created_at)s, %(updated_at)s)'
parameters = {'content_hash': 'abc', 'created_at': datetime.datetime(2025, 12, 18, 3, 19, 44, 58033), 'document_id': UUID('8ae0df36-d946-4427-9fe5-2fd9b24de39d'), 'filename': 'test.txt', ...}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x7129a6fab740>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "documents" does not exist
E       LINE 1: INSERT INTO documents (document_id, filename, source_path, c...
E                           ^
E       
E       [SQL: INSERT INTO documents (document_id, filename, source_path, content_hash, total_chunks, metadata, status, created_at, updated_at) VALUES (%(document_id)s::UUID, %(filename)s, %(source_path)s, %(content_hash)s, %(total_chunks)s, %(metadata)s, %(status)s, %(created_at)s, %(updated_at)s)]
E       [parameters: {'document_id': UUID('8ae0df36-d946-4427-9fe5-2fd9b24de39d'), 'filename': 'test.txt', 'source_path': '/path/test.txt', 'content_hash': 'abc', 'total_chunks': 0, 'metadata': '{}', 'status': 'pending', 'created_at': datetime.datetime(2025, 12, 18, 3, 19, 44, 58033), 'updated_at': datetime.datetime(2025, 12, 18, 3, 19, 44, 58044)}]
E       (Background on this error at: https://sqlalche.me/e/20/f405)

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: ProgrammingError
____________ TestPgVectorIntegration.test_cosine_similarity_search _____________

self = <tests.unit.database.test_pgvector.TestPgVectorIntegration object at 0x7129a934c260>
mock_pool = (<MagicMock id='124423430815616'>, <AsyncMock name='mock.acquire().__aenter__()' id='124423747673824'>)

    @pytest.mark.asyncio
    async def test_cosine_similarity_search(self, mock_pool):
        """Test vector similarity search using cosine distance."""
        pool, conn = mock_pool
    
        with patch('rag_factory.services.database.postgres.ASYNCPG_AVAILABLE', True):
            service = PostgresqlDatabaseService(
                host="localhost",
                password="test"
            )
            service._pool = pool
    
            # Mock search results
            conn.fetch.return_value = [
                {
                    "chunk_id": "doc_0",
                    "text": "test 0",
                    "metadata": None,
                    "similarity": 0.95
                },
                {
                    "chunk_id": "doc_1",
                    "text": "test 1",
                    "metadata": None,
                    "similarity": 0.85
                }
            ]
    
            query_vec = [1.0, 0.0, 0.0]
            results = await service.search_chunks(query_vec, top_k=2)
    
            assert len(results) == 2
>           assert results[0]['chunk_id'] == 'doc_0'
                   ^^^^^^^^^^^^^^^^^^^^^^
E           TypeError: 'Chunk' object is not subscriptable

tests/unit/database/test_pgvector.py:56: TypeError
__________ TestCodeExamples.test_all_code_examples_have_valid_syntax ___________

self = <test_code_examples.TestCodeExamples object at 0x7129a932b2c0>
docs_root = PosixPath('/mnt/MCPProyects/ragTools/docs')

    def test_all_code_examples_have_valid_syntax(self, docs_root):
        """Test that all Python code examples have valid syntax."""
        errors = []
    
        for md_file in docs_root.rglob("*.md"):
            # Skip project planning documents (epics, stories, verification docs)
            # and internal/migration documentation
            file_str = str(md_file).lower()
            skip_patterns = ['epic', 'stor', 'verification', 'completion-summary',
                           'onnx', 'migration', 'project-plan', 'readme']
            if any(skip in file_str for skip in skip_patterns):
                continue
    
            examples = self.extract_python_examples(md_file)
    
            for i, code in enumerate(examples):
                try:
                    # Try to compile the code
                    compile(code, f"{md_file.name}:example_{i}", "exec")
                except SyntaxError as e:
                    errors.append(f"{md_file.name}:example_{i}: {e}")
    
>       assert len(errors) == 0, \
            f"Syntax errors in code examples:\n" + "\n".join(errors)
E       AssertionError: Syntax errors in code examples:
E         semantic-local-pair-guide.md:example_0: 'await' outside function (semantic-local-pair-guide.md:example_0, line 21)
E         environment-variables.md:example_3: invalid syntax (environment-variables.md:example_3, line 13)
E         QUICK-REFERENCE.md:example_2: unexpected indent (QUICK-REFERENCE.md:example_2, line 1)
E       assert 3 == 0
E        +  where 3 = len(["semantic-local-pair-guide.md:example_0: 'await' outside function (semantic-local-pair-guide.md:example_0, line 21)", 'environment-variables.md:example_3: invalid syntax (environment-variables.md:example_3, line 13)', 'QUICK-REFERENCE.md:example_2: unexpected indent (QUICK-REFERENCE.md:example_2, line 1)'])

tests/unit/documentation/test_code_examples.py:57: AssertionError
_____________ TestDocumentationLinks.test_no_broken_internal_links _____________

self = <test_links.TestDocumentationLinks object at 0x7129a934ca70>
docs_root = PosixPath('/mnt/MCPProyects/ragTools/docs')

    def test_no_broken_internal_links(self, docs_root):
        """Test that all internal links are valid."""
        broken_links = []
    
        for md_file in docs_root.rglob("*.md"):
            links = self.extract_links(md_file)
    
            for text, link in links:
                # Skip external links
                if link.startswith("http"):
                    continue
    
                # Skip anchors
                if link.startswith("#"):
                    continue
    
                # Skip file:// links (used in implementation plan)
                if link.startswith("file://"):
                    continue
    
                # Resolve relative path
                target = (md_file.parent / link).resolve()
    
                if not target.exists():
                    broken_links.append(f"{md_file.name} -> {link}")
    
>       assert len(broken_links) == 0, \
            f"Broken internal links:\n" + "\n".join(broken_links)
E       AssertionError: Broken internal links:
E         MIGRATION_MANAGER_REMOVAL.md -> ../stories/epic-16/story-16.5-remove-migration-manager.md
E         README.md -> ./story-17.1-service-registry-configuration-schema.md
E         README.md -> ./story-17.2-service-registry-implementation.md
E         README.md -> ./story-17.4-migration-validator-alembic.md
E         README.md -> ./story-17.6-first-strategy-pair-testing.md
E         README.md -> ./story-17.7-remaining-strategy-pairs.md
E         README.md -> ./story-17.8-cli-validation-sample-docs.md
E         README.md -> ../../epics/epic-16-database-consolidation.md
E         README.md -> ../../epics/epic-16-database-consolidation.md
E         README.md -> ../../database/README.md
E         README.md -> ../../getting-started/installation.md
E       assert 11 == 0
E        +  where 11 = len(['MIGRATION_MANAGER_REMOVAL.md -> ../stories/epic-16/story-16.5-remove-migration-manager.md', 'README.md -> ./story-17.1-service-registry-configuration-schema.md', 'README.md -> ./story-17.2-service-registry-implementation.md', 'README.md -> ./story-17.4-migration-validator-alembic.md', 'README.md -> ./story-17.6-first-strategy-pair-testing.md', 'README.md -> ./story-17.7-remaining-strategy-pairs.md', ...])

tests/unit/documentation/test_links.py:60: AssertionError
____________ TestLLMServiceCreation.test_create_llm_service_openai _____________

self = <tests.unit.registry.test_service_factory.TestLLMServiceCreation object at 0x7129a92ca7b0>
factory = <rag_factory.registry.service_factory.ServiceFactory object at 0x7129966ea4e0>

    def test_create_llm_service_openai(self, factory):
        """Test creating OpenAI LLM service."""
        config = {
            "name": "openai-llm",
            "url": "https://api.openai.com/v1",
            "api_key": "sk-test",
            "model": "gpt-4",
            "temperature": 0.8,
            "max_tokens": 2000
        }
    
>       with patch('rag_factory.registry.service_factory.OpenAILLMService') as mock_class:

tests/unit/registry/test_service_factory.py:73: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.12/unittest/mock.py:1458: in __enter__
    original, local = self.get_original()
                      ^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x7129966ea2a0>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'rag_factory.registry.service_factory' from '/mnt/MCPProyects/ragTools/rag_factory/registry/service_factory.py'> does not have the attribute 'OpenAILLMService'

/usr/lib/python3.12/unittest/mock.py:1431: AttributeError
_______ TestEmbeddingServiceCreation.test_create_embedding_service_onnx ________

self = <tests.unit.registry.test_service_factory.TestEmbeddingServiceCreation object at 0x7129a92c9730>
factory = <rag_factory.registry.service_factory.ServiceFactory object at 0x7129966e8b90>

    def test_create_embedding_service_onnx(self, factory):
        """Test creating ONNX embedding service."""
        config = {
            "name": "onnx-embed",
            "provider": "onnx",
            "model": "Xenova/all-MiniLM-L6-v2",
            "cache_dir": "./models",
            "batch_size": 32
        }
    
>       with patch('rag_factory.registry.service_factory.ONNXEmbeddingService') as mock_class:

tests/unit/registry/test_service_factory.py:128: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.12/unittest/mock.py:1458: in __enter__
    original, local = self.get_original()
                      ^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x7129966ea9f0>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'rag_factory.registry.service_factory' from '/mnt/MCPProyects/ragTools/rag_factory/registry/service_factory.py'> does not have the attribute 'ONNXEmbeddingService'

/usr/lib/python3.12/unittest/mock.py:1431: AttributeError
_ TestEmbeddingServiceCreation.test_create_embedding_service_onnx_with_defaults _

self = <tests.unit.registry.test_service_factory.TestEmbeddingServiceCreation object at 0x7129a92cac90>
factory = <rag_factory.registry.service_factory.ServiceFactory object at 0x7129967da150>

    def test_create_embedding_service_onnx_with_defaults(self, factory):
        """Test creating ONNX embedding service with defaults."""
        config = {
            "provider": "onnx",
            "model": "Xenova/all-MiniLM-L6-v2"
        }
    
>       with patch('rag_factory.registry.service_factory.ONNXEmbeddingService') as mock_class:

tests/unit/registry/test_service_factory.py:148: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.12/unittest/mock.py:1458: in __enter__
    original, local = self.get_original()
                      ^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x7129a6fbe600>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'rag_factory.registry.service_factory' from '/mnt/MCPProyects/ragTools/rag_factory/registry/service_factory.py'> does not have the attribute 'ONNXEmbeddingService'

/usr/lib/python3.12/unittest/mock.py:1431: AttributeError
______ TestEmbeddingServiceCreation.test_create_embedding_service_openai _______

self = <tests.unit.registry.test_service_factory.TestEmbeddingServiceCreation object at 0x7129a92ca990>
factory = <rag_factory.registry.service_factory.ServiceFactory object at 0x7129a6f66b40>

    def test_create_embedding_service_openai(self, factory):
        """Test creating OpenAI embedding service."""
        config = {
            "provider": "openai",
            "api_key": "sk-test",
            "model": "text-embedding-ada-002"
        }
    
>       with patch('rag_factory.registry.service_factory.OpenAIEmbeddingService') as mock_class:

tests/unit/registry/test_service_factory.py:167: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.12/unittest/mock.py:1458: in __enter__
    original, local = self.get_original()
                      ^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x7129a6f667e0>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'rag_factory.registry.service_factory' from '/mnt/MCPProyects/ragTools/rag_factory/registry/service_factory.py'> does not have the attribute 'OpenAIEmbeddingService'

/usr/lib/python3.12/unittest/mock.py:1431: AttributeError
_ TestDatabaseServiceCreation.test_create_database_service_postgres_with_connection_string _

self = <tests.unit.registry.test_service_factory.TestDatabaseServiceCreation object at 0x7129a92c8290>
factory = <rag_factory.registry.service_factory.ServiceFactory object at 0x7129a4cbda00>

    def test_create_database_service_postgres_with_connection_string(self, factory):
        """Test creating PostgreSQL database service with connection string."""
        config = {
            "name": "postgres-db",
            "type": "postgres",
            "connection_string": "postgresql://user:pass@localhost:5432/db",
            "pool_size": 10,
            "max_overflow": 20
        }
    
>       with patch('rag_factory.registry.service_factory.PostgresqlDatabaseService') as mock_class:

tests/unit/registry/test_service_factory.py:218: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.12/unittest/mock.py:1458: in __enter__
    original, local = self.get_original()
                      ^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x7129a6f65790>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'rag_factory.registry.service_factory' from '/mnt/MCPProyects/ragTools/rag_factory/registry/service_factory.py'> does not have the attribute 'PostgresqlDatabaseService'

/usr/lib/python3.12/unittest/mock.py:1431: AttributeError
_ TestDatabaseServiceCreation.test_create_database_service_postgres_with_components _

self = <tests.unit.registry.test_service_factory.TestDatabaseServiceCreation object at 0x7129a92c8710>
factory = <rag_factory.registry.service_factory.ServiceFactory object at 0x7129a4cbc200>

    def test_create_database_service_postgres_with_components(self, factory):
        """Test creating PostgreSQL database service with connection components."""
        config = {
            "type": "postgres",
            "user": "testuser",
            "password": "testpass",
            "host": "localhost",
            "port": 5432,
            "database": "testdb",
            "pool_size": 5
        }
    
>       with patch('rag_factory.registry.service_factory.PostgresqlDatabaseService') as mock_class:

tests/unit/registry/test_service_factory.py:243: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.12/unittest/mock.py:1458: in __enter__
    original, local = self.get_original()
                      ^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x7129a6f64b90>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'rag_factory.registry.service_factory' from '/mnt/MCPProyects/ragTools/rag_factory/registry/service_factory.py'> does not have the attribute 'PostgresqlDatabaseService'

/usr/lib/python3.12/unittest/mock.py:1431: AttributeError
_ TestDatabaseServiceCreation.test_create_database_service_postgres_with_defaults _

self = <tests.unit.registry.test_service_factory.TestDatabaseServiceCreation object at 0x7129a92cb200>
factory = <rag_factory.registry.service_factory.ServiceFactory object at 0x7129a72dadb0>

    def test_create_database_service_postgres_with_defaults(self, factory):
        """Test creating PostgreSQL database service with default values."""
        config = {
            "type": "postgres",
            "user": "testuser",
            "password": "testpass",
            "host": "localhost",
            "database": "testdb"
        }
    
>       with patch('rag_factory.registry.service_factory.PostgresqlDatabaseService') as mock_class:

tests/unit/registry/test_service_factory.py:264: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.12/unittest/mock.py:1458: in __enter__
    original, local = self.get_original()
                      ^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x7129a72daf90>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'rag_factory.registry.service_factory' from '/mnt/MCPProyects/ragTools/rag_factory/registry/service_factory.py'> does not have the attribute 'PostgresqlDatabaseService'

/usr/lib/python3.12/unittest/mock.py:1431: AttributeError
________ TestDatabaseServiceCreation.test_create_database_service_neo4j ________

self = <tests.unit.registry.test_service_factory.TestDatabaseServiceCreation object at 0x7129a92cb530>
factory = <rag_factory.registry.service_factory.ServiceFactory object at 0x7129a72dac30>

    def test_create_database_service_neo4j(self, factory):
        """Test creating Neo4j database service."""
        config = {
            "type": "neo4j",
            "uri": "bolt://localhost:7687",
            "user": "neo4j",
            "password": "testpass"
        }
    
>       with patch('rag_factory.registry.service_factory.Neo4jGraphService') as mock_class:

tests/unit/registry/test_service_factory.py:287: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.12/unittest/mock.py:1458: in __enter__
    original, local = self.get_original()
                      ^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x7129a72d8e60>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'rag_factory.registry.service_factory' from '/mnt/MCPProyects/ragTools/rag_factory/registry/service_factory.py'> does not have the attribute 'Neo4jGraphService'

/usr/lib/python3.12/unittest/mock.py:1431: AttributeError
_ TestDatabaseServiceCreation.test_create_database_service_neo4j_with_defaults _

self = <tests.unit.registry.test_service_factory.TestDatabaseServiceCreation object at 0x7129a92cb860>
factory = <rag_factory.registry.service_factory.ServiceFactory object at 0x7129a4cbd220>

    def test_create_database_service_neo4j_with_defaults(self, factory):
        """Test creating Neo4j database service with default URI."""
        config = {
            "type": "neo4j",
            "host": "localhost",
            "port": 7687,
            "user": "neo4j",
            "password": "testpass"
        }
    
>       with patch('rag_factory.registry.service_factory.Neo4jGraphService') as mock_class:

tests/unit/registry/test_service_factory.py:310: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.12/unittest/mock.py:1458: in __enter__
    original, local = self.get_original()
                      ^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x7129a4cbfa40>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'rag_factory.registry.service_factory' from '/mnt/MCPProyects/ragTools/rag_factory/registry/service_factory.py'> does not have the attribute 'Neo4jGraphService'

/usr/lib/python3.12/unittest/mock.py:1431: AttributeError
_________________________ test_calculate_cost_is_zero __________________________

onnx_config = {'max_batch_size': 32, 'model': 'Xenova/all-MiniLM-L6-v2'}
mock_onnx_env = <function create_mock_onnx_environment at 0x7129be179760>

    def test_calculate_cost_is_zero(onnx_config, mock_onnx_env):
        """Test that local ONNX provider has zero cost.
    
        Uses centralized mock_onnx_env to handle all ONNX mocking.
        """
        with mock_onnx_env(dimension=384):
            from rag_factory.services.embedding.providers.onnx_local import ONNXLocalProvider
    
            provider = ONNXLocalProvider(onnx_config)
>           cost = provider.calculate_cost(num_texts=100)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E           TypeError: ONNXLocalProvider.calculate_cost() got an unexpected keyword argument 'num_texts'

tests/unit/services/embedding/test_onnx_local_provider.py:78: TypeError
______________________________ test_store_chunks _______________________________

service = <rag_factory.services.database.postgres.PostgresqlDatabaseService object at 0x71299666faa0>
mock_pool = (<AsyncMock id='124423430926992'>, <AsyncMock id='124423710566368'>)

    @pytest.mark.asyncio
    async def test_store_chunks(service, mock_pool):
        """Test storing chunks."""
        pool, conn = mock_pool
    
        chunks = [
            {
                "chunk_id": "1",
                "text": "Hello",
                "embedding": [0.1, 0.2, 0.3],
                "metadata": {"source": "doc1"}
            }
        ]
    
        await service.store_chunks(chunks)
    
        conn.execute.assert_called()
        call_args = conn.execute.call_args
        assert "INSERT INTO chunks" in call_args[0][0]
        assert call_args[0][1] == "1"
        assert call_args[0][2] == "Hello"
>       assert call_args[0][3] == "[0.1,0.2,0.3]"
E       assert '{"source": "doc1"}' == '[0.1,0.2,0.3]'
E         
E         - [0.1,0.2,0.3]
E         + {"source": "doc1"}

tests/unit/services/test_database_service.py:107: AssertionError
______________________________ test_search_chunks ______________________________

service = <rag_factory.services.database.postgres.PostgresqlDatabaseService object at 0x7129a4c80680>
mock_pool = (<AsyncMock id='124423672178656'>, <AsyncMock id='124423710567136'>)

    @pytest.mark.asyncio
    async def test_search_chunks(service, mock_pool):
        """Test searching chunks."""
        pool, conn = mock_pool
    
        # Mock search results
        conn.fetch.return_value = [
            {
                "chunk_id": "1",
                "text": "Hello",
                "metadata": '{"source": "doc1"}',
                "similarity": 0.95
            }
        ]
    
        results = await service.search_chunks([0.1, 0.2, 0.3], top_k=5)
    
        assert len(results) == 1
>       assert results[0]["chunk_id"] == "1"
               ^^^^^^^^^^^^^^^^^^^^^^
E       TypeError: 'Chunk' object is not subscriptable

tests/unit/services/test_database_service.py:135: TypeError
______________________________ test_budget_alert _______________________________

cost_tracker = <rag_factory.strategies.contextual.cost_tracker.CostTracker object at 0x7129a6f5f950>
caplog = <_pytest.logging.LogCaptureFixture object at 0x7129a6f5c470>

    def test_budget_alert(cost_tracker, caplog):
        """Test budget alert threshold."""
        import logging
        caplog.set_level(logging.WARNING)
    
        # Exceed budget threshold
        for i in range(100):
            cost_tracker.record_chunk_cost(
                chunk_id=f"chunk_{i}",
                input_tokens=1000,
                output_tokens=200,
                cost=0.02  # High cost
            )
    
        # Should trigger alert
>       assert "Cost alert" in caplog.text
E       AssertionError: assert 'Cost alert' in ''
E        +  where '' = <_pytest.logging.LogCaptureFixture object at 0x7129a6f5c470>.text

tests/unit/strategies/contextual/test_cost_tracker.py:88: AssertionError
______________________________ test_capabilities _______________________________

strategy = <rag_factory.strategies.indexing.context_aware.ContextAwareChunkingIndexing object at 0x7129a7227d40>

    def test_capabilities(strategy):
        """Test produces capabilities."""
>       assert strategy.produces() == {
            IndexCapability.CHUNKS,
            IndexCapability.DATABASE
        }
E       AssertionError: assert {<IndexCapabi...y.VECTORS: 1>} == {<IndexCapabi...ty.CHUNKS: 5>}
E         
E         Extra items in the left set:
E         <IndexCapability.VECTORS: 1>
E         
E         Full diff:
E           {
E         +     <IndexCapability.VECTORS: 1>,...
E         
E         ...Full output truncated (3 lines hidden), use '-vv' to show

tests/unit/strategies/indexing/test_context_aware.py:33: AssertionError
_______________________ TestImports.test_import_factory ________________________

self = <tests.unit.test_package.TestImports object at 0x7129a8c48500>

    def test_import_factory(self) -> None:
        """Test RAGFactory can be imported."""
>       from rag_factory import RAGFactory
E       ImportError: cannot import name 'RAGFactory' from 'rag_factory' (/mnt/MCPProyects/ragTools/rag_factory/__init__.py)

tests/unit/test_package.py:18: ImportError
_______________________ TestImports.test_import_pipeline _______________________

self = <tests.unit.test_package.TestImports object at 0x7129a8c07950>

    def test_import_pipeline(self) -> None:
        """Test StrategyPipeline can be imported."""
>       from rag_factory import StrategyPipeline
E       ImportError: cannot import name 'StrategyPipeline' from 'rag_factory' (/mnt/MCPProyects/ragTools/rag_factory/__init__.py)

tests/unit/test_package.py:24: ImportError
________________________ TestImports.test_import_config ________________________

self = <tests.unit.test_package.TestImports object at 0x7129a8c079e0>

    def test_import_config(self) -> None:
        """Test ConfigManager can be imported."""
>       from rag_factory import ConfigManager
E       ImportError: cannot import name 'ConfigManager' from 'rag_factory' (/mnt/MCPProyects/ragTools/rag_factory/__init__.py)

tests/unit/test_package.py:30: ImportError
________________ TestPackageStructure.test_no_circular_imports _________________

self = <tests.unit.test_package.TestPackageStructure object at 0x7129a8c48980>

    def test_no_circular_imports(self) -> None:
        """Test importing doesn't cause circular import errors."""
        try:
>           from rag_factory import RAGFactory
E           ImportError: cannot import name 'RAGFactory' from 'rag_factory' (/mnt/MCPProyects/ragTools/rag_factory/__init__.py)

tests/unit/test_package.py:81: ImportError

During handling of the above exception, another exception occurred:

self = <tests.unit.test_package.TestPackageStructure object at 0x7129a8c48980>

    def test_no_circular_imports(self) -> None:
        """Test importing doesn't cause circular import errors."""
        try:
            from rag_factory import RAGFactory
            from rag_factory import StrategyPipeline
            from rag_factory import ConfigManager
            from rag_factory.strategies import IRAGStrategy
    
            # If we get here, no circular imports
            assert RAGFactory is not None
            assert StrategyPipeline is not None
            assert ConfigManager is not None
            assert IRAGStrategy is not None
        except ImportError as e:
>           pytest.fail(f"Circular import detected: {e}")
E           Failed: Circular import detected: cannot import name 'RAGFactory' from 'rag_factory' (/mnt/MCPProyects/ragTools/rag_factory/__init__.py)

tests/unit/test_package.py:92: Failed
_____________ TestDependencies.test_optional_dependencies_handled ______________

self = <tests.unit.test_package.TestDependencies object at 0x7129a8c482f0>

    def test_optional_dependencies_handled(self) -> None:
        """Test package works without optional dependencies."""
        # Should not fail if optional dependencies missing
>       from rag_factory import RAGFactory
E       ImportError: cannot import name 'RAGFactory' from 'rag_factory' (/mnt/MCPProyects/ragTools/rag_factory/__init__.py)

tests/unit/test_package.py:111: ImportError
=============================== warnings summary ===============================
rag_factory/services/llm/config.py:8
  /mnt/MCPProyects/ragTools/rag_factory/services/llm/config.py:8: PydanticDeprecatedSince20: Support for class-based `config` is deprecated, use ConfigDict instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    class LLMServiceConfig(BaseModel):

rag_factory/database/config.py:12
  /mnt/MCPProyects/ragTools/rag_factory/database/config.py:12: PydanticDeprecatedSince20: Support for class-based `config` is deprecated, use ConfigDict instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    class DatabaseConfig(BaseSettings):

rag_factory/strategies/contextual/config.py:31
  /mnt/MCPProyects/ragTools/rag_factory/strategies/contextual/config.py:31: PydanticDeprecatedSince20: Support for class-based `config` is deprecated, use ConfigDict instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    class ContextualRetrievalConfig(BaseModel):

rag_factory/strategies/late_chunking/models.py:21
  /mnt/MCPProyects/ragTools/rag_factory/strategies/late_chunking/models.py:21: PydanticDeprecatedSince20: Support for class-based `config` is deprecated, use ConfigDict instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    class TokenEmbedding(BaseModel):

rag_factory/strategies/late_chunking/models.py:34
  /mnt/MCPProyects/ragTools/rag_factory/strategies/late_chunking/models.py:34: PydanticDeprecatedSince20: Support for class-based `config` is deprecated, use ConfigDict instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    class DocumentEmbedding(BaseModel):

rag_factory/strategies/late_chunking/models.py:49
  /mnt/MCPProyects/ragTools/rag_factory/strategies/late_chunking/models.py:49: PydanticDeprecatedSince20: Support for class-based `config` is deprecated, use ConfigDict instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    class EmbeddingChunk(BaseModel):

rag_factory/strategies/fine_tuned/config.py:6
  /mnt/MCPProyects/ragTools/rag_factory/strategies/fine_tuned/config.py:6: PydanticDeprecatedSince20: Support for class-based `config` is deprecated, use ConfigDict instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    class FineTunedConfig(BaseSettings):

rag_factory/strategies/agentic/config.py:9
  /mnt/MCPProyects/ragTools/rag_factory/strategies/agentic/config.py:9: PydanticDeprecatedSince20: Support for class-based `config` is deprecated, use ConfigDict instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    class AgenticStrategyConfig(BaseModel):

tests/integration/test_config_integration.py:34
  /mnt/MCPProyects/ragTools/tests/integration/test_config_integration.py:34: PytestCollectionWarning: cannot collect test class 'TestIntegrationStrategy' because it has a __init__ constructor (from: tests/integration/test_config_integration.py)
    class TestIntegrationStrategy(IRAGStrategy):

tests/integration/test_pipeline_integration.py:22
  /mnt/MCPProyects/ragTools/tests/integration/test_pipeline_integration.py:22: PytestCollectionWarning: cannot collect test class 'TestStrategy' because it has a __init__ constructor (from: tests/integration/test_pipeline_integration.py)
    class TestStrategy(IRAGStrategy):

tests/unit/test_factory.py:35
  /mnt/MCPProyects/ragTools/tests/unit/test_factory.py:35: PytestCollectionWarning: cannot collect test class 'TestStrategy' because it has a __init__ constructor (from: tests/unit/test_factory.py)
    class TestStrategy(IRAGStrategy):

tests/integration/database/test_database_integration.py: 4277 warnings
tests/integration/repositories/test_repository_integration.py: 596 warnings
tests/unit/database/test_models.py: 10 warnings
  /mnt/MCPProyects/ragTools/venv/lib/python3.12/site-packages/sqlalchemy/sql/schema.py:3592: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
    return util.wrap_callable(lambda ctx: fn(), fn)  # type: ignore

tests/integration/database/test_migration_validator_integration.py: 13 warnings
  /mnt/MCPProyects/ragTools/tests/integration/database/test_migration_validator_integration.py:50: RuntimeWarning: coroutine 'PostgresqlDatabaseService.close' was never awaited
    service.close()
  Enable tracemalloc to get traceback where the object was allocated.
  See https://docs.pytest.org/en/stable/how-to/capture-warnings.html#resource-warnings for more info.

tests/integration/database/test_migration_validator_integration.py::TestMigrationValidatorEdgeCases::test_validator_with_auto_discovered_config
tests/integration/database/test_migration_validator_integration.py::TestMigrationValidatorEdgeCases::test_validate_empty_requirements
  /mnt/MCPProyects/ragTools/tests/integration/database/test_migration_validator_integration.py:336: RuntimeWarning: coroutine 'PostgresqlDatabaseService.close' was never awaited
    service.close()
  Enable tracemalloc to get traceback where the object was allocated.
  See https://docs.pytest.org/en/stable/how-to/capture-warnings.html#resource-warnings for more info.

tests/integration/models/test_fine_tuned_embeddings_integration.py::test_ab_testing_framework_logic
tests/integration/models/test_fine_tuned_embeddings_integration.py::test_model_comparison_workflow
tests/unit/models/evaluation/test_ab_testing.py::test_winner_determination_clear_winner
tests/unit/models/evaluation/test_ab_testing.py::test_metrics_comparison_calculation
  /mnt/MCPProyects/ragTools/venv/lib/python3.12/site-packages/scipy/stats/_axis_nan_policy.py:579: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.
    res = hypotest_fun_out(*samples, **kwds)

tests/integration/models/test_fine_tuned_embeddings_integration.py::test_ab_testing_framework_logic
tests/integration/models/test_fine_tuned_embeddings_integration.py::test_model_comparison_workflow
tests/unit/models/evaluation/test_ab_testing.py::test_metrics_comparison_calculation
  /mnt/MCPProyects/ragTools/venv/lib/python3.12/site-packages/scipy/stats/_distn_infrastructure.py:2323: RuntimeWarning: invalid value encountered in multiply
    lower_bound = _a * scale + loc

tests/integration/models/test_fine_tuned_embeddings_integration.py::test_ab_testing_framework_logic
tests/integration/models/test_fine_tuned_embeddings_integration.py::test_model_comparison_workflow
tests/unit/models/evaluation/test_ab_testing.py::test_metrics_comparison_calculation
  /mnt/MCPProyects/ragTools/venv/lib/python3.12/site-packages/scipy/stats/_distn_infrastructure.py:2324: RuntimeWarning: invalid value encountered in multiply
    upper_bound = _b * scale + loc

tests/integration/repositories/test_repository_integration.py::TestRepositoryTransactions::test_transaction_rollback
tests/integration/repositories/test_repository_integration.py::TestRepositoryTransactions::test_transaction_rollback_on_error
tests/unit/database/test_models.py::TestDocumentModel::test_document_persistence
tests/unit/database/test_models.py::TestChunkModel::test_chunk_persistence
tests/unit/database/test_models.py::TestModelRelationships::test_document_chunks_relationship
tests/unit/database/test_models.py::TestModelRelationships::test_chunk_document_relationship
tests/unit/database/test_models.py::TestModelRelationships::test_cascade_delete
  /mnt/MCPProyects/ragTools/tests/conftest.py:236: SAWarning: transaction already deassociated from connection
    transaction.rollback()

tests/integration/services/test_fine_tuned_onnx_integration.py: 1 warning
tests/unit/strategies/fine_tuned/test_model_registry.py: 9 warnings
  /mnt/MCPProyects/ragTools/rag_factory/strategies/fine_tuned/model_registry.py:293: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    key: meta.dict()

tests/integration/strategies/test_knowledge_graph_integration.py::test_knowledge_graph_workflow
  /mnt/MCPProyects/ragTools/tests/integration/strategies/test_knowledge_graph_integration.py:119: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    config=config.dict() if hasattr(config, 'dict') else config.__dict__,

tests/integration/strategies/test_knowledge_graph_integration.py::test_hybrid_retrieval
  /mnt/MCPProyects/ragTools/tests/integration/strategies/test_knowledge_graph_integration.py:158: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    config=config.dict() if hasattr(config, 'dict') else config.__dict__,

tests/integration/strategies/test_knowledge_graph_integration.py::test_relationship_queries
  /mnt/MCPProyects/ragTools/tests/integration/strategies/test_knowledge_graph_integration.py:192: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    config=config.dict() if hasattr(config, 'dict') else config.__dict__,

tests/integration/strategies/test_knowledge_graph_integration.py::test_graph_statistics
  /mnt/MCPProyects/ragTools/tests/integration/strategies/test_knowledge_graph_integration.py:224: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    config=config.dict() if hasattr(config, 'dict') else config.__dict__,

tests/integration/strategies/test_multi_query_integration.py::TestMultiQueryIntegration::test_multi_query_complete_workflow
  /mnt/MCPProyects/ragTools/rag_factory/strategies/multi_query/strategy.py:142: RuntimeWarning: coroutine 'MultiQueryRAGStrategy.aretrieve' was never awaited
    return asyncio.run(self.aretrieve(query, **kwargs))
  Enable tracemalloc to get traceback where the object was allocated.
  See https://docs.pytest.org/en/stable/how-to/capture-warnings.html#resource-warnings for more info.

tests/integration/strategies/test_multi_query_integration.py::TestMultiQueryIntegration::test_fallback_on_failure
  /mnt/MCPProyects/ragTools/tests/integration/strategies/test_multi_query_integration.py:209: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    config=config.dict() if hasattr(config, 'dict') else config.__dict__,

tests/integration/strategies/test_multi_query_integration.py::TestMultiQueryIntegration::test_ranking_strategy_comparison
  /mnt/MCPProyects/ragTools/tests/integration/strategies/test_multi_query_integration.py:234: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    config=config_max.dict() if hasattr(config_max, 'dict') else config_max.__dict__,

tests/integration/strategies/test_multi_query_integration.py::TestMultiQueryIntegration::test_ranking_strategy_comparison
  /mnt/MCPProyects/ragTools/tests/integration/strategies/test_multi_query_integration.py:250: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    config=config_freq.dict() if hasattr(config_freq, 'dict') else config_freq.__dict__,

tests/unit/config/test_env_validator.py::TestEnvironmentValidator::test_validate_production_success
  /mnt/MCPProyects/ragTools/tests/unit/config/test_env_validator.py:18: DeprecationWarning: Environment variable 'DATABASE_TEST_URL' is deprecated. Please use 'TEST_DATABASE_URL' instead. Support for 'DATABASE_TEST_URL' will be removed in a future version.
  Migration: Rename DATABASE_TEST_URL=TEST_DATABASE_URL in your .env file.
    EnvironmentValidator.validate(mode='production')

tests/unit/config/test_env_validator.py::TestEnvironmentValidator::test_validate_development_success
  /mnt/MCPProyects/ragTools/tests/unit/config/test_env_validator.py:24: DeprecationWarning: Environment variable 'DATABASE_TEST_URL' is deprecated. Please use 'TEST_DATABASE_URL' instead. Support for 'DATABASE_TEST_URL' will be removed in a future version.
  Migration: Rename DATABASE_TEST_URL=TEST_DATABASE_URL in your .env file.
    EnvironmentValidator.validate(mode='development')

tests/unit/config/test_env_validator.py::TestEnvironmentValidator::test_validate_test_success
  /mnt/MCPProyects/ragTools/tests/unit/config/test_env_validator.py:30: DeprecationWarning: Environment variable 'DATABASE_TEST_URL' is deprecated. Please use 'TEST_DATABASE_URL' instead. Support for 'DATABASE_TEST_URL' will be removed in a future version.
  Migration: Rename DATABASE_TEST_URL=TEST_DATABASE_URL in your .env file.
    EnvironmentValidator.validate(mode='test')

tests/unit/evaluation/test_statistical_testing.py::TestStatisticalAnalyzer::test_paired_t_test_significant_difference
tests/unit/evaluation/test_statistical_testing.py::TestStatisticalAnalyzer::test_analyze_metric_comprehensive
tests/unit/evaluation/test_statistical_testing.py::TestStatisticalAnalyzer::test_edge_case_high_variance
tests/unit/evaluation/test_statistical_testing.py::TestStatisticalAnalyzer::test_edge_case_small_sample
  /mnt/MCPProyects/ragTools/venv/lib/python3.12/site-packages/scipy/stats/_axis_nan_policy.py:423: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.
    return hypotest_fun_in(*args, **kwds)

tests/unit/evaluation/test_statistical_testing.py::TestStatisticalAnalyzer::test_confidence_interval_single_value
  /mnt/MCPProyects/ragTools/rag_factory/evaluation/analysis/statistics.py:156: SmallSampleWarning: One or more sample arguments is too small; all returned values will be NaN. See documentation for sample size requirements.
    sem = stats.sem(scores)

tests/unit/strategies/agentic/test_strategy.py::test_strategy_get_stats
  /mnt/MCPProyects/ragTools/rag_factory/strategies/agentic/strategy.py:289: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    "config": self.strategy_config.dict()

tests/unit/strategies/self_reflective/test_strategy.py: 12 warnings
  /mnt/MCPProyects/ragTools/rag_factory/strategies/self_reflective/strategy.py:179: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    result["refinements"] = [r.dict() for r in refinements]

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
================================ tests coverage ================================
_______________ coverage: platform linux, python 3.12.3-final-0 ________________

Name                                                               Stmts   Miss  Cover   Missing
------------------------------------------------------------------------------------------------
rag_factory/__init__.py                                                3      0   100%
rag_factory/__version__.py                                             1      0   100%
rag_factory/cli/__init__.py                                            2      0   100%
rag_factory/cli/commands/__init__.py                                   1      0   100%
rag_factory/cli/commands/benchmark.py                                 96     17    82%   44, 49, 51, 67-84, 174-175, 257-258, 261
rag_factory/cli/commands/check_consistency.py                         43      3    93%   77, 90, 118
rag_factory/cli/commands/config.py                                    78     13    83%   36, 44, 46, 50-54, 59, 135, 182-183, 186
rag_factory/cli/commands/index.py                                     65      3    95%   179-180, 183
rag_factory/cli/commands/query.py                                     47      6    87%   131, 140-141, 143-144, 147
rag_factory/cli/commands/repl.py                                     152    104    32%   39-40, 63-108, 112-120, 124-133, 137-155, 159-172, 176-186, 203-207, 211-220, 256-260
rag_factory/cli/commands/strategies.py                                45      2    96%   72, 118
rag_factory/cli/commands/validate_e2e.py                              91     69    24%   37-38, 42-142, 145-156
rag_factory/cli/commands/validate_pipeline.py                         70     11    84%   65-66, 69-70, 117-119, 153-156
rag_factory/cli/formatters/__init__.py                                 4      0   100%
rag_factory/cli/formatters/consistency.py                             61      0   100%
rag_factory/cli/formatters/output.py                                  20      0   100%
rag_factory/cli/formatters/results.py                                 71      0   100%
rag_factory/cli/formatters/validation.py                              63      0   100%
rag_factory/cli/main.py                                               31      8    74%   26-28, 49, 76-78, 82
rag_factory/cli/utils/__init__.py                                      3      0   100%
rag_factory/cli/utils/progress.py                                     14      0   100%
rag_factory/cli/utils/validation.py                                   53     15    72%   57-77
rag_factory/config/__init__.py                                         4      0   100%
rag_factory/config/env_resolver.py                                    52      3    94%   142-144
rag_factory/config/schemas/__init__.py                                 2      0   100%
rag_factory/config/schemas/version.py                                 10      6    40%   29-38
rag_factory/config/strategy_loader.py                                 54     12    78%   33, 49-60, 86
rag_factory/config/strategy_pair_manager.py                          105     16    85%   57-58, 66-70, 93, 114, 156-157, 195-196, 212-213, 275
rag_factory/config/validator.py                                       93      2    98%   70, 277
rag_factory/core/__init__.py                                           4      4     0%   7-23
rag_factory/core/capabilities.py                                      61      0   100%
rag_factory/core/indexing_interface.py                                54      3    94%   144, 164, 208
rag_factory/core/pipeline.py                                          49      0   100%
rag_factory/core/retrieval_interface.py                               38      3    92%   138, 158, 196
rag_factory/database/__init__.py                                       4      0   100%
rag_factory/database/config.py                                        17      0   100%
rag_factory/database/connection.py                                    80      9    89%   168-170, 181-183, 212-214
rag_factory/database/env_validator.py                                 38      0   100%
rag_factory/database/models.py                                        85     10    88%   34, 42-45, 52, 69, 73, 77, 81, 85
rag_factory/database/vector_indexing.py                               38      1    97%   78
rag_factory/evaluation/__init__.py                                     4      0   100%
rag_factory/evaluation/analysis/__init__.py                            3      0   100%
rag_factory/evaluation/analysis/comparison.py                        135      9    93%   57, 59, 152, 175, 191, 253, 269, 316, 320
rag_factory/evaluation/analysis/statistics.py                         81      6    93%   98, 100, 153, 183, 252, 271
rag_factory/evaluation/benchmarks/__init__.py                          3      0   100%
rag_factory/evaluation/benchmarks/config.py                           25      4    84%   49, 51, 53, 55
rag_factory/evaluation/benchmarks/runner.py                          155     26    83%   17-18, 159-163, 182, 187, 205, 239-244, 279-287, 297-309
rag_factory/evaluation/datasets/__init__.py                            3      0   100%
rag_factory/evaluation/datasets/loader.py                             88     10    89%   103-104, 136, 149-150, 179, 192, 201-202, 236
rag_factory/evaluation/datasets/schema.py                             52      3    94%   46, 48, 149
rag_factory/evaluation/datasets/statistics.py                         65     65     0%   8-226
rag_factory/evaluation/exporters/__init__.py                           4      0   100%
rag_factory/evaluation/exporters/csv_exporter.py                      52      1    98%   70
rag_factory/evaluation/exporters/html_exporter.py                     47     39    17%   31-37, 41-165, 181-187, 192-293
rag_factory/evaluation/exporters/json_exporter.py                     19      0   100%
rag_factory/evaluation/metrics/__init__.py                             3      0   100%
rag_factory/evaluation/metrics/base.py                                31      3    90%   93, 99, 115
rag_factory/evaluation/metrics/cost.py                                65     65     0%   8-313
rag_factory/evaluation/metrics/performance.py                         42     42     0%   8-202
rag_factory/evaluation/metrics/quality.py                             84     84     0%   8-377
rag_factory/evaluation/metrics/retrieval.py                           77      8    90%   84, 118, 165, 233, 269, 327, 362, 401
rag_factory/exceptions.py                                             13      0   100%
rag_factory/factory.py                                               187     39    79%   257-258, 270, 530, 585, 604-606, 609, 644-699, 706, 709-714
rag_factory/legacy_config.py                                         155      9    94%   389, 418-419, 506-508, 523-525, 541-542
rag_factory/models/__init__.py                                         6      0   100%
rag_factory/models/embedding/__init__.py                               4      0   100%
rag_factory/models/embedding/loader.py                               179    151    16%   8, 16-18, 23-25, 60-88, 92-97, 101-114, 118-135, 139-166, 175-191, 200-235, 244-313, 322-341, 350-367
rag_factory/models/embedding/models.py                                47      0   100%
rag_factory/models/embedding/registry.py                             128     16    88%   47-50, 57-59, 75-76, 117, 183, 187, 253, 259, 275, 278
rag_factory/models/evaluation/__init__.py                              3      0   100%
rag_factory/models/evaluation/ab_testing.py                           98      7    93%   10-12, 107, 127, 189, 242
rag_factory/models/evaluation/models.py                               29      0   100%
rag_factory/observability/__init__.py                                  3      0   100%
rag_factory/observability/integrations/__init__.py                     1      0   100%
rag_factory/observability/integrations/prometheus.py                  47      8    83%   171, 204-206, 224-229
rag_factory/observability/logging/__init__.py                          2      0   100%
rag_factory/observability/logging/config.py                           16     16     0%   3-37
rag_factory/observability/logging/filters.py                          41      1    98%   73
rag_factory/observability/logging/logger.py                           86      0   100%
rag_factory/observability/metrics/__init__.py                          2      0   100%
rag_factory/observability/metrics/collector.py                       143      1    99%   89
rag_factory/observability/metrics/cost.py                             39      0   100%
rag_factory/observability/metrics/performance.py                      64      1    98%   118
rag_factory/observability/monitoring/__init__.py                       1      0   100%
rag_factory/observability/monitoring/api.py                          101     43    57%   26-30, 81-82, 103-104, 130-147, 168-169, 190-191, 207-221, 237-249, 267, 282-285, 310-318, 328
rag_factory/pipeline.py                                              156      1    99%   187
rag_factory/registry/__init__.py                                       4      0   100%
rag_factory/registry/exceptions.py                                     6      0   100%
rag_factory/registry/service_factory.py                               62     10    84%   166-176, 184-191
rag_factory/registry/service_registry.py                              91      3    97%   118, 191-192
rag_factory/repositories/__init__.py                                   5      0   100%
rag_factory/repositories/base.py                                      42      8    81%   53, 70, 87, 103, 136-139
rag_factory/repositories/chunk.py                                    206     59    71%   75-76, 94-95, 200-202, 229-231, 358, 360, 395-396, 425, 438, 473-474, 519-521, 537-543, 557-563, 577-587, 604-626, 639-670
rag_factory/repositories/document.py                                  93     13    86%   67-68, 114-115, 253-255, 278-279, 292-293, 311-312
rag_factory/repositories/exceptions.py                                18      0   100%
rag_factory/services/__init__.py                                       4      0   100%
rag_factory/services/api/__init__.py                                   4      0   100%
rag_factory/services/api/anthropic.py                                 27     10    63%   118-141
rag_factory/services/api/cohere.py                                    30      7    77%   14-15, 50, 83, 111-113
rag_factory/services/api/openai.py                                    46     27    41%   75-93, 117-140, 189-199, 216-227, 235
rag_factory/services/consistency.py                                   32      0   100%
rag_factory/services/database/__init__.py                              5      0   100%
rag_factory/services/database/database_context.py                    181    102    44%   310, 312, 314, 321-330, 338-339, 343-406, 414-415, 430-510, 516-517, 521-546
rag_factory/services/database/migration_validator.py                  85      3    96%   168-170
rag_factory/services/database/neo4j.py                                54     36    33%   14, 60-71, 79-84, 103-114, 134-150, 172-181, 188-191, 195, 199
rag_factory/services/database/postgres.py                            177     24    86%   17-18, 26-27, 85, 91-103, 211, 213, 217-218, 294-297, 393
rag_factory/services/dependencies.py                                  41      0   100%
rag_factory/services/embedding/__init__.py                             4      0   100%
rag_factory/services/embedding/base.py                                31      6    81%   44, 59, 68, 77, 86, 98
rag_factory/services/embedding/cache.py                               43      0   100%
rag_factory/services/embedding/config.py                              29      3    90%   57, 63, 80
rag_factory/services/embedding/providers/__init__.py                   5      0   100%
rag_factory/services/embedding/providers/cohere.py                    53     36    32%   10-20, 55-75, 90-117, 125, 133, 141, 152-153
rag_factory/services/embedding/providers/local.py                     43     27    37%   8-9, 46-67, 83-109, 117, 125, 133, 146
rag_factory/services/embedding/providers/onnx_local.py               114     30    74%   18-19, 114, 143-147, 158, 170-175, 248-250, 273, 289-308
rag_factory/services/embedding/providers/openai.py                    51     13    75%   10-20, 106-108
rag_factory/services/embedding/rate_limiter.py                        20      0   100%
rag_factory/services/embedding/service.py                            100      1    99%   88
rag_factory/services/interfaces.py                                    35      0   100%
rag_factory/services/llm/__init__.py                                   5      0   100%
rag_factory/services/llm/base.py                                      43      0   100%
rag_factory/services/llm/config.py                                    23      4    83%   48, 51-53
rag_factory/services/llm/prompt_template.py                           43      0   100%
rag_factory/services/llm/providers/__init__.py                        12     10    17%   10-22
rag_factory/services/llm/providers/anthropic.py                       57      2    96%   125, 139
rag_factory/services/llm/providers/ollama.py                          55      0   100%
rag_factory/services/llm/providers/openai.py                          57      4    93%   101-105
rag_factory/services/llm/service.py                                   66      5    92%   68, 161, 173-175
rag_factory/services/llm/token_counter.py                             27      4    85%   56-57, 71-72
rag_factory/services/local/__init__.py                                 2      0   100%
rag_factory/services/local/reranker.py                                32      7    78%   13-14, 46, 79, 114-116
rag_factory/services/onnx/__init__.py                                  2      0   100%
rag_factory/services/onnx/embedding.py                                29      8    72%   61, 65, 93, 110-121
rag_factory/services/utils/__init__.py                                 2      0   100%
rag_factory/services/utils/model_converter.py                        104    104     0%   8-291
rag_factory/services/utils/onnx_utils.py                             133     27    80%   22-23, 37, 79-84, 96-97, 142-146, 175, 189-190, 194, 198-201, 216-218, 258, 265-268
rag_factory/services/utils/reranker_selector.py                       68      3    96%   123-125
rag_factory/strategies/__init__.py                                     2      0   100%
rag_factory/strategies/agentic/__init__.py                             7      0   100%
rag_factory/strategies/agentic/agent.py                              151     35    77%   77-78, 156, 212-214, 230-265, 291-293, 324-325, 357-368, 400-402, 407
rag_factory/strategies/agentic/config.py                              12      0   100%
rag_factory/strategies/agentic/frameworks/__init__.py                  1      1     0%   9
rag_factory/strategies/agentic/query_analyzer.py                      89      2    98%   176, 203
rag_factory/strategies/agentic/strategy.py                            87     10    89%   144, 156, 169, 242-243, 254-258
rag_factory/strategies/agentic/tool_implementations.py               135     12    91%   244-247, 370-373, 508-511
rag_factory/strategies/agentic/tools.py                               40      8    80%   66, 79, 89, 101, 139-142
rag_factory/strategies/base.py                                        55      0   100%
rag_factory/strategies/chunking/__init__.py                           15      4    73%   45-48
rag_factory/strategies/chunking/base.py                               91     10    89%   116, 122, 128, 159, 171, 191-196, 229
rag_factory/strategies/chunking/docling_chunker.py                    45     21    53%   18, 69-73, 89-101, 112, 131-136, 147-152, 163-168, 187
rag_factory/strategies/chunking/fixed_size_chunker.py                 74     11    85%   8-9, 36-40, 44-46, 199-204
rag_factory/strategies/chunking/hybrid_chunker.py                     70      8    89%   70, 107-113, 129-130, 158
rag_factory/strategies/chunking/semantic_chunker.py                  195     28    86%   9-10, 14-15, 53, 59, 69-71, 90, 125-126, 194, 225, 252, 258, 294, 306-314, 437-441, 489
rag_factory/strategies/chunking/structural_chunker.py                147     25    83%   9-10, 40-44, 48-50, 121, 127-130, 246, 305, 325, 332-346, 380-385, 406, 413, 423
rag_factory/strategies/chunking/utils.py                              89     89     0%   3-264
rag_factory/strategies/contextual/__init__.py                          7      0   100%
rag_factory/strategies/contextual/batch_processor.py                  91     12    87%   124-125, 153-159, 191-196, 266
rag_factory/strategies/contextual/config.py                           46      0   100%
rag_factory/strategies/contextual/context_generator.py                84     12    86%   99, 113, 125-127, 131-133, 171-172, 226, 234
rag_factory/strategies/contextual/cost_tracker.py                     32      0   100%
rag_factory/strategies/contextual/prompts.py                          25      4    84%   98-101
rag_factory/strategies/contextual/storage.py                          44      0   100%
rag_factory/strategies/contextual/strategy.py                         78     13    83%   83, 173, 186, 207-215, 239-240, 249, 278, 284, 289
rag_factory/strategies/fine_tuned/__init__.py                          4      0   100%
rag_factory/strategies/fine_tuned/ab_testing.py                       78      5    94%   63, 106, 110, 119, 125
rag_factory/strategies/fine_tuned/config.py                           11      0   100%
rag_factory/strategies/fine_tuned/custom_loader.py                    40      4    90%   41, 69, 87-88
rag_factory/strategies/fine_tuned/model_registry.py                  126     23    82%   40, 147, 185, 201, 211-223, 235-240, 256, 286-287, 302-303
rag_factory/strategies/hierarchical/__init__.py                        5      0   100%
rag_factory/strategies/hierarchical/hierarchy_builder.py              79     13    84%   117, 149, 281, 310-335
rag_factory/strategies/hierarchical/models.py                         58      0   100%
rag_factory/strategies/hierarchical/parent_retriever.py               89     19    79%   66-74, 141-142, 213-227, 254-257
rag_factory/strategies/hierarchical/strategy.py                       76     19    75%   77, 92-93, 101, 112-144, 254, 268-269
rag_factory/strategies/indexing/__init__.py                            6      0   100%
rag_factory/strategies/indexing/context_aware.py                     108     10    91%   74, 81, 89-91, 115, 126-128, 197
rag_factory/strategies/indexing/hierarchical.py                       90      1    99%   277
rag_factory/strategies/indexing/in_memory.py                          41      0   100%
rag_factory/strategies/indexing/keyword_indexing.py                   42      1    98%   86
rag_factory/strategies/indexing/knowledge_graph_indexing.py           46     33    28%   18, 27, 48-89, 108-129
rag_factory/strategies/indexing/vector_embedding.py                   98      2    98%   64-65
rag_factory/strategies/knowledge_graph/__init__.py                     4      0   100%
rag_factory/strategies/knowledge_graph/config.py                      21      2    90%   128-129
rag_factory/strategies/knowledge_graph/entity_extractor.py            70      4    94%   135-137, 179
rag_factory/strategies/knowledge_graph/graph_store.py                 31      9    71%   25, 35, 48, 66, 86, 99, 109, 114, 124
rag_factory/strategies/knowledge_graph/hybrid_retriever.py            56      0   100%
rag_factory/strategies/knowledge_graph/memory_graph_store.py          97      8    92%   71, 82-85, 102-103, 126
rag_factory/strategies/knowledge_graph/models.py                      53      0   100%
rag_factory/strategies/knowledge_graph/relationship_extractor.py      62      8    87%   57, 137-138, 142-144, 157-161
rag_factory/strategies/knowledge_graph/strategy.py                    80      9    89%   61, 112-119, 238, 242, 246, 251, 256
rag_factory/strategies/late_chunking/__init__.py                       6      0   100%
rag_factory/strategies/late_chunking/coherence_analyzer.py            27      1    96%   59
rag_factory/strategies/late_chunking/document_embedder.py            104      8    92%   35, 62-63, 72, 232-233, 277, 303
rag_factory/strategies/late_chunking/embedding_chunker.py            117      3    97%   53, 57, 145
rag_factory/strategies/late_chunking/models.py                        62      0   100%
rag_factory/strategies/late_chunking/strategy.py                      70     12    83%   58, 77, 88, 107-122
rag_factory/strategies/multi_query/__init__.py                         7      0   100%
rag_factory/strategies/multi_query/config.py                          36      0   100%
rag_factory/strategies/multi_query/deduplicator.py                    87     14    84%   63-64, 121, 131-135, 146, 160-165, 173-174, 195
rag_factory/strategies/multi_query/parallel_executor.py               52      1    98%   163
rag_factory/strategies/multi_query/prompts.py                         10      2    80%   76-80
rag_factory/strategies/multi_query/ranker.py                          80      8    90%   47, 56-60, 98-103, 163
rag_factory/strategies/multi_query/strategy.py                        68     18    74%   97-105, 109, 113, 132-136, 154-174
rag_factory/strategies/multi_query/variant_generator.py               62      3    95%   79, 129, 177
rag_factory/strategies/query_expansion/__init__.py                     8      0   100%
rag_factory/strategies/query_expansion/base.py                        66      1    98%   103
rag_factory/strategies/query_expansion/cache.py                       52     21    60%   47-51, 81-97, 105-112
rag_factory/strategies/query_expansion/expander_service.py            92      1    99%   178
rag_factory/strategies/query_expansion/hyde_expander.py               19      1    95%   48
rag_factory/strategies/query_expansion/llm_expander.py                25      0   100%
rag_factory/strategies/query_expansion/metrics.py                     66     30    55%   44-45, 53-57, 76-109, 130, 134, 146-152, 160
rag_factory/strategies/query_expansion/prompts.py                     13      0   100%
rag_factory/strategies/reranking/__init__.py                           7      0   100%
rag_factory/strategies/reranking/base.py                              68      2    97%   101, 106
rag_factory/strategies/reranking/bge_reranker.py                      51     37    27%   14, 53-81, 103-147, 151
rag_factory/strategies/reranking/cache.py                             48      0   100%
rag_factory/strategies/reranking/cohere_reranker.py                   34     20    41%   15-16, 55-71, 94-115, 119
rag_factory/strategies/reranking/cosine_reranker.py                   62      7    89%   128, 163-171
rag_factory/strategies/reranking/cross_encoder_reranker.py            40     24    40%   13-14, 65-76, 98-120, 124
rag_factory/strategies/reranking/metrics.py                           67      0   100%
rag_factory/strategies/reranking/reranker_service.py                 115      8    93%   80, 84-89, 167, 203-204
rag_factory/strategies/retrieval/__init__.py                           6      0   100%
rag_factory/strategies/retrieval/keyword_retriever.py                 56     41    27%   41, 52, 71-113, 126-133, 153-172
rag_factory/strategies/retrieval/knowledge_graph_retriever.py         22      9    59%   19, 27, 48-70
rag_factory/strategies/retrieval/multi_query_retriever.py             22      9    59%   19, 26, 44-66
rag_factory/strategies/retrieval/query_expansion_retriever.py         24      9    62%   20, 27, 45-67
rag_factory/strategies/retrieval/semantic_retriever.py                23      0   100%
rag_factory/strategies/self_reflective/__init__.py                     6      0   100%
rag_factory/strategies/self_reflective/config.py                      20      8    60%   29-42
rag_factory/strategies/self_reflective/grader.py                      80      3    96%   234-237
rag_factory/strategies/self_reflective/models.py                      48      0   100%
rag_factory/strategies/self_reflective/refiner.py                     69      3    96%   131, 221-222
rag_factory/strategies/self_reflective/strategy.py                    92      2    98%   84-85
rag_factory/utils/__init__.py                                          3      0   100%
rag_factory/utils/token_counter.py                                    45      0   100%
rag_factory/utils/tokenization.py                                     95      6    94%   63-64, 144, 185, 251-252
------------------------------------------------------------------------------------------------
TOTAL                                                              12307   2361    81%
=========================== short test summary info ============================
FAILED tests/integration/database/test_migration_integration.py::TestMigrationIntegration::test_real_migration_execution
FAILED tests/integration/database/test_migration_integration.py::TestMigrationIntegration::test_migration_with_existing_data
FAILED tests/integration/database/test_migration_integration.py::TestMigrationIntegration::test_rollback_functionality
FAILED tests/integration/database/test_migration_integration.py::TestMigrationIntegration::test_pgvector_extension_installed
FAILED tests/integration/database/test_migration_validator_integration.py::TestMigrationValidatorIntegration::test_validate_with_no_migrations
FAILED tests/integration/database/test_migration_validator_integration.py::TestMigrationValidatorIntegration::test_validate_with_partial_migrations
FAILED tests/integration/database/test_migration_validator_integration.py::TestMigrationValidatorIntegration::test_validate_with_all_migrations
FAILED tests/integration/database/test_migration_validator_integration.py::TestMigrationValidatorIntegration::test_validate_or_raise_success
FAILED tests/integration/database/test_migration_validator_integration.py::TestMigrationValidatorIntegration::test_validate_or_raise_failure
FAILED tests/integration/database/test_migration_validator_integration.py::TestMigrationValidatorIntegration::test_get_current_revision
FAILED tests/integration/database/test_migration_validator_integration.py::TestMigrationValidatorIntegration::test_is_at_head
FAILED tests/integration/database/test_migration_validator_integration.py::TestMigrationValidatorIntegration::test_error_message_details
FAILED tests/integration/database/test_migration_validator_integration.py::TestMigrationValidatorIntegration::test_validate_single_migration
FAILED tests/integration/database/test_migration_validator_integration.py::TestMigrationValidatorIntegration::test_validate_nonexistent_migration
FAILED tests/integration/database/test_migration_validator_integration.py::TestMigrationValidatorIntegration::test_validate_after_downgrade
FAILED tests/integration/database/test_migration_validator_integration.py::TestMigrationValidatorIntegration::test_multiple_validators_same_database
FAILED tests/integration/registry/test_registry_integration.py::TestRealServiceInstantiation::test_multiple_service_instantiation
FAILED tests/integration/registry/test_registry_integration.py::TestErrorHandling::test_invalid_service_config
FAILED tests/integration/registry/test_registry_integration.py::TestConfigurationValidation::test_configuration_warnings
FAILED tests/integration/services/test_service_integration.py::test_rag_workflow
FAILED tests/integration/services/test_service_integration.py::test_embedding_database_consistency
FAILED tests/integration/strategies/test_self_reflective_integration.py::TestSelfReflectiveIntegration::test_end_to_end_workflow
FAILED tests/integration/strategies/test_self_reflective_integration.py::TestSelfReflectiveIntegration::test_retry_with_poor_results
FAILED tests/integration/strategies/test_self_reflective_integration.py::TestSelfReflectiveIntegration::test_performance_within_limits
FAILED tests/integration/strategies/test_self_reflective_integration.py::TestSelfReflectiveWithLMStudio::test_with_real_llm
FAILED tests/integration/test_factory_consistency.py::TestFactoryConsistencyIntegration::test_inconsistent_indexing_strategy_logs_warnings
FAILED tests/integration/test_factory_consistency.py::TestFactoryConsistencyIntegration::test_inconsistent_retrieval_strategy_logs_warnings
FAILED tests/integration/test_fine_tuned_embeddings_pair.py::test_fine_tuned_embeddings_pair_loading
FAILED tests/integration/test_hierarchical_rag_pair.py::test_hierarchical_rag_pair_loading
FAILED tests/integration/test_hybrid_search_pair.py::test_hybrid_search_pair_loading
FAILED tests/integration/test_keyword_pair.py::test_keyword_pair_loading - ra...
FAILED tests/integration/test_knowledge_graph_pair.py::test_knowledge_graph_pair_loading
FAILED tests/integration/test_late_chunking_pair.py::test_late_chunking_pair_loading
FAILED tests/integration/test_multi_query_pair.py::test_multi_query_pair_loading
FAILED tests/integration/test_package_integration.py::TestSmokeTest::test_basic_usage_smoke_test
FAILED tests/integration/test_package_integration.py::TestFullWorkflow::test_full_workflow_with_installed_package
FAILED tests/integration/test_query_expansion_pair.py::test_query_expansion_pair_loading
FAILED tests/integration/test_reranking_pair.py::test_reranking_pair_loading
FAILED tests/integration/test_self_reflective_pair.py::test_self_reflective_pair_loading
FAILED tests/integration/test_semantic_api_pair.py::test_semantic_api_pair_loading
FAILED tests/integration/test_semantic_local_pair.py::test_semantic_local_pair_loading
FAILED tests/integration_real/test_llm_real.py::test_llm_streaming - TypeErro...
FAILED tests/unit/config/test_strategy_pair_manager.py::test_load_pair_success
FAILED tests/unit/config/test_strategy_pair_manager.py::test_db_context_creation
FAILED tests/unit/database/test_batch_operations.py::TestBatchOperations::test_store_chunks_with_hierarchy
FAILED tests/unit/database/test_migrations.py::TestAlembicMigrations::test_migration_upgrade_to_head
FAILED tests/unit/database/test_migrations.py::TestAlembicMigrations::test_migration_downgrade
FAILED tests/unit/database/test_migrations.py::TestAlembicMigrations::test_migration_idempotency
FAILED tests/unit/database/test_migrations.py::TestAlembicMigrations::test_get_current_version
FAILED tests/unit/database/test_migrations.py::TestAlembicMigrations::test_migration_creates_tables
FAILED tests/unit/database/test_migrations.py::TestAlembicMigrations::test_migration_creates_indexes
FAILED tests/unit/database/test_models.py::TestDocumentModel::test_document_persistence
FAILED tests/unit/database/test_models.py::TestChunkModel::test_chunk_persistence
FAILED tests/unit/database/test_models.py::TestModelRelationships::test_document_chunks_relationship
FAILED tests/unit/database/test_models.py::TestModelRelationships::test_chunk_document_relationship
FAILED tests/unit/database/test_models.py::TestModelRelationships::test_cascade_delete
FAILED tests/unit/database/test_pgvector.py::TestPgVectorIntegration::test_cosine_similarity_search
FAILED tests/unit/documentation/test_code_examples.py::TestCodeExamples::test_all_code_examples_have_valid_syntax
FAILED tests/unit/documentation/test_links.py::TestDocumentationLinks::test_no_broken_internal_links
FAILED tests/unit/registry/test_service_factory.py::TestLLMServiceCreation::test_create_llm_service_openai
FAILED tests/unit/registry/test_service_factory.py::TestEmbeddingServiceCreation::test_create_embedding_service_onnx
FAILED tests/unit/registry/test_service_factory.py::TestEmbeddingServiceCreation::test_create_embedding_service_onnx_with_defaults
FAILED tests/unit/registry/test_service_factory.py::TestEmbeddingServiceCreation::test_create_embedding_service_openai
FAILED tests/unit/registry/test_service_factory.py::TestDatabaseServiceCreation::test_create_database_service_postgres_with_connection_string
FAILED tests/unit/registry/test_service_factory.py::TestDatabaseServiceCreation::test_create_database_service_postgres_with_components
FAILED tests/unit/registry/test_service_factory.py::TestDatabaseServiceCreation::test_create_database_service_postgres_with_defaults
FAILED tests/unit/registry/test_service_factory.py::TestDatabaseServiceCreation::test_create_database_service_neo4j
FAILED tests/unit/registry/test_service_factory.py::TestDatabaseServiceCreation::test_create_database_service_neo4j_with_defaults
FAILED tests/unit/services/embedding/test_onnx_local_provider.py::test_calculate_cost_is_zero
FAILED tests/unit/services/test_database_service.py::test_store_chunks - asse...
FAILED tests/unit/services/test_database_service.py::test_search_chunks - Typ...
FAILED tests/unit/strategies/contextual/test_cost_tracker.py::test_budget_alert
FAILED tests/unit/strategies/indexing/test_context_aware.py::test_capabilities
FAILED tests/unit/test_package.py::TestImports::test_import_factory - ImportE...
FAILED tests/unit/test_package.py::TestImports::test_import_pipeline - Import...
FAILED tests/unit/test_package.py::TestImports::test_import_config - ImportEr...
FAILED tests/unit/test_package.py::TestPackageStructure::test_no_circular_imports
FAILED tests/unit/test_package.py::TestDependencies::test_optional_dependencies_handled
=== 78 failed, 1993 passed, 64 skipped, 4965 warnings in 1188.34s (0:19:48) ====
