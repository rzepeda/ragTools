========================================
Test Results - 2025-12-17 21:20:35
========================================
Environment Configuration:
  EMBEDDING_MODEL_NAME: Xenova/all-MiniLM-L6-v2
  EMBEDDING_MODEL_PATH: models/embeddings
  LM_STUDIO_BASE_URL: http://192.168.56.1:1234/v1
  LM_STUDIO_MODEL: phi-4-mini-instruct

Command: pytest tests/benchmarks/test_late_chunking_performance.py tests/integration_real/test_database_real.py tests/integration_real/test_end_to_end_real.py tests/integration_real/test_llm_real.py tests/integration/registry/test_registry_integration.py tests/integration/strategies/test_hierarchical_integration.py tests/integration/strategies/test_late_chunking_integration.py tests/integration/strategies/test_self_reflective_integration.py tests/integration/test_package_integration.py tests/test_mock_registry.py tests/unit/config/test_strategy_pair_manager.py tests/unit/database/test_migrations.py tests/unit/documentation/test_code_examples.py tests/unit/documentation/test_links.py tests/unit/registry/test_service_factory.py tests/unit/services/embeddings/test_onnx_local.py tests/unit/services/embedding/test_onnx_local_provider.py tests/unit/strategies/indexing/test_context_aware.py tests/unit/strategies/self_reflective/test_strategy.py tests/unit/test_package.py tests/integration/database/test_migration_integration.py tests/integration/database/test_migration_validator_integration.py
========================================

============================= test session starts ==============================
platform linux -- Python 3.12.3, pytest-9.0.1, pluggy-1.6.0 -- /mnt/MCPProyects/ragTools/venv/bin/python3
cachedir: .pytest_cache
rootdir: /mnt/MCPProyects/ragTools
configfile: pytest.ini (WARNING: ignoring pytest config in pyproject.toml!)
plugins: anyio-4.12.0, cov-7.0.0, asyncio-1.3.0
asyncio: mode=Mode.STRICT, debug=False, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function
collecting ... collected 188 items

tests/benchmarks/test_late_chunking_performance.py::test_document_embedding_speed PASSED [  0%]
tests/benchmarks/test_late_chunking_performance.py::test_embedding_chunking_speed PASSED [  1%]
tests/benchmarks/test_late_chunking_performance.py::test_semantic_boundary_speed PASSED [  1%]
tests/benchmarks/test_late_chunking_performance.py::test_end_to_end_latency PASSED [  2%]
tests/benchmarks/test_late_chunking_performance.py::test_coherence_analysis_overhead PASSED [  2%]
tests/benchmarks/test_late_chunking_performance.py::test_batch_processing_speed PASSED [  3%]
tests/benchmarks/test_late_chunking_performance.py::test_adaptive_chunking_speed PASSED [  3%]
tests/benchmarks/test_late_chunking_performance.py::test_memory_efficiency PASSED [  4%]
tests/integration_real/test_database_real.py::test_postgres_connection PASSED [  4%]
tests/integration_real/test_database_real.py::test_table_creation PASSED [  5%]
tests/integration_real/test_database_real.py::test_store_and_retrieve_chunks PASSED [  5%]
tests/integration_real/test_database_real.py::test_vector_similarity_search PASSED [  6%]
tests/integration_real/test_database_real.py::test_batch_embedding_and_storage PASSED [  6%]
tests/integration_real/test_database_real.py::test_chunk_metadata_persistence PASSED [  7%]
tests/integration_real/test_database_real.py::test_database_context_table_mapping FAILED [  7%]
tests/integration_real/test_database_real.py::test_connection_pooling PASSED [  8%]
tests/integration_real/test_end_to_end_real.py::test_document_indexing_pipeline FAILED [  9%]
tests/integration_real/test_end_to_end_real.py::test_retrieval_pipeline FAILED [  9%]
tests/integration_real/test_end_to_end_real.py::test_full_rag_pipeline FAILED [ 10%]
tests/integration_real/test_end_to_end_real.py::test_multiple_document_batches FAILED [ 10%]
tests/integration_real/test_end_to_end_real.py::test_retrieval_with_metadata_filtering PASSED [ 11%]
tests/integration_real/test_end_to_end_real.py::test_large_document_indexing FAILED [ 11%]
tests/integration_real/test_end_to_end_real.py::test_retrieval_accuracy PASSED [ 12%]
tests/integration_real/test_llm_real.py::test_llm_basic_generation PASSED [ 12%]
tests/integration_real/test_llm_real.py::test_llm_conversation PASSED    [ 13%]
tests/integration_real/test_llm_real.py::test_llm_token_counting PASSED  [ 13%]
tests/integration_real/test_llm_real.py::test_llm_with_system_prompt PASSED [ 14%]
tests/integration_real/test_llm_real.py::test_llm_json_response PASSED   [ 14%]
tests/integration_real/test_llm_real.py::test_llm_max_tokens PASSED      [ 15%]
tests/integration_real/test_llm_real.py::test_llm_temperature PASSED     [ 15%]
tests/integration_real/test_llm_real.py::test_llm_streaming FAILED       [ 16%]
tests/integration_real/test_llm_real.py::test_llm_rag_context PASSED     [ 17%]
tests/integration_real/test_llm_real.py::test_llm_error_handling PASSED  [ 17%]
tests/integration/registry/test_registry_integration.py::TestRealServiceInstantiation::test_instantiate_onnx_embedding_service PASSED [ 18%]
tests/integration/registry/test_registry_integration.py::TestRealServiceInstantiation::test_embedding_service_functionality PASSED [ 18%]
tests/integration/registry/test_registry_integration.py::TestRealServiceInstantiation::test_multiple_service_instantiation FAILED [ 19%]
tests/integration/registry/test_registry_integration.py::TestEnvironmentVariableResolution::test_env_var_resolution PASSED [ 19%]
tests/integration/registry/test_registry_integration.py::TestEnvironmentVariableResolution::test_env_var_defaults PASSED [ 20%]
tests/integration/registry/test_registry_integration.py::TestServiceLifecycle::test_context_manager_cleanup PASSED [ 20%]
tests/integration/registry/test_registry_integration.py::TestServiceLifecycle::test_reload_service PASSED [ 21%]
tests/integration/registry/test_registry_integration.py::TestServiceLifecycle::test_shutdown_cleanup PASSED [ 21%]
tests/integration/registry/test_registry_integration.py::TestServiceSharing::test_service_instance_sharing PASSED [ 22%]
tests/integration/registry/test_registry_integration.py::TestServiceSharing::test_service_sharing_memory_efficiency PASSED [ 22%]
tests/integration/registry/test_registry_integration.py::TestErrorHandling::test_invalid_service_config FAILED [ 23%]
tests/integration/registry/test_registry_integration.py::TestErrorHandling::test_missing_service_file PASSED [ 23%]
tests/integration/registry/test_registry_integration.py::TestOpenAIServices::test_openai_llm_instantiation PASSED [ 24%]
tests/integration/registry/test_registry_integration.py::TestOpenAIServices::test_openai_embedding_instantiation PASSED [ 25%]
tests/integration/registry/test_registry_integration.py::TestConfigurationValidation::test_valid_configuration_loads PASSED [ 25%]
tests/integration/registry/test_registry_integration.py::TestConfigurationValidation::test_configuration_warnings FAILED [ 26%]
tests/integration/strategies/test_hierarchical_integration.py::TestHierarchicalIntegration::test_end_to_end_workflow PASSED [ 26%]
tests/integration/strategies/test_hierarchical_integration.py::TestHierarchicalIntegration::test_expansion_strategy_comparison PASSED [ 27%]
tests/integration/strategies/test_hierarchical_integration.py::TestHierarchicalIntegration::test_hierarchy_validation PASSED [ 27%]
tests/integration/strategies/test_hierarchical_integration.py::TestHierarchicalIntegration::test_multiple_documents PASSED [ 28%]
tests/integration/strategies/test_late_chunking_integration.py::test_late_chunking_workflow PASSED [ 28%]
tests/integration/strategies/test_late_chunking_integration.py::test_fixed_size_chunking_integration PASSED [ 29%]
tests/integration/strategies/test_late_chunking_integration.py::test_adaptive_chunking_integration PASSED [ 29%]
tests/integration/strategies/test_late_chunking_integration.py::test_multiple_documents PASSED [ 30%]
tests/integration/strategies/test_late_chunking_integration.py::test_strategy_properties PASSED [ 30%]
tests/integration/strategies/test_late_chunking_integration.py::test_coherence_scores_computed PASSED [ 31%]
tests/integration/strategies/test_late_chunking_integration.py::test_short_document PASSED [ 31%]
tests/integration/strategies/test_late_chunking_integration.py::test_chunk_embeddings_valid PASSED [ 32%]
tests/integration/strategies/test_late_chunking_integration.py::test_embedding_quality PASSED [ 32%]
tests/integration/strategies/test_self_reflective_integration.py::TestSelfReflectiveIntegration::test_end_to_end_workflow FAILED [ 33%]
tests/integration/strategies/test_self_reflective_integration.py::TestSelfReflectiveIntegration::test_retry_with_poor_results FAILED [ 34%]
tests/integration/strategies/test_self_reflective_integration.py::TestSelfReflectiveIntegration::test_performance_within_limits FAILED [ 34%]
tests/integration/strategies/test_self_reflective_integration.py::TestSelfReflectiveWithLMStudio::test_with_real_llm FAILED [ 35%]
tests/integration/test_package_integration.py::TestPackageInstallation::test_package_installable PASSED [ 35%]
tests/integration/test_package_integration.py::TestSmokeTest::test_basic_usage_smoke_test FAILED [ 36%]
tests/integration/test_package_integration.py::TestFullWorkflow::test_full_workflow_with_installed_package FAILED [ 36%]
tests/integration/test_package_integration.py::TestBuildAndDistribution::test_package_can_be_built SKIPPED [ 37%]
tests/unit/config/test_strategy_pair_manager.py::test_load_pair_success FAILED [ 37%]
tests/unit/config/test_strategy_pair_manager.py::test_load_pair_compatibility_error PASSED [ 38%]
tests/unit/config/test_strategy_pair_manager.py::test_migration_error PASSED [ 38%]
tests/unit/config/test_strategy_pair_manager.py::test_db_context_creation FAILED [ 39%]
tests/unit/database/test_migrations.py::TestAlembicMigrations::test_migration_upgrade_to_head FAILED [ 39%]
tests/unit/database/test_migrations.py::TestAlembicMigrations::test_migration_downgrade FAILED [ 40%]
tests/unit/database/test_migrations.py::TestAlembicMigrations::test_migration_history PASSED [ 40%]
tests/unit/database/test_migrations.py::TestAlembicMigrations::test_migration_idempotency FAILED [ 41%]
tests/unit/database/test_migrations.py::TestAlembicMigrations::test_get_current_version FAILED [ 42%]
tests/unit/database/test_migrations.py::TestAlembicMigrations::test_migration_creates_tables FAILED [ 42%]
tests/unit/database/test_migrations.py::TestAlembicMigrations::test_migration_creates_indexes FAILED [ 43%]
tests/unit/documentation/test_code_examples.py::TestCodeExamples::test_all_code_examples_have_valid_syntax FAILED [ 43%]
tests/unit/documentation/test_code_examples.py::TestCodeExamples::test_strategy_examples_have_imports PASSED [ 44%]
tests/unit/documentation/test_code_examples.py::TestCodeExamples::test_configuration_examples_valid SKIPPED [ 44%]
tests/unit/documentation/test_code_examples.py::TestCodeExamples::test_quick_start_example_complete PASSED [ 45%]
tests/unit/documentation/test_code_examples.py::TestCodeExamples::test_no_placeholder_code PASSED [ 45%]
tests/unit/documentation/test_links.py::TestDocumentationLinks::test_no_broken_internal_links FAILED [ 46%]
tests/unit/documentation/test_links.py::TestDocumentationLinks::test_all_diagrams_valid PASSED [ 46%]
tests/unit/documentation/test_links.py::TestDocumentationLinks::test_no_todo_links PASSED [ 47%]
tests/unit/documentation/test_links.py::TestDocumentationLinks::test_external_links_valid SKIPPED [ 47%]
tests/unit/registry/test_service_factory.py::TestServiceTypeDetection::test_is_llm_service PASSED [ 48%]
tests/unit/registry/test_service_factory.py::TestServiceTypeDetection::test_is_llm_service_missing_url PASSED [ 48%]
tests/unit/registry/test_service_factory.py::TestServiceTypeDetection::test_is_llm_service_missing_model PASSED [ 49%]
tests/unit/registry/test_service_factory.py::TestServiceTypeDetection::test_is_embedding_service PASSED [ 50%]
tests/unit/registry/test_service_factory.py::TestServiceTypeDetection::test_is_embedding_service_missing_provider PASSED [ 50%]
tests/unit/registry/test_service_factory.py::TestServiceTypeDetection::test_is_database_service_postgres PASSED [ 51%]
tests/unit/registry/test_service_factory.py::TestServiceTypeDetection::test_is_database_service_neo4j PASSED [ 51%]
tests/unit/registry/test_service_factory.py::TestServiceTypeDetection::test_is_database_service_unknown_type PASSED [ 52%]
tests/unit/registry/test_service_factory.py::TestLLMServiceCreation::test_create_llm_service_openai FAILED [ 52%]
tests/unit/registry/test_service_factory.py::TestLLMServiceCreation::test_create_llm_service_lm_studio PASSED [ 53%]
tests/unit/registry/test_service_factory.py::TestLLMServiceCreation::test_create_llm_service_with_defaults PASSED [ 53%]
tests/unit/registry/test_service_factory.py::TestEmbeddingServiceCreation::test_create_embedding_service_onnx FAILED [ 54%]
tests/unit/registry/test_service_factory.py::TestEmbeddingServiceCreation::test_create_embedding_service_onnx_with_defaults FAILED [ 54%]
tests/unit/registry/test_service_factory.py::TestEmbeddingServiceCreation::test_create_embedding_service_openai FAILED [ 55%]
tests/unit/registry/test_service_factory.py::TestEmbeddingServiceCreation::test_create_embedding_service_cohere_not_implemented PASSED [ 55%]
tests/unit/registry/test_service_factory.py::TestEmbeddingServiceCreation::test_create_embedding_service_unknown_provider PASSED [ 56%]
tests/unit/registry/test_service_factory.py::TestDatabaseServiceCreation::test_create_database_service_postgres_with_connection_string FAILED [ 56%]
tests/unit/registry/test_service_factory.py::TestDatabaseServiceCreation::test_create_database_service_postgres_with_components FAILED [ 57%]
tests/unit/registry/test_service_factory.py::TestDatabaseServiceCreation::test_create_database_service_postgres_with_defaults FAILED [ 57%]
tests/unit/registry/test_service_factory.py::TestDatabaseServiceCreation::test_create_database_service_neo4j FAILED [ 58%]
tests/unit/registry/test_service_factory.py::TestDatabaseServiceCreation::test_create_database_service_neo4j_with_defaults FAILED [ 59%]
tests/unit/registry/test_service_factory.py::TestDatabaseServiceCreation::test_create_database_service_unknown_type PASSED [ 59%]
tests/unit/registry/test_service_factory.py::TestServiceCreation::test_create_service_llm PASSED [ 60%]
tests/unit/registry/test_service_factory.py::TestServiceCreation::test_create_service_embedding PASSED [ 60%]
tests/unit/registry/test_service_factory.py::TestServiceCreation::test_create_service_database PASSED [ 61%]
tests/unit/registry/test_service_factory.py::TestServiceCreation::test_create_service_unknown_type PASSED [ 61%]
tests/unit/services/embeddings/test_onnx_local.py::TestONNXLocalProvider::test_initialization PASSED [ 62%]
tests/unit/services/embeddings/test_onnx_local.py::TestONNXLocalProvider::test_initialization_with_custom_config PASSED [ 62%]
tests/unit/services/embeddings/test_onnx_local.py::TestONNXLocalProvider::test_get_embeddings_single_text PASSED [ 63%]
tests/unit/services/embeddings/test_onnx_local.py::TestONNXLocalProvider::test_get_embeddings_multiple_texts PASSED [ 63%]
tests/unit/services/embeddings/test_onnx_local.py::TestONNXLocalProvider::test_get_embeddings_empty_list PASSED [ 64%]
tests/unit/services/embeddings/test_onnx_local.py::TestONNXLocalProvider::test_embedding_normalization PASSED [ 64%]
tests/unit/services/embeddings/test_onnx_local.py::TestONNXLocalProvider::test_get_dimensions PASSED [ 65%]
tests/unit/services/embeddings/test_onnx_local.py::TestONNXLocalProvider::test_get_max_batch_size PASSED [ 65%]
tests/unit/services/embeddings/test_onnx_local.py::TestONNXLocalProvider::test_get_model_name PASSED [ 66%]
tests/unit/services/embeddings/test_onnx_local.py::TestONNXLocalProvider::test_calculate_cost PASSED [ 67%]
tests/unit/services/embeddings/test_onnx_local.py::TestONNXLocalProvider::test_known_models PASSED [ 67%]
tests/unit/services/embeddings/test_onnx_local.py::TestONNXLocalProvider::test_missing_onnx_runtime PASSED [ 68%]
tests/unit/services/embeddings/test_onnx_local.py::TestONNXLocalProvider::test_model_loading_failure PASSED [ 68%]
tests/unit/services/embeddings/test_onnx_local.py::TestONNXLocalProvider::test_session_creation_failure PASSED [ 69%]
tests/unit/services/embedding/test_onnx_local_provider.py::test_provider_not_available_raises_error PASSED [ 69%]
tests/unit/services/embedding/test_onnx_local_provider.py::test_provider_initialization PASSED [ 70%]
tests/unit/services/embedding/test_onnx_local_provider.py::test_get_embeddings PASSED [ 70%]
tests/unit/services/embedding/test_onnx_local_provider.py::test_calculate_cost_is_zero FAILED [ 71%]
tests/unit/services/embedding/test_onnx_local_provider.py::test_known_model_dimensions PASSED [ 71%]
tests/unit/services/embedding/test_onnx_local_provider.py::test_unknown_model_uses_output_shape PASSED [ 72%]
tests/unit/services/embedding/test_onnx_local_provider.py::test_custom_batch_size PASSED [ 72%]
tests/unit/services/embedding/test_onnx_local_provider.py::test_model_loading_failure PASSED [ 73%]
tests/unit/services/embedding/test_onnx_local_provider.py::test_get_model_name PASSED [ 73%]
tests/unit/services/embedding/test_onnx_local_provider.py::test_mean_pooling PASSED [ 74%]
tests/unit/strategies/indexing/test_context_aware.py::test_capabilities FAILED [ 75%]
tests/unit/strategies/indexing/test_context_aware.py::test_requirements PASSED [ 75%]
tests/unit/strategies/indexing/test_context_aware.py::test_split_into_sentences PASSED [ 76%]
tests/unit/strategies/indexing/test_context_aware.py::test_create_windows PASSED [ 76%]
tests/unit/strategies/indexing/test_context_aware.py::test_find_boundaries PASSED [ 77%]
tests/unit/strategies/indexing/test_context_aware.py::test_create_chunks_respects_boundaries PASSED [ 77%]
tests/unit/strategies/indexing/test_context_aware.py::test_create_chunks_respects_min_size PASSED [ 78%]
tests/unit/strategies/indexing/test_context_aware.py::test_create_chunks_respects_max_size PASSED [ 78%]
tests/unit/strategies/indexing/test_context_aware.py::test_process_flow PASSED [ 79%]
tests/unit/strategies/self_reflective/test_strategy.py::test_retrieve_good_results_no_retry PASSED [ 79%]
tests/unit/strategies/self_reflective/test_strategy.py::test_retrieve_poor_results_triggers_retry PASSED [ 80%]
tests/unit/strategies/self_reflective/test_strategy.py::test_max_retries_enforced PASSED [ 80%]
tests/unit/strategies/self_reflective/test_strategy.py::test_result_aggregation PASSED [ 81%]
tests/unit/strategies/self_reflective/test_strategy.py::test_timeout_protection PASSED [ 81%]
tests/unit/strategies/self_reflective/test_strategy.py::test_same_query_prevention PASSED [ 82%]
tests/unit/strategies/self_reflective/test_strategy.py::test_normalize_results PASSED [ 82%]
tests/unit/strategies/self_reflective/test_strategy.py::test_strategy_properties PASSED [ 83%]
tests/unit/test_package.py::TestImports::test_import_main_package PASSED [ 84%]
tests/unit/test_package.py::TestImports::test_import_factory FAILED      [ 84%]
tests/unit/test_package.py::TestImports::test_import_pipeline FAILED     [ 85%]
tests/unit/test_package.py::TestImports::test_import_config FAILED       [ 85%]
tests/unit/test_package.py::TestImports::test_import_base_strategy PASSED [ 86%]
tests/unit/test_package.py::TestImports::test_import_all_exports PASSED  [ 86%]
tests/unit/test_package.py::TestVersion::test_version_format PASSED      [ 87%]
tests/unit/test_package.py::TestVersion::test_version_accessible PASSED  [ 87%]
tests/unit/test_package.py::TestPackageStructure::test_strategies_subpackage_exists PASSED [ 88%]
tests/unit/test_package.py::TestPackageStructure::test_no_circular_imports FAILED [ 88%]
tests/unit/test_package.py::TestDependencies::test_required_dependencies_installed PASSED [ 89%]
tests/unit/test_package.py::TestDependencies::test_optional_dependencies_handled FAILED [ 89%]
tests/integration/database/test_migration_integration.py::TestMigrationIntegration::test_real_migration_execution FAILED [ 90%]
tests/integration/database/test_migration_integration.py::TestMigrationIntegration::test_migration_with_existing_data FAILED [ 90%]
tests/integration/database/test_migration_integration.py::TestMigrationIntegration::test_rollback_functionality FAILED [ 91%]
tests/integration/database/test_migration_integration.py::TestMigrationIntegration::test_pgvector_extension_installed FAILED [ 92%]
tests/integration/database/test_migration_validator_integration.py::TestMigrationValidatorIntegration::test_validate_with_no_migrations FAILED [ 92%]
tests/integration/database/test_migration_validator_integration.py::TestMigrationValidatorIntegration::test_validate_with_partial_migrations FAILED [ 93%]
tests/integration/database/test_migration_validator_integration.py::TestMigrationValidatorIntegration::test_validate_with_all_migrations FAILED [ 93%]
tests/integration/database/test_migration_validator_integration.py::TestMigrationValidatorIntegration::test_validate_or_raise_success FAILED [ 94%]
tests/integration/database/test_migration_validator_integration.py::TestMigrationValidatorIntegration::test_validate_or_raise_failure FAILED [ 94%]
tests/integration/database/test_migration_validator_integration.py::TestMigrationValidatorIntegration::test_get_current_revision FAILED [ 95%]
tests/integration/database/test_migration_validator_integration.py::TestMigrationValidatorIntegration::test_get_all_revisions PASSED [ 95%]
tests/integration/database/test_migration_validator_integration.py::TestMigrationValidatorIntegration::test_is_at_head FAILED [ 96%]
tests/integration/database/test_migration_validator_integration.py::TestMigrationValidatorIntegration::test_error_message_details FAILED [ 96%]
tests/integration/database/test_migration_validator_integration.py::TestMigrationValidatorIntegration::test_validate_single_migration FAILED [ 97%]
tests/integration/database/test_migration_validator_integration.py::TestMigrationValidatorIntegration::test_validate_nonexistent_migration FAILED [ 97%]
tests/integration/database/test_migration_validator_integration.py::TestMigrationValidatorIntegration::test_validate_after_downgrade FAILED [ 98%]
tests/integration/database/test_migration_validator_integration.py::TestMigrationValidatorIntegration::test_multiple_validators_same_database FAILED [ 98%]
tests/integration/database/test_migration_validator_integration.py::TestMigrationValidatorEdgeCases::test_validator_with_auto_discovered_config PASSED [ 99%]
tests/integration/database/test_migration_validator_integration.py::TestMigrationValidatorEdgeCases::test_validate_empty_requirements PASSED [100%]

=================================== FAILURES ===================================
_____________________ test_database_context_table_mapping ______________________

real_db_service = <rag_factory.services.database.postgres.PostgresqlDatabaseService object at 0x788cc893a360>

    @pytest.mark.real_integration
    @pytest.mark.requires_postgres
    @pytest.mark.asyncio
    async def test_database_context_table_mapping(real_db_service):
        """Test DatabaseContext with custom table/field mappings."""
        # Get a database context with custom table name
>       context = real_db_service.get_context(table_name="custom_chunks_test")
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E       TypeError: PostgresqlDatabaseService.get_context() got an unexpected keyword argument 'table_name'

tests/integration_real/test_database_real.py:200: TypeError
---------------------------- Captured stderr setup -----------------------------
DEBUG:asyncio:Using selector: EpollSelector
INFO:rag_factory.services.database.postgres:Initialized PostgreSQL service for 192.168.56.1:5432/rag_test
------------------------------ Captured log setup ------------------------------
DEBUG    asyncio:selector_events.py:64 Using selector: EpollSelector
INFO     rag_factory.services.database.postgres:postgres.py:121 Initialized PostgreSQL service for 192.168.56.1:5432/rag_test
--------------------------- Captured stderr teardown ---------------------------
INFO:rag_factory.services.database.postgres:Created synchronous SQLAlchemy engine for contexts
INFO:rag_factory.services.database.postgres:Disposed synchronous SQLAlchemy engine
DEBUG:rag_factory.services.database.postgres:Cleared DatabaseContext cache
---------------------------- Captured log teardown -----------------------------
INFO     rag_factory.services.database.postgres:postgres.py:492 Created synchronous SQLAlchemy engine for contexts
INFO     rag_factory.services.database.postgres:postgres.py:583 Disposed synchronous SQLAlchemy engine
DEBUG    rag_factory.services.database.postgres:postgres.py:586 Cleared DatabaseContext cache
_______________________ test_document_indexing_pipeline ________________________

real_db_service = <rag_factory.services.database.postgres.PostgresqlDatabaseService object at 0x788cc8a18500>
real_embedding_service = <tests.integration_real.conftest.real_embedding_service.<locals>.AsyncEmbeddingWrapper object at 0x788cc8a1a690>
sample_documents = [{'metadata': {'category': 'animals', 'source': 'test1.txt'}, 'text': 'The quick brown fox jumps over the lazy dog'}, ...}, 'text': 'Machine learning algorithms can learn from data and make predictions without being explicitly programmed'}]

    @pytest.mark.real_integration
    @pytest.mark.requires_postgres
    @pytest.mark.requires_embeddings
    @pytest.mark.asyncio
    async def test_document_indexing_pipeline(real_db_service, real_embedding_service, sample_documents):
        """Test complete document indexing pipeline."""
        from rag_factory.strategies.indexing.vector_embedding import VectorEmbeddingIndexing
        from rag_factory.strategies.base import StrategyConfig
        from rag_factory.services.dependencies import StrategyDependencies
        from rag_factory.core.indexing_interface import IndexingContext
        from dataclasses import asdict
    
        # Create indexing strategy
        config = StrategyConfig(
            strategy_name="test_indexing",
            chunk_size=200,
            chunk_overlap=50
        )
    
        dependencies = StrategyDependencies(
            embedding_service=real_embedding_service,
            database_service=real_db_service
        )
    
        strategy = VectorEmbeddingIndexing(config=asdict(config), dependencies=dependencies)
    
        # Create indexing context
        context = IndexingContext(database_service=real_db_service, config=asdict(config))
    
        # Index documents
>       await strategy.process(sample_documents, context)

tests/integration_real/test_end_to_end_real.py:41: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
rag_factory/strategies/indexing/vector_embedding.py:113: in process
    embedding_dim = self.deps.embedding_service.get_dimension()
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tests.integration_real.conftest.real_embedding_service.<locals>.AsyncEmbeddingWrapper object at 0x788cc8a1a690>

    def get_dimension(self):
        """Get embedding dimension."""
>       return self.provider.get_dimension()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
E       AttributeError: 'ONNXLocalProvider' object has no attribute 'get_dimension'. Did you mean: 'get_dimensions'?

tests/integration_real/conftest.py:217: AttributeError
---------------------------- Captured stderr setup -----------------------------
DEBUG:asyncio:Using selector: EpollSelector
INFO:rag_factory.services.database.postgres:Initialized PostgreSQL service for 192.168.56.1:5432/rag_test
INFO:rag_factory.services.embedding.providers.onnx_local:Loading ONNX model: Xenova/all-MiniLM-L6-v2
INFO:rag_factory.services.utils.onnx_utils:Using model from EMBEDDING_MODEL_NAME env: Xenova/all-MiniLM-L6-v2
INFO:rag_factory.services.utils.onnx_utils:Using cached ONNX model: models/embeddings/Xenova_all-MiniLM-L6-v2/onnx/model.onnx
INFO:rag_factory.services.utils.onnx_utils:Created ONNX session with providers: ['CPUExecutionProvider']
INFO:rag_factory.services.utils.onnx_utils:Model has 3 inputs and 1 outputs
DEBUG:rag_factory.services.utils.onnx_utils:  Input: input_ids, shape: ['batch_size', 'sequence_length'], type: tensor(int64)
DEBUG:rag_factory.services.utils.onnx_utils:  Input: attention_mask, shape: ['batch_size', 'sequence_length'], type: tensor(int64)
DEBUG:rag_factory.services.utils.onnx_utils:  Input: token_type_ids, shape: ['batch_size', 'sequence_length'], type: tensor(int64)
DEBUG:rag_factory.services.utils.onnx_utils:  Output: last_hidden_state, shape: ['batch_size', 'sequence_length', 384], type: tensor(float)
INFO:rag_factory.services.utils.onnx_utils:Model validation passed
INFO:rag_factory.services.embedding.providers.onnx_local:Loaded tokenizer from models/embeddings/Xenova_all-MiniLM-L6-v2/tokenizer.json
INFO:rag_factory.services.embedding.providers.onnx_local:Loaded ONNX model Xenova/all-MiniLM-L6-v2 with 384 dimensions
------------------------------ Captured log setup ------------------------------
DEBUG    asyncio:selector_events.py:64 Using selector: EpollSelector
INFO     rag_factory.services.database.postgres:postgres.py:121 Initialized PostgreSQL service for 192.168.56.1:5432/rag_test
INFO     rag_factory.services.embedding.providers.onnx_local:onnx_local.py:111 Loading ONNX model: Xenova/all-MiniLM-L6-v2
INFO     rag_factory.services.utils.onnx_utils:onnx_utils.py:90 Using model from EMBEDDING_MODEL_NAME env: Xenova/all-MiniLM-L6-v2
INFO     rag_factory.services.utils.onnx_utils:onnx_utils.py:113 Using cached ONNX model: models/embeddings/Xenova_all-MiniLM-L6-v2/onnx/model.onnx
INFO     rag_factory.services.utils.onnx_utils:onnx_utils.py:211 Created ONNX session with providers: ['CPUExecutionProvider']
INFO     rag_factory.services.utils.onnx_utils:onnx_utils.py:243 Model has 3 inputs and 1 outputs
DEBUG    rag_factory.services.utils.onnx_utils:onnx_utils.py:247   Input: input_ids, shape: ['batch_size', 'sequence_length'], type: tensor(int64)
DEBUG    rag_factory.services.utils.onnx_utils:onnx_utils.py:247   Input: attention_mask, shape: ['batch_size', 'sequence_length'], type: tensor(int64)
DEBUG    rag_factory.services.utils.onnx_utils:onnx_utils.py:247   Input: token_type_ids, shape: ['batch_size', 'sequence_length'], type: tensor(int64)
DEBUG    rag_factory.services.utils.onnx_utils:onnx_utils.py:251   Output: last_hidden_state, shape: ['batch_size', 'sequence_length', 384], type: tensor(float)
INFO     rag_factory.services.utils.onnx_utils:onnx_utils.py:273 Model validation passed
INFO     rag_factory.services.embedding.providers.onnx_local:onnx_local.py:168 Loaded tokenizer from models/embeddings/Xenova_all-MiniLM-L6-v2/tokenizer.json
INFO     rag_factory.services.embedding.providers.onnx_local:onnx_local.py:177 Loaded ONNX model Xenova/all-MiniLM-L6-v2 with 384 dimensions
----------------------------- Captured stderr call -----------------------------
INFO:rag_factory.strategies.indexing.vector_embedding:Starting VectorEmbeddingIndexing.process with 3 documents
DEBUG:rag_factory.strategies.indexing.vector_embedding:Configuration: batch_size=32, chunk_size=200, overlap=50
INFO:rag_factory.strategies.indexing.vector_embedding:Using embedding service: AsyncEmbeddingWrapper
INFO:rag_factory.strategies.indexing.vector_embedding:Starting document chunking...
DEBUG:rag_factory.strategies.indexing.vector_embedding:_chunk_documents called with 3 documents, chunk_size=200, overlap=50
DEBUG:rag_factory.strategies.indexing.vector_embedding:Processing document 1/3: doc_id='', text_length=43
DEBUG:rag_factory.strategies.indexing.vector_embedding:Document  fits in single chunk (length=43 <= 200)
DEBUG:rag_factory.strategies.indexing.vector_embedding:Processing document 2/3: doc_id='', text_length=98
DEBUG:rag_factory.strategies.indexing.vector_embedding:Document  fits in single chunk (length=98 <= 200)
DEBUG:rag_factory.strategies.indexing.vector_embedding:Processing document 3/3: doc_id='', text_length=104
DEBUG:rag_factory.strategies.indexing.vector_embedding:Document  fits in single chunk (length=104 <= 200)
DEBUG:rag_factory.strategies.indexing.vector_embedding:_chunk_documents complete: total 3 chunks created
INFO:rag_factory.strategies.indexing.vector_embedding:Document chunking complete: created 3 chunks from 3 documents
INFO:rag_factory.strategies.indexing.vector_embedding:Starting embedding generation for 3 chunks in batches of 32...
DEBUG:rag_factory.strategies.indexing.vector_embedding:Processing batch 1/1 with 3 texts
DEBUG:rag_factory.strategies.indexing.vector_embedding:Batch 1/1 complete: generated 3 embeddings
INFO:rag_factory.strategies.indexing.vector_embedding:Embedding generation complete: created 3 embeddings
INFO:rag_factory.strategies.indexing.vector_embedding:Adding embeddings to chunks...
INFO:rag_factory.strategies.indexing.vector_embedding:Storing 3 chunks to database...
INFO:rag_factory.services.database.postgres:Ensured table test_chunks_real exists
DEBUG:rag_factory.services.database.postgres:Storing chunk _0: embedding dims=384, first 3 values=[0.0343538336455822, 0.07440994679927826, 0.05604083091020584]
DEBUG:rag_factory.services.database.postgres:Storing chunk _0: embedding dims=384, first 3 values=[0.01752028986811638, 0.10716250538825989, 0.03238148242235184]
DEBUG:rag_factory.services.database.postgres:Storing chunk _0: embedding dims=384, first 3 values=[-0.015417386777698994, 0.07431276142597198, 0.007554365321993828]
DEBUG:rag_factory.services.database.postgres:Stored 3 chunks
INFO:rag_factory.strategies.indexing.vector_embedding:Database storage complete
------------------------------ Captured log call -------------------------------
INFO     rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:55 Starting VectorEmbeddingIndexing.process with 3 documents
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:61 Configuration: batch_size=32, chunk_size=200, overlap=50
INFO     rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:67 Using embedding service: AsyncEmbeddingWrapper
INFO     rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:70 Starting document chunking...
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:137 _chunk_documents called with 3 documents, chunk_size=200, overlap=50
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:146 Processing document 1/3: doc_id='', text_length=43
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:158 Document  fits in single chunk (length=43 <= 200)
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:146 Processing document 2/3: doc_id='', text_length=98
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:158 Document  fits in single chunk (length=98 <= 200)
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:146 Processing document 3/3: doc_id='', text_length=104
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:158 Document  fits in single chunk (length=104 <= 200)
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:220 _chunk_documents complete: total 3 chunks created
INFO     rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:72 Document chunking complete: created 3 chunks from 3 documents
INFO     rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:85 Starting embedding generation for 3 chunks in batches of 32...
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:94 Processing batch 1/1 with 3 texts
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:100 Batch 1/1 complete: generated 3 embeddings
INFO     rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:102 Embedding generation complete: created 3 embeddings
INFO     rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:105 Adding embeddings to chunks...
INFO     rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:109 Storing 3 chunks to database...
INFO     rag_factory.services.database.postgres:postgres.py:173 Ensured table test_chunks_real exists
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk _0: embedding dims=384, first 3 values=[0.0343538336455822, 0.07440994679927826, 0.05604083091020584]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk _0: embedding dims=384, first 3 values=[0.01752028986811638, 0.10716250538825989, 0.03238148242235184]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk _0: embedding dims=384, first 3 values=[-0.015417386777698994, 0.07431276142597198, 0.007554365321993828]
DEBUG    rag_factory.services.database.postgres:postgres.py:241 Stored 3 chunks
INFO     rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:111 Database storage complete
--------------------------- Captured stderr teardown ---------------------------
INFO:rag_factory.services.database.postgres:Created synchronous SQLAlchemy engine for contexts
INFO:rag_factory.services.database.postgres:Closed PostgreSQL async connection pool
INFO:rag_factory.services.database.postgres:Disposed synchronous SQLAlchemy engine
DEBUG:rag_factory.services.database.postgres:Cleared DatabaseContext cache
---------------------------- Captured log teardown -----------------------------
INFO     rag_factory.services.database.postgres:postgres.py:492 Created synchronous SQLAlchemy engine for contexts
INFO     rag_factory.services.database.postgres:postgres.py:577 Closed PostgreSQL async connection pool
INFO     rag_factory.services.database.postgres:postgres.py:583 Disposed synchronous SQLAlchemy engine
DEBUG    rag_factory.services.database.postgres:postgres.py:586 Cleared DatabaseContext cache
___________________________ test_retrieval_pipeline ____________________________

real_db_service = <rag_factory.services.database.postgres.PostgresqlDatabaseService object at 0x788cc8a192e0>
real_embedding_service = <tests.integration_real.conftest.real_embedding_service.<locals>.AsyncEmbeddingWrapper object at 0x788cc8a18ce0>

    @pytest.mark.real_integration
    @pytest.mark.requires_postgres
    @pytest.mark.requires_embeddings
    @pytest.mark.asyncio
    async def test_retrieval_pipeline(real_db_service, real_embedding_service):
        """Test complete retrieval pipeline."""
        from rag_factory.strategies.retrieval.semantic_retriever import SemanticRetriever
        from rag_factory.strategies.base import StrategyConfig
        from rag_factory.services.dependencies import StrategyDependencies
    
        # First, index some documents
        texts = [
            "Python is a high-level programming language.",
            "Machine learning is a subset of artificial intelligence.",
            "The Eiffel Tower is located in Paris, France."
        ]
    
        chunks = []
        for i, text in enumerate(texts):
            embedding = await real_embedding_service.embed(text)
            chunk = Chunk(
                chunk_id=f"retrieval_test_{i}",
                text=text,
                embedding=embedding,
                metadata={"source": f"doc{i}.txt"}
            )
            chunks.append(chunk)
    
        await real_db_service.store_chunks(chunks)
    
        # Create retrieval strategy
        config = StrategyConfig(
            strategy_name="test_retrieval",
            top_k=2
        )
    
        dependencies = StrategyDependencies(
            embedding_service=real_embedding_service,
            database_service=real_db_service
        )
    
        strategy = SemanticRetriever(config=config, dependencies=dependencies)
    
        # Retrieve relevant chunks
        query = "What is Python?"
>       results = await strategy.retrieve(query)
                        ^^^^^^^^^^^^^^^^^^^^^^^^
E       TypeError: SemanticRetriever.retrieve() missing 1 required positional argument: 'context'

tests/integration_real/test_end_to_end_real.py:98: TypeError
---------------------------- Captured stderr setup -----------------------------
DEBUG:asyncio:Using selector: EpollSelector
INFO:rag_factory.services.database.postgres:Initialized PostgreSQL service for 192.168.56.1:5432/rag_test
INFO:rag_factory.services.embedding.providers.onnx_local:Loading ONNX model: Xenova/all-MiniLM-L6-v2
INFO:rag_factory.services.utils.onnx_utils:Using model from EMBEDDING_MODEL_NAME env: Xenova/all-MiniLM-L6-v2
INFO:rag_factory.services.utils.onnx_utils:Using cached ONNX model: models/embeddings/Xenova_all-MiniLM-L6-v2/onnx/model.onnx
INFO:rag_factory.services.utils.onnx_utils:Created ONNX session with providers: ['CPUExecutionProvider']
INFO:rag_factory.services.utils.onnx_utils:Model has 3 inputs and 1 outputs
DEBUG:rag_factory.services.utils.onnx_utils:  Input: input_ids, shape: ['batch_size', 'sequence_length'], type: tensor(int64)
DEBUG:rag_factory.services.utils.onnx_utils:  Input: attention_mask, shape: ['batch_size', 'sequence_length'], type: tensor(int64)
DEBUG:rag_factory.services.utils.onnx_utils:  Input: token_type_ids, shape: ['batch_size', 'sequence_length'], type: tensor(int64)
DEBUG:rag_factory.services.utils.onnx_utils:  Output: last_hidden_state, shape: ['batch_size', 'sequence_length', 384], type: tensor(float)
INFO:rag_factory.services.utils.onnx_utils:Model validation passed
INFO:rag_factory.services.embedding.providers.onnx_local:Loaded tokenizer from models/embeddings/Xenova_all-MiniLM-L6-v2/tokenizer.json
INFO:rag_factory.services.embedding.providers.onnx_local:Loaded ONNX model Xenova/all-MiniLM-L6-v2 with 384 dimensions
------------------------------ Captured log setup ------------------------------
DEBUG    asyncio:selector_events.py:64 Using selector: EpollSelector
INFO     rag_factory.services.database.postgres:postgres.py:121 Initialized PostgreSQL service for 192.168.56.1:5432/rag_test
INFO     rag_factory.services.embedding.providers.onnx_local:onnx_local.py:111 Loading ONNX model: Xenova/all-MiniLM-L6-v2
INFO     rag_factory.services.utils.onnx_utils:onnx_utils.py:90 Using model from EMBEDDING_MODEL_NAME env: Xenova/all-MiniLM-L6-v2
INFO     rag_factory.services.utils.onnx_utils:onnx_utils.py:113 Using cached ONNX model: models/embeddings/Xenova_all-MiniLM-L6-v2/onnx/model.onnx
INFO     rag_factory.services.utils.onnx_utils:onnx_utils.py:211 Created ONNX session with providers: ['CPUExecutionProvider']
INFO     rag_factory.services.utils.onnx_utils:onnx_utils.py:243 Model has 3 inputs and 1 outputs
DEBUG    rag_factory.services.utils.onnx_utils:onnx_utils.py:247   Input: input_ids, shape: ['batch_size', 'sequence_length'], type: tensor(int64)
DEBUG    rag_factory.services.utils.onnx_utils:onnx_utils.py:247   Input: attention_mask, shape: ['batch_size', 'sequence_length'], type: tensor(int64)
DEBUG    rag_factory.services.utils.onnx_utils:onnx_utils.py:247   Input: token_type_ids, shape: ['batch_size', 'sequence_length'], type: tensor(int64)
DEBUG    rag_factory.services.utils.onnx_utils:onnx_utils.py:251   Output: last_hidden_state, shape: ['batch_size', 'sequence_length', 384], type: tensor(float)
INFO     rag_factory.services.utils.onnx_utils:onnx_utils.py:273 Model validation passed
INFO     rag_factory.services.embedding.providers.onnx_local:onnx_local.py:168 Loaded tokenizer from models/embeddings/Xenova_all-MiniLM-L6-v2/tokenizer.json
INFO     rag_factory.services.embedding.providers.onnx_local:onnx_local.py:177 Loaded ONNX model Xenova/all-MiniLM-L6-v2 with 384 dimensions
----------------------------- Captured stderr call -----------------------------
INFO:rag_factory.services.database.postgres:Ensured table test_chunks_real exists
DEBUG:rag_factory.services.database.postgres:Storing chunk retrieval_test_0: embedding dims=384, first 3 values=[0.036329373717308044, 0.1258840411901474, 0.04253153130412102]
DEBUG:rag_factory.services.database.postgres:Storing chunk retrieval_test_1: embedding dims=384, first 3 values=[-0.0017120783450081944, 0.08779999613761902, 0.036195073276758194]
DEBUG:rag_factory.services.database.postgres:Storing chunk retrieval_test_2: embedding dims=384, first 3 values=[0.07582288980484009, 0.09381315112113953, 0.04505017772316933]
DEBUG:rag_factory.services.database.postgres:Stored 3 chunks
------------------------------ Captured log call -------------------------------
INFO     rag_factory.services.database.postgres:postgres.py:173 Ensured table test_chunks_real exists
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk retrieval_test_0: embedding dims=384, first 3 values=[0.036329373717308044, 0.1258840411901474, 0.04253153130412102]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk retrieval_test_1: embedding dims=384, first 3 values=[-0.0017120783450081944, 0.08779999613761902, 0.036195073276758194]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk retrieval_test_2: embedding dims=384, first 3 values=[0.07582288980484009, 0.09381315112113953, 0.04505017772316933]
DEBUG    rag_factory.services.database.postgres:postgres.py:241 Stored 3 chunks
--------------------------- Captured stderr teardown ---------------------------
INFO:rag_factory.services.database.postgres:Created synchronous SQLAlchemy engine for contexts
INFO:rag_factory.services.database.postgres:Closed PostgreSQL async connection pool
INFO:rag_factory.services.database.postgres:Disposed synchronous SQLAlchemy engine
DEBUG:rag_factory.services.database.postgres:Cleared DatabaseContext cache
---------------------------- Captured log teardown -----------------------------
INFO     rag_factory.services.database.postgres:postgres.py:492 Created synchronous SQLAlchemy engine for contexts
INFO     rag_factory.services.database.postgres:postgres.py:577 Closed PostgreSQL async connection pool
INFO     rag_factory.services.database.postgres:postgres.py:583 Disposed synchronous SQLAlchemy engine
DEBUG    rag_factory.services.database.postgres:postgres.py:586 Cleared DatabaseContext cache
____________________________ test_full_rag_pipeline ____________________________

real_db_service = <rag_factory.services.database.postgres.PostgresqlDatabaseService object at 0x788cc8a0a120>
real_embedding_service = <tests.integration_real.conftest.real_embedding_service.<locals>.AsyncEmbeddingWrapper object at 0x788cc8a0bec0>
real_llm_service = <rag_factory.services.llm.service.LLMService object at 0x788cc8a0acf0>

    @pytest.mark.real_integration
    @pytest.mark.requires_postgres
    @pytest.mark.requires_embeddings
    @pytest.mark.requires_llm
    @pytest.mark.asyncio
    async def test_full_rag_pipeline(real_db_service, real_embedding_service, real_llm_service):
        """Test complete RAG pipeline: indexing -> retrieval -> generation."""
        from rag_factory.strategies.indexing.vector_embedding import VectorEmbeddingIndexing
        from rag_factory.strategies.retrieval.semantic_retriever import SemanticRetriever
        from rag_factory.strategies.base import StrategyConfig
        from rag_factory.services.dependencies import StrategyDependencies
        from rag_factory.services.llm.base import Message, MessageRole
        from rag_factory.core.indexing_interface import IndexingContext
        from dataclasses import asdict
    
        # Step 1: Index documents
        documents = [
            {
                "text": "The Eiffel Tower was built in 1889 by Gustave Eiffel. It is located in Paris, France and stands 330 meters tall.",
                "id": "eiffel_doc",
                "metadata": {"source": "eiffel.txt"}
            },
            {
                "text": "Python is a high-level programming language created by Guido van Rossum in 1991. It is known for its simplicity and readability.",
                "id": "python_doc",
                "metadata": {"source": "python.txt"}
            }
        ]
    
        indexing_config = StrategyConfig(strategy_name="indexing", chunk_size=200, chunk_overlap=50)
        indexing_deps = StrategyDependencies(
            embedding_service=real_embedding_service,
            database_service=real_db_service
        )
        indexing_strategy = VectorEmbeddingIndexing(config=asdict(indexing_config), dependencies=indexing_deps)
    
        # Create indexing context
        indexing_context = IndexingContext(database_service=real_db_service, config=asdict(indexing_config))
    
>       await indexing_strategy.process(documents, indexing_context)

tests/integration_real/test_end_to_end_real.py:146: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
rag_factory/strategies/indexing/vector_embedding.py:113: in process
    embedding_dim = self.deps.embedding_service.get_dimension()
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tests.integration_real.conftest.real_embedding_service.<locals>.AsyncEmbeddingWrapper object at 0x788cc8a0bec0>

    def get_dimension(self):
        """Get embedding dimension."""
>       return self.provider.get_dimension()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
E       AttributeError: 'ONNXLocalProvider' object has no attribute 'get_dimension'. Did you mean: 'get_dimensions'?

tests/integration_real/conftest.py:217: AttributeError
---------------------------- Captured stderr setup -----------------------------
DEBUG:asyncio:Using selector: EpollSelector
INFO:rag_factory.services.database.postgres:Initialized PostgreSQL service for 192.168.56.1:5432/rag_test
INFO:rag_factory.services.embedding.providers.onnx_local:Loading ONNX model: Xenova/all-MiniLM-L6-v2
INFO:rag_factory.services.utils.onnx_utils:Using model from EMBEDDING_MODEL_NAME env: Xenova/all-MiniLM-L6-v2
INFO:rag_factory.services.utils.onnx_utils:Using cached ONNX model: models/embeddings/Xenova_all-MiniLM-L6-v2/onnx/model.onnx
INFO:rag_factory.services.utils.onnx_utils:Created ONNX session with providers: ['CPUExecutionProvider']
INFO:rag_factory.services.utils.onnx_utils:Model has 3 inputs and 1 outputs
DEBUG:rag_factory.services.utils.onnx_utils:  Input: input_ids, shape: ['batch_size', 'sequence_length'], type: tensor(int64)
DEBUG:rag_factory.services.utils.onnx_utils:  Input: attention_mask, shape: ['batch_size', 'sequence_length'], type: tensor(int64)
DEBUG:rag_factory.services.utils.onnx_utils:  Input: token_type_ids, shape: ['batch_size', 'sequence_length'], type: tensor(int64)
DEBUG:rag_factory.services.utils.onnx_utils:  Output: last_hidden_state, shape: ['batch_size', 'sequence_length', 384], type: tensor(float)
INFO:rag_factory.services.utils.onnx_utils:Model validation passed
INFO:rag_factory.services.embedding.providers.onnx_local:Loaded tokenizer from models/embeddings/Xenova_all-MiniLM-L6-v2/tokenizer.json
INFO:rag_factory.services.embedding.providers.onnx_local:Loaded ONNX model Xenova/all-MiniLM-L6-v2 with 384 dimensions
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 192.168.56.1:1234
DEBUG:urllib3.connectionpool:http://192.168.56.1:1234 "GET /v1/models HTTP/1.1" 200 1082
------------------------------ Captured log setup ------------------------------
DEBUG    asyncio:selector_events.py:64 Using selector: EpollSelector
INFO     rag_factory.services.database.postgres:postgres.py:121 Initialized PostgreSQL service for 192.168.56.1:5432/rag_test
INFO     rag_factory.services.embedding.providers.onnx_local:onnx_local.py:111 Loading ONNX model: Xenova/all-MiniLM-L6-v2
INFO     rag_factory.services.utils.onnx_utils:onnx_utils.py:90 Using model from EMBEDDING_MODEL_NAME env: Xenova/all-MiniLM-L6-v2
INFO     rag_factory.services.utils.onnx_utils:onnx_utils.py:113 Using cached ONNX model: models/embeddings/Xenova_all-MiniLM-L6-v2/onnx/model.onnx
INFO     rag_factory.services.utils.onnx_utils:onnx_utils.py:211 Created ONNX session with providers: ['CPUExecutionProvider']
INFO     rag_factory.services.utils.onnx_utils:onnx_utils.py:243 Model has 3 inputs and 1 outputs
DEBUG    rag_factory.services.utils.onnx_utils:onnx_utils.py:247   Input: input_ids, shape: ['batch_size', 'sequence_length'], type: tensor(int64)
DEBUG    rag_factory.services.utils.onnx_utils:onnx_utils.py:247   Input: attention_mask, shape: ['batch_size', 'sequence_length'], type: tensor(int64)
DEBUG    rag_factory.services.utils.onnx_utils:onnx_utils.py:247   Input: token_type_ids, shape: ['batch_size', 'sequence_length'], type: tensor(int64)
DEBUG    rag_factory.services.utils.onnx_utils:onnx_utils.py:251   Output: last_hidden_state, shape: ['batch_size', 'sequence_length', 384], type: tensor(float)
INFO     rag_factory.services.utils.onnx_utils:onnx_utils.py:273 Model validation passed
INFO     rag_factory.services.embedding.providers.onnx_local:onnx_local.py:168 Loaded tokenizer from models/embeddings/Xenova_all-MiniLM-L6-v2/tokenizer.json
INFO     rag_factory.services.embedding.providers.onnx_local:onnx_local.py:177 Loaded ONNX model Xenova/all-MiniLM-L6-v2 with 384 dimensions
DEBUG    urllib3.connectionpool:connectionpool.py:241 Starting new HTTP connection (1): 192.168.56.1:1234
DEBUG    urllib3.connectionpool:connectionpool.py:544 http://192.168.56.1:1234 "GET /v1/models HTTP/1.1" 200 1082
----------------------------- Captured stderr call -----------------------------
INFO:rag_factory.strategies.indexing.vector_embedding:Starting VectorEmbeddingIndexing.process with 2 documents
DEBUG:rag_factory.strategies.indexing.vector_embedding:Configuration: batch_size=32, chunk_size=200, overlap=50
INFO:rag_factory.strategies.indexing.vector_embedding:Using embedding service: AsyncEmbeddingWrapper
INFO:rag_factory.strategies.indexing.vector_embedding:Starting document chunking...
DEBUG:rag_factory.strategies.indexing.vector_embedding:_chunk_documents called with 2 documents, chunk_size=200, overlap=50
DEBUG:rag_factory.strategies.indexing.vector_embedding:Processing document 1/2: doc_id='eiffel_doc', text_length=112
DEBUG:rag_factory.strategies.indexing.vector_embedding:Document eiffel_doc fits in single chunk (length=112 <= 200)
DEBUG:rag_factory.strategies.indexing.vector_embedding:Processing document 2/2: doc_id='python_doc', text_length=128
DEBUG:rag_factory.strategies.indexing.vector_embedding:Document python_doc fits in single chunk (length=128 <= 200)
DEBUG:rag_factory.strategies.indexing.vector_embedding:_chunk_documents complete: total 2 chunks created
INFO:rag_factory.strategies.indexing.vector_embedding:Document chunking complete: created 2 chunks from 2 documents
INFO:rag_factory.strategies.indexing.vector_embedding:Starting embedding generation for 2 chunks in batches of 32...
DEBUG:rag_factory.strategies.indexing.vector_embedding:Processing batch 1/1 with 2 texts
DEBUG:rag_factory.strategies.indexing.vector_embedding:Batch 1/1 complete: generated 2 embeddings
INFO:rag_factory.strategies.indexing.vector_embedding:Embedding generation complete: created 2 embeddings
INFO:rag_factory.strategies.indexing.vector_embedding:Adding embeddings to chunks...
INFO:rag_factory.strategies.indexing.vector_embedding:Storing 2 chunks to database...
INFO:rag_factory.services.database.postgres:Ensured table test_chunks_real exists
DEBUG:rag_factory.services.database.postgres:Storing chunk eiffel_doc_0: embedding dims=384, first 3 values=[0.054607685655355453, 0.10627976804971695, 0.011374696157872677]
DEBUG:rag_factory.services.database.postgres:Storing chunk python_doc_0: embedding dims=384, first 3 values=[0.038421668112277985, 0.10197843611240387, 0.02736414037644863]
DEBUG:rag_factory.services.database.postgres:Stored 2 chunks
INFO:rag_factory.strategies.indexing.vector_embedding:Database storage complete
------------------------------ Captured log call -------------------------------
INFO     rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:55 Starting VectorEmbeddingIndexing.process with 2 documents
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:61 Configuration: batch_size=32, chunk_size=200, overlap=50
INFO     rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:67 Using embedding service: AsyncEmbeddingWrapper
INFO     rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:70 Starting document chunking...
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:137 _chunk_documents called with 2 documents, chunk_size=200, overlap=50
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:146 Processing document 1/2: doc_id='eiffel_doc', text_length=112
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:158 Document eiffel_doc fits in single chunk (length=112 <= 200)
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:146 Processing document 2/2: doc_id='python_doc', text_length=128
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:158 Document python_doc fits in single chunk (length=128 <= 200)
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:220 _chunk_documents complete: total 2 chunks created
INFO     rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:72 Document chunking complete: created 2 chunks from 2 documents
INFO     rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:85 Starting embedding generation for 2 chunks in batches of 32...
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:94 Processing batch 1/1 with 2 texts
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:100 Batch 1/1 complete: generated 2 embeddings
INFO     rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:102 Embedding generation complete: created 2 embeddings
INFO     rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:105 Adding embeddings to chunks...
INFO     rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:109 Storing 2 chunks to database...
INFO     rag_factory.services.database.postgres:postgres.py:173 Ensured table test_chunks_real exists
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk eiffel_doc_0: embedding dims=384, first 3 values=[0.054607685655355453, 0.10627976804971695, 0.011374696157872677]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk python_doc_0: embedding dims=384, first 3 values=[0.038421668112277985, 0.10197843611240387, 0.02736414037644863]
DEBUG    rag_factory.services.database.postgres:postgres.py:241 Stored 2 chunks
INFO     rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:111 Database storage complete
--------------------------- Captured stderr teardown ---------------------------
INFO:rag_factory.services.database.postgres:Created synchronous SQLAlchemy engine for contexts
INFO:rag_factory.services.database.postgres:Closed PostgreSQL async connection pool
INFO:rag_factory.services.database.postgres:Disposed synchronous SQLAlchemy engine
DEBUG:rag_factory.services.database.postgres:Cleared DatabaseContext cache
---------------------------- Captured log teardown -----------------------------
INFO     rag_factory.services.database.postgres:postgres.py:492 Created synchronous SQLAlchemy engine for contexts
INFO     rag_factory.services.database.postgres:postgres.py:577 Closed PostgreSQL async connection pool
INFO     rag_factory.services.database.postgres:postgres.py:583 Disposed synchronous SQLAlchemy engine
DEBUG    rag_factory.services.database.postgres:postgres.py:586 Cleared DatabaseContext cache
________________________ test_multiple_document_batches ________________________

real_db_service = <rag_factory.services.database.postgres.PostgresqlDatabaseService object at 0x788cd98fa7e0>
real_embedding_service = <tests.integration_real.conftest.real_embedding_service.<locals>.AsyncEmbeddingWrapper object at 0x788cd98fb9e0>

    @pytest.mark.real_integration
    @pytest.mark.requires_postgres
    @pytest.mark.requires_embeddings
    @pytest.mark.asyncio
    async def test_multiple_document_batches(real_db_service, real_embedding_service):
        """Test indexing multiple batches of documents."""
        from rag_factory.strategies.indexing.vector_embedding import VectorEmbeddingIndexing
        from rag_factory.strategies.base import StrategyConfig
        from rag_factory.services.dependencies import StrategyDependencies
        from rag_factory.core.indexing_interface import IndexingContext
        from dataclasses import asdict
    
        config = StrategyConfig(strategy_name="batch_test", chunk_size=100, chunk_overlap=20)
        dependencies = StrategyDependencies(
            embedding_service=real_embedding_service,
            database_service=real_db_service
        )
        strategy = VectorEmbeddingIndexing(config=asdict(config), dependencies=dependencies)
    
        # Create indexing context
        context = IndexingContext(database_service=real_db_service, config=asdict(config))
    
        # Index first batch
        batch1 = [
            {"text": f"Document {i} from batch 1", "id": f"batch1_doc{i}", "metadata": {"batch": 1}}
            for i in range(5)
        ]
>       await strategy.process(batch1, context)

tests/integration_real/test_end_to_end_real.py:208: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
rag_factory/strategies/indexing/vector_embedding.py:113: in process
    embedding_dim = self.deps.embedding_service.get_dimension()
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tests.integration_real.conftest.real_embedding_service.<locals>.AsyncEmbeddingWrapper object at 0x788cd98fb9e0>

    def get_dimension(self):
        """Get embedding dimension."""
>       return self.provider.get_dimension()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
E       AttributeError: 'ONNXLocalProvider' object has no attribute 'get_dimension'. Did you mean: 'get_dimensions'?

tests/integration_real/conftest.py:217: AttributeError
---------------------------- Captured stderr setup -----------------------------
DEBUG:asyncio:Using selector: EpollSelector
INFO:rag_factory.services.database.postgres:Initialized PostgreSQL service for 192.168.56.1:5432/rag_test
INFO:rag_factory.services.embedding.providers.onnx_local:Loading ONNX model: Xenova/all-MiniLM-L6-v2
INFO:rag_factory.services.utils.onnx_utils:Using model from EMBEDDING_MODEL_NAME env: Xenova/all-MiniLM-L6-v2
INFO:rag_factory.services.utils.onnx_utils:Using cached ONNX model: models/embeddings/Xenova_all-MiniLM-L6-v2/onnx/model.onnx
INFO:rag_factory.services.utils.onnx_utils:Created ONNX session with providers: ['CPUExecutionProvider']
INFO:rag_factory.services.utils.onnx_utils:Model has 3 inputs and 1 outputs
DEBUG:rag_factory.services.utils.onnx_utils:  Input: input_ids, shape: ['batch_size', 'sequence_length'], type: tensor(int64)
DEBUG:rag_factory.services.utils.onnx_utils:  Input: attention_mask, shape: ['batch_size', 'sequence_length'], type: tensor(int64)
DEBUG:rag_factory.services.utils.onnx_utils:  Input: token_type_ids, shape: ['batch_size', 'sequence_length'], type: tensor(int64)
DEBUG:rag_factory.services.utils.onnx_utils:  Output: last_hidden_state, shape: ['batch_size', 'sequence_length', 384], type: tensor(float)
INFO:rag_factory.services.utils.onnx_utils:Model validation passed
INFO:rag_factory.services.embedding.providers.onnx_local:Loaded tokenizer from models/embeddings/Xenova_all-MiniLM-L6-v2/tokenizer.json
INFO:rag_factory.services.embedding.providers.onnx_local:Loaded ONNX model Xenova/all-MiniLM-L6-v2 with 384 dimensions
------------------------------ Captured log setup ------------------------------
DEBUG    asyncio:selector_events.py:64 Using selector: EpollSelector
INFO     rag_factory.services.database.postgres:postgres.py:121 Initialized PostgreSQL service for 192.168.56.1:5432/rag_test
INFO     rag_factory.services.embedding.providers.onnx_local:onnx_local.py:111 Loading ONNX model: Xenova/all-MiniLM-L6-v2
INFO     rag_factory.services.utils.onnx_utils:onnx_utils.py:90 Using model from EMBEDDING_MODEL_NAME env: Xenova/all-MiniLM-L6-v2
INFO     rag_factory.services.utils.onnx_utils:onnx_utils.py:113 Using cached ONNX model: models/embeddings/Xenova_all-MiniLM-L6-v2/onnx/model.onnx
INFO     rag_factory.services.utils.onnx_utils:onnx_utils.py:211 Created ONNX session with providers: ['CPUExecutionProvider']
INFO     rag_factory.services.utils.onnx_utils:onnx_utils.py:243 Model has 3 inputs and 1 outputs
DEBUG    rag_factory.services.utils.onnx_utils:onnx_utils.py:247   Input: input_ids, shape: ['batch_size', 'sequence_length'], type: tensor(int64)
DEBUG    rag_factory.services.utils.onnx_utils:onnx_utils.py:247   Input: attention_mask, shape: ['batch_size', 'sequence_length'], type: tensor(int64)
DEBUG    rag_factory.services.utils.onnx_utils:onnx_utils.py:247   Input: token_type_ids, shape: ['batch_size', 'sequence_length'], type: tensor(int64)
DEBUG    rag_factory.services.utils.onnx_utils:onnx_utils.py:251   Output: last_hidden_state, shape: ['batch_size', 'sequence_length', 384], type: tensor(float)
INFO     rag_factory.services.utils.onnx_utils:onnx_utils.py:273 Model validation passed
INFO     rag_factory.services.embedding.providers.onnx_local:onnx_local.py:168 Loaded tokenizer from models/embeddings/Xenova_all-MiniLM-L6-v2/tokenizer.json
INFO     rag_factory.services.embedding.providers.onnx_local:onnx_local.py:177 Loaded ONNX model Xenova/all-MiniLM-L6-v2 with 384 dimensions
----------------------------- Captured stderr call -----------------------------
INFO:rag_factory.strategies.indexing.vector_embedding:Starting VectorEmbeddingIndexing.process with 5 documents
DEBUG:rag_factory.strategies.indexing.vector_embedding:Configuration: batch_size=32, chunk_size=100, overlap=50
INFO:rag_factory.strategies.indexing.vector_embedding:Using embedding service: AsyncEmbeddingWrapper
INFO:rag_factory.strategies.indexing.vector_embedding:Starting document chunking...
DEBUG:rag_factory.strategies.indexing.vector_embedding:_chunk_documents called with 5 documents, chunk_size=100, overlap=50
DEBUG:rag_factory.strategies.indexing.vector_embedding:Processing document 1/5: doc_id='batch1_doc0', text_length=23
DEBUG:rag_factory.strategies.indexing.vector_embedding:Document batch1_doc0 fits in single chunk (length=23 <= 100)
DEBUG:rag_factory.strategies.indexing.vector_embedding:Processing document 2/5: doc_id='batch1_doc1', text_length=23
DEBUG:rag_factory.strategies.indexing.vector_embedding:Document batch1_doc1 fits in single chunk (length=23 <= 100)
DEBUG:rag_factory.strategies.indexing.vector_embedding:Processing document 3/5: doc_id='batch1_doc2', text_length=23
DEBUG:rag_factory.strategies.indexing.vector_embedding:Document batch1_doc2 fits in single chunk (length=23 <= 100)
DEBUG:rag_factory.strategies.indexing.vector_embedding:Processing document 4/5: doc_id='batch1_doc3', text_length=23
DEBUG:rag_factory.strategies.indexing.vector_embedding:Document batch1_doc3 fits in single chunk (length=23 <= 100)
DEBUG:rag_factory.strategies.indexing.vector_embedding:Processing document 5/5: doc_id='batch1_doc4', text_length=23
DEBUG:rag_factory.strategies.indexing.vector_embedding:Document batch1_doc4 fits in single chunk (length=23 <= 100)
DEBUG:rag_factory.strategies.indexing.vector_embedding:_chunk_documents complete: total 5 chunks created
INFO:rag_factory.strategies.indexing.vector_embedding:Document chunking complete: created 5 chunks from 5 documents
INFO:rag_factory.strategies.indexing.vector_embedding:Starting embedding generation for 5 chunks in batches of 32...
DEBUG:rag_factory.strategies.indexing.vector_embedding:Processing batch 1/1 with 5 texts
DEBUG:rag_factory.strategies.indexing.vector_embedding:Batch 1/1 complete: generated 5 embeddings
INFO:rag_factory.strategies.indexing.vector_embedding:Embedding generation complete: created 5 embeddings
INFO:rag_factory.strategies.indexing.vector_embedding:Adding embeddings to chunks...
INFO:rag_factory.strategies.indexing.vector_embedding:Storing 5 chunks to database...
INFO:rag_factory.services.database.postgres:Ensured table test_chunks_real exists
DEBUG:rag_factory.services.database.postgres:Storing chunk batch1_doc0_0: embedding dims=384, first 3 values=[0.020688241347670555, 0.12281712144613266, 0.06246292218565941]
DEBUG:rag_factory.services.database.postgres:Storing chunk batch1_doc1_0: embedding dims=384, first 3 values=[0.01468011736869812, 0.10811313986778259, 0.06262077391147614]
DEBUG:rag_factory.services.database.postgres:Storing chunk batch1_doc2_0: embedding dims=384, first 3 values=[0.02036687545478344, 0.10672854632139206, 0.06972838938236237]
DEBUG:rag_factory.services.database.postgres:Storing chunk batch1_doc3_0: embedding dims=384, first 3 values=[0.017245156690478325, 0.10236173123121262, 0.045331232249736786]
DEBUG:rag_factory.services.database.postgres:Storing chunk batch1_doc4_0: embedding dims=384, first 3 values=[0.037890903651714325, 0.1138983741402626, 0.060195472091436386]
DEBUG:rag_factory.services.database.postgres:Stored 5 chunks
INFO:rag_factory.strategies.indexing.vector_embedding:Database storage complete
------------------------------ Captured log call -------------------------------
INFO     rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:55 Starting VectorEmbeddingIndexing.process with 5 documents
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:61 Configuration: batch_size=32, chunk_size=100, overlap=50
INFO     rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:67 Using embedding service: AsyncEmbeddingWrapper
INFO     rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:70 Starting document chunking...
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:137 _chunk_documents called with 5 documents, chunk_size=100, overlap=50
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:146 Processing document 1/5: doc_id='batch1_doc0', text_length=23
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:158 Document batch1_doc0 fits in single chunk (length=23 <= 100)
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:146 Processing document 2/5: doc_id='batch1_doc1', text_length=23
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:158 Document batch1_doc1 fits in single chunk (length=23 <= 100)
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:146 Processing document 3/5: doc_id='batch1_doc2', text_length=23
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:158 Document batch1_doc2 fits in single chunk (length=23 <= 100)
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:146 Processing document 4/5: doc_id='batch1_doc3', text_length=23
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:158 Document batch1_doc3 fits in single chunk (length=23 <= 100)
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:146 Processing document 5/5: doc_id='batch1_doc4', text_length=23
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:158 Document batch1_doc4 fits in single chunk (length=23 <= 100)
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:220 _chunk_documents complete: total 5 chunks created
INFO     rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:72 Document chunking complete: created 5 chunks from 5 documents
INFO     rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:85 Starting embedding generation for 5 chunks in batches of 32...
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:94 Processing batch 1/1 with 5 texts
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:100 Batch 1/1 complete: generated 5 embeddings
INFO     rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:102 Embedding generation complete: created 5 embeddings
INFO     rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:105 Adding embeddings to chunks...
INFO     rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:109 Storing 5 chunks to database...
INFO     rag_factory.services.database.postgres:postgres.py:173 Ensured table test_chunks_real exists
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk batch1_doc0_0: embedding dims=384, first 3 values=[0.020688241347670555, 0.12281712144613266, 0.06246292218565941]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk batch1_doc1_0: embedding dims=384, first 3 values=[0.01468011736869812, 0.10811313986778259, 0.06262077391147614]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk batch1_doc2_0: embedding dims=384, first 3 values=[0.02036687545478344, 0.10672854632139206, 0.06972838938236237]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk batch1_doc3_0: embedding dims=384, first 3 values=[0.017245156690478325, 0.10236173123121262, 0.045331232249736786]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk batch1_doc4_0: embedding dims=384, first 3 values=[0.037890903651714325, 0.1138983741402626, 0.060195472091436386]
DEBUG    rag_factory.services.database.postgres:postgres.py:241 Stored 5 chunks
INFO     rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:111 Database storage complete
--------------------------- Captured stderr teardown ---------------------------
INFO:rag_factory.services.database.postgres:Created synchronous SQLAlchemy engine for contexts
INFO:rag_factory.services.database.postgres:Closed PostgreSQL async connection pool
INFO:rag_factory.services.database.postgres:Disposed synchronous SQLAlchemy engine
DEBUG:rag_factory.services.database.postgres:Cleared DatabaseContext cache
---------------------------- Captured log teardown -----------------------------
INFO     rag_factory.services.database.postgres:postgres.py:492 Created synchronous SQLAlchemy engine for contexts
INFO     rag_factory.services.database.postgres:postgres.py:577 Closed PostgreSQL async connection pool
INFO     rag_factory.services.database.postgres:postgres.py:583 Disposed synchronous SQLAlchemy engine
DEBUG    rag_factory.services.database.postgres:postgres.py:586 Cleared DatabaseContext cache
_________________________ test_large_document_indexing _________________________

real_db_service = <rag_factory.services.database.postgres.PostgresqlDatabaseService object at 0x788cd99210a0>
real_embedding_service = <tests.integration_real.conftest.real_embedding_service.<locals>.AsyncEmbeddingWrapper object at 0x788cd9921550>

    @pytest.mark.real_integration
    @pytest.mark.requires_postgres
    @pytest.mark.requires_embeddings
    @pytest.mark.slow
    @pytest.mark.asyncio
    async def test_large_document_indexing(real_db_service, real_embedding_service):
        """Test indexing a large document."""
        from rag_factory.strategies.indexing.vector_embedding import VectorEmbeddingIndexing
        from rag_factory.strategies.base import StrategyConfig
        from rag_factory.services.dependencies import StrategyDependencies
        from rag_factory.core.indexing_interface import IndexingContext
        from dataclasses import asdict
    
        # Create a large document
        large_text = " ".join([f"This is sentence number {i}." for i in range(1000)])
    
        document = {
            "text": large_text,
            "id": "large_doc",
            "metadata": {"source": "large_doc.txt", "size": "large"}
        }
    
        config = StrategyConfig(strategy_name="large_doc_test", chunk_size=200, chunk_overlap=50)
        dependencies = StrategyDependencies(
            embedding_service=real_embedding_service,
            database_service=real_db_service
        )
        strategy = VectorEmbeddingIndexing(config=asdict(config), dependencies=dependencies)
    
        # Create indexing context
        context = IndexingContext(database_service=real_db_service, config=asdict(config))
    
        # Index the large document
>       await strategy.process([document], context)

tests/integration_real/test_end_to_end_real.py:288: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
rag_factory/strategies/indexing/vector_embedding.py:113: in process
    embedding_dim = self.deps.embedding_service.get_dimension()
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tests.integration_real.conftest.real_embedding_service.<locals>.AsyncEmbeddingWrapper object at 0x788cd9921550>

    def get_dimension(self):
        """Get embedding dimension."""
>       return self.provider.get_dimension()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
E       AttributeError: 'ONNXLocalProvider' object has no attribute 'get_dimension'. Did you mean: 'get_dimensions'?

tests/integration_real/conftest.py:217: AttributeError
---------------------------- Captured stderr setup -----------------------------
DEBUG:asyncio:Using selector: EpollSelector
INFO:rag_factory.services.database.postgres:Initialized PostgreSQL service for 192.168.56.1:5432/rag_test
INFO:rag_factory.services.embedding.providers.onnx_local:Loading ONNX model: Xenova/all-MiniLM-L6-v2
INFO:rag_factory.services.utils.onnx_utils:Using model from EMBEDDING_MODEL_NAME env: Xenova/all-MiniLM-L6-v2
INFO:rag_factory.services.utils.onnx_utils:Using cached ONNX model: models/embeddings/Xenova_all-MiniLM-L6-v2/onnx/model.onnx
INFO:rag_factory.services.utils.onnx_utils:Created ONNX session with providers: ['CPUExecutionProvider']
INFO:rag_factory.services.utils.onnx_utils:Model has 3 inputs and 1 outputs
DEBUG:rag_factory.services.utils.onnx_utils:  Input: input_ids, shape: ['batch_size', 'sequence_length'], type: tensor(int64)
DEBUG:rag_factory.services.utils.onnx_utils:  Input: attention_mask, shape: ['batch_size', 'sequence_length'], type: tensor(int64)
DEBUG:rag_factory.services.utils.onnx_utils:  Input: token_type_ids, shape: ['batch_size', 'sequence_length'], type: tensor(int64)
DEBUG:rag_factory.services.utils.onnx_utils:  Output: last_hidden_state, shape: ['batch_size', 'sequence_length', 384], type: tensor(float)
INFO:rag_factory.services.utils.onnx_utils:Model validation passed
INFO:rag_factory.services.embedding.providers.onnx_local:Loaded tokenizer from models/embeddings/Xenova_all-MiniLM-L6-v2/tokenizer.json
INFO:rag_factory.services.embedding.providers.onnx_local:Loaded ONNX model Xenova/all-MiniLM-L6-v2 with 384 dimensions
------------------------------ Captured log setup ------------------------------
DEBUG    asyncio:selector_events.py:64 Using selector: EpollSelector
INFO     rag_factory.services.database.postgres:postgres.py:121 Initialized PostgreSQL service for 192.168.56.1:5432/rag_test
INFO     rag_factory.services.embedding.providers.onnx_local:onnx_local.py:111 Loading ONNX model: Xenova/all-MiniLM-L6-v2
INFO     rag_factory.services.utils.onnx_utils:onnx_utils.py:90 Using model from EMBEDDING_MODEL_NAME env: Xenova/all-MiniLM-L6-v2
INFO     rag_factory.services.utils.onnx_utils:onnx_utils.py:113 Using cached ONNX model: models/embeddings/Xenova_all-MiniLM-L6-v2/onnx/model.onnx
INFO     rag_factory.services.utils.onnx_utils:onnx_utils.py:211 Created ONNX session with providers: ['CPUExecutionProvider']
INFO     rag_factory.services.utils.onnx_utils:onnx_utils.py:243 Model has 3 inputs and 1 outputs
DEBUG    rag_factory.services.utils.onnx_utils:onnx_utils.py:247   Input: input_ids, shape: ['batch_size', 'sequence_length'], type: tensor(int64)
DEBUG    rag_factory.services.utils.onnx_utils:onnx_utils.py:247   Input: attention_mask, shape: ['batch_size', 'sequence_length'], type: tensor(int64)
DEBUG    rag_factory.services.utils.onnx_utils:onnx_utils.py:247   Input: token_type_ids, shape: ['batch_size', 'sequence_length'], type: tensor(int64)
DEBUG    rag_factory.services.utils.onnx_utils:onnx_utils.py:251   Output: last_hidden_state, shape: ['batch_size', 'sequence_length', 384], type: tensor(float)
INFO     rag_factory.services.utils.onnx_utils:onnx_utils.py:273 Model validation passed
INFO     rag_factory.services.embedding.providers.onnx_local:onnx_local.py:168 Loaded tokenizer from models/embeddings/Xenova_all-MiniLM-L6-v2/tokenizer.json
INFO     rag_factory.services.embedding.providers.onnx_local:onnx_local.py:177 Loaded ONNX model Xenova/all-MiniLM-L6-v2 with 384 dimensions
----------------------------- Captured stderr call -----------------------------
INFO:rag_factory.strategies.indexing.vector_embedding:Starting VectorEmbeddingIndexing.process with 1 documents
DEBUG:rag_factory.strategies.indexing.vector_embedding:Configuration: batch_size=32, chunk_size=200, overlap=50
INFO:rag_factory.strategies.indexing.vector_embedding:Using embedding service: AsyncEmbeddingWrapper
INFO:rag_factory.strategies.indexing.vector_embedding:Starting document chunking...
DEBUG:rag_factory.strategies.indexing.vector_embedding:_chunk_documents called with 1 documents, chunk_size=200, overlap=50
DEBUG:rag_factory.strategies.indexing.vector_embedding:Processing document 1/1: doc_id='large_doc', text_length=28889
DEBUG:rag_factory.strategies.indexing.vector_embedding:Document large_doc requires chunking (length=28889 > 200)
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 200 -> 196
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 0 for doc large_doc: start=0, end=196, chunk_length=196
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 346 -> 342
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 1 for doc large_doc: start=146, end=342, chunk_length=196
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 492 -> 489
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 2 for doc large_doc: start=292, end=489, chunk_length=197
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 639 -> 638
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 3 for doc large_doc: start=439, end=638, chunk_length=199
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 788 -> 781
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 4 for doc large_doc: start=588, end=781, chunk_length=193
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 931 -> 930
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 5 for doc large_doc: start=731, end=930, chunk_length=199
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 1080 -> 1077
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 6 for doc large_doc: start=880, end=1077, chunk_length=197
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 1227 -> 1226
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 7 for doc large_doc: start=1027, end=1226, chunk_length=199
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 1376 -> 1369
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 8 for doc large_doc: start=1176, end=1369, chunk_length=193
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 1519 -> 1518
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 9 for doc large_doc: start=1319, end=1518, chunk_length=199
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 1668 -> 1665
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 10 for doc large_doc: start=1468, end=1665, chunk_length=197
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 1815 -> 1814
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 11 for doc large_doc: start=1615, end=1814, chunk_length=199
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 1964 -> 1957
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 12 for doc large_doc: start=1764, end=1957, chunk_length=193
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 2107 -> 2106
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 13 for doc large_doc: start=1907, end=2106, chunk_length=199
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 2256 -> 2253
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 14 for doc large_doc: start=2056, end=2253, chunk_length=197
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 2403 -> 2402
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 15 for doc large_doc: start=2203, end=2402, chunk_length=199
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 2552 -> 2545
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 16 for doc large_doc: start=2352, end=2545, chunk_length=193
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 2695 -> 2694
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 17 for doc large_doc: start=2495, end=2694, chunk_length=199
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 2844 -> 2842
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 18 for doc large_doc: start=2644, end=2842, chunk_length=198
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 2992 -> 2987
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 19 for doc large_doc: start=2792, end=2987, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 3137 -> 3132
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 20 for doc large_doc: start=2937, end=3132, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 3282 -> 3277
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 21 for doc large_doc: start=3082, end=3277, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 3427 -> 3422
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 22 for doc large_doc: start=3227, end=3422, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 3572 -> 3567
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 23 for doc large_doc: start=3372, end=3567, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 3717 -> 3712
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 24 for doc large_doc: start=3517, end=3712, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 3862 -> 3857
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 25 for doc large_doc: start=3662, end=3857, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 4007 -> 4002
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 26 for doc large_doc: start=3807, end=4002, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 4152 -> 4147
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 27 for doc large_doc: start=3952, end=4147, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 4297 -> 4292
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 28 for doc large_doc: start=4097, end=4292, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 4442 -> 4437
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 29 for doc large_doc: start=4242, end=4437, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 4587 -> 4582
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 30 for doc large_doc: start=4387, end=4582, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 4732 -> 4727
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 31 for doc large_doc: start=4532, end=4727, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 4877 -> 4872
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 32 for doc large_doc: start=4677, end=4872, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 5022 -> 5017
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 33 for doc large_doc: start=4822, end=5017, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 5167 -> 5162
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 34 for doc large_doc: start=4967, end=5162, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 5312 -> 5307
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 35 for doc large_doc: start=5112, end=5307, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 5457 -> 5452
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 36 for doc large_doc: start=5257, end=5452, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 5602 -> 5597
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 37 for doc large_doc: start=5402, end=5597, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 5747 -> 5742
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 38 for doc large_doc: start=5547, end=5742, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 5892 -> 5887
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 39 for doc large_doc: start=5692, end=5887, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 6037 -> 6032
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 40 for doc large_doc: start=5837, end=6032, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 6182 -> 6177
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 41 for doc large_doc: start=5982, end=6177, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 6327 -> 6322
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 42 for doc large_doc: start=6127, end=6322, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 6472 -> 6467
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 43 for doc large_doc: start=6272, end=6467, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 6617 -> 6612
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 44 for doc large_doc: start=6417, end=6612, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 6762 -> 6757
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 45 for doc large_doc: start=6562, end=6757, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 6907 -> 6902
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 46 for doc large_doc: start=6707, end=6902, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 7052 -> 7047
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 47 for doc large_doc: start=6852, end=7047, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 7197 -> 7192
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 48 for doc large_doc: start=6997, end=7192, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 7342 -> 7337
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 49 for doc large_doc: start=7142, end=7337, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 7487 -> 7482
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 50 for doc large_doc: start=7287, end=7482, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 7632 -> 7627
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 51 for doc large_doc: start=7432, end=7627, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 7777 -> 7772
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 52 for doc large_doc: start=7577, end=7772, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 7922 -> 7917
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 53 for doc large_doc: start=7722, end=7917, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 8067 -> 8062
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 54 for doc large_doc: start=7867, end=8062, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 8212 -> 8207
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 55 for doc large_doc: start=8012, end=8207, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 8357 -> 8352
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 56 for doc large_doc: start=8157, end=8352, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 8502 -> 8497
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 57 for doc large_doc: start=8302, end=8497, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 8647 -> 8642
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 58 for doc large_doc: start=8447, end=8642, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 8792 -> 8787
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 59 for doc large_doc: start=8592, end=8787, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 8937 -> 8932
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 60 for doc large_doc: start=8737, end=8932, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 9082 -> 9077
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 61 for doc large_doc: start=8882, end=9077, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 9227 -> 9222
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 62 for doc large_doc: start=9027, end=9222, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 9372 -> 9367
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 63 for doc large_doc: start=9172, end=9367, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 9517 -> 9512
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 64 for doc large_doc: start=9317, end=9512, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 9662 -> 9657
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 65 for doc large_doc: start=9462, end=9657, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 9807 -> 9802
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 66 for doc large_doc: start=9607, end=9802, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 9952 -> 9947
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 67 for doc large_doc: start=9752, end=9947, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 10097 -> 10092
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 68 for doc large_doc: start=9897, end=10092, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 10242 -> 10237
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 69 for doc large_doc: start=10042, end=10237, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 10387 -> 10382
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 70 for doc large_doc: start=10187, end=10382, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 10532 -> 10527
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 71 for doc large_doc: start=10332, end=10527, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 10677 -> 10672
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 72 for doc large_doc: start=10477, end=10672, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 10822 -> 10817
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 73 for doc large_doc: start=10622, end=10817, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 10967 -> 10962
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 74 for doc large_doc: start=10767, end=10962, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 11112 -> 11107
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 75 for doc large_doc: start=10912, end=11107, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 11257 -> 11252
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 76 for doc large_doc: start=11057, end=11252, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 11402 -> 11397
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 77 for doc large_doc: start=11202, end=11397, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 11547 -> 11542
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 78 for doc large_doc: start=11347, end=11542, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 11692 -> 11687
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 79 for doc large_doc: start=11492, end=11687, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 11837 -> 11832
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 80 for doc large_doc: start=11637, end=11832, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 11982 -> 11977
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 81 for doc large_doc: start=11782, end=11977, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 12127 -> 12122
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 82 for doc large_doc: start=11927, end=12122, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 12272 -> 12267
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 83 for doc large_doc: start=12072, end=12267, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 12417 -> 12412
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 84 for doc large_doc: start=12217, end=12412, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 12562 -> 12557
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 85 for doc large_doc: start=12362, end=12557, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 12707 -> 12702
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 86 for doc large_doc: start=12507, end=12702, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 12852 -> 12847
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 87 for doc large_doc: start=12652, end=12847, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 12997 -> 12992
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 88 for doc large_doc: start=12797, end=12992, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 13142 -> 13137
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 89 for doc large_doc: start=12942, end=13137, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 13287 -> 13282
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 90 for doc large_doc: start=13087, end=13282, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 13432 -> 13427
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 91 for doc large_doc: start=13232, end=13427, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 13577 -> 13572
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 92 for doc large_doc: start=13377, end=13572, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 13722 -> 13717
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 93 for doc large_doc: start=13522, end=13717, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 13867 -> 13862
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 94 for doc large_doc: start=13667, end=13862, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 14012 -> 14007
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 95 for doc large_doc: start=13812, end=14007, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 14157 -> 14152
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 96 for doc large_doc: start=13957, end=14152, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 14302 -> 14297
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 97 for doc large_doc: start=14102, end=14297, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 14447 -> 14442
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 98 for doc large_doc: start=14247, end=14442, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 14592 -> 14587
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 99 for doc large_doc: start=14392, end=14587, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 14737 -> 14732
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 100 for doc large_doc: start=14537, end=14732, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 14882 -> 14877
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 101 for doc large_doc: start=14682, end=14877, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 15027 -> 15022
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 102 for doc large_doc: start=14827, end=15022, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 15172 -> 15167
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 103 for doc large_doc: start=14972, end=15167, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 15317 -> 15312
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 104 for doc large_doc: start=15117, end=15312, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 15462 -> 15457
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 105 for doc large_doc: start=15262, end=15457, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 15607 -> 15602
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 106 for doc large_doc: start=15407, end=15602, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 15752 -> 15747
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 107 for doc large_doc: start=15552, end=15747, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 15897 -> 15892
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 108 for doc large_doc: start=15697, end=15892, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 16042 -> 16037
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 109 for doc large_doc: start=15842, end=16037, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 16187 -> 16182
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 110 for doc large_doc: start=15987, end=16182, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 16332 -> 16327
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 111 for doc large_doc: start=16132, end=16327, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 16477 -> 16472
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 112 for doc large_doc: start=16277, end=16472, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 16622 -> 16617
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 113 for doc large_doc: start=16422, end=16617, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 16767 -> 16762
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 114 for doc large_doc: start=16567, end=16762, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 16912 -> 16907
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 115 for doc large_doc: start=16712, end=16907, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 17057 -> 17052
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 116 for doc large_doc: start=16857, end=17052, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 17202 -> 17197
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 117 for doc large_doc: start=17002, end=17197, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 17347 -> 17342
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 118 for doc large_doc: start=17147, end=17342, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 17492 -> 17487
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 119 for doc large_doc: start=17292, end=17487, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 17637 -> 17632
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 120 for doc large_doc: start=17437, end=17632, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 17782 -> 17777
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 121 for doc large_doc: start=17582, end=17777, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 17927 -> 17922
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 122 for doc large_doc: start=17727, end=17922, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 18072 -> 18067
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 123 for doc large_doc: start=17872, end=18067, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 18217 -> 18212
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 124 for doc large_doc: start=18017, end=18212, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 18362 -> 18357
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 125 for doc large_doc: start=18162, end=18357, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 18507 -> 18502
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 126 for doc large_doc: start=18307, end=18502, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 18652 -> 18647
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 127 for doc large_doc: start=18452, end=18647, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 18797 -> 18792
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 128 for doc large_doc: start=18597, end=18792, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 18942 -> 18937
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 129 for doc large_doc: start=18742, end=18937, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 19087 -> 19082
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 130 for doc large_doc: start=18887, end=19082, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 19232 -> 19227
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 131 for doc large_doc: start=19032, end=19227, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 19377 -> 19372
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 132 for doc large_doc: start=19177, end=19372, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 19522 -> 19517
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 133 for doc large_doc: start=19322, end=19517, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 19667 -> 19662
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 134 for doc large_doc: start=19467, end=19662, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 19812 -> 19807
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 135 for doc large_doc: start=19612, end=19807, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 19957 -> 19952
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 136 for doc large_doc: start=19757, end=19952, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 20102 -> 20097
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 137 for doc large_doc: start=19902, end=20097, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 20247 -> 20242
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 138 for doc large_doc: start=20047, end=20242, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 20392 -> 20387
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 139 for doc large_doc: start=20192, end=20387, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 20537 -> 20532
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 140 for doc large_doc: start=20337, end=20532, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 20682 -> 20677
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 141 for doc large_doc: start=20482, end=20677, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 20827 -> 20822
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 142 for doc large_doc: start=20627, end=20822, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 20972 -> 20967
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 143 for doc large_doc: start=20772, end=20967, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 21117 -> 21112
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 144 for doc large_doc: start=20917, end=21112, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 21262 -> 21257
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 145 for doc large_doc: start=21062, end=21257, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 21407 -> 21402
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 146 for doc large_doc: start=21207, end=21402, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 21552 -> 21547
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 147 for doc large_doc: start=21352, end=21547, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 21697 -> 21692
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 148 for doc large_doc: start=21497, end=21692, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 21842 -> 21837
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 149 for doc large_doc: start=21642, end=21837, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 21987 -> 21982
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 150 for doc large_doc: start=21787, end=21982, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 22132 -> 22127
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 151 for doc large_doc: start=21932, end=22127, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 22277 -> 22272
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 152 for doc large_doc: start=22077, end=22272, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 22422 -> 22417
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 153 for doc large_doc: start=22222, end=22417, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 22567 -> 22562
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 154 for doc large_doc: start=22367, end=22562, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 22712 -> 22707
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 155 for doc large_doc: start=22512, end=22707, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 22857 -> 22852
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 156 for doc large_doc: start=22657, end=22852, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 23002 -> 22997
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 157 for doc large_doc: start=22802, end=22997, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 23147 -> 23142
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 158 for doc large_doc: start=22947, end=23142, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 23292 -> 23287
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 159 for doc large_doc: start=23092, end=23287, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 23437 -> 23432
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 160 for doc large_doc: start=23237, end=23432, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 23582 -> 23577
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 161 for doc large_doc: start=23382, end=23577, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 23727 -> 23722
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 162 for doc large_doc: start=23527, end=23722, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 23872 -> 23867
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 163 for doc large_doc: start=23672, end=23867, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 24017 -> 24012
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 164 for doc large_doc: start=23817, end=24012, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 24162 -> 24157
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 165 for doc large_doc: start=23962, end=24157, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 24307 -> 24302
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 166 for doc large_doc: start=24107, end=24302, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 24452 -> 24447
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 167 for doc large_doc: start=24252, end=24447, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 24597 -> 24592
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 168 for doc large_doc: start=24397, end=24592, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 24742 -> 24737
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 169 for doc large_doc: start=24542, end=24737, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 24887 -> 24882
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 170 for doc large_doc: start=24687, end=24882, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 25032 -> 25027
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 171 for doc large_doc: start=24832, end=25027, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 25177 -> 25172
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 172 for doc large_doc: start=24977, end=25172, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 25322 -> 25317
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 173 for doc large_doc: start=25122, end=25317, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 25467 -> 25462
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 174 for doc large_doc: start=25267, end=25462, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 25612 -> 25607
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 175 for doc large_doc: start=25412, end=25607, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 25757 -> 25752
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 176 for doc large_doc: start=25557, end=25752, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 25902 -> 25897
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 177 for doc large_doc: start=25702, end=25897, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 26047 -> 26042
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 178 for doc large_doc: start=25847, end=26042, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 26192 -> 26187
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 179 for doc large_doc: start=25992, end=26187, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 26337 -> 26332
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 180 for doc large_doc: start=26137, end=26332, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 26482 -> 26477
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 181 for doc large_doc: start=26282, end=26477, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 26627 -> 26622
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 182 for doc large_doc: start=26427, end=26622, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 26772 -> 26767
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 183 for doc large_doc: start=26572, end=26767, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 26917 -> 26912
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 184 for doc large_doc: start=26717, end=26912, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 27062 -> 27057
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 185 for doc large_doc: start=26862, end=27057, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 27207 -> 27202
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 186 for doc large_doc: start=27007, end=27202, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 27352 -> 27347
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 187 for doc large_doc: start=27152, end=27347, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 27497 -> 27492
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 188 for doc large_doc: start=27297, end=27492, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 27642 -> 27637
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 189 for doc large_doc: start=27442, end=27637, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 27787 -> 27782
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 190 for doc large_doc: start=27587, end=27782, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 27932 -> 27927
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 191 for doc large_doc: start=27732, end=27927, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 28077 -> 28072
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 192 for doc large_doc: start=27877, end=28072, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 28222 -> 28217
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 193 for doc large_doc: start=28022, end=28217, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 28367 -> 28362
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 194 for doc large_doc: start=28167, end=28362, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 28512 -> 28507
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 195 for doc large_doc: start=28312, end=28507, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 28657 -> 28652
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 196 for doc large_doc: start=28457, end=28652, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Adjusted chunk boundary at word break: 28802 -> 28797
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 197 for doc large_doc: start=28602, end=28797, chunk_length=195
DEBUG:rag_factory.strategies.indexing.vector_embedding:Creating chunk 198 for doc large_doc: start=28747, end=28889, chunk_length=142
DEBUG:rag_factory.strategies.indexing.vector_embedding:Document large_doc chunking complete: created 198 chunks
DEBUG:rag_factory.strategies.indexing.vector_embedding:_chunk_documents complete: total 199 chunks created
INFO:rag_factory.strategies.indexing.vector_embedding:Document chunking complete: created 199 chunks from 1 documents
INFO:rag_factory.strategies.indexing.vector_embedding:Starting embedding generation for 199 chunks in batches of 32...
DEBUG:rag_factory.strategies.indexing.vector_embedding:Processing batch 1/7 with 32 texts
DEBUG:rag_factory.strategies.indexing.vector_embedding:Batch 1/7 complete: generated 32 embeddings
DEBUG:rag_factory.strategies.indexing.vector_embedding:Processing batch 2/7 with 32 texts
DEBUG:rag_factory.strategies.indexing.vector_embedding:Batch 2/7 complete: generated 32 embeddings
DEBUG:rag_factory.strategies.indexing.vector_embedding:Processing batch 3/7 with 32 texts
DEBUG:rag_factory.strategies.indexing.vector_embedding:Batch 3/7 complete: generated 32 embeddings
DEBUG:rag_factory.strategies.indexing.vector_embedding:Processing batch 4/7 with 32 texts
DEBUG:rag_factory.strategies.indexing.vector_embedding:Batch 4/7 complete: generated 32 embeddings
DEBUG:rag_factory.strategies.indexing.vector_embedding:Processing batch 5/7 with 32 texts
DEBUG:rag_factory.strategies.indexing.vector_embedding:Batch 5/7 complete: generated 32 embeddings
DEBUG:rag_factory.strategies.indexing.vector_embedding:Processing batch 6/7 with 32 texts
DEBUG:rag_factory.strategies.indexing.vector_embedding:Batch 6/7 complete: generated 32 embeddings
DEBUG:rag_factory.strategies.indexing.vector_embedding:Processing batch 7/7 with 7 texts
DEBUG:rag_factory.strategies.indexing.vector_embedding:Batch 7/7 complete: generated 7 embeddings
INFO:rag_factory.strategies.indexing.vector_embedding:Embedding generation complete: created 199 embeddings
INFO:rag_factory.strategies.indexing.vector_embedding:Adding embeddings to chunks...
INFO:rag_factory.strategies.indexing.vector_embedding:Storing 199 chunks to database...
INFO:rag_factory.services.database.postgres:Ensured table test_chunks_real exists
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_0: embedding dims=384, first 3 values=[0.02799859642982483, 0.07309788465499878, 0.08444493263959885]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_1: embedding dims=384, first 3 values=[-0.0139410849660635, 0.06598219275474548, 0.11920242011547089]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_2: embedding dims=384, first 3 values=[0.0022691157646477222, 0.10726439207792282, 0.061405472457408905]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_3: embedding dims=384, first 3 values=[0.07219570130109787, 0.14062559604644775, 0.07474837452173233]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_4: embedding dims=384, first 3 values=[0.021203389391303062, 0.07583949714899063, 0.07818005979061127]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_5: embedding dims=384, first 3 values=[0.01640111766755581, 0.0774582102894783, 0.06611668318510056]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_6: embedding dims=384, first 3 values=[0.04800533503293991, 0.06695621460676193, 0.030410634353756905]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_7: embedding dims=384, first 3 values=[0.0871889740228653, 0.10403882712125778, 0.06079583615064621]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_8: embedding dims=384, first 3 values=[0.03813648968935013, 0.0785255953669548, 0.07808704674243927]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_9: embedding dims=384, first 3 values=[0.02351500652730465, 0.10453754663467407, 0.08586435765028]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_10: embedding dims=384, first 3 values=[0.03300342708826065, 0.09480496495962143, 0.04218963161110878]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_11: embedding dims=384, first 3 values=[0.06537987291812897, 0.11510927230119705, 0.045214295387268066]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_12: embedding dims=384, first 3 values=[0.03269461542367935, 0.08438222855329514, 0.028433557599782944]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_13: embedding dims=384, first 3 values=[0.03390435501933098, 0.10607118159532547, 0.04248868674039841]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_14: embedding dims=384, first 3 values=[0.05567469820380211, 0.10480788350105286, 0.014676382765173912]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_15: embedding dims=384, first 3 values=[0.079818956553936, 0.1366087645292282, 0.03948361054062843]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_16: embedding dims=384, first 3 values=[0.014349248260259628, 0.09319233149290085, 0.054950013756752014]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_17: embedding dims=384, first 3 values=[0.010572394356131554, 0.10219941288232803, 0.06961081176996231]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_18: embedding dims=384, first 3 values=[0.02662261389195919, 0.07669974118471146, 0.03837931528687477]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_19: embedding dims=384, first 3 values=[0.03581523895263672, 0.09170985966920853, 0.08957945555448532]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_20: embedding dims=384, first 3 values=[0.02938654273748398, 0.07855645567178726, 0.0908600389957428]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_21: embedding dims=384, first 3 values=[0.029597757384181023, 0.08094656467437744, 0.09083419293165207]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_22: embedding dims=384, first 3 values=[0.03294233977794647, 0.06987693905830383, 0.08495794981718063]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_23: embedding dims=384, first 3 values=[0.0321536622941494, 0.06634969264268875, 0.06766871362924576]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_24: embedding dims=384, first 3 values=[0.040591415017843246, 0.07279277592897415, 0.09102124720811844]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_25: embedding dims=384, first 3 values=[0.03316045552492142, 0.06924033910036087, 0.03581966459751129]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_26: embedding dims=384, first 3 values=[0.04316495731472969, 0.06539949774742126, 0.06817837059497833]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_27: embedding dims=384, first 3 values=[0.061653174459934235, 0.07251974940299988, 0.0719989463686943]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_28: embedding dims=384, first 3 values=[0.06796260178089142, 0.06484085321426392, 0.06806488335132599]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_29: embedding dims=384, first 3 values=[0.06058840826153755, 0.06581608951091766, 0.06057944521307945]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_30: embedding dims=384, first 3 values=[0.05921192467212677, 0.0720934122800827, 0.07255405187606812]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_31: embedding dims=384, first 3 values=[0.05864547938108444, 0.0717061460018158, 0.054329268634319305]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_32: embedding dims=384, first 3 values=[0.04882967099547386, 0.07170986384153366, 0.05883268266916275]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_33: embedding dims=384, first 3 values=[0.05481573939323425, 0.07852070033550262, 0.06043079122900963]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_34: embedding dims=384, first 3 values=[0.06448780000209808, 0.08334837853908539, 0.04369151592254639]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_35: embedding dims=384, first 3 values=[0.0597793273627758, 0.06624269485473633, 0.03874005377292633]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_36: embedding dims=384, first 3 values=[0.04176666960120201, 0.07626298815011978, 0.054040227085351944]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_37: embedding dims=384, first 3 values=[0.047304946929216385, 0.07470616698265076, 0.06839655339717865]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_38: embedding dims=384, first 3 values=[0.03825787454843521, 0.06625726073980331, 0.08175885677337646]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_39: embedding dims=384, first 3 values=[0.027880914509296417, 0.08104821294546127, 0.08248881995677948]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_40: embedding dims=384, first 3 values=[0.04197162762284279, 0.07139770686626434, 0.0711500272154808]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_41: embedding dims=384, first 3 values=[0.04299841448664665, 0.06510418653488159, 0.0783064141869545]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_42: embedding dims=384, first 3 values=[0.04417729750275612, 0.05328566953539848, 0.054516106843948364]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_43: embedding dims=384, first 3 values=[0.03953712433576584, 0.04744740203022957, 0.053272150456905365]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_44: embedding dims=384, first 3 values=[0.057374775409698486, 0.03679675981402397, 0.060882817953825]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_45: embedding dims=384, first 3 values=[0.05536071956157684, 0.05191948637366295, 0.06897880136966705]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_46: embedding dims=384, first 3 values=[0.062401704490184784, 0.044428128749132156, 0.05374114587903023]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_47: embedding dims=384, first 3 values=[0.05556502193212509, 0.0334104485809803, 0.060461390763521194]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_48: embedding dims=384, first 3 values=[0.0576971173286438, 0.042451296001672745, 0.07628981024026871]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_49: embedding dims=384, first 3 values=[0.03912993147969246, 0.021516870707273483, 0.08900687843561172]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_50: embedding dims=384, first 3 values=[0.05986965820193291, 0.053549591451883316, 0.07207790017127991]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_51: embedding dims=384, first 3 values=[0.05229760706424713, 0.039725933223962784, 0.057083502411842346]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_52: embedding dims=384, first 3 values=[0.06254798173904419, 0.01837681606411934, 0.03782834857702255]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_53: embedding dims=384, first 3 values=[0.05744225159287453, 0.03275202214717865, 0.04441174119710922]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_54: embedding dims=384, first 3 values=[0.03629129007458687, 0.038209669291973114, 0.047846805304288864]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_55: embedding dims=384, first 3 values=[0.04597241431474686, 0.02459808625280857, 0.03853052854537964]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_56: embedding dims=384, first 3 values=[0.04543692246079445, 0.0289131011813879, 0.039138443768024445]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_57: embedding dims=384, first 3 values=[0.04922495409846306, 0.03606795892119408, 0.03400880843400955]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_58: embedding dims=384, first 3 values=[0.06562797725200653, 0.06316075474023819, 0.040147945284843445]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_59: embedding dims=384, first 3 values=[0.040052276104688644, 0.04230505973100662, 0.040268346667289734]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_60: embedding dims=384, first 3 values=[0.041399139910936356, 0.03705893084406853, 0.038381993770599365]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_61: embedding dims=384, first 3 values=[0.01689511351287365, 0.045600343495607376, 0.013468494638800621]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_62: embedding dims=384, first 3 values=[0.03537115827202797, 0.048797138035297394, 0.034402817487716675]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_63: embedding dims=384, first 3 values=[0.056302815675735474, 0.05756403133273125, 0.028467122465372086]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_64: embedding dims=384, first 3 values=[0.06210287660360336, 0.05909991264343262, 0.05664077773690224]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_65: embedding dims=384, first 3 values=[0.04069298133254051, 0.0395379364490509, 0.033169884234666824]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_66: embedding dims=384, first 3 values=[0.06183839216828346, 0.04928991198539734, 0.05462897568941116]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_67: embedding dims=384, first 3 values=[0.061414238065481186, 0.06386692076921463, 0.061931952834129333]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_68: embedding dims=384, first 3 values=[0.05713982135057449, 0.04479861259460449, 0.0663968101143837]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_69: embedding dims=384, first 3 values=[0.06146388128399849, 0.044467743486166, 0.04876268282532692]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_70: embedding dims=384, first 3 values=[0.05277853086590767, 0.06631295382976532, 0.04667474702000618]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_71: embedding dims=384, first 3 values=[0.08091467618942261, 0.07267076522111893, 0.05002862587571144]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_72: embedding dims=384, first 3 values=[0.0779915526509285, 0.09485411643981934, 0.06546534597873688]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_73: embedding dims=384, first 3 values=[0.07346110790967941, 0.08109256625175476, 0.05915248766541481]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_74: embedding dims=384, first 3 values=[0.05988049879670143, 0.08843541145324707, 0.048802439123392105]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_75: embedding dims=384, first 3 values=[0.05957484245300293, 0.07920088618993759, 0.04933365061879158]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_76: embedding dims=384, first 3 values=[0.056501805782318115, 0.08753141760826111, 0.056395091116428375]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_77: embedding dims=384, first 3 values=[0.05415850132703781, 0.05244186148047447, 0.06690846383571625]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_78: embedding dims=384, first 3 values=[0.06347551941871643, 0.07561259716749191, 0.07688819617033005]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_79: embedding dims=384, first 3 values=[0.03563688322901726, 0.09431014209985733, 0.04793635755777359]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_80: embedding dims=384, first 3 values=[0.049551818519830704, 0.08614715188741684, 0.06923313438892365]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_81: embedding dims=384, first 3 values=[0.06580051779747009, 0.08184467256069183, 0.08877124637365341]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_82: embedding dims=384, first 3 values=[0.08290830254554749, 0.1039666160941124, 0.09504278004169464]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_83: embedding dims=384, first 3 values=[0.0700099989771843, 0.08336377888917923, 0.09908890724182129]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_84: embedding dims=384, first 3 values=[0.0620155856013298, 0.05696887895464897, 0.08209210634231567]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_85: embedding dims=384, first 3 values=[0.07563823461532593, 0.06361258774995804, 0.0835520476102829]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_86: embedding dims=384, first 3 values=[0.06641186028718948, 0.07308617234230042, 0.10028300434350967]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_87: embedding dims=384, first 3 values=[0.06780191510915756, 0.09449891746044159, 0.08667109906673431]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_88: embedding dims=384, first 3 values=[0.05360860377550125, 0.09493028372526169, 0.09627950191497803]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_89: embedding dims=384, first 3 values=[0.04793014004826546, 0.09371966123580933, 0.10649263858795166]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_90: embedding dims=384, first 3 values=[0.047467127442359924, 0.08958937972784042, 0.12026600539684296]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_91: embedding dims=384, first 3 values=[0.06085094437003136, 0.0745530053973198, 0.11594295501708984]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_92: embedding dims=384, first 3 values=[0.04707751050591469, 0.07452055811882019, 0.10850071161985397]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_93: embedding dims=384, first 3 values=[0.06207861751317978, 0.09152612835168839, 0.08744721859693527]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_94: embedding dims=384, first 3 values=[0.041991520673036575, 0.09601974487304688, 0.0977603867650032]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_95: embedding dims=384, first 3 values=[0.037084221839904785, 0.07961316406726837, 0.08506303280591965]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_96: embedding dims=384, first 3 values=[0.045742303133010864, 0.0719837099313736, 0.09607213735580444]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_97: embedding dims=384, first 3 values=[0.0641927719116211, 0.06934016942977905, 0.0929444432258606]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_98: embedding dims=384, first 3 values=[0.05749324709177017, 0.07895511388778687, 0.09942615777254105]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_99: embedding dims=384, first 3 values=[0.04388361796736717, 0.11700329184532166, 0.10487315058708191]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_100: embedding dims=384, first 3 values=[0.029495375230908394, 0.09621304273605347, 0.11193668842315674]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_101: embedding dims=384, first 3 values=[0.03438941016793251, 0.10077370703220367, 0.08598817139863968]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_102: embedding dims=384, first 3 values=[0.03487084060907364, 0.08155260980129242, 0.1099284216761589]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_103: embedding dims=384, first 3 values=[0.042852602899074554, 0.07981035113334656, 0.08021589368581772]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_104: embedding dims=384, first 3 values=[0.038736533373594284, 0.08702614158391953, 0.08602805435657501]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_105: embedding dims=384, first 3 values=[0.041772883385419846, 0.0717642679810524, 0.08836731314659119]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_106: embedding dims=384, first 3 values=[0.02638341672718525, 0.06800669431686401, 0.09031352400779724]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_107: embedding dims=384, first 3 values=[0.056437186896800995, 0.0663534626364708, 0.06596779078245163]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_108: embedding dims=384, first 3 values=[0.05901017040014267, 0.07676289975643158, 0.0871170163154602]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_109: embedding dims=384, first 3 values=[0.04393480718135834, 0.0930902361869812, 0.09751082956790924]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_110: embedding dims=384, first 3 values=[0.030718712136149406, 0.09876242280006409, 0.09978006035089493]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_111: embedding dims=384, first 3 values=[0.03930163010954857, 0.08308698236942291, 0.06605853140354156]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_112: embedding dims=384, first 3 values=[0.0444658137857914, 0.08068957924842834, 0.0830368846654892]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_113: embedding dims=384, first 3 values=[0.05689337104558945, 0.09734117239713669, 0.07443275302648544]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_114: embedding dims=384, first 3 values=[0.058436766266822815, 0.1008530706167221, 0.056029364466667175]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_115: embedding dims=384, first 3 values=[0.046354569494724274, 0.08400298655033112, 0.06280882656574249]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_116: embedding dims=384, first 3 values=[0.020743006840348244, 0.07663532346487045, 0.07348199933767319]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_117: embedding dims=384, first 3 values=[0.037092965096235275, 0.08821660280227661, 0.042946312576532364]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_118: embedding dims=384, first 3 values=[0.04183557629585266, 0.09480571001768112, 0.07291025668382645]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_119: embedding dims=384, first 3 values=[0.027599642053246498, 0.09879688173532486, 0.062257371842861176]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_120: embedding dims=384, first 3 values=[0.031233517453074455, 0.09125825762748718, 0.07107032835483551]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_121: embedding dims=384, first 3 values=[0.03252055495977402, 0.06529763340950012, 0.0662023276090622]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_122: embedding dims=384, first 3 values=[0.023644944652915, 0.07567659020423889, 0.08239981532096863]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_123: embedding dims=384, first 3 values=[0.03495215252041817, 0.059841930866241455, 0.03128759562969208]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_124: embedding dims=384, first 3 values=[0.03994378075003624, 0.053062256425619125, 0.033934131264686584]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_125: embedding dims=384, first 3 values=[0.0571044497191906, 0.08191687613725662, 0.037482596933841705]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_126: embedding dims=384, first 3 values=[0.052012719213962555, 0.08646715432405472, 0.05396003648638725]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_127: embedding dims=384, first 3 values=[0.05755317211151123, 0.08977280557155609, 0.047951024025678635]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_128: embedding dims=384, first 3 values=[0.054531507194042206, 0.08755907416343689, 0.0785646140575409]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_129: embedding dims=384, first 3 values=[0.04748564958572388, 0.10881052166223526, 0.06993895769119263]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_130: embedding dims=384, first 3 values=[0.05481251701712608, 0.10296542942523956, 0.0752071887254715]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_131: embedding dims=384, first 3 values=[0.035628434270620346, 0.08551368117332458, 0.059930820018053055]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_132: embedding dims=384, first 3 values=[0.034795742481946945, 0.0846843421459198, 0.07641337066888809]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_133: embedding dims=384, first 3 values=[0.04584648460149765, 0.07075534015893936, 0.03971853852272034]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_134: embedding dims=384, first 3 values=[0.034351300448179245, 0.0781259834766388, 0.06097361445426941]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_135: embedding dims=384, first 3 values=[0.04021989926695824, 0.07449168711900711, 0.04177013784646988]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_136: embedding dims=384, first 3 values=[0.03637266531586647, 0.07384133338928223, 0.05255225673317909]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_137: embedding dims=384, first 3 values=[0.04756097123026848, 0.0578000545501709, 0.044591400772333145]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_138: embedding dims=384, first 3 values=[0.03784135729074478, 0.07579529285430908, 0.06360068917274475]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_139: embedding dims=384, first 3 values=[0.03992689028382301, 0.09460800886154175, 0.0632225051522255]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_140: embedding dims=384, first 3 values=[0.040887266397476196, 0.1057654544711113, 0.0787011906504631]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_141: embedding dims=384, first 3 values=[0.038958046585321426, 0.08740153908729553, 0.05598273500800133]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_142: embedding dims=384, first 3 values=[0.04307069256901741, 0.08570872247219086, 0.060146793723106384]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_143: embedding dims=384, first 3 values=[0.049970027059316635, 0.08411448448896408, 0.029143361374735832]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_144: embedding dims=384, first 3 values=[0.06347507983446121, 0.09306997060775757, 0.04791926220059395]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_145: embedding dims=384, first 3 values=[0.07326909154653549, 0.08527520298957825, 0.03347651660442352]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_146: embedding dims=384, first 3 values=[0.058104682713747025, 0.08717762678861618, 0.06434350460767746]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_147: embedding dims=384, first 3 values=[0.06776569783687592, 0.08643902093172073, 0.08409053087234497]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_148: embedding dims=384, first 3 values=[0.07855751365423203, 0.08684998005628586, 0.08111438900232315]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_149: embedding dims=384, first 3 values=[0.05998489260673523, 0.09302318841218948, 0.060315996408462524]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_150: embedding dims=384, first 3 values=[0.06029912456870079, 0.08714394271373749, 0.056854601949453354]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_151: embedding dims=384, first 3 values=[0.05332668125629425, 0.0689835399389267, 0.02765589952468872]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_152: embedding dims=384, first 3 values=[0.052180349826812744, 0.0879182294011116, 0.06496557593345642]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_153: embedding dims=384, first 3 values=[0.056033361703157425, 0.08971858024597168, 0.05633337423205376]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_154: embedding dims=384, first 3 values=[0.03805241733789444, 0.08916663378477097, 0.0685155838727951]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_155: embedding dims=384, first 3 values=[0.03454281762242317, 0.07953984290361404, 0.047914057970047]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_156: embedding dims=384, first 3 values=[0.044410232454538345, 0.092562735080719, 0.06584126502275467]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_157: embedding dims=384, first 3 values=[0.07049035280942917, 0.09858564287424088, 0.044911254197359085]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_158: embedding dims=384, first 3 values=[0.05461394414305687, 0.09648794680833817, 0.06356121599674225]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_159: embedding dims=384, first 3 values=[0.03913748636841774, 0.1083637997508049, 0.07766425609588623]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_160: embedding dims=384, first 3 values=[0.05031329393386841, 0.10584673285484314, 0.09824246168136597]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_161: embedding dims=384, first 3 values=[0.06316039711236954, 0.09420958161354065, 0.07818207144737244]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_162: embedding dims=384, first 3 values=[0.0547931045293808, 0.0899651050567627, 0.08803552389144897]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_163: embedding dims=384, first 3 values=[0.051902011036872864, 0.08613883703947067, 0.07810606062412262]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_164: embedding dims=384, first 3 values=[0.048549309372901917, 0.08660398423671722, 0.07711447030305862]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_165: embedding dims=384, first 3 values=[0.05738482624292374, 0.09553901851177216, 0.0754084587097168]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_166: embedding dims=384, first 3 values=[0.05705498903989792, 0.0881194993853569, 0.0856529250741005]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_167: embedding dims=384, first 3 values=[0.06258475035429001, 0.07664714753627777, 0.07290809601545334]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_168: embedding dims=384, first 3 values=[0.04996940493583679, 0.0877370536327362, 0.08361713588237762]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_169: embedding dims=384, first 3 values=[0.05089958384633064, 0.09716206043958664, 0.07451826333999634]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_170: embedding dims=384, first 3 values=[0.04961540549993515, 0.0883483961224556, 0.07719160616397858]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_171: embedding dims=384, first 3 values=[0.048394251614809036, 0.08222777396440506, 0.08335249125957489]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_172: embedding dims=384, first 3 values=[0.03209099546074867, 0.08349171280860901, 0.08742135018110275]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_173: embedding dims=384, first 3 values=[0.01941528543829918, 0.07858337461948395, 0.04787720367312431]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_174: embedding dims=384, first 3 values=[0.019583359360694885, 0.07630378007888794, 0.05995912104845047]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_175: embedding dims=384, first 3 values=[0.03018631599843502, 0.08183880895376205, 0.07280443608760834]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_176: embedding dims=384, first 3 values=[0.026782849803566933, 0.08385859429836273, 0.07504476606845856]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_177: embedding dims=384, first 3 values=[0.052243467420339584, 0.08332924544811249, 0.07534981518983841]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_178: embedding dims=384, first 3 values=[0.04263107851147652, 0.08638178557157516, 0.08572060614824295]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_179: embedding dims=384, first 3 values=[0.03660052642226219, 0.09716479480266571, 0.07899808138608932]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_180: embedding dims=384, first 3 values=[0.02831585519015789, 0.09647950530052185, 0.09386352449655533]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_181: embedding dims=384, first 3 values=[0.03447021171450615, 0.0825837031006813, 0.08707156777381897]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_182: embedding dims=384, first 3 values=[0.04877365753054619, 0.09100881218910217, 0.08010300993919373]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_183: embedding dims=384, first 3 values=[0.05880918726325035, 0.06306438148021698, 0.0545368567109108]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_184: embedding dims=384, first 3 values=[0.041646506637334824, 0.061413027346134186, 0.06664086133241653]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_185: embedding dims=384, first 3 values=[0.022899746894836426, 0.060370299965143204, 0.06428156048059464]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_186: embedding dims=384, first 3 values=[0.03713822737336159, 0.07313980162143707, 0.07793962210416794]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_187: embedding dims=384, first 3 values=[0.06351441890001297, 0.0763571560382843, 0.05232197046279907]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_188: embedding dims=384, first 3 values=[0.04615190997719765, 0.08075902611017227, 0.06888587772846222]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_189: embedding dims=384, first 3 values=[0.03657031059265137, 0.07753241062164307, 0.07534211874008179]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_190: embedding dims=384, first 3 values=[0.039439406245946884, 0.08145742118358612, 0.08726637065410614]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_191: embedding dims=384, first 3 values=[0.052269816398620605, 0.06961918622255325, 0.06848636269569397]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_192: embedding dims=384, first 3 values=[0.04742748662829399, 0.07627754658460617, 0.08272907882928848]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_193: embedding dims=384, first 3 values=[0.05314631015062332, 0.06688307970762253, 0.06785435229539871]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_194: embedding dims=384, first 3 values=[0.050144262611866, 0.0625569075345993, 0.0728619322180748]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_195: embedding dims=384, first 3 values=[0.04729757085442543, 0.07525894790887833, 0.0796288475394249]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_196: embedding dims=384, first 3 values=[0.04460558295249939, 0.08437354117631912, 0.0923139676451683]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_197: embedding dims=384, first 3 values=[0.04857679829001427, 0.06417775899171829, 0.07488103210926056]
DEBUG:rag_factory.services.database.postgres:Storing chunk large_doc_198: embedding dims=384, first 3 values=[0.03292453661561012, 0.07108371704816818, 0.08879712969064713]
DEBUG:rag_factory.services.database.postgres:Stored 199 chunks
INFO:rag_factory.strategies.indexing.vector_embedding:Database storage complete
------------------------------ Captured log call -------------------------------
INFO     rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:55 Starting VectorEmbeddingIndexing.process with 1 documents
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:61 Configuration: batch_size=32, chunk_size=200, overlap=50
INFO     rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:67 Using embedding service: AsyncEmbeddingWrapper
INFO     rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:70 Starting document chunking...
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:137 _chunk_documents called with 1 documents, chunk_size=200, overlap=50
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:146 Processing document 1/1: doc_id='large_doc', text_length=28889
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:167 Document large_doc requires chunking (length=28889 > 200)
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 200 -> 196
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 0 for doc large_doc: start=0, end=196, chunk_length=196
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 346 -> 342
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 1 for doc large_doc: start=146, end=342, chunk_length=196
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 492 -> 489
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 2 for doc large_doc: start=292, end=489, chunk_length=197
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 639 -> 638
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 3 for doc large_doc: start=439, end=638, chunk_length=199
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 788 -> 781
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 4 for doc large_doc: start=588, end=781, chunk_length=193
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 931 -> 930
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 5 for doc large_doc: start=731, end=930, chunk_length=199
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 1080 -> 1077
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 6 for doc large_doc: start=880, end=1077, chunk_length=197
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 1227 -> 1226
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 7 for doc large_doc: start=1027, end=1226, chunk_length=199
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 1376 -> 1369
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 8 for doc large_doc: start=1176, end=1369, chunk_length=193
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 1519 -> 1518
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 9 for doc large_doc: start=1319, end=1518, chunk_length=199
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 1668 -> 1665
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 10 for doc large_doc: start=1468, end=1665, chunk_length=197
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 1815 -> 1814
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 11 for doc large_doc: start=1615, end=1814, chunk_length=199
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 1964 -> 1957
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 12 for doc large_doc: start=1764, end=1957, chunk_length=193
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 2107 -> 2106
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 13 for doc large_doc: start=1907, end=2106, chunk_length=199
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 2256 -> 2253
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 14 for doc large_doc: start=2056, end=2253, chunk_length=197
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 2403 -> 2402
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 15 for doc large_doc: start=2203, end=2402, chunk_length=199
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 2552 -> 2545
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 16 for doc large_doc: start=2352, end=2545, chunk_length=193
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 2695 -> 2694
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 17 for doc large_doc: start=2495, end=2694, chunk_length=199
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 2844 -> 2842
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 18 for doc large_doc: start=2644, end=2842, chunk_length=198
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 2992 -> 2987
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 19 for doc large_doc: start=2792, end=2987, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 3137 -> 3132
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 20 for doc large_doc: start=2937, end=3132, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 3282 -> 3277
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 21 for doc large_doc: start=3082, end=3277, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 3427 -> 3422
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 22 for doc large_doc: start=3227, end=3422, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 3572 -> 3567
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 23 for doc large_doc: start=3372, end=3567, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 3717 -> 3712
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 24 for doc large_doc: start=3517, end=3712, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 3862 -> 3857
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 25 for doc large_doc: start=3662, end=3857, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 4007 -> 4002
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 26 for doc large_doc: start=3807, end=4002, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 4152 -> 4147
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 27 for doc large_doc: start=3952, end=4147, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 4297 -> 4292
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 28 for doc large_doc: start=4097, end=4292, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 4442 -> 4437
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 29 for doc large_doc: start=4242, end=4437, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 4587 -> 4582
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 30 for doc large_doc: start=4387, end=4582, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 4732 -> 4727
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 31 for doc large_doc: start=4532, end=4727, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 4877 -> 4872
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 32 for doc large_doc: start=4677, end=4872, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 5022 -> 5017
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 33 for doc large_doc: start=4822, end=5017, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 5167 -> 5162
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 34 for doc large_doc: start=4967, end=5162, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 5312 -> 5307
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 35 for doc large_doc: start=5112, end=5307, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 5457 -> 5452
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 36 for doc large_doc: start=5257, end=5452, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 5602 -> 5597
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 37 for doc large_doc: start=5402, end=5597, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 5747 -> 5742
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 38 for doc large_doc: start=5547, end=5742, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 5892 -> 5887
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 39 for doc large_doc: start=5692, end=5887, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 6037 -> 6032
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 40 for doc large_doc: start=5837, end=6032, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 6182 -> 6177
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 41 for doc large_doc: start=5982, end=6177, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 6327 -> 6322
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 42 for doc large_doc: start=6127, end=6322, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 6472 -> 6467
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 43 for doc large_doc: start=6272, end=6467, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 6617 -> 6612
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 44 for doc large_doc: start=6417, end=6612, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 6762 -> 6757
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 45 for doc large_doc: start=6562, end=6757, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 6907 -> 6902
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 46 for doc large_doc: start=6707, end=6902, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 7052 -> 7047
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 47 for doc large_doc: start=6852, end=7047, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 7197 -> 7192
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 48 for doc large_doc: start=6997, end=7192, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 7342 -> 7337
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 49 for doc large_doc: start=7142, end=7337, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 7487 -> 7482
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 50 for doc large_doc: start=7287, end=7482, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 7632 -> 7627
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 51 for doc large_doc: start=7432, end=7627, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 7777 -> 7772
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 52 for doc large_doc: start=7577, end=7772, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 7922 -> 7917
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 53 for doc large_doc: start=7722, end=7917, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 8067 -> 8062
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 54 for doc large_doc: start=7867, end=8062, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 8212 -> 8207
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 55 for doc large_doc: start=8012, end=8207, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 8357 -> 8352
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 56 for doc large_doc: start=8157, end=8352, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 8502 -> 8497
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 57 for doc large_doc: start=8302, end=8497, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 8647 -> 8642
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 58 for doc large_doc: start=8447, end=8642, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 8792 -> 8787
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 59 for doc large_doc: start=8592, end=8787, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 8937 -> 8932
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 60 for doc large_doc: start=8737, end=8932, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 9082 -> 9077
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 61 for doc large_doc: start=8882, end=9077, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 9227 -> 9222
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 62 for doc large_doc: start=9027, end=9222, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 9372 -> 9367
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 63 for doc large_doc: start=9172, end=9367, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 9517 -> 9512
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 64 for doc large_doc: start=9317, end=9512, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 9662 -> 9657
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 65 for doc large_doc: start=9462, end=9657, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 9807 -> 9802
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 66 for doc large_doc: start=9607, end=9802, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 9952 -> 9947
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 67 for doc large_doc: start=9752, end=9947, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 10097 -> 10092
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 68 for doc large_doc: start=9897, end=10092, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 10242 -> 10237
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 69 for doc large_doc: start=10042, end=10237, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 10387 -> 10382
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 70 for doc large_doc: start=10187, end=10382, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 10532 -> 10527
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 71 for doc large_doc: start=10332, end=10527, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 10677 -> 10672
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 72 for doc large_doc: start=10477, end=10672, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 10822 -> 10817
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 73 for doc large_doc: start=10622, end=10817, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 10967 -> 10962
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 74 for doc large_doc: start=10767, end=10962, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 11112 -> 11107
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 75 for doc large_doc: start=10912, end=11107, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 11257 -> 11252
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 76 for doc large_doc: start=11057, end=11252, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 11402 -> 11397
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 77 for doc large_doc: start=11202, end=11397, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 11547 -> 11542
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 78 for doc large_doc: start=11347, end=11542, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 11692 -> 11687
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 79 for doc large_doc: start=11492, end=11687, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 11837 -> 11832
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 80 for doc large_doc: start=11637, end=11832, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 11982 -> 11977
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 81 for doc large_doc: start=11782, end=11977, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 12127 -> 12122
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 82 for doc large_doc: start=11927, end=12122, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 12272 -> 12267
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 83 for doc large_doc: start=12072, end=12267, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 12417 -> 12412
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 84 for doc large_doc: start=12217, end=12412, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 12562 -> 12557
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 85 for doc large_doc: start=12362, end=12557, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 12707 -> 12702
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 86 for doc large_doc: start=12507, end=12702, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 12852 -> 12847
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 87 for doc large_doc: start=12652, end=12847, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 12997 -> 12992
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 88 for doc large_doc: start=12797, end=12992, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 13142 -> 13137
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 89 for doc large_doc: start=12942, end=13137, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 13287 -> 13282
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 90 for doc large_doc: start=13087, end=13282, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 13432 -> 13427
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 91 for doc large_doc: start=13232, end=13427, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 13577 -> 13572
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 92 for doc large_doc: start=13377, end=13572, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 13722 -> 13717
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 93 for doc large_doc: start=13522, end=13717, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 13867 -> 13862
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 94 for doc large_doc: start=13667, end=13862, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 14012 -> 14007
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 95 for doc large_doc: start=13812, end=14007, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 14157 -> 14152
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 96 for doc large_doc: start=13957, end=14152, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 14302 -> 14297
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 97 for doc large_doc: start=14102, end=14297, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 14447 -> 14442
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 98 for doc large_doc: start=14247, end=14442, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 14592 -> 14587
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 99 for doc large_doc: start=14392, end=14587, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 14737 -> 14732
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 100 for doc large_doc: start=14537, end=14732, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 14882 -> 14877
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 101 for doc large_doc: start=14682, end=14877, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 15027 -> 15022
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 102 for doc large_doc: start=14827, end=15022, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 15172 -> 15167
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 103 for doc large_doc: start=14972, end=15167, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 15317 -> 15312
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 104 for doc large_doc: start=15117, end=15312, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 15462 -> 15457
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 105 for doc large_doc: start=15262, end=15457, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 15607 -> 15602
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 106 for doc large_doc: start=15407, end=15602, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 15752 -> 15747
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 107 for doc large_doc: start=15552, end=15747, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 15897 -> 15892
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 108 for doc large_doc: start=15697, end=15892, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 16042 -> 16037
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 109 for doc large_doc: start=15842, end=16037, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 16187 -> 16182
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 110 for doc large_doc: start=15987, end=16182, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 16332 -> 16327
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 111 for doc large_doc: start=16132, end=16327, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 16477 -> 16472
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 112 for doc large_doc: start=16277, end=16472, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 16622 -> 16617
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 113 for doc large_doc: start=16422, end=16617, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 16767 -> 16762
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 114 for doc large_doc: start=16567, end=16762, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 16912 -> 16907
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 115 for doc large_doc: start=16712, end=16907, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 17057 -> 17052
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 116 for doc large_doc: start=16857, end=17052, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 17202 -> 17197
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 117 for doc large_doc: start=17002, end=17197, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 17347 -> 17342
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 118 for doc large_doc: start=17147, end=17342, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 17492 -> 17487
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 119 for doc large_doc: start=17292, end=17487, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 17637 -> 17632
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 120 for doc large_doc: start=17437, end=17632, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 17782 -> 17777
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 121 for doc large_doc: start=17582, end=17777, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 17927 -> 17922
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 122 for doc large_doc: start=17727, end=17922, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 18072 -> 18067
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 123 for doc large_doc: start=17872, end=18067, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 18217 -> 18212
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 124 for doc large_doc: start=18017, end=18212, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 18362 -> 18357
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 125 for doc large_doc: start=18162, end=18357, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 18507 -> 18502
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 126 for doc large_doc: start=18307, end=18502, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 18652 -> 18647
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 127 for doc large_doc: start=18452, end=18647, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 18797 -> 18792
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 128 for doc large_doc: start=18597, end=18792, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 18942 -> 18937
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 129 for doc large_doc: start=18742, end=18937, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 19087 -> 19082
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 130 for doc large_doc: start=18887, end=19082, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 19232 -> 19227
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 131 for doc large_doc: start=19032, end=19227, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 19377 -> 19372
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 132 for doc large_doc: start=19177, end=19372, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 19522 -> 19517
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 133 for doc large_doc: start=19322, end=19517, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 19667 -> 19662
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 134 for doc large_doc: start=19467, end=19662, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 19812 -> 19807
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 135 for doc large_doc: start=19612, end=19807, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 19957 -> 19952
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 136 for doc large_doc: start=19757, end=19952, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 20102 -> 20097
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 137 for doc large_doc: start=19902, end=20097, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 20247 -> 20242
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 138 for doc large_doc: start=20047, end=20242, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 20392 -> 20387
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 139 for doc large_doc: start=20192, end=20387, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 20537 -> 20532
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 140 for doc large_doc: start=20337, end=20532, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 20682 -> 20677
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 141 for doc large_doc: start=20482, end=20677, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 20827 -> 20822
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 142 for doc large_doc: start=20627, end=20822, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 20972 -> 20967
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 143 for doc large_doc: start=20772, end=20967, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 21117 -> 21112
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 144 for doc large_doc: start=20917, end=21112, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 21262 -> 21257
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 145 for doc large_doc: start=21062, end=21257, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 21407 -> 21402
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 146 for doc large_doc: start=21207, end=21402, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 21552 -> 21547
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 147 for doc large_doc: start=21352, end=21547, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 21697 -> 21692
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 148 for doc large_doc: start=21497, end=21692, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 21842 -> 21837
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 149 for doc large_doc: start=21642, end=21837, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 21987 -> 21982
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 150 for doc large_doc: start=21787, end=21982, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 22132 -> 22127
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 151 for doc large_doc: start=21932, end=22127, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 22277 -> 22272
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 152 for doc large_doc: start=22077, end=22272, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 22422 -> 22417
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 153 for doc large_doc: start=22222, end=22417, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 22567 -> 22562
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 154 for doc large_doc: start=22367, end=22562, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 22712 -> 22707
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 155 for doc large_doc: start=22512, end=22707, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 22857 -> 22852
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 156 for doc large_doc: start=22657, end=22852, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 23002 -> 22997
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 157 for doc large_doc: start=22802, end=22997, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 23147 -> 23142
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 158 for doc large_doc: start=22947, end=23142, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 23292 -> 23287
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 159 for doc large_doc: start=23092, end=23287, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 23437 -> 23432
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 160 for doc large_doc: start=23237, end=23432, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 23582 -> 23577
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 161 for doc large_doc: start=23382, end=23577, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 23727 -> 23722
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 162 for doc large_doc: start=23527, end=23722, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 23872 -> 23867
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 163 for doc large_doc: start=23672, end=23867, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 24017 -> 24012
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 164 for doc large_doc: start=23817, end=24012, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 24162 -> 24157
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 165 for doc large_doc: start=23962, end=24157, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 24307 -> 24302
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 166 for doc large_doc: start=24107, end=24302, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 24452 -> 24447
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 167 for doc large_doc: start=24252, end=24447, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 24597 -> 24592
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 168 for doc large_doc: start=24397, end=24592, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 24742 -> 24737
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 169 for doc large_doc: start=24542, end=24737, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 24887 -> 24882
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 170 for doc large_doc: start=24687, end=24882, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 25032 -> 25027
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 171 for doc large_doc: start=24832, end=25027, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 25177 -> 25172
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 172 for doc large_doc: start=24977, end=25172, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 25322 -> 25317
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 173 for doc large_doc: start=25122, end=25317, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 25467 -> 25462
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 174 for doc large_doc: start=25267, end=25462, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 25612 -> 25607
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 175 for doc large_doc: start=25412, end=25607, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 25757 -> 25752
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 176 for doc large_doc: start=25557, end=25752, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 25902 -> 25897
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 177 for doc large_doc: start=25702, end=25897, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 26047 -> 26042
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 178 for doc large_doc: start=25847, end=26042, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 26192 -> 26187
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 179 for doc large_doc: start=25992, end=26187, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 26337 -> 26332
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 180 for doc large_doc: start=26137, end=26332, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 26482 -> 26477
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 181 for doc large_doc: start=26282, end=26477, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 26627 -> 26622
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 182 for doc large_doc: start=26427, end=26622, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 26772 -> 26767
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 183 for doc large_doc: start=26572, end=26767, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 26917 -> 26912
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 184 for doc large_doc: start=26717, end=26912, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 27062 -> 27057
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 185 for doc large_doc: start=26862, end=27057, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 27207 -> 27202
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 186 for doc large_doc: start=27007, end=27202, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 27352 -> 27347
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 187 for doc large_doc: start=27152, end=27347, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 27497 -> 27492
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 188 for doc large_doc: start=27297, end=27492, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 27642 -> 27637
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 189 for doc large_doc: start=27442, end=27637, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 27787 -> 27782
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 190 for doc large_doc: start=27587, end=27782, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 27932 -> 27927
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 191 for doc large_doc: start=27732, end=27927, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 28077 -> 28072
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 192 for doc large_doc: start=27877, end=28072, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 28222 -> 28217
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 193 for doc large_doc: start=28022, end=28217, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 28367 -> 28362
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 194 for doc large_doc: start=28167, end=28362, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 28512 -> 28507
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 195 for doc large_doc: start=28312, end=28507, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 28657 -> 28652
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 196 for doc large_doc: start=28457, end=28652, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:189 Adjusted chunk boundary at word break: 28802 -> 28797
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 197 for doc large_doc: start=28602, end=28797, chunk_length=195
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:191 Creating chunk 198 for doc large_doc: start=28747, end=28889, chunk_length=142
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:218 Document large_doc chunking complete: created 198 chunks
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:220 _chunk_documents complete: total 199 chunks created
INFO     rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:72 Document chunking complete: created 199 chunks from 1 documents
INFO     rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:85 Starting embedding generation for 199 chunks in batches of 32...
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:94 Processing batch 1/7 with 32 texts
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:100 Batch 1/7 complete: generated 32 embeddings
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:94 Processing batch 2/7 with 32 texts
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:100 Batch 2/7 complete: generated 32 embeddings
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:94 Processing batch 3/7 with 32 texts
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:100 Batch 3/7 complete: generated 32 embeddings
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:94 Processing batch 4/7 with 32 texts
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:100 Batch 4/7 complete: generated 32 embeddings
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:94 Processing batch 5/7 with 32 texts
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:100 Batch 5/7 complete: generated 32 embeddings
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:94 Processing batch 6/7 with 32 texts
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:100 Batch 6/7 complete: generated 32 embeddings
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:94 Processing batch 7/7 with 7 texts
DEBUG    rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:100 Batch 7/7 complete: generated 7 embeddings
INFO     rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:102 Embedding generation complete: created 199 embeddings
INFO     rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:105 Adding embeddings to chunks...
INFO     rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:109 Storing 199 chunks to database...
INFO     rag_factory.services.database.postgres:postgres.py:173 Ensured table test_chunks_real exists
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_0: embedding dims=384, first 3 values=[0.02799859642982483, 0.07309788465499878, 0.08444493263959885]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_1: embedding dims=384, first 3 values=[-0.0139410849660635, 0.06598219275474548, 0.11920242011547089]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_2: embedding dims=384, first 3 values=[0.0022691157646477222, 0.10726439207792282, 0.061405472457408905]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_3: embedding dims=384, first 3 values=[0.07219570130109787, 0.14062559604644775, 0.07474837452173233]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_4: embedding dims=384, first 3 values=[0.021203389391303062, 0.07583949714899063, 0.07818005979061127]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_5: embedding dims=384, first 3 values=[0.01640111766755581, 0.0774582102894783, 0.06611668318510056]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_6: embedding dims=384, first 3 values=[0.04800533503293991, 0.06695621460676193, 0.030410634353756905]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_7: embedding dims=384, first 3 values=[0.0871889740228653, 0.10403882712125778, 0.06079583615064621]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_8: embedding dims=384, first 3 values=[0.03813648968935013, 0.0785255953669548, 0.07808704674243927]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_9: embedding dims=384, first 3 values=[0.02351500652730465, 0.10453754663467407, 0.08586435765028]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_10: embedding dims=384, first 3 values=[0.03300342708826065, 0.09480496495962143, 0.04218963161110878]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_11: embedding dims=384, first 3 values=[0.06537987291812897, 0.11510927230119705, 0.045214295387268066]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_12: embedding dims=384, first 3 values=[0.03269461542367935, 0.08438222855329514, 0.028433557599782944]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_13: embedding dims=384, first 3 values=[0.03390435501933098, 0.10607118159532547, 0.04248868674039841]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_14: embedding dims=384, first 3 values=[0.05567469820380211, 0.10480788350105286, 0.014676382765173912]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_15: embedding dims=384, first 3 values=[0.079818956553936, 0.1366087645292282, 0.03948361054062843]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_16: embedding dims=384, first 3 values=[0.014349248260259628, 0.09319233149290085, 0.054950013756752014]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_17: embedding dims=384, first 3 values=[0.010572394356131554, 0.10219941288232803, 0.06961081176996231]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_18: embedding dims=384, first 3 values=[0.02662261389195919, 0.07669974118471146, 0.03837931528687477]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_19: embedding dims=384, first 3 values=[0.03581523895263672, 0.09170985966920853, 0.08957945555448532]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_20: embedding dims=384, first 3 values=[0.02938654273748398, 0.07855645567178726, 0.0908600389957428]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_21: embedding dims=384, first 3 values=[0.029597757384181023, 0.08094656467437744, 0.09083419293165207]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_22: embedding dims=384, first 3 values=[0.03294233977794647, 0.06987693905830383, 0.08495794981718063]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_23: embedding dims=384, first 3 values=[0.0321536622941494, 0.06634969264268875, 0.06766871362924576]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_24: embedding dims=384, first 3 values=[0.040591415017843246, 0.07279277592897415, 0.09102124720811844]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_25: embedding dims=384, first 3 values=[0.03316045552492142, 0.06924033910036087, 0.03581966459751129]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_26: embedding dims=384, first 3 values=[0.04316495731472969, 0.06539949774742126, 0.06817837059497833]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_27: embedding dims=384, first 3 values=[0.061653174459934235, 0.07251974940299988, 0.0719989463686943]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_28: embedding dims=384, first 3 values=[0.06796260178089142, 0.06484085321426392, 0.06806488335132599]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_29: embedding dims=384, first 3 values=[0.06058840826153755, 0.06581608951091766, 0.06057944521307945]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_30: embedding dims=384, first 3 values=[0.05921192467212677, 0.0720934122800827, 0.07255405187606812]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_31: embedding dims=384, first 3 values=[0.05864547938108444, 0.0717061460018158, 0.054329268634319305]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_32: embedding dims=384, first 3 values=[0.04882967099547386, 0.07170986384153366, 0.05883268266916275]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_33: embedding dims=384, first 3 values=[0.05481573939323425, 0.07852070033550262, 0.06043079122900963]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_34: embedding dims=384, first 3 values=[0.06448780000209808, 0.08334837853908539, 0.04369151592254639]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_35: embedding dims=384, first 3 values=[0.0597793273627758, 0.06624269485473633, 0.03874005377292633]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_36: embedding dims=384, first 3 values=[0.04176666960120201, 0.07626298815011978, 0.054040227085351944]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_37: embedding dims=384, first 3 values=[0.047304946929216385, 0.07470616698265076, 0.06839655339717865]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_38: embedding dims=384, first 3 values=[0.03825787454843521, 0.06625726073980331, 0.08175885677337646]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_39: embedding dims=384, first 3 values=[0.027880914509296417, 0.08104821294546127, 0.08248881995677948]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_40: embedding dims=384, first 3 values=[0.04197162762284279, 0.07139770686626434, 0.0711500272154808]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_41: embedding dims=384, first 3 values=[0.04299841448664665, 0.06510418653488159, 0.0783064141869545]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_42: embedding dims=384, first 3 values=[0.04417729750275612, 0.05328566953539848, 0.054516106843948364]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_43: embedding dims=384, first 3 values=[0.03953712433576584, 0.04744740203022957, 0.053272150456905365]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_44: embedding dims=384, first 3 values=[0.057374775409698486, 0.03679675981402397, 0.060882817953825]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_45: embedding dims=384, first 3 values=[0.05536071956157684, 0.05191948637366295, 0.06897880136966705]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_46: embedding dims=384, first 3 values=[0.062401704490184784, 0.044428128749132156, 0.05374114587903023]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_47: embedding dims=384, first 3 values=[0.05556502193212509, 0.0334104485809803, 0.060461390763521194]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_48: embedding dims=384, first 3 values=[0.0576971173286438, 0.042451296001672745, 0.07628981024026871]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_49: embedding dims=384, first 3 values=[0.03912993147969246, 0.021516870707273483, 0.08900687843561172]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_50: embedding dims=384, first 3 values=[0.05986965820193291, 0.053549591451883316, 0.07207790017127991]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_51: embedding dims=384, first 3 values=[0.05229760706424713, 0.039725933223962784, 0.057083502411842346]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_52: embedding dims=384, first 3 values=[0.06254798173904419, 0.01837681606411934, 0.03782834857702255]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_53: embedding dims=384, first 3 values=[0.05744225159287453, 0.03275202214717865, 0.04441174119710922]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_54: embedding dims=384, first 3 values=[0.03629129007458687, 0.038209669291973114, 0.047846805304288864]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_55: embedding dims=384, first 3 values=[0.04597241431474686, 0.02459808625280857, 0.03853052854537964]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_56: embedding dims=384, first 3 values=[0.04543692246079445, 0.0289131011813879, 0.039138443768024445]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_57: embedding dims=384, first 3 values=[0.04922495409846306, 0.03606795892119408, 0.03400880843400955]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_58: embedding dims=384, first 3 values=[0.06562797725200653, 0.06316075474023819, 0.040147945284843445]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_59: embedding dims=384, first 3 values=[0.040052276104688644, 0.04230505973100662, 0.040268346667289734]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_60: embedding dims=384, first 3 values=[0.041399139910936356, 0.03705893084406853, 0.038381993770599365]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_61: embedding dims=384, first 3 values=[0.01689511351287365, 0.045600343495607376, 0.013468494638800621]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_62: embedding dims=384, first 3 values=[0.03537115827202797, 0.048797138035297394, 0.034402817487716675]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_63: embedding dims=384, first 3 values=[0.056302815675735474, 0.05756403133273125, 0.028467122465372086]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_64: embedding dims=384, first 3 values=[0.06210287660360336, 0.05909991264343262, 0.05664077773690224]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_65: embedding dims=384, first 3 values=[0.04069298133254051, 0.0395379364490509, 0.033169884234666824]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_66: embedding dims=384, first 3 values=[0.06183839216828346, 0.04928991198539734, 0.05462897568941116]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_67: embedding dims=384, first 3 values=[0.061414238065481186, 0.06386692076921463, 0.061931952834129333]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_68: embedding dims=384, first 3 values=[0.05713982135057449, 0.04479861259460449, 0.0663968101143837]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_69: embedding dims=384, first 3 values=[0.06146388128399849, 0.044467743486166, 0.04876268282532692]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_70: embedding dims=384, first 3 values=[0.05277853086590767, 0.06631295382976532, 0.04667474702000618]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_71: embedding dims=384, first 3 values=[0.08091467618942261, 0.07267076522111893, 0.05002862587571144]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_72: embedding dims=384, first 3 values=[0.0779915526509285, 0.09485411643981934, 0.06546534597873688]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_73: embedding dims=384, first 3 values=[0.07346110790967941, 0.08109256625175476, 0.05915248766541481]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_74: embedding dims=384, first 3 values=[0.05988049879670143, 0.08843541145324707, 0.048802439123392105]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_75: embedding dims=384, first 3 values=[0.05957484245300293, 0.07920088618993759, 0.04933365061879158]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_76: embedding dims=384, first 3 values=[0.056501805782318115, 0.08753141760826111, 0.056395091116428375]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_77: embedding dims=384, first 3 values=[0.05415850132703781, 0.05244186148047447, 0.06690846383571625]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_78: embedding dims=384, first 3 values=[0.06347551941871643, 0.07561259716749191, 0.07688819617033005]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_79: embedding dims=384, first 3 values=[0.03563688322901726, 0.09431014209985733, 0.04793635755777359]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_80: embedding dims=384, first 3 values=[0.049551818519830704, 0.08614715188741684, 0.06923313438892365]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_81: embedding dims=384, first 3 values=[0.06580051779747009, 0.08184467256069183, 0.08877124637365341]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_82: embedding dims=384, first 3 values=[0.08290830254554749, 0.1039666160941124, 0.09504278004169464]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_83: embedding dims=384, first 3 values=[0.0700099989771843, 0.08336377888917923, 0.09908890724182129]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_84: embedding dims=384, first 3 values=[0.0620155856013298, 0.05696887895464897, 0.08209210634231567]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_85: embedding dims=384, first 3 values=[0.07563823461532593, 0.06361258774995804, 0.0835520476102829]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_86: embedding dims=384, first 3 values=[0.06641186028718948, 0.07308617234230042, 0.10028300434350967]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_87: embedding dims=384, first 3 values=[0.06780191510915756, 0.09449891746044159, 0.08667109906673431]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_88: embedding dims=384, first 3 values=[0.05360860377550125, 0.09493028372526169, 0.09627950191497803]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_89: embedding dims=384, first 3 values=[0.04793014004826546, 0.09371966123580933, 0.10649263858795166]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_90: embedding dims=384, first 3 values=[0.047467127442359924, 0.08958937972784042, 0.12026600539684296]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_91: embedding dims=384, first 3 values=[0.06085094437003136, 0.0745530053973198, 0.11594295501708984]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_92: embedding dims=384, first 3 values=[0.04707751050591469, 0.07452055811882019, 0.10850071161985397]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_93: embedding dims=384, first 3 values=[0.06207861751317978, 0.09152612835168839, 0.08744721859693527]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_94: embedding dims=384, first 3 values=[0.041991520673036575, 0.09601974487304688, 0.0977603867650032]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_95: embedding dims=384, first 3 values=[0.037084221839904785, 0.07961316406726837, 0.08506303280591965]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_96: embedding dims=384, first 3 values=[0.045742303133010864, 0.0719837099313736, 0.09607213735580444]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_97: embedding dims=384, first 3 values=[0.0641927719116211, 0.06934016942977905, 0.0929444432258606]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_98: embedding dims=384, first 3 values=[0.05749324709177017, 0.07895511388778687, 0.09942615777254105]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_99: embedding dims=384, first 3 values=[0.04388361796736717, 0.11700329184532166, 0.10487315058708191]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_100: embedding dims=384, first 3 values=[0.029495375230908394, 0.09621304273605347, 0.11193668842315674]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_101: embedding dims=384, first 3 values=[0.03438941016793251, 0.10077370703220367, 0.08598817139863968]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_102: embedding dims=384, first 3 values=[0.03487084060907364, 0.08155260980129242, 0.1099284216761589]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_103: embedding dims=384, first 3 values=[0.042852602899074554, 0.07981035113334656, 0.08021589368581772]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_104: embedding dims=384, first 3 values=[0.038736533373594284, 0.08702614158391953, 0.08602805435657501]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_105: embedding dims=384, first 3 values=[0.041772883385419846, 0.0717642679810524, 0.08836731314659119]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_106: embedding dims=384, first 3 values=[0.02638341672718525, 0.06800669431686401, 0.09031352400779724]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_107: embedding dims=384, first 3 values=[0.056437186896800995, 0.0663534626364708, 0.06596779078245163]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_108: embedding dims=384, first 3 values=[0.05901017040014267, 0.07676289975643158, 0.0871170163154602]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_109: embedding dims=384, first 3 values=[0.04393480718135834, 0.0930902361869812, 0.09751082956790924]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_110: embedding dims=384, first 3 values=[0.030718712136149406, 0.09876242280006409, 0.09978006035089493]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_111: embedding dims=384, first 3 values=[0.03930163010954857, 0.08308698236942291, 0.06605853140354156]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_112: embedding dims=384, first 3 values=[0.0444658137857914, 0.08068957924842834, 0.0830368846654892]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_113: embedding dims=384, first 3 values=[0.05689337104558945, 0.09734117239713669, 0.07443275302648544]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_114: embedding dims=384, first 3 values=[0.058436766266822815, 0.1008530706167221, 0.056029364466667175]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_115: embedding dims=384, first 3 values=[0.046354569494724274, 0.08400298655033112, 0.06280882656574249]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_116: embedding dims=384, first 3 values=[0.020743006840348244, 0.07663532346487045, 0.07348199933767319]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_117: embedding dims=384, first 3 values=[0.037092965096235275, 0.08821660280227661, 0.042946312576532364]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_118: embedding dims=384, first 3 values=[0.04183557629585266, 0.09480571001768112, 0.07291025668382645]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_119: embedding dims=384, first 3 values=[0.027599642053246498, 0.09879688173532486, 0.062257371842861176]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_120: embedding dims=384, first 3 values=[0.031233517453074455, 0.09125825762748718, 0.07107032835483551]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_121: embedding dims=384, first 3 values=[0.03252055495977402, 0.06529763340950012, 0.0662023276090622]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_122: embedding dims=384, first 3 values=[0.023644944652915, 0.07567659020423889, 0.08239981532096863]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_123: embedding dims=384, first 3 values=[0.03495215252041817, 0.059841930866241455, 0.03128759562969208]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_124: embedding dims=384, first 3 values=[0.03994378075003624, 0.053062256425619125, 0.033934131264686584]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_125: embedding dims=384, first 3 values=[0.0571044497191906, 0.08191687613725662, 0.037482596933841705]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_126: embedding dims=384, first 3 values=[0.052012719213962555, 0.08646715432405472, 0.05396003648638725]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_127: embedding dims=384, first 3 values=[0.05755317211151123, 0.08977280557155609, 0.047951024025678635]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_128: embedding dims=384, first 3 values=[0.054531507194042206, 0.08755907416343689, 0.0785646140575409]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_129: embedding dims=384, first 3 values=[0.04748564958572388, 0.10881052166223526, 0.06993895769119263]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_130: embedding dims=384, first 3 values=[0.05481251701712608, 0.10296542942523956, 0.0752071887254715]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_131: embedding dims=384, first 3 values=[0.035628434270620346, 0.08551368117332458, 0.059930820018053055]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_132: embedding dims=384, first 3 values=[0.034795742481946945, 0.0846843421459198, 0.07641337066888809]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_133: embedding dims=384, first 3 values=[0.04584648460149765, 0.07075534015893936, 0.03971853852272034]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_134: embedding dims=384, first 3 values=[0.034351300448179245, 0.0781259834766388, 0.06097361445426941]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_135: embedding dims=384, first 3 values=[0.04021989926695824, 0.07449168711900711, 0.04177013784646988]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_136: embedding dims=384, first 3 values=[0.03637266531586647, 0.07384133338928223, 0.05255225673317909]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_137: embedding dims=384, first 3 values=[0.04756097123026848, 0.0578000545501709, 0.044591400772333145]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_138: embedding dims=384, first 3 values=[0.03784135729074478, 0.07579529285430908, 0.06360068917274475]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_139: embedding dims=384, first 3 values=[0.03992689028382301, 0.09460800886154175, 0.0632225051522255]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_140: embedding dims=384, first 3 values=[0.040887266397476196, 0.1057654544711113, 0.0787011906504631]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_141: embedding dims=384, first 3 values=[0.038958046585321426, 0.08740153908729553, 0.05598273500800133]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_142: embedding dims=384, first 3 values=[0.04307069256901741, 0.08570872247219086, 0.060146793723106384]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_143: embedding dims=384, first 3 values=[0.049970027059316635, 0.08411448448896408, 0.029143361374735832]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_144: embedding dims=384, first 3 values=[0.06347507983446121, 0.09306997060775757, 0.04791926220059395]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_145: embedding dims=384, first 3 values=[0.07326909154653549, 0.08527520298957825, 0.03347651660442352]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_146: embedding dims=384, first 3 values=[0.058104682713747025, 0.08717762678861618, 0.06434350460767746]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_147: embedding dims=384, first 3 values=[0.06776569783687592, 0.08643902093172073, 0.08409053087234497]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_148: embedding dims=384, first 3 values=[0.07855751365423203, 0.08684998005628586, 0.08111438900232315]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_149: embedding dims=384, first 3 values=[0.05998489260673523, 0.09302318841218948, 0.060315996408462524]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_150: embedding dims=384, first 3 values=[0.06029912456870079, 0.08714394271373749, 0.056854601949453354]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_151: embedding dims=384, first 3 values=[0.05332668125629425, 0.0689835399389267, 0.02765589952468872]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_152: embedding dims=384, first 3 values=[0.052180349826812744, 0.0879182294011116, 0.06496557593345642]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_153: embedding dims=384, first 3 values=[0.056033361703157425, 0.08971858024597168, 0.05633337423205376]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_154: embedding dims=384, first 3 values=[0.03805241733789444, 0.08916663378477097, 0.0685155838727951]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_155: embedding dims=384, first 3 values=[0.03454281762242317, 0.07953984290361404, 0.047914057970047]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_156: embedding dims=384, first 3 values=[0.044410232454538345, 0.092562735080719, 0.06584126502275467]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_157: embedding dims=384, first 3 values=[0.07049035280942917, 0.09858564287424088, 0.044911254197359085]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_158: embedding dims=384, first 3 values=[0.05461394414305687, 0.09648794680833817, 0.06356121599674225]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_159: embedding dims=384, first 3 values=[0.03913748636841774, 0.1083637997508049, 0.07766425609588623]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_160: embedding dims=384, first 3 values=[0.05031329393386841, 0.10584673285484314, 0.09824246168136597]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_161: embedding dims=384, first 3 values=[0.06316039711236954, 0.09420958161354065, 0.07818207144737244]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_162: embedding dims=384, first 3 values=[0.0547931045293808, 0.0899651050567627, 0.08803552389144897]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_163: embedding dims=384, first 3 values=[0.051902011036872864, 0.08613883703947067, 0.07810606062412262]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_164: embedding dims=384, first 3 values=[0.048549309372901917, 0.08660398423671722, 0.07711447030305862]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_165: embedding dims=384, first 3 values=[0.05738482624292374, 0.09553901851177216, 0.0754084587097168]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_166: embedding dims=384, first 3 values=[0.05705498903989792, 0.0881194993853569, 0.0856529250741005]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_167: embedding dims=384, first 3 values=[0.06258475035429001, 0.07664714753627777, 0.07290809601545334]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_168: embedding dims=384, first 3 values=[0.04996940493583679, 0.0877370536327362, 0.08361713588237762]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_169: embedding dims=384, first 3 values=[0.05089958384633064, 0.09716206043958664, 0.07451826333999634]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_170: embedding dims=384, first 3 values=[0.04961540549993515, 0.0883483961224556, 0.07719160616397858]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_171: embedding dims=384, first 3 values=[0.048394251614809036, 0.08222777396440506, 0.08335249125957489]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_172: embedding dims=384, first 3 values=[0.03209099546074867, 0.08349171280860901, 0.08742135018110275]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_173: embedding dims=384, first 3 values=[0.01941528543829918, 0.07858337461948395, 0.04787720367312431]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_174: embedding dims=384, first 3 values=[0.019583359360694885, 0.07630378007888794, 0.05995912104845047]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_175: embedding dims=384, first 3 values=[0.03018631599843502, 0.08183880895376205, 0.07280443608760834]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_176: embedding dims=384, first 3 values=[0.026782849803566933, 0.08385859429836273, 0.07504476606845856]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_177: embedding dims=384, first 3 values=[0.052243467420339584, 0.08332924544811249, 0.07534981518983841]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_178: embedding dims=384, first 3 values=[0.04263107851147652, 0.08638178557157516, 0.08572060614824295]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_179: embedding dims=384, first 3 values=[0.03660052642226219, 0.09716479480266571, 0.07899808138608932]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_180: embedding dims=384, first 3 values=[0.02831585519015789, 0.09647950530052185, 0.09386352449655533]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_181: embedding dims=384, first 3 values=[0.03447021171450615, 0.0825837031006813, 0.08707156777381897]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_182: embedding dims=384, first 3 values=[0.04877365753054619, 0.09100881218910217, 0.08010300993919373]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_183: embedding dims=384, first 3 values=[0.05880918726325035, 0.06306438148021698, 0.0545368567109108]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_184: embedding dims=384, first 3 values=[0.041646506637334824, 0.061413027346134186, 0.06664086133241653]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_185: embedding dims=384, first 3 values=[0.022899746894836426, 0.060370299965143204, 0.06428156048059464]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_186: embedding dims=384, first 3 values=[0.03713822737336159, 0.07313980162143707, 0.07793962210416794]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_187: embedding dims=384, first 3 values=[0.06351441890001297, 0.0763571560382843, 0.05232197046279907]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_188: embedding dims=384, first 3 values=[0.04615190997719765, 0.08075902611017227, 0.06888587772846222]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_189: embedding dims=384, first 3 values=[0.03657031059265137, 0.07753241062164307, 0.07534211874008179]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_190: embedding dims=384, first 3 values=[0.039439406245946884, 0.08145742118358612, 0.08726637065410614]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_191: embedding dims=384, first 3 values=[0.052269816398620605, 0.06961918622255325, 0.06848636269569397]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_192: embedding dims=384, first 3 values=[0.04742748662829399, 0.07627754658460617, 0.08272907882928848]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_193: embedding dims=384, first 3 values=[0.05314631015062332, 0.06688307970762253, 0.06785435229539871]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_194: embedding dims=384, first 3 values=[0.050144262611866, 0.0625569075345993, 0.0728619322180748]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_195: embedding dims=384, first 3 values=[0.04729757085442543, 0.07525894790887833, 0.0796288475394249]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_196: embedding dims=384, first 3 values=[0.04460558295249939, 0.08437354117631912, 0.0923139676451683]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_197: embedding dims=384, first 3 values=[0.04857679829001427, 0.06417775899171829, 0.07488103210926056]
DEBUG    rag_factory.services.database.postgres:postgres.py:223 Storing chunk large_doc_198: embedding dims=384, first 3 values=[0.03292453661561012, 0.07108371704816818, 0.08879712969064713]
DEBUG    rag_factory.services.database.postgres:postgres.py:241 Stored 199 chunks
INFO     rag_factory.strategies.indexing.vector_embedding:vector_embedding.py:111 Database storage complete
--------------------------- Captured stderr teardown ---------------------------
INFO:rag_factory.services.database.postgres:Created synchronous SQLAlchemy engine for contexts
INFO:rag_factory.services.database.postgres:Closed PostgreSQL async connection pool
INFO:rag_factory.services.database.postgres:Disposed synchronous SQLAlchemy engine
DEBUG:rag_factory.services.database.postgres:Cleared DatabaseContext cache
---------------------------- Captured log teardown -----------------------------
INFO     rag_factory.services.database.postgres:postgres.py:492 Created synchronous SQLAlchemy engine for contexts
INFO     rag_factory.services.database.postgres:postgres.py:577 Closed PostgreSQL async connection pool
INFO     rag_factory.services.database.postgres:postgres.py:583 Disposed synchronous SQLAlchemy engine
DEBUG    rag_factory.services.database.postgres:postgres.py:586 Cleared DatabaseContext cache
______________________________ test_llm_streaming ______________________________

real_llm_service = <rag_factory.services.llm.service.LLMService object at 0x788cd9945220>

    @pytest.mark.real_integration
    @pytest.mark.requires_llm
    @pytest.mark.asyncio
    async def test_llm_streaming(real_llm_service):
        """Test LLM streaming responses."""
        from rag_factory.services.llm.base import Message, MessageRole
    
        messages = [
            Message(
                role=MessageRole.USER,
                content="Count from 1 to 5."
            )
        ]
    
        # Check if service supports streaming
        if hasattr(real_llm_service, 'stream'):
            chunks = []
>           async for chunk in real_llm_service.stream(messages):
E           TypeError: 'async for' requires an object with __aiter__ method, got generator

tests/integration_real/test_llm_real.py:197: TypeError
---------------------------- Captured stderr setup -----------------------------
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 192.168.56.1:1234
DEBUG:urllib3.connectionpool:http://192.168.56.1:1234 "GET /v1/models HTTP/1.1" 200 1082
DEBUG:asyncio:Using selector: EpollSelector
------------------------------ Captured log setup ------------------------------
DEBUG    urllib3.connectionpool:connectionpool.py:241 Starting new HTTP connection (1): 192.168.56.1:1234
DEBUG    urllib3.connectionpool:connectionpool.py:544 http://192.168.56.1:1234 "GET /v1/models HTTP/1.1" 200 1082
DEBUG    asyncio:selector_events.py:64 Using selector: EpollSelector
--------------------------- Captured stderr teardown ---------------------------
DEBUG:httpcore.connection:close.started
DEBUG:httpcore.connection:close.complete
DEBUG:httpcore.connection:close.started
DEBUG:httpcore.connection:close.complete
_______ TestRealServiceInstantiation.test_multiple_service_instantiation _______

self = <rag_factory.registry.service_registry.ServiceRegistry object at 0x788cd90a2ab0>
service_ref = 'embedding_local'

    def get(self, service_ref: str) -> Any:
        """Get or create a service instance.
    
        Args:
            service_ref: Service reference like "$llm1" or "llm1"
    
        Returns:
            Service instance implementing appropriate interface
    
        Raises:
            ServiceNotFoundError: If service not found in registry
            ServiceInstantiationError: If service creation fails
        """
        # Strip $ prefix if present
        service_name = service_ref.lstrip('$')
    
        # Return cached instance if exists
        if service_name in self._instances:
            logger.debug(f"Service '{service_name}' returned from cache")
            return self._instances[service_name]
    
        # Thread-safe instantiation
        with self._locks[service_name]:
            # Double-check after acquiring lock
            if service_name in self._instances:
                return self._instances[service_name]
    
            # Validate service exists
            if 'services' not in self.config:
                raise ServiceNotFoundError(
                    f"No services defined in registry configuration"
                )
    
            if service_name not in self.config['services']:
                available = list(self.config['services'].keys())
                raise ServiceNotFoundError(
                    f"Service '{service_name}' not found in registry. "
                    f"Available services: {available}"
                )
    
            # Get service configuration
            service_config = self.config['services'][service_name]
    
            # Create service instance
            logger.info(f"Instantiating service: {service_name}")
            start_time = time.time()
    
            try:
>               service_instance = self._factory.create_service(
                    service_name,
                    service_config
                )

rag_factory/registry/service_registry.py:137: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
rag_factory/registry/service_factory.py:48: in create_service
    return self._create_embedding_service(service_name, config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
rag_factory/registry/service_factory.py:127: in _create_embedding_service
    return ONNXEmbeddingService(
rag_factory/services/onnx/embedding.py:68: in __init__
    self._provider = ONNXLocalProvider(config)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
rag_factory/services/embedding/providers/onnx_local.py:116: in __init__
    self.model_path = get_onnx_model_path(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

model_name = 'Xenova/all-MiniLM-L6-v2', cache_dir = PosixPath('models')
filename = 'model.onnx'

    def get_onnx_model_path(
        model_name: str,
        cache_dir: Optional[Path] = None,
        filename: str = "model.onnx",
    ) -> Path:
        """Get path to local ONNX model.
    
        This function checks:
        1. Local model paths (if model exists locally)
        2. Local cache directory
    
        Args:
            model_name: Model identifier or local path
            cache_dir: Directory for model caching
            filename: Name of the ONNX model file
    
        Returns:
            Path to ONNX model file
    
        Raises:
            FileNotFoundError: If model is not found locally
        """
        import os
    
        check_dependencies()
    
        # Check for environment variable configuration
        env_model_path = os.getenv("EMBEDDING_MODEL_PATH")
        env_model_name = os.getenv("EMBEDDING_MODEL_NAME")
    
        # Use environment variable for cache_dir if not specified
        if cache_dir is None:
            if env_model_path:
                cache_dir = Path(env_model_path)
            elif Path("models/embeddings").exists():
                cache_dir = Path("models/embeddings").resolve()
                logger.info(f"Using local project cache: {cache_dir}")
            else:
                # Default to standard location, but don't create it if we're not downloading
                cache_dir = Path.home() / ".cache" / "rag_factory" / "onnx_models"
    
        cache_dir = Path(cache_dir)
    
        # Use environment variable for model_name if it matches default
        if env_model_name and model_name == "Xenova/all-MiniLM-L6-v2":
            logger.info(f"Using model from EMBEDDING_MODEL_NAME env: {env_model_name}")
            model_name = env_model_name
    
        # Check if model_name is a local path
        potential_local_path = Path(model_name)
        if potential_local_path.exists() and potential_local_path.is_file():
            logger.info(f"Using local ONNX model: {potential_local_path}")
            return potential_local_path
    
        # Check if model exists in cache directory
        # Try both naming conventions: underscore (old) and double-dash (HF standard)
        model_dir_name_underscore = model_name.replace("/", "_")
        model_dir_name_dash = model_name.replace("/", "--")
    
        for model_dir_name in [model_dir_name_dash, model_dir_name_underscore]:
            local_model_dir = cache_dir / model_dir_name
    
            if local_model_dir.exists():
                # Look for ONNX files in the directory (recursively, Xenova models have onnx/ subdirectory)
                onnx_files = list(local_model_dir.rglob("*.onnx"))
                if onnx_files:
                    # Prefer the main model.onnx if available, otherwise use first one
                    main_model = next((f for f in onnx_files if f.name == "model.onnx"), onnx_files[0])
                    logger.info(f"Using cached ONNX model: {main_model}")
                    return main_model
    
        # Model not found locally
        error_msg = (
            f"ONNX model '{model_name}' not found locally.\n"
            f"Checked path: {cache_dir}\n"
            f"Automatic downloading is disabled. Please ensure the model is available directly in the infrastructure.\n"
            f"Set EMBEDDING_MODEL_PATH environment variable to the directory containing the model."
        )
>       raise FileNotFoundError(error_msg)
E       FileNotFoundError: ONNX model 'Xenova/all-MiniLM-L6-v2' not found locally.
E       Checked path: models
E       Automatic downloading is disabled. Please ensure the model is available directly in the infrastructure.
E       Set EMBEDDING_MODEL_PATH environment variable to the directory containing the model.

rag_factory/services/utils/onnx_utils.py:123: FileNotFoundError

During handling of the above exception, another exception occurred:

self = <tests.integration.registry.test_registry_integration.TestRealServiceInstantiation object at 0x788cda04a0f0>
test_services_yaml_with_env = '/tmp/pytest-of-admindevmac/pytest-50/test_multiple_service_instanti0/services.yaml'

    def test_multiple_service_instantiation(self, test_services_yaml_with_env):
        """Test instantiating multiple services."""
        registry = ServiceRegistry(test_services_yaml_with_env)
    
        # Get both services
>       embedding = registry.get("embedding_local")
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/integration/registry/test_registry_integration.py:95: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <rag_factory.registry.service_registry.ServiceRegistry object at 0x788cd90a2ab0>
service_ref = 'embedding_local'

    def get(self, service_ref: str) -> Any:
        """Get or create a service instance.
    
        Args:
            service_ref: Service reference like "$llm1" or "llm1"
    
        Returns:
            Service instance implementing appropriate interface
    
        Raises:
            ServiceNotFoundError: If service not found in registry
            ServiceInstantiationError: If service creation fails
        """
        # Strip $ prefix if present
        service_name = service_ref.lstrip('$')
    
        # Return cached instance if exists
        if service_name in self._instances:
            logger.debug(f"Service '{service_name}' returned from cache")
            return self._instances[service_name]
    
        # Thread-safe instantiation
        with self._locks[service_name]:
            # Double-check after acquiring lock
            if service_name in self._instances:
                return self._instances[service_name]
    
            # Validate service exists
            if 'services' not in self.config:
                raise ServiceNotFoundError(
                    f"No services defined in registry configuration"
                )
    
            if service_name not in self.config['services']:
                available = list(self.config['services'].keys())
                raise ServiceNotFoundError(
                    f"Service '{service_name}' not found in registry. "
                    f"Available services: {available}"
                )
    
            # Get service configuration
            service_config = self.config['services'][service_name]
    
            # Create service instance
            logger.info(f"Instantiating service: {service_name}")
            start_time = time.time()
    
            try:
                service_instance = self._factory.create_service(
                    service_name,
                    service_config
                )
                instantiation_time = time.time() - start_time
    
                logger.info(
                    f"Service '{service_name}' instantiated successfully "
                    f"in {instantiation_time:.2f}s"
                )
    
            except Exception as e:
                logger.error(f"Failed to instantiate service '{service_name}': {e}")
>               raise ServiceInstantiationError(
                    f"Service instantiation failed for '{service_name}': {e}"
                )
E               rag_factory.registry.exceptions.ServiceInstantiationError: Service instantiation failed for 'embedding_local': ONNX model 'Xenova/all-MiniLM-L6-v2' not found locally.
E               Checked path: models
E               Automatic downloading is disabled. Please ensure the model is available directly in the infrastructure.
E               Set EMBEDDING_MODEL_PATH environment variable to the directory containing the model.

rag_factory/registry/service_registry.py:150: ServiceInstantiationError
----------------------------- Captured stderr call -----------------------------
INFO:rag_factory.registry.service_registry:Loading service registry from: /tmp/pytest-of-admindevmac/pytest-50/test_multiple_service_instanti0/services.yaml
DEBUG:httpcore.connection:close.started
DEBUG:httpcore.connection:close.complete
WARNING:rag_factory.registry.service_registry:WARNING: Potential plaintext secret in services.llm_local.api_key. Consider using environment variable: ${ENV_VAR}
INFO:rag_factory.registry.service_registry:Service registry loaded: 2 services available
INFO:rag_factory.registry.service_registry:Instantiating service: embedding_local
DEBUG:rag_factory.registry.service_factory:Creating embedding service: embedding_local
INFO:rag_factory.services.embedding.providers.onnx_local:Loading ONNX model: Xenova/all-MiniLM-L6-v2
INFO:rag_factory.services.utils.onnx_utils:Using model from EMBEDDING_MODEL_NAME env: Xenova/all-MiniLM-L6-v2
ERROR:rag_factory.registry.service_registry:Failed to instantiate service 'embedding_local': ONNX model 'Xenova/all-MiniLM-L6-v2' not found locally.
Checked path: models
Automatic downloading is disabled. Please ensure the model is available directly in the infrastructure.
Set EMBEDDING_MODEL_PATH environment variable to the directory containing the model.
------------------------------ Captured log call -------------------------------
INFO     rag_factory.registry.service_registry:service_registry.py:55 Loading service registry from: /tmp/pytest-of-admindevmac/pytest-50/test_multiple_service_instanti0/services.yaml
DEBUG    httpcore.connection:_trace.py:47 close.started
DEBUG    httpcore.connection:_trace.py:47 close.complete
WARNING  rag_factory.registry.service_registry:service_registry.py:70 WARNING: Potential plaintext secret in services.llm_local.api_key. Consider using environment variable: ${ENV_VAR}
INFO     rag_factory.registry.service_registry:service_registry.py:75 Service registry loaded: 2 services available
INFO     rag_factory.registry.service_registry:service_registry.py:133 Instantiating service: embedding_local
DEBUG    rag_factory.registry.service_factory:service_factory.py:121 Creating embedding service: embedding_local
INFO     rag_factory.services.embedding.providers.onnx_local:onnx_local.py:111 Loading ONNX model: Xenova/all-MiniLM-L6-v2
INFO     rag_factory.services.utils.onnx_utils:onnx_utils.py:90 Using model from EMBEDDING_MODEL_NAME env: Xenova/all-MiniLM-L6-v2
ERROR    rag_factory.registry.service_registry:service_registry.py:149 Failed to instantiate service 'embedding_local': ONNX model 'Xenova/all-MiniLM-L6-v2' not found locally.
Checked path: models
Automatic downloading is disabled. Please ensure the model is available directly in the infrastructure.
Set EMBEDDING_MODEL_PATH environment variable to the directory containing the model.
________________ TestErrorHandling.test_invalid_service_config _________________

self = <rag_factory.config.validator.ConfigValidator object at 0x788cc876f500>
config = {'services': {'invalid_service': {'unknown_field': 'value'}}}
file_path = '/tmp/pytest-of-admindevmac/pytest-50/test_invalid_service_config0/services.yaml'

    def validate_services_yaml(
        self,
        config: Dict[str, Any],
        file_path: Optional[str] = None
    ) -> List[str]:
        """
        Validate services.yaml configuration.
    
        Args:
            config: Parsed YAML configuration
            file_path: Path to YAML file (for error messages)
    
        Returns:
            List of warning messages (empty if no warnings)
    
        Raises:
            ConfigValidationError: If validation fails
    
        Examples:
            >>> validator = ConfigValidator()
            >>> config = {
            ...     "services": {
            ...         "llm1": {
            ...             "name": "test-llm",
            ...             "type": "llm",
            ...             "url": "http://localhost:1234/v1",
            ...             "api_key": "${API_KEY}",
            ...             "model": "test-model"
            ...         }
            ...     }
            ... }
            >>> warnings = validator.validate_services_yaml(config)
            >>> len(warnings)
            0
        """
        try:
            # JSON Schema validation
>           jsonschema.validate(
                instance=config,
                schema=self._schemas["service_registry"]
            )

rag_factory/config/validator.py:113: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

instance = {'services': {'invalid_service': {'unknown_field': 'value'}}}
schema = {'$schema': 'http://json-schema.org/draft-07/schema#', 'definitions': {'database_service': {'properties': {'connection...tion': 'Schema version (semver)', 'pattern': '^\\d+\\.\\d+\\.\\d+$', 'type': 'string'}}, 'required': ['services'], ...}
cls = <class 'jsonschema.validators.Draft7Validator'>, args = (), kwargs = {}
validator = Draft7Validator(schema={'$schema': 'http://json-...ft-07/schema#', 'definitions': {'database_service': {'properties': ... (semver)', 'pattern': '^\\d+\\.\\d+\\.\\d+$', 'type': 'string'}}, 'required': ['services'], ...}, format_checker=None)
error = <ValidationError: "{'unknown_field': 'value'} is not valid under any of the given schemas">

    def validate(instance, schema, cls=None, *args, **kwargs):  # noqa: D417
        """
        Validate an instance under the given schema.
    
            >>> validate([2, 3, 4], {"maxItems": 2})
            Traceback (most recent call last):
                ...
            ValidationError: [2, 3, 4] is too long
    
        :func:`~jsonschema.validators.validate` will first verify that the
        provided schema is itself valid, since not doing so can lead to less
        obvious error messages and fail in less obvious or consistent ways.
    
        If you know you have a valid schema already, especially
        if you intend to validate multiple instances with
        the same schema, you likely would prefer using the
        `jsonschema.protocols.Validator.validate` method directly on a
        specific validator (e.g. ``Draft202012Validator.validate``).
    
    
        Arguments:
    
            instance:
    
                The instance to validate
    
            schema:
    
                The schema to validate with
    
            cls (jsonschema.protocols.Validator):
    
                The class that will be used to validate the instance.
    
        If the ``cls`` argument is not provided, two things will happen
        in accordance with the specification. First, if the schema has a
        :kw:`$schema` keyword containing a known meta-schema [#]_ then the
        proper validator will be used. The specification recommends that
        all schemas contain :kw:`$schema` properties for this reason. If no
        :kw:`$schema` property is found, the default validator class is the
        latest released draft.
    
        Any other provided positional and keyword arguments will be passed
        on when instantiating the ``cls``.
    
        Raises:
    
            `jsonschema.exceptions.ValidationError`:
    
                if the instance is invalid
    
            `jsonschema.exceptions.SchemaError`:
    
                if the schema itself is invalid
    
        .. rubric:: Footnotes
        .. [#] known by a validator registered with
            `jsonschema.validators.validates`
    
        """
        if cls is None:
            cls = validator_for(schema)
    
        cls.check_schema(schema)
        validator = cls(schema, *args, **kwargs)
        error = exceptions.best_match(validator.iter_errors(instance))
        if error is not None:
>           raise error
E           jsonschema.exceptions.ValidationError: {'unknown_field': 'value'} is not valid under any of the given schemas
E           
E           Failed validating 'oneOf' in schema['properties']['services']['patternProperties']['^[a-zA-Z0-9_]+$']:
E               {'oneOf': [{'$ref': '#/definitions/llm_service'},
E                          {'$ref': '#/definitions/embedding_service'},
E                          {'$ref': '#/definitions/database_service'}]}
E           
E           On instance['services']['invalid_service']:
E               {'unknown_field': 'value'}

venv/lib/python3.12/site-packages/jsonschema/validators.py:1332: ValidationError

During handling of the above exception, another exception occurred:

self = <rag_factory.registry.service_registry.ServiceRegistry object at 0x788cc876ee10>

    def _load_config(self) -> None:
        """Load and validate services.yaml configuration."""
        logger.info(f"Loading service registry from: {self.config_path}")
    
        try:
            # Load YAML
            with open(self.config_path, 'r') as f:
                raw_config = yaml.safe_load(f)
    
            # Validate schema
>           warnings = self._validator.validate_services_yaml(
                raw_config,
                file_path=self.config_path
            )

rag_factory/registry/service_registry.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <rag_factory.config.validator.ConfigValidator object at 0x788cc876f500>
config = {'services': {'invalid_service': {'unknown_field': 'value'}}}
file_path = '/tmp/pytest-of-admindevmac/pytest-50/test_invalid_service_config0/services.yaml'

    def validate_services_yaml(
        self,
        config: Dict[str, Any],
        file_path: Optional[str] = None
    ) -> List[str]:
        """
        Validate services.yaml configuration.
    
        Args:
            config: Parsed YAML configuration
            file_path: Path to YAML file (for error messages)
    
        Returns:
            List of warning messages (empty if no warnings)
    
        Raises:
            ConfigValidationError: If validation fails
    
        Examples:
            >>> validator = ConfigValidator()
            >>> config = {
            ...     "services": {
            ...         "llm1": {
            ...             "name": "test-llm",
            ...             "type": "llm",
            ...             "url": "http://localhost:1234/v1",
            ...             "api_key": "${API_KEY}",
            ...             "model": "test-model"
            ...         }
            ...     }
            ... }
            >>> warnings = validator.validate_services_yaml(config)
            >>> len(warnings)
            0
        """
        try:
            # JSON Schema validation
            jsonschema.validate(
                instance=config,
                schema=self._schemas["service_registry"]
            )
        except jsonschema.ValidationError as e:
>           raise ConfigValidationError(
                message=f"Schema validation failed: {e.message}",
                file_path=file_path,
                field=".".join(str(p) for p in e.path)
            )
E           rag_factory.config.validator.ConfigValidationError: Schema validation failed: {'unknown_field': 'value'} is not valid under any of the given schemas
E           File: /tmp/pytest-of-admindevmac/pytest-50/test_invalid_service_config0/services.yaml
E           Field: services.invalid_service

rag_factory/config/validator.py:118: ConfigValidationError

During handling of the above exception, another exception occurred:

self = <tests.integration.registry.test_registry_integration.TestErrorHandling object at 0x788cda065d60>
tmp_path = PosixPath('/tmp/pytest-of-admindevmac/pytest-50/test_invalid_service_config0')

        def test_invalid_service_config(self, tmp_path):
            """Test handling of invalid service configuration."""
            content = """
    services:
      invalid_service:
        unknown_field: "value"
    """
            services_file = tmp_path / "services.yaml"
            services_file.write_text(content)
    
>           registry = ServiceRegistry(str(services_file))
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/integration/registry/test_registry_integration.py:230: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
rag_factory/registry/service_registry.py:51: in __init__
    self._load_config()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <rag_factory.registry.service_registry.ServiceRegistry object at 0x788cc876ee10>

    def _load_config(self) -> None:
        """Load and validate services.yaml configuration."""
        logger.info(f"Loading service registry from: {self.config_path}")
    
        try:
            # Load YAML
            with open(self.config_path, 'r') as f:
                raw_config = yaml.safe_load(f)
    
            # Validate schema
            warnings = self._validator.validate_services_yaml(
                raw_config,
                file_path=self.config_path
            )
    
            # Print warnings
            for warning in warnings:
                logger.warning(warning)
    
            # Resolve environment variables
            self.config = EnvResolver.resolve(raw_config)
    
            logger.info(
                f"Service registry loaded: "
                f"{len(self.config.get('services', {}))} services available"
            )
    
        except FileNotFoundError:
            raise ServiceInstantiationError(
                f"Service registry configuration not found: {self.config_path}"
            )
        except Exception as e:
>           raise ServiceInstantiationError(
                f"Failed to load service registry: {e}"
            )
E           rag_factory.registry.exceptions.ServiceInstantiationError: Failed to load service registry: Schema validation failed: {'unknown_field': 'value'} is not valid under any of the given schemas
E           File: /tmp/pytest-of-admindevmac/pytest-50/test_invalid_service_config0/services.yaml
E           Field: services.invalid_service

rag_factory/registry/service_registry.py:85: ServiceInstantiationError
----------------------------- Captured stderr call -----------------------------
INFO:rag_factory.registry.service_registry:Loading service registry from: /tmp/pytest-of-admindevmac/pytest-50/test_invalid_service_config0/services.yaml
------------------------------ Captured log call -------------------------------
INFO     rag_factory.registry.service_registry:service_registry.py:55 Loading service registry from: /tmp/pytest-of-admindevmac/pytest-50/test_invalid_service_config0/services.yaml
--------------------------- Captured stderr teardown ---------------------------
DEBUG:httpcore.connection:close.started
DEBUG:httpcore.connection:close.complete
___________ TestConfigurationValidation.test_configuration_warnings ____________

self = <rag_factory.config.validator.ConfigValidator object at 0x788cd90a3ce0>
config = {'services': {'test_service': {'api_key': 'plaintext-secret', 'model': 'test-model', 'provider': 'onnx'}}}
file_path = '/tmp/pytest-of-admindevmac/pytest-50/test_configuration_warnings0/services.yaml'

    def validate_services_yaml(
        self,
        config: Dict[str, Any],
        file_path: Optional[str] = None
    ) -> List[str]:
        """
        Validate services.yaml configuration.
    
        Args:
            config: Parsed YAML configuration
            file_path: Path to YAML file (for error messages)
    
        Returns:
            List of warning messages (empty if no warnings)
    
        Raises:
            ConfigValidationError: If validation fails
    
        Examples:
            >>> validator = ConfigValidator()
            >>> config = {
            ...     "services": {
            ...         "llm1": {
            ...             "name": "test-llm",
            ...             "type": "llm",
            ...             "url": "http://localhost:1234/v1",
            ...             "api_key": "${API_KEY}",
            ...             "model": "test-model"
            ...         }
            ...     }
            ... }
            >>> warnings = validator.validate_services_yaml(config)
            >>> len(warnings)
            0
        """
        try:
            # JSON Schema validation
>           jsonschema.validate(
                instance=config,
                schema=self._schemas["service_registry"]
            )

rag_factory/config/validator.py:113: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

instance = {'services': {'test_service': {'api_key': 'plaintext-secret', 'model': 'test-model', 'provider': 'onnx'}}}
schema = {'$schema': 'http://json-schema.org/draft-07/schema#', 'definitions': {'database_service': {'properties': {'connection...tion': 'Schema version (semver)', 'pattern': '^\\d+\\.\\d+\\.\\d+$', 'type': 'string'}}, 'required': ['services'], ...}
cls = <class 'jsonschema.validators.Draft7Validator'>, args = (), kwargs = {}
validator = Draft7Validator(schema={'$schema': 'http://json-...ft-07/schema#', 'definitions': {'database_service': {'properties': ... (semver)', 'pattern': '^\\d+\\.\\d+\\.\\d+$', 'type': 'string'}}, 'required': ['services'], ...}, format_checker=None)
error = <ValidationError: "{'provider': 'onnx', 'model': 'test-model', 'api_key': 'plaintext-secret'} is not valid under any of the given schemas">

    def validate(instance, schema, cls=None, *args, **kwargs):  # noqa: D417
        """
        Validate an instance under the given schema.
    
            >>> validate([2, 3, 4], {"maxItems": 2})
            Traceback (most recent call last):
                ...
            ValidationError: [2, 3, 4] is too long
    
        :func:`~jsonschema.validators.validate` will first verify that the
        provided schema is itself valid, since not doing so can lead to less
        obvious error messages and fail in less obvious or consistent ways.
    
        If you know you have a valid schema already, especially
        if you intend to validate multiple instances with
        the same schema, you likely would prefer using the
        `jsonschema.protocols.Validator.validate` method directly on a
        specific validator (e.g. ``Draft202012Validator.validate``).
    
    
        Arguments:
    
            instance:
    
                The instance to validate
    
            schema:
    
                The schema to validate with
    
            cls (jsonschema.protocols.Validator):
    
                The class that will be used to validate the instance.
    
        If the ``cls`` argument is not provided, two things will happen
        in accordance with the specification. First, if the schema has a
        :kw:`$schema` keyword containing a known meta-schema [#]_ then the
        proper validator will be used. The specification recommends that
        all schemas contain :kw:`$schema` properties for this reason. If no
        :kw:`$schema` property is found, the default validator class is the
        latest released draft.
    
        Any other provided positional and keyword arguments will be passed
        on when instantiating the ``cls``.
    
        Raises:
    
            `jsonschema.exceptions.ValidationError`:
    
                if the instance is invalid
    
            `jsonschema.exceptions.SchemaError`:
    
                if the schema itself is invalid
    
        .. rubric:: Footnotes
        .. [#] known by a validator registered with
            `jsonschema.validators.validates`
    
        """
        if cls is None:
            cls = validator_for(schema)
    
        cls.check_schema(schema)
        validator = cls(schema, *args, **kwargs)
        error = exceptions.best_match(validator.iter_errors(instance))
        if error is not None:
>           raise error
E           jsonschema.exceptions.ValidationError: {'provider': 'onnx', 'model': 'test-model', 'api_key': 'plaintext-secret'} is not valid under any of the given schemas
E           
E           Failed validating 'oneOf' in schema['properties']['services']['patternProperties']['^[a-zA-Z0-9_]+$']:
E               {'oneOf': [{'$ref': '#/definitions/llm_service'},
E                          {'$ref': '#/definitions/embedding_service'},
E                          {'$ref': '#/definitions/database_service'}]}
E           
E           On instance['services']['test_service']:
E               {'provider': 'onnx',
E                'model': 'test-model',
E                'api_key': 'plaintext-secret'}

venv/lib/python3.12/site-packages/jsonschema/validators.py:1332: ValidationError

During handling of the above exception, another exception occurred:

self = <rag_factory.registry.service_registry.ServiceRegistry object at 0x788cd90a3380>

    def _load_config(self) -> None:
        """Load and validate services.yaml configuration."""
        logger.info(f"Loading service registry from: {self.config_path}")
    
        try:
            # Load YAML
            with open(self.config_path, 'r') as f:
                raw_config = yaml.safe_load(f)
    
            # Validate schema
>           warnings = self._validator.validate_services_yaml(
                raw_config,
                file_path=self.config_path
            )

rag_factory/registry/service_registry.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <rag_factory.config.validator.ConfigValidator object at 0x788cd90a3ce0>
config = {'services': {'test_service': {'api_key': 'plaintext-secret', 'model': 'test-model', 'provider': 'onnx'}}}
file_path = '/tmp/pytest-of-admindevmac/pytest-50/test_configuration_warnings0/services.yaml'

    def validate_services_yaml(
        self,
        config: Dict[str, Any],
        file_path: Optional[str] = None
    ) -> List[str]:
        """
        Validate services.yaml configuration.
    
        Args:
            config: Parsed YAML configuration
            file_path: Path to YAML file (for error messages)
    
        Returns:
            List of warning messages (empty if no warnings)
    
        Raises:
            ConfigValidationError: If validation fails
    
        Examples:
            >>> validator = ConfigValidator()
            >>> config = {
            ...     "services": {
            ...         "llm1": {
            ...             "name": "test-llm",
            ...             "type": "llm",
            ...             "url": "http://localhost:1234/v1",
            ...             "api_key": "${API_KEY}",
            ...             "model": "test-model"
            ...         }
            ...     }
            ... }
            >>> warnings = validator.validate_services_yaml(config)
            >>> len(warnings)
            0
        """
        try:
            # JSON Schema validation
            jsonschema.validate(
                instance=config,
                schema=self._schemas["service_registry"]
            )
        except jsonschema.ValidationError as e:
>           raise ConfigValidationError(
                message=f"Schema validation failed: {e.message}",
                file_path=file_path,
                field=".".join(str(p) for p in e.path)
            )
E           rag_factory.config.validator.ConfigValidationError: Schema validation failed: {'provider': 'onnx', 'model': 'test-model', 'api_key': 'plaintext-secret'} is not valid under any of the given schemas
E           File: /tmp/pytest-of-admindevmac/pytest-50/test_configuration_warnings0/services.yaml
E           Field: services.test_service

rag_factory/config/validator.py:118: ConfigValidationError

During handling of the above exception, another exception occurred:

self = <tests.integration.registry.test_registry_integration.TestConfigurationValidation object at 0x788cda0665a0>
tmp_path = PosixPath('/tmp/pytest-of-admindevmac/pytest-50/test_configuration_warnings0')
caplog = <_pytest.logging.LogCaptureFixture object at 0x788cd90a3710>

        def test_configuration_warnings(self, tmp_path, caplog):
            """Test that configuration warnings are logged."""
            import logging
            caplog.set_level(logging.WARNING)
    
            content = """
    services:
      test_service:
        provider: "onnx"
        model: "test-model"
        api_key: "plaintext-secret"  # Should trigger warning
    """
            services_file = tmp_path / "services.yaml"
            services_file.write_text(content)
    
>           registry = ServiceRegistry(str(services_file))
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/integration/registry/test_registry_integration.py:332: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
rag_factory/registry/service_registry.py:51: in __init__
    self._load_config()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <rag_factory.registry.service_registry.ServiceRegistry object at 0x788cd90a3380>

    def _load_config(self) -> None:
        """Load and validate services.yaml configuration."""
        logger.info(f"Loading service registry from: {self.config_path}")
    
        try:
            # Load YAML
            with open(self.config_path, 'r') as f:
                raw_config = yaml.safe_load(f)
    
            # Validate schema
            warnings = self._validator.validate_services_yaml(
                raw_config,
                file_path=self.config_path
            )
    
            # Print warnings
            for warning in warnings:
                logger.warning(warning)
    
            # Resolve environment variables
            self.config = EnvResolver.resolve(raw_config)
    
            logger.info(
                f"Service registry loaded: "
                f"{len(self.config.get('services', {}))} services available"
            )
    
        except FileNotFoundError:
            raise ServiceInstantiationError(
                f"Service registry configuration not found: {self.config_path}"
            )
        except Exception as e:
>           raise ServiceInstantiationError(
                f"Failed to load service registry: {e}"
            )
E           rag_factory.registry.exceptions.ServiceInstantiationError: Failed to load service registry: Schema validation failed: {'provider': 'onnx', 'model': 'test-model', 'api_key': 'plaintext-secret'} is not valid under any of the given schemas
E           File: /tmp/pytest-of-admindevmac/pytest-50/test_configuration_warnings0/services.yaml
E           Field: services.test_service

rag_factory/registry/service_registry.py:85: ServiceInstantiationError
____________ TestSelfReflectiveIntegration.test_end_to_end_workflow ____________

self = <tests.integration.strategies.test_self_reflective_integration.TestSelfReflectiveIntegration object at 0x788cda0c0080>
mock_base_strategy = <Mock id='132546330213024'>
mock_llm_service = <Mock id='132546330213504'>

    def test_end_to_end_workflow(self, mock_base_strategy, mock_llm_service):
        """Test complete self-reflective retrieval workflow."""
        # Create strategy
>       strategy = SelfReflectiveRAGStrategy(
            base_retrieval_strategy=mock_base_strategy,
            llm_service=mock_llm_service,
            config={"grade_threshold": 4.0, "max_retries": 2}
        )
E       TypeError: SelfReflectiveRAGStrategy.__init__() got an unexpected keyword argument 'base_retrieval_strategy'

tests/integration/strategies/test_self_reflective_integration.py:80: TypeError
__________ TestSelfReflectiveIntegration.test_retry_with_poor_results __________

self = <tests.integration.strategies.test_self_reflective_integration.TestSelfReflectiveIntegration object at 0x788cda0c0440>
mock_base_strategy = <Mock id='132546330211248'>
mock_llm_service = <Mock id='132546330211056'>

    def test_retry_with_poor_results(self, mock_base_strategy, mock_llm_service):
        """Test that retry is triggered for poor results."""
>       strategy = SelfReflectiveRAGStrategy(
            base_retrieval_strategy=mock_base_strategy,
            llm_service=mock_llm_service,
            config={"grade_threshold": 4.0, "max_retries": 2}
        )
E       TypeError: SelfReflectiveRAGStrategy.__init__() got an unexpected keyword argument 'base_retrieval_strategy'

tests/integration/strategies/test_self_reflective_integration.py:100: TypeError
_________ TestSelfReflectiveIntegration.test_performance_within_limits _________

self = <tests.integration.strategies.test_self_reflective_integration.TestSelfReflectiveIntegration object at 0x788cda0c07d0>
mock_base_strategy = <Mock id='132546330208896'>
mock_llm_service = <Mock id='132546330208800'>

    def test_performance_within_limits(self, mock_base_strategy, mock_llm_service):
        """Test that self-reflective retrieval completes within timeout."""
        import time
    
>       strategy = SelfReflectiveRAGStrategy(
            base_retrieval_strategy=mock_base_strategy,
            llm_service=mock_llm_service,
            config={"grade_threshold": 4.0, "max_retries": 2, "timeout_seconds": 10}
        )
E       TypeError: SelfReflectiveRAGStrategy.__init__() got an unexpected keyword argument 'base_retrieval_strategy'

tests/integration/strategies/test_self_reflective_integration.py:119: TypeError
______________ TestSelfReflectiveWithLMStudio.test_with_real_llm _______________

self = <tests.integration.strategies.test_self_reflective_integration.TestSelfReflectiveWithLMStudio object at 0x788cda0c08f0>
llm_service_from_env = <rag_factory.services.llm.service.LLMService object at 0x788cd8ed9fd0>

    def test_with_real_llm(self, llm_service_from_env):
        """Test with real LLM service from environment (LM Studio)."""
        from unittest.mock import Mock
    
        # Mock base strategy
        base_strategy = Mock()
        base_strategy.retrieve.return_value = [
            {"chunk_id": "c1", "text": "Sample result", "score": 0.9}
        ]
    
        # Create self-reflective strategy
>       strategy = SelfReflectiveRAGStrategy(
            base_retrieval_strategy=base_strategy,
            llm_service=llm_service_from_env,
            config={"grade_threshold": 4.0, "max_retries": 1}
        )
E       TypeError: SelfReflectiveRAGStrategy.__init__() got an unexpected keyword argument 'base_retrieval_strategy'

tests/integration/strategies/test_self_reflective_integration.py:149: TypeError
__________________ TestSmokeTest.test_basic_usage_smoke_test ___________________

self = <tests.integration.test_package_integration.TestSmokeTest object at 0x788cda0c1af0>

    def test_basic_usage_smoke_test(self) -> None:
        """Test basic usage works after import."""
>       from rag_factory import RAGFactory, StrategyPipeline, ConfigManager
E       ImportError: cannot import name 'RAGFactory' from 'rag_factory' (/mnt/MCPProyects/ragTools/rag_factory/__init__.py)

tests/integration/test_package_integration.py:60: ImportError
__________ TestFullWorkflow.test_full_workflow_with_installed_package __________

self = <tests.integration.test_package_integration.TestFullWorkflow object at 0x788cda0c1e50>

    def test_full_workflow_with_installed_package(self) -> None:
        """Test complete workflow using installed package."""
>       from rag_factory import RAGFactory, StrategyPipeline
E       ImportError: cannot import name 'RAGFactory' from 'rag_factory' (/mnt/MCPProyects/ragTools/rag_factory/__init__.py)

tests/integration/test_package_integration.py:90: ImportError
____________________________ test_load_pair_success ____________________________

manager = <rag_factory.config.strategy_pair_manager.StrategyPairManager object at 0x788cd8e8a780>
mock_loader = <MagicMock name='StrategyPairLoader()' id='132546330212016'>
mock_registry = <MagicMock spec='ServiceRegistry' id='132546330206352'>

    def test_load_pair_success(manager, mock_loader, mock_registry):
        # Setup Loader return
        mock_config = {
            "strategy_name": "test-pair",
            "indexer": {
                "strategy": "indexer.module.Class",
                "services": {"llm": "$gpt4", "db": "$db1"},
                "config": {"some": "param"}
            },
            "retriever": {
                "strategy": "retriever.module.Class",
                "services": {"embedding": "$embed1"},
                "config": {"top_k": 5}
            },
            "migrations": {
                "required_revisions": ["1234"]
            }
        }
        mock_loader.load_config.return_value = mock_config
    
        # Mock _import_strategy_class
        with patch.object(manager, "_import_strategy_class") as mock_import:
            mock_import.side_effect = lambda x: MockIndexingStrategy if "indexer" in x else MockRetrievalStrategy
    
            # Run
            idx, ret = manager.load_pair("test-pair")
    
            # Assertions
            assert isinstance(idx, MockIndexingStrategy)
            assert isinstance(ret, MockRetrievalStrategy)
    
            # Verify loader usage
            mock_loader.load_config.assert_called_with(Path("/tmp/strategies/test-pair.yaml"))
    
            # Verify Migration Validation
            manager.migration_validator.validate.assert_called_with(["1234"])
    
            # Verify Service Resolution
>           mock_registry.get.assert_any_call("$gpt4")

tests/unit/config/test_strategy_pair_manager.py:100: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MagicMock name='mock.get' id='132546103590352'>, args = ('$gpt4',)
kwargs = {}, expected = call('$gpt4'), cause = None
actual = [call('db_main'), call('gpt4'), call('db1'), call('embed1')]
expected_string = "get('$gpt4')"

    def assert_any_call(self, /, *args, **kwargs):
        """assert the mock has been called with the specified arguments.
    
        The assert passes if the mock has *ever* been called, unlike
        `assert_called_with` and `assert_called_once_with` that only pass if
        the call is the most recent one."""
        expected = self._call_matcher(_Call((args, kwargs), two=True))
        cause = expected if isinstance(expected, Exception) else None
        actual = [self._call_matcher(c) for c in self.call_args_list]
        if cause or expected not in _AnyComparer(actual):
            expected_string = self._format_mock_call_signature(args, kwargs)
>           raise AssertionError(
                '%s call not found' % expected_string
            ) from cause
E           AssertionError: get('$gpt4') call not found

/usr/lib/python3.12/unittest/mock.py:1015: AssertionError
----------------------------- Captured stderr call -----------------------------
INFO:rag_factory.config.strategy_pair_manager:Loading strategy pair from /tmp/strategies/test-pair.yaml
------------------------------ Captured log call -------------------------------
INFO     rag_factory.config.strategy_pair_manager:strategy_pair_manager.py:96 Loading strategy pair from /tmp/strategies/test-pair.yaml
___________________________ test_db_context_creation ___________________________

manager = <rag_factory.config.strategy_pair_manager.StrategyPairManager object at 0x788cd8d5bad0>
mock_loader = <MagicMock name='StrategyPairLoader()' id='132546328628256'>
mock_registry = <MagicMock spec='ServiceRegistry' id='132546328807136'>

    def test_db_context_creation(manager, mock_loader, mock_registry):
        mock_config = {
            "strategy_name": "db-context-pair",
            "indexer": {
                "strategy": "indexer.module.Class",
                "services": {"db": "$db1"},
                "db_config": {
                    "tables": {"logical": "physical"},
                    "fields": {"f1": "col1"}
                }
            },
            "retriever": { "strategy": "retriever.module.Class" }
        }
        mock_loader.load_config.return_value = mock_config
    
        # Mock DB service with get_context
        mock_db = MagicMock()
        mock_context = MagicMock()
        mock_db.get_context.return_value = mock_context
    
        # Configure registry to return mock_db
        def get_service(ref):
            if ref == "$db1": return mock_db
            return MagicMock()
        mock_registry.get.side_effect = get_service
    
        with patch.object(manager, "_import_strategy_class") as mock_import:
            mock_import.return_value = MagicMock() # Generic mock strategy
    
            manager.load_pair("db-context-pair")
    
            # Verify get_context called
>           mock_db.get_context.assert_called_with(
                table_mapping={"logical": "physical"},
                field_mapping={"f1": "col1"}
            )

tests/unit/config/test_strategy_pair_manager.py:172: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MagicMock name='mock.get_context' id='132546333085088'>, args = ()
kwargs = {'field_mapping': {'f1': 'col1'}, 'table_mapping': {'logical': 'physical'}}
expected = "get_context(table_mapping={'logical': 'physical'}, field_mapping={'f1': 'col1'})"
actual = 'not called.'
error_message = "expected call not found.\nExpected: get_context(table_mapping={'logical': 'physical'}, field_mapping={'f1': 'col1'})\n  Actual: not called."

    def assert_called_with(self, /, *args, **kwargs):
        """assert that the last call was made with the specified arguments.
    
        Raises an AssertionError if the args and keyword args passed in are
        different to the last call to the mock."""
        if self.call_args is None:
            expected = self._format_mock_call_signature(args, kwargs)
            actual = 'not called.'
            error_message = ('expected call not found.\nExpected: %s\n  Actual: %s'
                    % (expected, actual))
>           raise AssertionError(error_message)
E           AssertionError: expected call not found.
E           Expected: get_context(table_mapping={'logical': 'physical'}, field_mapping={'f1': 'col1'})
E             Actual: not called.

/usr/lib/python3.12/unittest/mock.py:935: AssertionError
----------------------------- Captured stderr call -----------------------------
INFO:rag_factory.config.strategy_pair_manager:Loading strategy pair from /tmp/strategies/db-context-pair.yaml
------------------------------ Captured log call -------------------------------
INFO     rag_factory.config.strategy_pair_manager:strategy_pair_manager.py:96 Loading strategy pair from /tmp/strategies/db-context-pair.yaml
_____________ TestAlembicMigrations.test_migration_upgrade_to_head _____________

self = <sqlalchemy.engine.base.Connection object at 0x788cda112150>
dialect = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x788cd8dc3ef0>
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x788cd8dba7e0>
statement = <sqlalchemy.dialects.postgresql.base.PGCompiler object at 0x788cd8dba780>
parameters = [{}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x788cd8dc3ef0>
cursor = <cursor object at 0x788cd98f0310; closed: -1>
statement = 'DROP EXTENSION IF EXISTS vector', parameters = {}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x788cd8dba7e0>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       psycopg2.errors.DependentObjectsStillExist: cannot drop extension vector because other objects depend on it
E       DETAIL:  column embedding of table test_chunks_real depends on type vector
E       HINT:  Use DROP ... CASCADE to drop the dependent objects too.

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: DependentObjectsStillExist

The above exception was the direct cause of the following exception:

self = <tests.unit.database.test_migrations.TestAlembicMigrations object at 0x788cda0dad20>
alembic_config = <alembic.config.Config object at 0x788cd8d86420>
test_db_url = 'postgresql://rag_user:rag_password@192.168.56.1:5432/rag_test'

    def test_migration_upgrade_to_head(self, alembic_config: Config, test_db_url: str) -> None:
        """Test upgrading migrations to head."""
        # Start from clean state
>       command.downgrade(alembic_config, "base")

tests/unit/database/test_migrations.py:39: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
venv/lib/python3.12/site-packages/alembic/command.py:449: in downgrade
    script.run_env()
venv/lib/python3.12/site-packages/alembic/script/base.py:583: in run_env
    util.load_python_file(self.dir, "env.py")
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:95: in load_python_file
    module = load_module_py(module_id, path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:113: in load_module_py
    spec.loader.exec_module(module)  # type: ignore
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
<frozen importlib._bootstrap_external>:995: in exec_module
    ???
<frozen importlib._bootstrap>:488: in _call_with_frames_removed
    ???
migrations/env.py:93: in <module>
    run_migrations_online()
migrations/env.py:87: in run_migrations_online
    context.run_migrations()
<string>:8: in run_migrations
    ???
venv/lib/python3.12/site-packages/alembic/runtime/environment.py:948: in run_migrations
    self.get_context().run_migrations(**kw)
venv/lib/python3.12/site-packages/alembic/runtime/migration.py:627: in run_migrations
    step.migration_fn(**kw)
migrations/versions/001_initial_schema.py:129: in downgrade
    op.execute("DROP EXTENSION IF EXISTS vector")
<string>:8: in execute
    ???
<string>:3: in execute
    ???
venv/lib/python3.12/site-packages/alembic/operations/ops.py:2537: in execute
    return operations.invoke(op)
           ^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/base.py:445: in invoke
    return fn(self, operation)
           ^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/toimpl.py:224: in execute_sql
    operations.migration_context.impl.execute(
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:214: in execute
    self._exec(sql, execution_options)
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:207: in _exec
    return conn.execute(construct, multiparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1416: in execute
    return meth(
venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py:516: in _execute_on_connection
    return connection._execute_clauseelement(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1639: in _execute_clauseelement
    ret = self._execute_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1848: in _execute_context
    return self._exec_single_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1988: in _exec_single_context
    self._handle_dbapi_exception(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2343: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: in _exec_single_context
    self.dialect.do_execute(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x788cd8dc3ef0>
cursor = <cursor object at 0x788cd98f0310; closed: -1>
statement = 'DROP EXTENSION IF EXISTS vector', parameters = {}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x788cd8dba7e0>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.InternalError: (psycopg2.errors.DependentObjectsStillExist) cannot drop extension vector because other objects depend on it
E       DETAIL:  column embedding of table test_chunks_real depends on type vector
E       HINT:  Use DROP ... CASCADE to drop the dependent objects too.
E       
E       [SQL: DROP EXTENSION IF EXISTS vector]
E       (Background on this error at: https://sqlalche.me/e/20/2j85)

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: InternalError
----------------------------- Captured stderr call -----------------------------
INFO  [alembic.runtime.migration] Context impl PostgresqlImpl.
INFO  [alembic.runtime.migration] Will assume transactional DDL.
INFO  [alembic.runtime.migration] Running downgrade 001 -> , Initial schema with documents and chunks tables
________________ TestAlembicMigrations.test_migration_downgrade ________________

self = <sqlalchemy.engine.base.Connection object at 0x788cd8dc3140>
dialect = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x788cc876c6e0>
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x788cc87f4fe0>
statement = <sqlalchemy.dialects.postgresql.base.PGCompiler object at 0x788cc87f4c20>
parameters = [{}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x788cc876c6e0>
cursor = <cursor object at 0x788cd8d68220; closed: -1>
statement = 'DROP EXTENSION IF EXISTS vector', parameters = {}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x788cc87f4fe0>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       psycopg2.errors.DependentObjectsStillExist: cannot drop extension vector because other objects depend on it
E       DETAIL:  column embedding of table test_chunks_real depends on type vector
E       HINT:  Use DROP ... CASCADE to drop the dependent objects too.

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: DependentObjectsStillExist

The above exception was the direct cause of the following exception:

self = <tests.unit.database.test_migrations.TestAlembicMigrations object at 0x788cda0dafc0>
alembic_config = <alembic.config.Config object at 0x788cd8dbabd0>
test_db_url = 'postgresql://rag_user:rag_password@192.168.56.1:5432/rag_test'

    def test_migration_downgrade(self, alembic_config: Config, test_db_url: str) -> None:
        """Test downgrading migrations."""
        # Start from clean state
>       command.downgrade(alembic_config, "base")

tests/unit/database/test_migrations.py:60: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
venv/lib/python3.12/site-packages/alembic/command.py:449: in downgrade
    script.run_env()
venv/lib/python3.12/site-packages/alembic/script/base.py:583: in run_env
    util.load_python_file(self.dir, "env.py")
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:95: in load_python_file
    module = load_module_py(module_id, path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:113: in load_module_py
    spec.loader.exec_module(module)  # type: ignore
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
<frozen importlib._bootstrap_external>:995: in exec_module
    ???
<frozen importlib._bootstrap>:488: in _call_with_frames_removed
    ???
migrations/env.py:93: in <module>
    run_migrations_online()
migrations/env.py:87: in run_migrations_online
    context.run_migrations()
<string>:8: in run_migrations
    ???
venv/lib/python3.12/site-packages/alembic/runtime/environment.py:948: in run_migrations
    self.get_context().run_migrations(**kw)
venv/lib/python3.12/site-packages/alembic/runtime/migration.py:627: in run_migrations
    step.migration_fn(**kw)
migrations/versions/001_initial_schema.py:129: in downgrade
    op.execute("DROP EXTENSION IF EXISTS vector")
<string>:8: in execute
    ???
<string>:3: in execute
    ???
venv/lib/python3.12/site-packages/alembic/operations/ops.py:2537: in execute
    return operations.invoke(op)
           ^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/base.py:445: in invoke
    return fn(self, operation)
           ^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/toimpl.py:224: in execute_sql
    operations.migration_context.impl.execute(
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:214: in execute
    self._exec(sql, execution_options)
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:207: in _exec
    return conn.execute(construct, multiparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1416: in execute
    return meth(
venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py:516: in _execute_on_connection
    return connection._execute_clauseelement(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1639: in _execute_clauseelement
    ret = self._execute_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1848: in _execute_context
    return self._exec_single_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1988: in _exec_single_context
    self._handle_dbapi_exception(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2343: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: in _exec_single_context
    self.dialect.do_execute(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x788cc876c6e0>
cursor = <cursor object at 0x788cd8d68220; closed: -1>
statement = 'DROP EXTENSION IF EXISTS vector', parameters = {}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x788cc87f4fe0>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.InternalError: (psycopg2.errors.DependentObjectsStillExist) cannot drop extension vector because other objects depend on it
E       DETAIL:  column embedding of table test_chunks_real depends on type vector
E       HINT:  Use DROP ... CASCADE to drop the dependent objects too.
E       
E       [SQL: DROP EXTENSION IF EXISTS vector]
E       (Background on this error at: https://sqlalche.me/e/20/2j85)

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: InternalError
----------------------------- Captured stderr call -----------------------------
INFO  [alembic.runtime.migration] Context impl PostgresqlImpl.
INFO  [alembic.runtime.migration] Will assume transactional DDL.
INFO  [alembic.runtime.migration] Running downgrade 001 -> , Initial schema with documents and chunks tables
_______________ TestAlembicMigrations.test_migration_idempotency _______________

self = <sqlalchemy.engine.base.Connection object at 0x788cc87f61b0>
dialect = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x788cc87f6630>
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x788cd8d219d0>
statement = <sqlalchemy.dialects.postgresql.base.PGCompiler object at 0x788cd8d233e0>
parameters = [{}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x788cc87f6630>
cursor = <cursor object at 0x788cd8d68f40; closed: -1>
statement = 'DROP EXTENSION IF EXISTS vector', parameters = {}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x788cd8d219d0>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       psycopg2.errors.DependentObjectsStillExist: cannot drop extension vector because other objects depend on it
E       DETAIL:  column embedding of table test_chunks_real depends on type vector
E       HINT:  Use DROP ... CASCADE to drop the dependent objects too.

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: DependentObjectsStillExist

The above exception was the direct cause of the following exception:

self = <tests.unit.database.test_migrations.TestAlembicMigrations object at 0x788cda0db620>
alembic_config = <alembic.config.Config object at 0x788cd8ec4c20>
test_db_url = 'postgresql://rag_user:rag_password@192.168.56.1:5432/rag_test'

    def test_migration_idempotency(self, alembic_config: Config, test_db_url: str) -> None:
        """Test that running migrations twice doesn't cause errors."""
        # Start from clean state
>       command.downgrade(alembic_config, "base")

tests/unit/database/test_migrations.py:102: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
venv/lib/python3.12/site-packages/alembic/command.py:449: in downgrade
    script.run_env()
venv/lib/python3.12/site-packages/alembic/script/base.py:583: in run_env
    util.load_python_file(self.dir, "env.py")
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:95: in load_python_file
    module = load_module_py(module_id, path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:113: in load_module_py
    spec.loader.exec_module(module)  # type: ignore
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
<frozen importlib._bootstrap_external>:995: in exec_module
    ???
<frozen importlib._bootstrap>:488: in _call_with_frames_removed
    ???
migrations/env.py:93: in <module>
    run_migrations_online()
migrations/env.py:87: in run_migrations_online
    context.run_migrations()
<string>:8: in run_migrations
    ???
venv/lib/python3.12/site-packages/alembic/runtime/environment.py:948: in run_migrations
    self.get_context().run_migrations(**kw)
venv/lib/python3.12/site-packages/alembic/runtime/migration.py:627: in run_migrations
    step.migration_fn(**kw)
migrations/versions/001_initial_schema.py:129: in downgrade
    op.execute("DROP EXTENSION IF EXISTS vector")
<string>:8: in execute
    ???
<string>:3: in execute
    ???
venv/lib/python3.12/site-packages/alembic/operations/ops.py:2537: in execute
    return operations.invoke(op)
           ^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/base.py:445: in invoke
    return fn(self, operation)
           ^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/toimpl.py:224: in execute_sql
    operations.migration_context.impl.execute(
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:214: in execute
    self._exec(sql, execution_options)
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:207: in _exec
    return conn.execute(construct, multiparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1416: in execute
    return meth(
venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py:516: in _execute_on_connection
    return connection._execute_clauseelement(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1639: in _execute_clauseelement
    ret = self._execute_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1848: in _execute_context
    return self._exec_single_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1988: in _exec_single_context
    self._handle_dbapi_exception(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2343: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: in _exec_single_context
    self.dialect.do_execute(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x788cc87f6630>
cursor = <cursor object at 0x788cd8d68f40; closed: -1>
statement = 'DROP EXTENSION IF EXISTS vector', parameters = {}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x788cd8d219d0>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.InternalError: (psycopg2.errors.DependentObjectsStillExist) cannot drop extension vector because other objects depend on it
E       DETAIL:  column embedding of table test_chunks_real depends on type vector
E       HINT:  Use DROP ... CASCADE to drop the dependent objects too.
E       
E       [SQL: DROP EXTENSION IF EXISTS vector]
E       (Background on this error at: https://sqlalche.me/e/20/2j85)

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: InternalError
----------------------------- Captured stderr call -----------------------------
INFO  [alembic.runtime.migration] Context impl PostgresqlImpl.
INFO  [alembic.runtime.migration] Will assume transactional DDL.
INFO  [alembic.runtime.migration] Running downgrade 001 -> , Initial schema with documents and chunks tables
________________ TestAlembicMigrations.test_get_current_version ________________

self = <sqlalchemy.engine.base.Connection object at 0x788cd8ec62a0>
dialect = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x788cda088140>
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x788cd8e89a60>
statement = <sqlalchemy.dialects.postgresql.base.PGCompiler object at 0x788cd8e89cd0>
parameters = [{}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x788cda088140>
cursor = <cursor object at 0x788cd8d6a5c0; closed: -1>
statement = 'DROP EXTENSION IF EXISTS vector', parameters = {}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x788cd8e89a60>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       psycopg2.errors.DependentObjectsStillExist: cannot drop extension vector because other objects depend on it
E       DETAIL:  column embedding of table test_chunks_real depends on type vector
E       HINT:  Use DROP ... CASCADE to drop the dependent objects too.

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: DependentObjectsStillExist

The above exception was the direct cause of the following exception:

self = <tests.unit.database.test_migrations.TestAlembicMigrations object at 0x788cda0db950>
alembic_config = <alembic.config.Config object at 0x788cd8d224e0>
test_db_url = 'postgresql://rag_user:rag_password@192.168.56.1:5432/rag_test'

    def test_get_current_version(self, alembic_config: Config, test_db_url: str) -> None:
        """Test retrieving current schema version."""
        # Start from clean state
>       command.downgrade(alembic_config, "base")

tests/unit/database/test_migrations.py:129: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
venv/lib/python3.12/site-packages/alembic/command.py:449: in downgrade
    script.run_env()
venv/lib/python3.12/site-packages/alembic/script/base.py:583: in run_env
    util.load_python_file(self.dir, "env.py")
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:95: in load_python_file
    module = load_module_py(module_id, path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:113: in load_module_py
    spec.loader.exec_module(module)  # type: ignore
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
<frozen importlib._bootstrap_external>:995: in exec_module
    ???
<frozen importlib._bootstrap>:488: in _call_with_frames_removed
    ???
migrations/env.py:93: in <module>
    run_migrations_online()
migrations/env.py:87: in run_migrations_online
    context.run_migrations()
<string>:8: in run_migrations
    ???
venv/lib/python3.12/site-packages/alembic/runtime/environment.py:948: in run_migrations
    self.get_context().run_migrations(**kw)
venv/lib/python3.12/site-packages/alembic/runtime/migration.py:627: in run_migrations
    step.migration_fn(**kw)
migrations/versions/001_initial_schema.py:129: in downgrade
    op.execute("DROP EXTENSION IF EXISTS vector")
<string>:8: in execute
    ???
<string>:3: in execute
    ???
venv/lib/python3.12/site-packages/alembic/operations/ops.py:2537: in execute
    return operations.invoke(op)
           ^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/base.py:445: in invoke
    return fn(self, operation)
           ^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/toimpl.py:224: in execute_sql
    operations.migration_context.impl.execute(
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:214: in execute
    self._exec(sql, execution_options)
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:207: in _exec
    return conn.execute(construct, multiparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1416: in execute
    return meth(
venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py:516: in _execute_on_connection
    return connection._execute_clauseelement(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1639: in _execute_clauseelement
    ret = self._execute_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1848: in _execute_context
    return self._exec_single_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1988: in _exec_single_context
    self._handle_dbapi_exception(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2343: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: in _exec_single_context
    self.dialect.do_execute(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x788cda088140>
cursor = <cursor object at 0x788cd8d6a5c0; closed: -1>
statement = 'DROP EXTENSION IF EXISTS vector', parameters = {}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x788cd8e89a60>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.InternalError: (psycopg2.errors.DependentObjectsStillExist) cannot drop extension vector because other objects depend on it
E       DETAIL:  column embedding of table test_chunks_real depends on type vector
E       HINT:  Use DROP ... CASCADE to drop the dependent objects too.
E       
E       [SQL: DROP EXTENSION IF EXISTS vector]
E       (Background on this error at: https://sqlalche.me/e/20/2j85)

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: InternalError
----------------------------- Captured stderr call -----------------------------
INFO  [alembic.runtime.migration] Context impl PostgresqlImpl.
INFO  [alembic.runtime.migration] Will assume transactional DDL.
INFO  [alembic.runtime.migration] Running downgrade 001 -> , Initial schema with documents and chunks tables
_____________ TestAlembicMigrations.test_migration_creates_tables ______________

self = <sqlalchemy.engine.base.Connection object at 0x788cd8d21520>
dialect = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x788cd91e77d0>
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x788cd8d6c2c0>
statement = <sqlalchemy.dialects.postgresql.base.PGCompiler object at 0x788cd8d6c200>
parameters = [{}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x788cd91e77d0>
cursor = <cursor object at 0x788cd8d6b880; closed: -1>
statement = 'DROP EXTENSION IF EXISTS vector', parameters = {}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x788cd8d6c2c0>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       psycopg2.errors.DependentObjectsStillExist: cannot drop extension vector because other objects depend on it
E       DETAIL:  column embedding of table test_chunks_real depends on type vector
E       HINT:  Use DROP ... CASCADE to drop the dependent objects too.

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: DependentObjectsStillExist

The above exception was the direct cause of the following exception:

self = <tests.unit.database.test_migrations.TestAlembicMigrations object at 0x788cda0db500>
alembic_config = <alembic.config.Config object at 0x788cd8edb7a0>
test_db_url = 'postgresql://rag_user:rag_password@192.168.56.1:5432/rag_test'

    def test_migration_creates_tables(self, alembic_config: Config, test_db_url: str) -> None:
        """Test that migrations create expected tables."""
        # Start from clean state
>       command.downgrade(alembic_config, "base")

tests/unit/database/test_migrations.py:147: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
venv/lib/python3.12/site-packages/alembic/command.py:449: in downgrade
    script.run_env()
venv/lib/python3.12/site-packages/alembic/script/base.py:583: in run_env
    util.load_python_file(self.dir, "env.py")
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:95: in load_python_file
    module = load_module_py(module_id, path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:113: in load_module_py
    spec.loader.exec_module(module)  # type: ignore
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
<frozen importlib._bootstrap_external>:995: in exec_module
    ???
<frozen importlib._bootstrap>:488: in _call_with_frames_removed
    ???
migrations/env.py:93: in <module>
    run_migrations_online()
migrations/env.py:87: in run_migrations_online
    context.run_migrations()
<string>:8: in run_migrations
    ???
venv/lib/python3.12/site-packages/alembic/runtime/environment.py:948: in run_migrations
    self.get_context().run_migrations(**kw)
venv/lib/python3.12/site-packages/alembic/runtime/migration.py:627: in run_migrations
    step.migration_fn(**kw)
migrations/versions/001_initial_schema.py:129: in downgrade
    op.execute("DROP EXTENSION IF EXISTS vector")
<string>:8: in execute
    ???
<string>:3: in execute
    ???
venv/lib/python3.12/site-packages/alembic/operations/ops.py:2537: in execute
    return operations.invoke(op)
           ^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/base.py:445: in invoke
    return fn(self, operation)
           ^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/toimpl.py:224: in execute_sql
    operations.migration_context.impl.execute(
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:214: in execute
    self._exec(sql, execution_options)
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:207: in _exec
    return conn.execute(construct, multiparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1416: in execute
    return meth(
venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py:516: in _execute_on_connection
    return connection._execute_clauseelement(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1639: in _execute_clauseelement
    ret = self._execute_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1848: in _execute_context
    return self._exec_single_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1988: in _exec_single_context
    self._handle_dbapi_exception(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2343: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: in _exec_single_context
    self.dialect.do_execute(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x788cd91e77d0>
cursor = <cursor object at 0x788cd8d6b880; closed: -1>
statement = 'DROP EXTENSION IF EXISTS vector', parameters = {}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x788cd8d6c2c0>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.InternalError: (psycopg2.errors.DependentObjectsStillExist) cannot drop extension vector because other objects depend on it
E       DETAIL:  column embedding of table test_chunks_real depends on type vector
E       HINT:  Use DROP ... CASCADE to drop the dependent objects too.
E       
E       [SQL: DROP EXTENSION IF EXISTS vector]
E       (Background on this error at: https://sqlalche.me/e/20/2j85)

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: InternalError
----------------------------- Captured stderr call -----------------------------
INFO  [alembic.runtime.migration] Context impl PostgresqlImpl.
INFO  [alembic.runtime.migration] Will assume transactional DDL.
INFO  [alembic.runtime.migration] Running downgrade 001 -> , Initial schema with documents and chunks tables
_____________ TestAlembicMigrations.test_migration_creates_indexes _____________

self = <sqlalchemy.engine.base.Connection object at 0x788cd8ec6ed0>
dialect = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x788cd8d6f200>
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x788cc9909c10>
statement = <sqlalchemy.dialects.postgresql.base.PGCompiler object at 0x788cc9909b50>
parameters = [{}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x788cd8d6f200>
cursor = <cursor object at 0x788cd8d6a980; closed: -1>
statement = 'DROP EXTENSION IF EXISTS vector', parameters = {}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x788cc9909c10>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       psycopg2.errors.DependentObjectsStillExist: cannot drop extension vector because other objects depend on it
E       DETAIL:  column embedding of table test_chunks_real depends on type vector
E       HINT:  Use DROP ... CASCADE to drop the dependent objects too.

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: DependentObjectsStillExist

The above exception was the direct cause of the following exception:

self = <tests.unit.database.test_migrations.TestAlembicMigrations object at 0x788cda0db200>
alembic_config = <alembic.config.Config object at 0x788cd8d6eb40>
test_db_url = 'postgresql://rag_user:rag_password@192.168.56.1:5432/rag_test'

    def test_migration_creates_indexes(self, alembic_config: Config, test_db_url: str) -> None:
        """Test that migrations create expected indexes."""
        # Start from clean state
>       command.downgrade(alembic_config, "base")

tests/unit/database/test_migrations.py:167: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
venv/lib/python3.12/site-packages/alembic/command.py:449: in downgrade
    script.run_env()
venv/lib/python3.12/site-packages/alembic/script/base.py:583: in run_env
    util.load_python_file(self.dir, "env.py")
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:95: in load_python_file
    module = load_module_py(module_id, path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:113: in load_module_py
    spec.loader.exec_module(module)  # type: ignore
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
<frozen importlib._bootstrap_external>:995: in exec_module
    ???
<frozen importlib._bootstrap>:488: in _call_with_frames_removed
    ???
migrations/env.py:93: in <module>
    run_migrations_online()
migrations/env.py:87: in run_migrations_online
    context.run_migrations()
<string>:8: in run_migrations
    ???
venv/lib/python3.12/site-packages/alembic/runtime/environment.py:948: in run_migrations
    self.get_context().run_migrations(**kw)
venv/lib/python3.12/site-packages/alembic/runtime/migration.py:627: in run_migrations
    step.migration_fn(**kw)
migrations/versions/001_initial_schema.py:129: in downgrade
    op.execute("DROP EXTENSION IF EXISTS vector")
<string>:8: in execute
    ???
<string>:3: in execute
    ???
venv/lib/python3.12/site-packages/alembic/operations/ops.py:2537: in execute
    return operations.invoke(op)
           ^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/base.py:445: in invoke
    return fn(self, operation)
           ^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/toimpl.py:224: in execute_sql
    operations.migration_context.impl.execute(
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:214: in execute
    self._exec(sql, execution_options)
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:207: in _exec
    return conn.execute(construct, multiparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1416: in execute
    return meth(
venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py:516: in _execute_on_connection
    return connection._execute_clauseelement(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1639: in _execute_clauseelement
    ret = self._execute_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1848: in _execute_context
    return self._exec_single_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1988: in _exec_single_context
    self._handle_dbapi_exception(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2343: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: in _exec_single_context
    self.dialect.do_execute(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x788cd8d6f200>
cursor = <cursor object at 0x788cd8d6a980; closed: -1>
statement = 'DROP EXTENSION IF EXISTS vector', parameters = {}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x788cc9909c10>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.InternalError: (psycopg2.errors.DependentObjectsStillExist) cannot drop extension vector because other objects depend on it
E       DETAIL:  column embedding of table test_chunks_real depends on type vector
E       HINT:  Use DROP ... CASCADE to drop the dependent objects too.
E       
E       [SQL: DROP EXTENSION IF EXISTS vector]
E       (Background on this error at: https://sqlalche.me/e/20/2j85)

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: InternalError
----------------------------- Captured stderr call -----------------------------
INFO  [alembic.runtime.migration] Context impl PostgresqlImpl.
INFO  [alembic.runtime.migration] Will assume transactional DDL.
INFO  [alembic.runtime.migration] Running downgrade 001 -> , Initial schema with documents and chunks tables
__________ TestCodeExamples.test_all_code_examples_have_valid_syntax ___________

self = <test_code_examples.TestCodeExamples object at 0x788cda0dbb30>
docs_root = PosixPath('/mnt/MCPProyects/ragTools/docs')

    def test_all_code_examples_have_valid_syntax(self, docs_root):
        """Test that all Python code examples have valid syntax."""
        errors = []
    
        for md_file in docs_root.rglob("*.md"):
            # Skip project planning documents (epics, stories, verification docs)
            # and internal/migration documentation
            file_str = str(md_file).lower()
            skip_patterns = ['epic', 'stor', 'verification', 'completion-summary',
                           'onnx', 'migration', 'project-plan', 'readme']
            if any(skip in file_str for skip in skip_patterns):
                continue
    
            examples = self.extract_python_examples(md_file)
    
            for i, code in enumerate(examples):
                try:
                    # Try to compile the code
                    compile(code, f"{md_file.name}:example_{i}", "exec")
                except SyntaxError as e:
                    errors.append(f"{md_file.name}:example_{i}: {e}")
    
>       assert len(errors) == 0, \
            f"Syntax errors in code examples:\n" + "\n".join(errors)
E       AssertionError: Syntax errors in code examples:
E         semantic-local-pair-guide.md:example_0: 'await' outside function (semantic-local-pair-guide.md:example_0, line 21)
E         environment-variables.md:example_3: invalid syntax (environment-variables.md:example_3, line 13)
E         QUICK-REFERENCE.md:example_2: unexpected indent (QUICK-REFERENCE.md:example_2, line 1)
E       assert 3 == 0
E        +  where 3 = len(["semantic-local-pair-guide.md:example_0: 'await' outside function (semantic-local-pair-guide.md:example_0, line 21)", 'environment-variables.md:example_3: invalid syntax (environment-variables.md:example_3, line 13)', 'QUICK-REFERENCE.md:example_2: unexpected indent (QUICK-REFERENCE.md:example_2, line 1)'])

tests/unit/documentation/test_code_examples.py:57: AssertionError
_____________ TestDocumentationLinks.test_no_broken_internal_links _____________

self = <test_links.TestDocumentationLinks object at 0x788cd9f191c0>
docs_root = PosixPath('/mnt/MCPProyects/ragTools/docs')

    def test_no_broken_internal_links(self, docs_root):
        """Test that all internal links are valid."""
        broken_links = []
    
        for md_file in docs_root.rglob("*.md"):
            links = self.extract_links(md_file)
    
            for text, link in links:
                # Skip external links
                if link.startswith("http"):
                    continue
    
                # Skip anchors
                if link.startswith("#"):
                    continue
    
                # Skip file:// links (used in implementation plan)
                if link.startswith("file://"):
                    continue
    
                # Resolve relative path
                target = (md_file.parent / link).resolve()
    
                if not target.exists():
                    broken_links.append(f"{md_file.name} -> {link}")
    
>       assert len(broken_links) == 0, \
            f"Broken internal links:\n" + "\n".join(broken_links)
E       AssertionError: Broken internal links:
E         MIGRATION_MANAGER_REMOVAL.md -> ../stories/epic-16/story-16.5-remove-migration-manager.md
E         README.md -> ./story-17.1-service-registry-configuration-schema.md
E         README.md -> ./story-17.2-service-registry-implementation.md
E         README.md -> ./story-17.4-migration-validator-alembic.md
E         README.md -> ./story-17.6-first-strategy-pair-testing.md
E         README.md -> ./story-17.7-remaining-strategy-pairs.md
E         README.md -> ./story-17.8-cli-validation-sample-docs.md
E         README.md -> ../../epics/epic-16-database-consolidation.md
E         README.md -> ../../epics/epic-16-database-consolidation.md
E         README.md -> ../../database/README.md
E         README.md -> ../../getting-started/installation.md
E       assert 11 == 0
E        +  where 11 = len(['MIGRATION_MANAGER_REMOVAL.md -> ../stories/epic-16/story-16.5-remove-migration-manager.md', 'README.md -> ./story-17.1-service-registry-configuration-schema.md', 'README.md -> ./story-17.2-service-registry-implementation.md', 'README.md -> ./story-17.4-migration-validator-alembic.md', 'README.md -> ./story-17.6-first-strategy-pair-testing.md', 'README.md -> ./story-17.7-remaining-strategy-pairs.md', ...])

tests/unit/documentation/test_links.py:60: AssertionError
____________ TestLLMServiceCreation.test_create_llm_service_openai _____________

self = <tests.unit.registry.test_service_factory.TestLLMServiceCreation object at 0x788cd9f1b260>
factory = <rag_factory.registry.service_factory.ServiceFactory object at 0x788cd9199970>

    def test_create_llm_service_openai(self, factory):
        """Test creating OpenAI LLM service."""
        config = {
            "name": "openai-llm",
            "url": "https://api.openai.com/v1",
            "api_key": "sk-test",
            "model": "gpt-4",
            "temperature": 0.8,
            "max_tokens": 2000
        }
    
>       with patch('rag_factory.registry.service_factory.OpenAILLMService') as mock_class:

tests/unit/registry/test_service_factory.py:73: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.12/unittest/mock.py:1458: in __enter__
    original, local = self.get_original()
                      ^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x788cd919a3f0>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'rag_factory.registry.service_factory' from '/mnt/MCPProyects/ragTools/rag_factory/registry/service_factory.py'> does not have the attribute 'OpenAILLMService'

/usr/lib/python3.12/unittest/mock.py:1431: AttributeError
_______ TestEmbeddingServiceCreation.test_create_embedding_service_onnx ________

self = <tests.unit.registry.test_service_factory.TestEmbeddingServiceCreation object at 0x788cd9f1bc50>
factory = <rag_factory.registry.service_factory.ServiceFactory object at 0x788cd9198050>

    def test_create_embedding_service_onnx(self, factory):
        """Test creating ONNX embedding service."""
        config = {
            "name": "onnx-embed",
            "provider": "onnx",
            "model": "Xenova/all-MiniLM-L6-v2",
            "cache_dir": "./models",
            "batch_size": 32
        }
    
>       with patch('rag_factory.registry.service_factory.ONNXEmbeddingService') as mock_class:

tests/unit/registry/test_service_factory.py:128: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.12/unittest/mock.py:1458: in __enter__
    original, local = self.get_original()
                      ^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x788cd919a360>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'rag_factory.registry.service_factory' from '/mnt/MCPProyects/ragTools/rag_factory/registry/service_factory.py'> does not have the attribute 'ONNXEmbeddingService'

/usr/lib/python3.12/unittest/mock.py:1431: AttributeError
_ TestEmbeddingServiceCreation.test_create_embedding_service_onnx_with_defaults _

self = <tests.unit.registry.test_service_factory.TestEmbeddingServiceCreation object at 0x788cd9f44260>
factory = <rag_factory.registry.service_factory.ServiceFactory object at 0x788cd919b440>

    def test_create_embedding_service_onnx_with_defaults(self, factory):
        """Test creating ONNX embedding service with defaults."""
        config = {
            "provider": "onnx",
            "model": "Xenova/all-MiniLM-L6-v2"
        }
    
>       with patch('rag_factory.registry.service_factory.ONNXEmbeddingService') as mock_class:

tests/unit/registry/test_service_factory.py:148: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.12/unittest/mock.py:1458: in __enter__
    original, local = self.get_original()
                      ^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x788cd9198830>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'rag_factory.registry.service_factory' from '/mnt/MCPProyects/ragTools/rag_factory/registry/service_factory.py'> does not have the attribute 'ONNXEmbeddingService'

/usr/lib/python3.12/unittest/mock.py:1431: AttributeError
______ TestEmbeddingServiceCreation.test_create_embedding_service_openai _______

self = <tests.unit.registry.test_service_factory.TestEmbeddingServiceCreation object at 0x788cd9f1bef0>
factory = <rag_factory.registry.service_factory.ServiceFactory object at 0x788cd919be60>

    def test_create_embedding_service_openai(self, factory):
        """Test creating OpenAI embedding service."""
        config = {
            "provider": "openai",
            "api_key": "sk-test",
            "model": "text-embedding-ada-002"
        }
    
>       with patch('rag_factory.registry.service_factory.OpenAIEmbeddingService') as mock_class:

tests/unit/registry/test_service_factory.py:167: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.12/unittest/mock.py:1458: in __enter__
    original, local = self.get_original()
                      ^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x788cd919a240>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'rag_factory.registry.service_factory' from '/mnt/MCPProyects/ragTools/rag_factory/registry/service_factory.py'> does not have the attribute 'OpenAIEmbeddingService'

/usr/lib/python3.12/unittest/mock.py:1431: AttributeError
_ TestDatabaseServiceCreation.test_create_database_service_postgres_with_connection_string _

self = <tests.unit.registry.test_service_factory.TestDatabaseServiceCreation object at 0x788cd9f1acc0>
factory = <rag_factory.registry.service_factory.ServiceFactory object at 0x788cd91980e0>

    def test_create_database_service_postgres_with_connection_string(self, factory):
        """Test creating PostgreSQL database service with connection string."""
        config = {
            "name": "postgres-db",
            "type": "postgres",
            "connection_string": "postgresql://user:pass@localhost:5432/db",
            "pool_size": 10,
            "max_overflow": 20
        }
    
>       with patch('rag_factory.registry.service_factory.PostgresqlDatabaseService') as mock_class:

tests/unit/registry/test_service_factory.py:218: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.12/unittest/mock.py:1458: in __enter__
    original, local = self.get_original()
                      ^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x788cd91987a0>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'rag_factory.registry.service_factory' from '/mnt/MCPProyects/ragTools/rag_factory/registry/service_factory.py'> does not have the attribute 'PostgresqlDatabaseService'

/usr/lib/python3.12/unittest/mock.py:1431: AttributeError
_ TestDatabaseServiceCreation.test_create_database_service_postgres_with_components _

self = <tests.unit.registry.test_service_factory.TestDatabaseServiceCreation object at 0x788cd9f18290>
factory = <rag_factory.registry.service_factory.ServiceFactory object at 0x788cd8d229f0>

    def test_create_database_service_postgres_with_components(self, factory):
        """Test creating PostgreSQL database service with connection components."""
        config = {
            "type": "postgres",
            "user": "testuser",
            "password": "testpass",
            "host": "localhost",
            "port": 5432,
            "database": "testdb",
            "pool_size": 5
        }
    
>       with patch('rag_factory.registry.service_factory.PostgresqlDatabaseService') as mock_class:

tests/unit/registry/test_service_factory.py:243: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.12/unittest/mock.py:1458: in __enter__
    original, local = self.get_original()
                      ^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x788cd919a990>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'rag_factory.registry.service_factory' from '/mnt/MCPProyects/ragTools/rag_factory/registry/service_factory.py'> does not have the attribute 'PostgresqlDatabaseService'

/usr/lib/python3.12/unittest/mock.py:1431: AttributeError
_ TestDatabaseServiceCreation.test_create_database_service_postgres_with_defaults _

self = <tests.unit.registry.test_service_factory.TestDatabaseServiceCreation object at 0x788cd9f19250>
factory = <rag_factory.registry.service_factory.ServiceFactory object at 0x788cd8d23a40>

    def test_create_database_service_postgres_with_defaults(self, factory):
        """Test creating PostgreSQL database service with default values."""
        config = {
            "type": "postgres",
            "user": "testuser",
            "password": "testpass",
            "host": "localhost",
            "database": "testdb"
        }
    
>       with patch('rag_factory.registry.service_factory.PostgresqlDatabaseService') as mock_class:

tests/unit/registry/test_service_factory.py:264: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.12/unittest/mock.py:1458: in __enter__
    original, local = self.get_original()
                      ^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x788cd8d22cc0>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'rag_factory.registry.service_factory' from '/mnt/MCPProyects/ragTools/rag_factory/registry/service_factory.py'> does not have the attribute 'PostgresqlDatabaseService'

/usr/lib/python3.12/unittest/mock.py:1431: AttributeError
________ TestDatabaseServiceCreation.test_create_database_service_neo4j ________

self = <tests.unit.registry.test_service_factory.TestDatabaseServiceCreation object at 0x788cda0dad80>
factory = <rag_factory.registry.service_factory.ServiceFactory object at 0x788cd8d22240>

    def test_create_database_service_neo4j(self, factory):
        """Test creating Neo4j database service."""
        config = {
            "type": "neo4j",
            "uri": "bolt://localhost:7687",
            "user": "neo4j",
            "password": "testpass"
        }
    
>       with patch('rag_factory.registry.service_factory.Neo4jGraphService') as mock_class:

tests/unit/registry/test_service_factory.py:287: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.12/unittest/mock.py:1458: in __enter__
    original, local = self.get_original()
                      ^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x788cd8d21ee0>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'rag_factory.registry.service_factory' from '/mnt/MCPProyects/ragTools/rag_factory/registry/service_factory.py'> does not have the attribute 'Neo4jGraphService'

/usr/lib/python3.12/unittest/mock.py:1431: AttributeError
_ TestDatabaseServiceCreation.test_create_database_service_neo4j_with_defaults _

self = <tests.unit.registry.test_service_factory.TestDatabaseServiceCreation object at 0x788cd9f44050>
factory = <rag_factory.registry.service_factory.ServiceFactory object at 0x788cd919bd40>

    def test_create_database_service_neo4j_with_defaults(self, factory):
        """Test creating Neo4j database service with default URI."""
        config = {
            "type": "neo4j",
            "host": "localhost",
            "port": 7687,
            "user": "neo4j",
            "password": "testpass"
        }
    
>       with patch('rag_factory.registry.service_factory.Neo4jGraphService') as mock_class:

tests/unit/registry/test_service_factory.py:310: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.12/unittest/mock.py:1458: in __enter__
    original, local = self.get_original()
                      ^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x788cd919aa20>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'rag_factory.registry.service_factory' from '/mnt/MCPProyects/ragTools/rag_factory/registry/service_factory.py'> does not have the attribute 'Neo4jGraphService'

/usr/lib/python3.12/unittest/mock.py:1431: AttributeError
_________________________ test_calculate_cost_is_zero __________________________

onnx_config = {'max_batch_size': 32, 'model': 'Xenova/all-MiniLM-L6-v2'}
mock_onnx_env = <function create_mock_onnx_environment at 0x788cda279620>

    def test_calculate_cost_is_zero(onnx_config, mock_onnx_env):
        """Test that local ONNX provider has zero cost.
    
        Uses centralized mock_onnx_env to handle all ONNX mocking.
        """
        with mock_onnx_env(dimension=384):
            from rag_factory.services.embedding.providers.onnx_local import ONNXLocalProvider
    
            provider = ONNXLocalProvider(onnx_config)
>           cost = provider.calculate_cost(num_texts=100)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E           TypeError: ONNXLocalProvider.calculate_cost() got an unexpected keyword argument 'num_texts'

tests/unit/services/embedding/test_onnx_local_provider.py:78: TypeError
______________________________ test_capabilities _______________________________

strategy = <rag_factory.strategies.indexing.context_aware.ContextAwareChunkingIndexing object at 0x788cc9901eb0>

    def test_capabilities(strategy):
        """Test produces capabilities."""
>       assert strategy.produces() == {
            IndexCapability.CHUNKS,
            IndexCapability.DATABASE
        }
E       AssertionError: assert {<IndexCapabi...DATABASE: 10>} == {<IndexCapabi...DATABASE: 10>}
E         
E         Extra items in the left set:
E         <IndexCapability.VECTORS: 1>
E         
E         Full diff:
E           {
E         +     <IndexCapability.VECTORS: 1>,...
E         
E         ...Full output truncated (3 lines hidden), use '-vv' to show

tests/unit/strategies/indexing/test_context_aware.py:33: AssertionError
_______________________ TestImports.test_import_factory ________________________

self = <tests.unit.test_package.TestImports object at 0x788cd9f67200>

    def test_import_factory(self) -> None:
        """Test RAGFactory can be imported."""
>       from rag_factory import RAGFactory
E       ImportError: cannot import name 'RAGFactory' from 'rag_factory' (/mnt/MCPProyects/ragTools/rag_factory/__init__.py)

tests/unit/test_package.py:18: ImportError
_______________________ TestImports.test_import_pipeline _______________________

self = <tests.unit.test_package.TestImports object at 0x788cd9f67230>

    def test_import_pipeline(self) -> None:
        """Test StrategyPipeline can be imported."""
>       from rag_factory import StrategyPipeline
E       ImportError: cannot import name 'StrategyPipeline' from 'rag_factory' (/mnt/MCPProyects/ragTools/rag_factory/__init__.py)

tests/unit/test_package.py:24: ImportError
________________________ TestImports.test_import_config ________________________

self = <tests.unit.test_package.TestImports object at 0x788cd9f66900>

    def test_import_config(self) -> None:
        """Test ConfigManager can be imported."""
>       from rag_factory import ConfigManager
E       ImportError: cannot import name 'ConfigManager' from 'rag_factory' (/mnt/MCPProyects/ragTools/rag_factory/__init__.py)

tests/unit/test_package.py:30: ImportError
________________ TestPackageStructure.test_no_circular_imports _________________

self = <tests.unit.test_package.TestPackageStructure object at 0x788cd9f67b00>

    def test_no_circular_imports(self) -> None:
        """Test importing doesn't cause circular import errors."""
        try:
>           from rag_factory import RAGFactory
E           ImportError: cannot import name 'RAGFactory' from 'rag_factory' (/mnt/MCPProyects/ragTools/rag_factory/__init__.py)

tests/unit/test_package.py:81: ImportError

During handling of the above exception, another exception occurred:

self = <tests.unit.test_package.TestPackageStructure object at 0x788cd9f67b00>

    def test_no_circular_imports(self) -> None:
        """Test importing doesn't cause circular import errors."""
        try:
            from rag_factory import RAGFactory
            from rag_factory import StrategyPipeline
            from rag_factory import ConfigManager
            from rag_factory.strategies import IRAGStrategy
    
            # If we get here, no circular imports
            assert RAGFactory is not None
            assert StrategyPipeline is not None
            assert ConfigManager is not None
            assert IRAGStrategy is not None
        except ImportError as e:
>           pytest.fail(f"Circular import detected: {e}")
E           Failed: Circular import detected: cannot import name 'RAGFactory' from 'rag_factory' (/mnt/MCPProyects/ragTools/rag_factory/__init__.py)

tests/unit/test_package.py:92: Failed
_____________ TestDependencies.test_optional_dependencies_handled ______________

self = <tests.unit.test_package.TestDependencies object at 0x788cd9f844a0>

    def test_optional_dependencies_handled(self) -> None:
        """Test package works without optional dependencies."""
        # Should not fail if optional dependencies missing
>       from rag_factory import RAGFactory
E       ImportError: cannot import name 'RAGFactory' from 'rag_factory' (/mnt/MCPProyects/ragTools/rag_factory/__init__.py)

tests/unit/test_package.py:111: ImportError
____________ TestMigrationIntegration.test_real_migration_execution ____________

self = <sqlalchemy.engine.base.Connection object at 0x788cc992f950>
dialect = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x788cc992ebd0>
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x788cc99e0ad0>
statement = <sqlalchemy.dialects.postgresql.base.PGCompiler object at 0x788cc99e0b60>
parameters = [{}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x788cc992ebd0>
cursor = <cursor object at 0x788cc8a6d7b0; closed: -1>
statement = 'DROP EXTENSION IF EXISTS vector', parameters = {}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x788cc99e0ad0>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       psycopg2.errors.DependentObjectsStillExist: cannot drop extension vector because other objects depend on it
E       DETAIL:  column embedding of table test_chunks_real depends on type vector
E       HINT:  Use DROP ... CASCADE to drop the dependent objects too.

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: DependentObjectsStillExist

The above exception was the direct cause of the following exception:

self = <tests.integration.database.test_migration_integration.TestMigrationIntegration object at 0x788cd9f84c50>
alembic_config = <alembic.config.Config object at 0x788cc99e0230>
test_db_url = 'postgresql://rag_user:rag_password@192.168.56.1:5432/rag_test'

    @pytest.mark.asyncio
    async def test_real_migration_execution(self, alembic_config: Config, test_db_url: str) -> None:
        """Test running migrations against real database."""
        # Start from clean state
>       command.downgrade(alembic_config, "base")

tests/integration/database/test_migration_integration.py:29: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
venv/lib/python3.12/site-packages/alembic/command.py:449: in downgrade
    script.run_env()
venv/lib/python3.12/site-packages/alembic/script/base.py:583: in run_env
    util.load_python_file(self.dir, "env.py")
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:95: in load_python_file
    module = load_module_py(module_id, path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:113: in load_module_py
    spec.loader.exec_module(module)  # type: ignore
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
<frozen importlib._bootstrap_external>:995: in exec_module
    ???
<frozen importlib._bootstrap>:488: in _call_with_frames_removed
    ???
migrations/env.py:93: in <module>
    run_migrations_online()
migrations/env.py:87: in run_migrations_online
    context.run_migrations()
<string>:8: in run_migrations
    ???
venv/lib/python3.12/site-packages/alembic/runtime/environment.py:948: in run_migrations
    self.get_context().run_migrations(**kw)
venv/lib/python3.12/site-packages/alembic/runtime/migration.py:627: in run_migrations
    step.migration_fn(**kw)
migrations/versions/001_initial_schema.py:129: in downgrade
    op.execute("DROP EXTENSION IF EXISTS vector")
<string>:8: in execute
    ???
<string>:3: in execute
    ???
venv/lib/python3.12/site-packages/alembic/operations/ops.py:2537: in execute
    return operations.invoke(op)
           ^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/base.py:445: in invoke
    return fn(self, operation)
           ^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/toimpl.py:224: in execute_sql
    operations.migration_context.impl.execute(
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:214: in execute
    self._exec(sql, execution_options)
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:207: in _exec
    return conn.execute(construct, multiparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1416: in execute
    return meth(
venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py:516: in _execute_on_connection
    return connection._execute_clauseelement(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1639: in _execute_clauseelement
    ret = self._execute_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1848: in _execute_context
    return self._exec_single_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1988: in _exec_single_context
    self._handle_dbapi_exception(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2343: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: in _exec_single_context
    self.dialect.do_execute(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x788cc992ebd0>
cursor = <cursor object at 0x788cc8a6d7b0; closed: -1>
statement = 'DROP EXTENSION IF EXISTS vector', parameters = {}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x788cc99e0ad0>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.InternalError: (psycopg2.errors.DependentObjectsStillExist) cannot drop extension vector because other objects depend on it
E       DETAIL:  column embedding of table test_chunks_real depends on type vector
E       HINT:  Use DROP ... CASCADE to drop the dependent objects too.
E       
E       [SQL: DROP EXTENSION IF EXISTS vector]
E       (Background on this error at: https://sqlalche.me/e/20/2j85)

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: InternalError
----------------------------- Captured stderr call -----------------------------
INFO  [alembic.runtime.migration] Context impl PostgresqlImpl.
INFO  [alembic.runtime.migration] Will assume transactional DDL.
INFO  [alembic.runtime.migration] Running downgrade 001 -> , Initial schema with documents and chunks tables
__________ TestMigrationIntegration.test_migration_with_existing_data __________

self = <sqlalchemy.engine.base.Connection object at 0x788cc9911340>
dialect = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x788cc99113d0>
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x788cc9901ee0>
statement = <sqlalchemy.dialects.postgresql.base.PGCompiler object at 0x788cc9901790>
parameters = [{}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x788cc99113d0>
cursor = <cursor object at 0x788cd8d68f40; closed: -1>
statement = 'DROP EXTENSION IF EXISTS vector', parameters = {}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x788cc9901ee0>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       psycopg2.errors.DependentObjectsStillExist: cannot drop extension vector because other objects depend on it
E       DETAIL:  column embedding of table test_chunks_real depends on type vector
E       HINT:  Use DROP ... CASCADE to drop the dependent objects too.

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: DependentObjectsStillExist

The above exception was the direct cause of the following exception:

self = <tests.integration.database.test_migration_integration.TestMigrationIntegration object at 0x788cd9f84ef0>
alembic_config = <alembic.config.Config object at 0x788cc99e1790>
test_db_url = 'postgresql://rag_user:rag_password@192.168.56.1:5432/rag_test'

    @pytest.mark.asyncio
    async def test_migration_with_existing_data(self, alembic_config: Config, test_db_url: str) -> None:
        """Test migration with existing data in database."""
        # Start from clean state
>       command.downgrade(alembic_config, "base")

tests/integration/database/test_migration_integration.py:48: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
venv/lib/python3.12/site-packages/alembic/command.py:449: in downgrade
    script.run_env()
venv/lib/python3.12/site-packages/alembic/script/base.py:583: in run_env
    util.load_python_file(self.dir, "env.py")
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:95: in load_python_file
    module = load_module_py(module_id, path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:113: in load_module_py
    spec.loader.exec_module(module)  # type: ignore
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
<frozen importlib._bootstrap_external>:995: in exec_module
    ???
<frozen importlib._bootstrap>:488: in _call_with_frames_removed
    ???
migrations/env.py:93: in <module>
    run_migrations_online()
migrations/env.py:87: in run_migrations_online
    context.run_migrations()
<string>:8: in run_migrations
    ???
venv/lib/python3.12/site-packages/alembic/runtime/environment.py:948: in run_migrations
    self.get_context().run_migrations(**kw)
venv/lib/python3.12/site-packages/alembic/runtime/migration.py:627: in run_migrations
    step.migration_fn(**kw)
migrations/versions/001_initial_schema.py:129: in downgrade
    op.execute("DROP EXTENSION IF EXISTS vector")
<string>:8: in execute
    ???
<string>:3: in execute
    ???
venv/lib/python3.12/site-packages/alembic/operations/ops.py:2537: in execute
    return operations.invoke(op)
           ^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/base.py:445: in invoke
    return fn(self, operation)
           ^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/toimpl.py:224: in execute_sql
    operations.migration_context.impl.execute(
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:214: in execute
    self._exec(sql, execution_options)
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:207: in _exec
    return conn.execute(construct, multiparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1416: in execute
    return meth(
venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py:516: in _execute_on_connection
    return connection._execute_clauseelement(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1639: in _execute_clauseelement
    ret = self._execute_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1848: in _execute_context
    return self._exec_single_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1988: in _exec_single_context
    self._handle_dbapi_exception(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2343: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: in _exec_single_context
    self.dialect.do_execute(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x788cc99113d0>
cursor = <cursor object at 0x788cd8d68f40; closed: -1>
statement = 'DROP EXTENSION IF EXISTS vector', parameters = {}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x788cc9901ee0>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.InternalError: (psycopg2.errors.DependentObjectsStillExist) cannot drop extension vector because other objects depend on it
E       DETAIL:  column embedding of table test_chunks_real depends on type vector
E       HINT:  Use DROP ... CASCADE to drop the dependent objects too.
E       
E       [SQL: DROP EXTENSION IF EXISTS vector]
E       (Background on this error at: https://sqlalche.me/e/20/2j85)

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: InternalError
----------------------------- Captured stderr call -----------------------------
INFO  [alembic.runtime.migration] Context impl PostgresqlImpl.
INFO  [alembic.runtime.migration] Will assume transactional DDL.
INFO  [alembic.runtime.migration] Running downgrade 001 -> , Initial schema with documents and chunks tables
_____________ TestMigrationIntegration.test_rollback_functionality _____________

self = <sqlalchemy.engine.base.Connection object at 0x788cc99112e0>
dialect = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x788cc99d5fa0>
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x788cc992ed20>
statement = <sqlalchemy.dialects.postgresql.base.PGCompiler object at 0x788cc992df10>
parameters = [{}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x788cc99d5fa0>
cursor = <cursor object at 0x788cc8ad2f20; closed: -1>
statement = 'DROP EXTENSION IF EXISTS vector', parameters = {}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x788cc992ed20>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       psycopg2.errors.DependentObjectsStillExist: cannot drop extension vector because other objects depend on it
E       DETAIL:  column embedding of table test_chunks_real depends on type vector
E       HINT:  Use DROP ... CASCADE to drop the dependent objects too.

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: DependentObjectsStillExist

The above exception was the direct cause of the following exception:

self = <tests.integration.database.test_migration_integration.TestMigrationIntegration object at 0x788cd9f85310>
alembic_config = <alembic.config.Config object at 0x788cc9921760>
test_db_url = 'postgresql://rag_user:rag_password@192.168.56.1:5432/rag_test'

    @pytest.mark.asyncio
    async def test_rollback_functionality(self, alembic_config: Config, test_db_url: str) -> None:
        """Test rolling back migrations."""
        # Start from clean state
>       command.downgrade(alembic_config, "base")

tests/integration/database/test_migration_integration.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
venv/lib/python3.12/site-packages/alembic/command.py:449: in downgrade
    script.run_env()
venv/lib/python3.12/site-packages/alembic/script/base.py:583: in run_env
    util.load_python_file(self.dir, "env.py")
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:95: in load_python_file
    module = load_module_py(module_id, path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:113: in load_module_py
    spec.loader.exec_module(module)  # type: ignore
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
<frozen importlib._bootstrap_external>:995: in exec_module
    ???
<frozen importlib._bootstrap>:488: in _call_with_frames_removed
    ???
migrations/env.py:93: in <module>
    run_migrations_online()
migrations/env.py:87: in run_migrations_online
    context.run_migrations()
<string>:8: in run_migrations
    ???
venv/lib/python3.12/site-packages/alembic/runtime/environment.py:948: in run_migrations
    self.get_context().run_migrations(**kw)
venv/lib/python3.12/site-packages/alembic/runtime/migration.py:627: in run_migrations
    step.migration_fn(**kw)
migrations/versions/001_initial_schema.py:129: in downgrade
    op.execute("DROP EXTENSION IF EXISTS vector")
<string>:8: in execute
    ???
<string>:3: in execute
    ???
venv/lib/python3.12/site-packages/alembic/operations/ops.py:2537: in execute
    return operations.invoke(op)
           ^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/base.py:445: in invoke
    return fn(self, operation)
           ^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/toimpl.py:224: in execute_sql
    operations.migration_context.impl.execute(
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:214: in execute
    self._exec(sql, execution_options)
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:207: in _exec
    return conn.execute(construct, multiparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1416: in execute
    return meth(
venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py:516: in _execute_on_connection
    return connection._execute_clauseelement(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1639: in _execute_clauseelement
    ret = self._execute_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1848: in _execute_context
    return self._exec_single_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1988: in _exec_single_context
    self._handle_dbapi_exception(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2343: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: in _exec_single_context
    self.dialect.do_execute(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x788cc99d5fa0>
cursor = <cursor object at 0x788cc8ad2f20; closed: -1>
statement = 'DROP EXTENSION IF EXISTS vector', parameters = {}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x788cc992ed20>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.InternalError: (psycopg2.errors.DependentObjectsStillExist) cannot drop extension vector because other objects depend on it
E       DETAIL:  column embedding of table test_chunks_real depends on type vector
E       HINT:  Use DROP ... CASCADE to drop the dependent objects too.
E       
E       [SQL: DROP EXTENSION IF EXISTS vector]
E       (Background on this error at: https://sqlalche.me/e/20/2j85)

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: InternalError
----------------------------- Captured stderr call -----------------------------
INFO  [alembic.runtime.migration] Context impl PostgresqlImpl.
INFO  [alembic.runtime.migration] Will assume transactional DDL.
INFO  [alembic.runtime.migration] Running downgrade 001 -> , Initial schema with documents and chunks tables
__________ TestMigrationIntegration.test_pgvector_extension_installed __________

self = <sqlalchemy.engine.base.Connection object at 0x788cc99d5f40>
dialect = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x788cc99199a0>
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x788cc99eb020>
statement = <sqlalchemy.dialects.postgresql.base.PGDDLCompiler object at 0x788cc99e84a0>
parameters = [immutabledict({})]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x788cc99199a0>
cursor = <cursor object at 0x788cd8e247c0; closed: -1>
statement = 'ALTER TABLE chunks ADD COLUMN parent_chunk_id UUID'
parameters = immutabledict({})
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x788cc99eb020>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       psycopg2.errors.UndefinedTable: relation "chunks" does not exist

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: UndefinedTable

The above exception was the direct cause of the following exception:

self = <tests.integration.database.test_migration_integration.TestMigrationIntegration object at 0x788cd9f67ce0>
alembic_config = <alembic.config.Config object at 0x788cc991ad50>
test_db_url = 'postgresql://rag_user:rag_password@192.168.56.1:5432/rag_test'

    @pytest.mark.asyncio
    async def test_pgvector_extension_installed(self, alembic_config: Config, test_db_url: str) -> None:
        """Test that pgvector extension is installed by migrations."""
        # Upgrade to head
>       command.upgrade(alembic_config, "head")

tests/integration/database/test_migration_integration.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
venv/lib/python3.12/site-packages/alembic/command.py:403: in upgrade
    script.run_env()
venv/lib/python3.12/site-packages/alembic/script/base.py:583: in run_env
    util.load_python_file(self.dir, "env.py")
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:95: in load_python_file
    module = load_module_py(module_id, path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:113: in load_module_py
    spec.loader.exec_module(module)  # type: ignore
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
<frozen importlib._bootstrap_external>:995: in exec_module
    ???
<frozen importlib._bootstrap>:488: in _call_with_frames_removed
    ???
migrations/env.py:93: in <module>
    run_migrations_online()
migrations/env.py:87: in run_migrations_online
    context.run_migrations()
<string>:8: in run_migrations
    ???
venv/lib/python3.12/site-packages/alembic/runtime/environment.py:948: in run_migrations
    self.get_context().run_migrations(**kw)
venv/lib/python3.12/site-packages/alembic/runtime/migration.py:627: in run_migrations
    step.migration_fn(**kw)
migrations/versions/002_add_hierarchy_support.py:26: in upgrade
    op.add_column(
<string>:8: in add_column
    ???
<string>:3: in add_column
    ???
venv/lib/python3.12/site-packages/alembic/operations/ops.py:2142: in add_column
    return operations.invoke(op)
           ^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/base.py:445: in invoke
    return fn(self, operation)
           ^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/toimpl.py:171: in add_column
    operations.impl.add_column(table_name, column, schema=schema, **kw)
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:334: in add_column
    self._exec(base.AddColumn(table_name, column, schema=schema))
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:207: in _exec
    return conn.execute(construct, multiparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1416: in execute
    return meth(
venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:181: in _execute_on_connection
    return connection._execute_ddl(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1528: in _execute_ddl
    ret = self._execute_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1848: in _execute_context
    return self._exec_single_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1988: in _exec_single_context
    self._handle_dbapi_exception(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2343: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: in _exec_single_context
    self.dialect.do_execute(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x788cc99199a0>
cursor = <cursor object at 0x788cd8e247c0; closed: -1>
statement = 'ALTER TABLE chunks ADD COLUMN parent_chunk_id UUID'
parameters = immutabledict({})
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x788cc99eb020>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "chunks" does not exist
E       
E       [SQL: ALTER TABLE chunks ADD COLUMN parent_chunk_id UUID]
E       (Background on this error at: https://sqlalche.me/e/20/f405)

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: ProgrammingError
----------------------------- Captured stderr call -----------------------------
INFO  [alembic.runtime.migration] Context impl PostgresqlImpl.
INFO  [alembic.runtime.migration] Will assume transactional DDL.
INFO  [alembic.runtime.migration] Running upgrade 001 -> 002, Add hierarchy support to chunks table
______ TestMigrationValidatorIntegration.test_validate_with_no_migrations ______

self = <sqlalchemy.engine.base.Connection object at 0x788cc9919a30>
dialect = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x788cc990b680>
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x788cc990b770>
statement = <sqlalchemy.dialects.postgresql.base.PGCompiler object at 0x788cc990b7a0>
parameters = [{}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x788cc990b680>
cursor = <cursor object at 0x788cd8e258a0; closed: -1>
statement = 'DROP EXTENSION IF EXISTS vector', parameters = {}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x788cc990b770>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       psycopg2.errors.DependentObjectsStillExist: cannot drop extension vector because other objects depend on it
E       DETAIL:  column embedding of table test_chunks_real depends on type vector
E       HINT:  Use DROP ... CASCADE to drop the dependent objects too.

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: DependentObjectsStillExist

The above exception was the direct cause of the following exception:

self = <tests.integration.database.test_migration_validator_integration.TestMigrationValidatorIntegration object at 0x788cd9f84380>
validator = <rag_factory.services.database.migration_validator.MigrationValidator object at 0x788cc99e8320>
alembic_config = <alembic.config.Config object at 0x788cc99e87a0>

    @pytest.mark.asyncio
    async def test_validate_with_no_migrations(
        self,
        validator: MigrationValidator,
        alembic_config: Config
    ) -> None:
        """Test validation when no migrations are applied."""
        # Start from clean state
>       command.downgrade(alembic_config, "base")

tests/integration/database/test_migration_validator_integration.py:68: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
venv/lib/python3.12/site-packages/alembic/command.py:449: in downgrade
    script.run_env()
venv/lib/python3.12/site-packages/alembic/script/base.py:583: in run_env
    util.load_python_file(self.dir, "env.py")
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:95: in load_python_file
    module = load_module_py(module_id, path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:113: in load_module_py
    spec.loader.exec_module(module)  # type: ignore
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
<frozen importlib._bootstrap_external>:995: in exec_module
    ???
<frozen importlib._bootstrap>:488: in _call_with_frames_removed
    ???
migrations/env.py:93: in <module>
    run_migrations_online()
migrations/env.py:87: in run_migrations_online
    context.run_migrations()
<string>:8: in run_migrations
    ???
venv/lib/python3.12/site-packages/alembic/runtime/environment.py:948: in run_migrations
    self.get_context().run_migrations(**kw)
venv/lib/python3.12/site-packages/alembic/runtime/migration.py:627: in run_migrations
    step.migration_fn(**kw)
migrations/versions/001_initial_schema.py:129: in downgrade
    op.execute("DROP EXTENSION IF EXISTS vector")
<string>:8: in execute
    ???
<string>:3: in execute
    ???
venv/lib/python3.12/site-packages/alembic/operations/ops.py:2537: in execute
    return operations.invoke(op)
           ^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/base.py:445: in invoke
    return fn(self, operation)
           ^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/toimpl.py:224: in execute_sql
    operations.migration_context.impl.execute(
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:214: in execute
    self._exec(sql, execution_options)
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:207: in _exec
    return conn.execute(construct, multiparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1416: in execute
    return meth(
venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py:516: in _execute_on_connection
    return connection._execute_clauseelement(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1639: in _execute_clauseelement
    ret = self._execute_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1848: in _execute_context
    return self._exec_single_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1988: in _exec_single_context
    self._handle_dbapi_exception(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2343: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: in _exec_single_context
    self.dialect.do_execute(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x788cc990b680>
cursor = <cursor object at 0x788cd8e258a0; closed: -1>
statement = 'DROP EXTENSION IF EXISTS vector', parameters = {}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x788cc990b770>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.InternalError: (psycopg2.errors.DependentObjectsStillExist) cannot drop extension vector because other objects depend on it
E       DETAIL:  column embedding of table test_chunks_real depends on type vector
E       HINT:  Use DROP ... CASCADE to drop the dependent objects too.
E       
E       [SQL: DROP EXTENSION IF EXISTS vector]
E       (Background on this error at: https://sqlalche.me/e/20/2j85)

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: InternalError
----------------------------- Captured stderr call -----------------------------
INFO  [alembic.runtime.migration] Context impl PostgresqlImpl.
INFO  [alembic.runtime.migration] Will assume transactional DDL.
INFO  [alembic.runtime.migration] Running downgrade 001 -> , Initial schema with documents and chunks tables
___ TestMigrationValidatorIntegration.test_validate_with_partial_migrations ____

self = <sqlalchemy.engine.base.Connection object at 0x788cc99e1e80>
dialect = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x788cc99228a0>
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x788cc9913c50>
statement = <sqlalchemy.dialects.postgresql.base.PGCompiler object at 0x788cc9911310>
parameters = [{}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x788cc99228a0>
cursor = <cursor object at 0x788cc8a6f3d0; closed: -1>
statement = 'DROP EXTENSION IF EXISTS vector', parameters = {}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x788cc9913c50>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       psycopg2.errors.DependentObjectsStillExist: cannot drop extension vector because other objects depend on it
E       DETAIL:  column embedding of table test_chunks_real depends on type vector
E       HINT:  Use DROP ... CASCADE to drop the dependent objects too.

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: DependentObjectsStillExist

The above exception was the direct cause of the following exception:

self = <tests.integration.database.test_migration_validator_integration.TestMigrationValidatorIntegration object at 0x788cd9f857f0>
validator = <rag_factory.services.database.migration_validator.MigrationValidator object at 0x788cc99e2750>
alembic_config = <alembic.config.Config object at 0x788cd9f84560>

    @pytest.mark.asyncio
    async def test_validate_with_partial_migrations(
        self,
        validator: MigrationValidator,
        alembic_config: Config
    ) -> None:
        """Test validation when only some migrations are applied."""
        # Start from clean state
>       command.downgrade(alembic_config, "base")

tests/integration/database/test_migration_validator_integration.py:85: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
venv/lib/python3.12/site-packages/alembic/command.py:449: in downgrade
    script.run_env()
venv/lib/python3.12/site-packages/alembic/script/base.py:583: in run_env
    util.load_python_file(self.dir, "env.py")
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:95: in load_python_file
    module = load_module_py(module_id, path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:113: in load_module_py
    spec.loader.exec_module(module)  # type: ignore
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
<frozen importlib._bootstrap_external>:995: in exec_module
    ???
<frozen importlib._bootstrap>:488: in _call_with_frames_removed
    ???
migrations/env.py:93: in <module>
    run_migrations_online()
migrations/env.py:87: in run_migrations_online
    context.run_migrations()
<string>:8: in run_migrations
    ???
venv/lib/python3.12/site-packages/alembic/runtime/environment.py:948: in run_migrations
    self.get_context().run_migrations(**kw)
venv/lib/python3.12/site-packages/alembic/runtime/migration.py:627: in run_migrations
    step.migration_fn(**kw)
migrations/versions/001_initial_schema.py:129: in downgrade
    op.execute("DROP EXTENSION IF EXISTS vector")
<string>:8: in execute
    ???
<string>:3: in execute
    ???
venv/lib/python3.12/site-packages/alembic/operations/ops.py:2537: in execute
    return operations.invoke(op)
           ^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/base.py:445: in invoke
    return fn(self, operation)
           ^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/toimpl.py:224: in execute_sql
    operations.migration_context.impl.execute(
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:214: in execute
    self._exec(sql, execution_options)
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:207: in _exec
    return conn.execute(construct, multiparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1416: in execute
    return meth(
venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py:516: in _execute_on_connection
    return connection._execute_clauseelement(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1639: in _execute_clauseelement
    ret = self._execute_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1848: in _execute_context
    return self._exec_single_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1988: in _exec_single_context
    self._handle_dbapi_exception(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2343: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: in _exec_single_context
    self.dialect.do_execute(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x788cc99228a0>
cursor = <cursor object at 0x788cc8a6f3d0; closed: -1>
statement = 'DROP EXTENSION IF EXISTS vector', parameters = {}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x788cc9913c50>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.InternalError: (psycopg2.errors.DependentObjectsStillExist) cannot drop extension vector because other objects depend on it
E       DETAIL:  column embedding of table test_chunks_real depends on type vector
E       HINT:  Use DROP ... CASCADE to drop the dependent objects too.
E       
E       [SQL: DROP EXTENSION IF EXISTS vector]
E       (Background on this error at: https://sqlalche.me/e/20/2j85)

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: InternalError
----------------------------- Captured stderr call -----------------------------
INFO  [alembic.runtime.migration] Context impl PostgresqlImpl.
INFO  [alembic.runtime.migration] Will assume transactional DDL.
INFO  [alembic.runtime.migration] Running downgrade 001 -> , Initial schema with documents and chunks tables
_____ TestMigrationValidatorIntegration.test_validate_with_all_migrations ______

self = <sqlalchemy.engine.base.Connection object at 0x788cc9921820>
dialect = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x788cd8d6f710>
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x788cc99eabd0>
statement = <sqlalchemy.dialects.postgresql.base.PGDDLCompiler object at 0x788cd8d6fb60>
parameters = [immutabledict({})]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x788cd8d6f710>
cursor = <cursor object at 0x788cd8d6af20; closed: -1>
statement = 'ALTER TABLE chunks ADD COLUMN parent_chunk_id UUID'
parameters = immutabledict({})
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x788cc99eabd0>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       psycopg2.errors.UndefinedTable: relation "chunks" does not exist

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: UndefinedTable

The above exception was the direct cause of the following exception:

self = <tests.integration.database.test_migration_validator_integration.TestMigrationValidatorIntegration object at 0x788cd9f85c10>
validator = <rag_factory.services.database.migration_validator.MigrationValidator object at 0x788cd8d20b90>
alembic_config = <alembic.config.Config object at 0x788cc9921940>

    @pytest.mark.asyncio
    async def test_validate_with_all_migrations(
        self,
        validator: MigrationValidator,
        alembic_config: Config
    ) -> None:
        """Test validation when all required migrations are applied."""
        # Apply all migrations
>       command.upgrade(alembic_config, "head")

tests/integration/database/test_migration_validator_integration.py:105: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
venv/lib/python3.12/site-packages/alembic/command.py:403: in upgrade
    script.run_env()
venv/lib/python3.12/site-packages/alembic/script/base.py:583: in run_env
    util.load_python_file(self.dir, "env.py")
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:95: in load_python_file
    module = load_module_py(module_id, path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:113: in load_module_py
    spec.loader.exec_module(module)  # type: ignore
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
<frozen importlib._bootstrap_external>:995: in exec_module
    ???
<frozen importlib._bootstrap>:488: in _call_with_frames_removed
    ???
migrations/env.py:93: in <module>
    run_migrations_online()
migrations/env.py:87: in run_migrations_online
    context.run_migrations()
<string>:8: in run_migrations
    ???
venv/lib/python3.12/site-packages/alembic/runtime/environment.py:948: in run_migrations
    self.get_context().run_migrations(**kw)
venv/lib/python3.12/site-packages/alembic/runtime/migration.py:627: in run_migrations
    step.migration_fn(**kw)
migrations/versions/002_add_hierarchy_support.py:26: in upgrade
    op.add_column(
<string>:8: in add_column
    ???
<string>:3: in add_column
    ???
venv/lib/python3.12/site-packages/alembic/operations/ops.py:2142: in add_column
    return operations.invoke(op)
           ^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/base.py:445: in invoke
    return fn(self, operation)
           ^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/toimpl.py:171: in add_column
    operations.impl.add_column(table_name, column, schema=schema, **kw)
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:334: in add_column
    self._exec(base.AddColumn(table_name, column, schema=schema))
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:207: in _exec
    return conn.execute(construct, multiparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1416: in execute
    return meth(
venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:181: in _execute_on_connection
    return connection._execute_ddl(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1528: in _execute_ddl
    ret = self._execute_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1848: in _execute_context
    return self._exec_single_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1988: in _exec_single_context
    self._handle_dbapi_exception(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2343: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: in _exec_single_context
    self.dialect.do_execute(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x788cd8d6f710>
cursor = <cursor object at 0x788cd8d6af20; closed: -1>
statement = 'ALTER TABLE chunks ADD COLUMN parent_chunk_id UUID'
parameters = immutabledict({})
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x788cc99eabd0>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "chunks" does not exist
E       
E       [SQL: ALTER TABLE chunks ADD COLUMN parent_chunk_id UUID]
E       (Background on this error at: https://sqlalche.me/e/20/f405)

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: ProgrammingError
----------------------------- Captured stderr call -----------------------------
INFO  [alembic.runtime.migration] Context impl PostgresqlImpl.
INFO  [alembic.runtime.migration] Will assume transactional DDL.
INFO  [alembic.runtime.migration] Running upgrade 001 -> 002, Add hierarchy support to chunks table
_______ TestMigrationValidatorIntegration.test_validate_or_raise_success _______

self = <sqlalchemy.engine.base.Connection object at 0x788cc9902e10>
dialect = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x788cc9900440>
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x788cc992ea20>
statement = <sqlalchemy.dialects.postgresql.base.PGDDLCompiler object at 0x788cc992ec00>
parameters = [immutabledict({})]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x788cc9900440>
cursor = <cursor object at 0x788cd8e25a80; closed: -1>
statement = 'ALTER TABLE chunks ADD COLUMN parent_chunk_id UUID'
parameters = immutabledict({})
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x788cc992ea20>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       psycopg2.errors.UndefinedTable: relation "chunks" does not exist

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: UndefinedTable

The above exception was the direct cause of the following exception:

self = <tests.integration.database.test_migration_validator_integration.TestMigrationValidatorIntegration object at 0x788cd9f86000>
validator = <rag_factory.services.database.migration_validator.MigrationValidator object at 0x788cc99027e0>
alembic_config = <alembic.config.Config object at 0x788cc9902db0>

    @pytest.mark.asyncio
    async def test_validate_or_raise_success(
        self,
        validator: MigrationValidator,
        alembic_config: Config
    ) -> None:
        """Test validate_or_raise when all migrations are applied."""
        # Apply all migrations
>       command.upgrade(alembic_config, "head")

tests/integration/database/test_migration_validator_integration.py:121: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
venv/lib/python3.12/site-packages/alembic/command.py:403: in upgrade
    script.run_env()
venv/lib/python3.12/site-packages/alembic/script/base.py:583: in run_env
    util.load_python_file(self.dir, "env.py")
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:95: in load_python_file
    module = load_module_py(module_id, path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:113: in load_module_py
    spec.loader.exec_module(module)  # type: ignore
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
<frozen importlib._bootstrap_external>:995: in exec_module
    ???
<frozen importlib._bootstrap>:488: in _call_with_frames_removed
    ???
migrations/env.py:93: in <module>
    run_migrations_online()
migrations/env.py:87: in run_migrations_online
    context.run_migrations()
<string>:8: in run_migrations
    ???
venv/lib/python3.12/site-packages/alembic/runtime/environment.py:948: in run_migrations
    self.get_context().run_migrations(**kw)
venv/lib/python3.12/site-packages/alembic/runtime/migration.py:627: in run_migrations
    step.migration_fn(**kw)
migrations/versions/002_add_hierarchy_support.py:26: in upgrade
    op.add_column(
<string>:8: in add_column
    ???
<string>:3: in add_column
    ???
venv/lib/python3.12/site-packages/alembic/operations/ops.py:2142: in add_column
    return operations.invoke(op)
           ^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/base.py:445: in invoke
    return fn(self, operation)
           ^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/toimpl.py:171: in add_column
    operations.impl.add_column(table_name, column, schema=schema, **kw)
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:334: in add_column
    self._exec(base.AddColumn(table_name, column, schema=schema))
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:207: in _exec
    return conn.execute(construct, multiparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1416: in execute
    return meth(
venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:181: in _execute_on_connection
    return connection._execute_ddl(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1528: in _execute_ddl
    ret = self._execute_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1848: in _execute_context
    return self._exec_single_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1988: in _exec_single_context
    self._handle_dbapi_exception(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2343: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: in _exec_single_context
    self.dialect.do_execute(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x788cc9900440>
cursor = <cursor object at 0x788cd8e25a80; closed: -1>
statement = 'ALTER TABLE chunks ADD COLUMN parent_chunk_id UUID'
parameters = immutabledict({})
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x788cc992ea20>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "chunks" does not exist
E       
E       [SQL: ALTER TABLE chunks ADD COLUMN parent_chunk_id UUID]
E       (Background on this error at: https://sqlalche.me/e/20/f405)

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: ProgrammingError
----------------------------- Captured stderr call -----------------------------
INFO  [alembic.runtime.migration] Context impl PostgresqlImpl.
INFO  [alembic.runtime.migration] Will assume transactional DDL.
INFO  [alembic.runtime.migration] Running upgrade 001 -> 002, Add hierarchy support to chunks table
_______ TestMigrationValidatorIntegration.test_validate_or_raise_failure _______

self = <sqlalchemy.engine.base.Connection object at 0x788cc99024b0>
dialect = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x788cc87f5010>
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x788cd8e89f40>
statement = <sqlalchemy.dialects.postgresql.base.PGCompiler object at 0x788cd8e89a60>
parameters = [{}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x788cc87f5010>
cursor = <cursor object at 0x788cd8e265c0; closed: -1>
statement = 'DROP EXTENSION IF EXISTS vector', parameters = {}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x788cd8e89f40>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       psycopg2.errors.DependentObjectsStillExist: cannot drop extension vector because other objects depend on it
E       DETAIL:  column embedding of table test_chunks_real depends on type vector
E       HINT:  Use DROP ... CASCADE to drop the dependent objects too.

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: DependentObjectsStillExist

The above exception was the direct cause of the following exception:

self = <tests.integration.database.test_migration_validator_integration.TestMigrationValidatorIntegration object at 0x788cd9f863f0>
validator = <rag_factory.services.database.migration_validator.MigrationValidator object at 0x788cc99092e0>
alembic_config = <alembic.config.Config object at 0x788cc9908dd0>

    @pytest.mark.asyncio
    async def test_validate_or_raise_failure(
        self,
        validator: MigrationValidator,
        alembic_config: Config
    ) -> None:
        """Test validate_or_raise when migrations are missing."""
        # Start from clean state
>       command.downgrade(alembic_config, "base")

tests/integration/database/test_migration_validator_integration.py:134: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
venv/lib/python3.12/site-packages/alembic/command.py:449: in downgrade
    script.run_env()
venv/lib/python3.12/site-packages/alembic/script/base.py:583: in run_env
    util.load_python_file(self.dir, "env.py")
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:95: in load_python_file
    module = load_module_py(module_id, path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:113: in load_module_py
    spec.loader.exec_module(module)  # type: ignore
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
<frozen importlib._bootstrap_external>:995: in exec_module
    ???
<frozen importlib._bootstrap>:488: in _call_with_frames_removed
    ???
migrations/env.py:93: in <module>
    run_migrations_online()
migrations/env.py:87: in run_migrations_online
    context.run_migrations()
<string>:8: in run_migrations
    ???
venv/lib/python3.12/site-packages/alembic/runtime/environment.py:948: in run_migrations
    self.get_context().run_migrations(**kw)
venv/lib/python3.12/site-packages/alembic/runtime/migration.py:627: in run_migrations
    step.migration_fn(**kw)
migrations/versions/001_initial_schema.py:129: in downgrade
    op.execute("DROP EXTENSION IF EXISTS vector")
<string>:8: in execute
    ???
<string>:3: in execute
    ???
venv/lib/python3.12/site-packages/alembic/operations/ops.py:2537: in execute
    return operations.invoke(op)
           ^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/base.py:445: in invoke
    return fn(self, operation)
           ^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/toimpl.py:224: in execute_sql
    operations.migration_context.impl.execute(
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:214: in execute
    self._exec(sql, execution_options)
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:207: in _exec
    return conn.execute(construct, multiparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1416: in execute
    return meth(
venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py:516: in _execute_on_connection
    return connection._execute_clauseelement(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1639: in _execute_clauseelement
    ret = self._execute_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1848: in _execute_context
    return self._exec_single_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1988: in _exec_single_context
    self._handle_dbapi_exception(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2343: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: in _exec_single_context
    self.dialect.do_execute(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x788cc87f5010>
cursor = <cursor object at 0x788cd8e265c0; closed: -1>
statement = 'DROP EXTENSION IF EXISTS vector', parameters = {}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x788cd8e89f40>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.InternalError: (psycopg2.errors.DependentObjectsStillExist) cannot drop extension vector because other objects depend on it
E       DETAIL:  column embedding of table test_chunks_real depends on type vector
E       HINT:  Use DROP ... CASCADE to drop the dependent objects too.
E       
E       [SQL: DROP EXTENSION IF EXISTS vector]
E       (Background on this error at: https://sqlalche.me/e/20/2j85)

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: InternalError
----------------------------- Captured stderr call -----------------------------
INFO  [alembic.runtime.migration] Context impl PostgresqlImpl.
INFO  [alembic.runtime.migration] Will assume transactional DDL.
INFO  [alembic.runtime.migration] Running downgrade 001 -> , Initial schema with documents and chunks tables
_________ TestMigrationValidatorIntegration.test_get_current_revision __________

self = <sqlalchemy.engine.base.Connection object at 0x788cc87f46b0>
dialect = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x788cd8d2c560>
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x788cd8d862a0>
statement = <sqlalchemy.dialects.postgresql.base.PGCompiler object at 0x788cd8d86d50>
parameters = [{}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x788cd8d2c560>
cursor = <cursor object at 0x788cd8e273d0; closed: -1>
statement = 'DROP EXTENSION IF EXISTS vector', parameters = {}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x788cd8d862a0>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       psycopg2.errors.DependentObjectsStillExist: cannot drop extension vector because other objects depend on it
E       DETAIL:  column embedding of table test_chunks_real depends on type vector
E       HINT:  Use DROP ... CASCADE to drop the dependent objects too.

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: DependentObjectsStillExist

The above exception was the direct cause of the following exception:

self = <tests.integration.database.test_migration_validator_integration.TestMigrationValidatorIntegration object at 0x788cd9f867e0>
validator = <rag_factory.services.database.migration_validator.MigrationValidator object at 0x788cd91e4410>
alembic_config = <alembic.config.Config object at 0x788cd8edac00>

    @pytest.mark.asyncio
    async def test_get_current_revision(
        self,
        validator: MigrationValidator,
        alembic_config: Config
    ) -> None:
        """Test getting current revision from database."""
        # Start from clean state
>       command.downgrade(alembic_config, "base")

tests/integration/database/test_migration_validator_integration.py:153: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
venv/lib/python3.12/site-packages/alembic/command.py:449: in downgrade
    script.run_env()
venv/lib/python3.12/site-packages/alembic/script/base.py:583: in run_env
    util.load_python_file(self.dir, "env.py")
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:95: in load_python_file
    module = load_module_py(module_id, path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:113: in load_module_py
    spec.loader.exec_module(module)  # type: ignore
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
<frozen importlib._bootstrap_external>:995: in exec_module
    ???
<frozen importlib._bootstrap>:488: in _call_with_frames_removed
    ???
migrations/env.py:93: in <module>
    run_migrations_online()
migrations/env.py:87: in run_migrations_online
    context.run_migrations()
<string>:8: in run_migrations
    ???
venv/lib/python3.12/site-packages/alembic/runtime/environment.py:948: in run_migrations
    self.get_context().run_migrations(**kw)
venv/lib/python3.12/site-packages/alembic/runtime/migration.py:627: in run_migrations
    step.migration_fn(**kw)
migrations/versions/001_initial_schema.py:129: in downgrade
    op.execute("DROP EXTENSION IF EXISTS vector")
<string>:8: in execute
    ???
<string>:3: in execute
    ???
venv/lib/python3.12/site-packages/alembic/operations/ops.py:2537: in execute
    return operations.invoke(op)
           ^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/base.py:445: in invoke
    return fn(self, operation)
           ^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/toimpl.py:224: in execute_sql
    operations.migration_context.impl.execute(
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:214: in execute
    self._exec(sql, execution_options)
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:207: in _exec
    return conn.execute(construct, multiparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1416: in execute
    return meth(
venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py:516: in _execute_on_connection
    return connection._execute_clauseelement(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1639: in _execute_clauseelement
    ret = self._execute_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1848: in _execute_context
    return self._exec_single_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1988: in _exec_single_context
    self._handle_dbapi_exception(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2343: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: in _exec_single_context
    self.dialect.do_execute(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x788cd8d2c560>
cursor = <cursor object at 0x788cd8e273d0; closed: -1>
statement = 'DROP EXTENSION IF EXISTS vector', parameters = {}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x788cd8d862a0>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.InternalError: (psycopg2.errors.DependentObjectsStillExist) cannot drop extension vector because other objects depend on it
E       DETAIL:  column embedding of table test_chunks_real depends on type vector
E       HINT:  Use DROP ... CASCADE to drop the dependent objects too.
E       
E       [SQL: DROP EXTENSION IF EXISTS vector]
E       (Background on this error at: https://sqlalche.me/e/20/2j85)

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: InternalError
----------------------------- Captured stderr call -----------------------------
INFO  [alembic.runtime.migration] Context impl PostgresqlImpl.
INFO  [alembic.runtime.migration] Will assume transactional DDL.
INFO  [alembic.runtime.migration] Running downgrade 001 -> , Initial schema with documents and chunks tables
______________ TestMigrationValidatorIntegration.test_is_at_head _______________

self = <sqlalchemy.engine.base.Connection object at 0x788cd8d2f140>
dialect = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x788cd8d5b440>
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x788cd8d5ae10>
statement = <sqlalchemy.dialects.postgresql.base.PGCompiler object at 0x788cd8d5a150>
parameters = [{}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x788cd8d5b440>
cursor = <cursor object at 0x788cc9a905e0; closed: -1>
statement = 'DROP EXTENSION IF EXISTS vector', parameters = {}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x788cd8d5ae10>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       psycopg2.errors.DependentObjectsStillExist: cannot drop extension vector because other objects depend on it
E       DETAIL:  column embedding of table test_chunks_real depends on type vector
E       HINT:  Use DROP ... CASCADE to drop the dependent objects too.

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: DependentObjectsStillExist

The above exception was the direct cause of the following exception:

self = <tests.integration.database.test_migration_validator_integration.TestMigrationValidatorIntegration object at 0x788cd9f86f60>
validator = <rag_factory.services.database.migration_validator.MigrationValidator object at 0x788cd90a3e00>
alembic_config = <alembic.config.Config object at 0x788cc9921280>

    @pytest.mark.asyncio
    async def test_is_at_head(
        self,
        validator: MigrationValidator,
        alembic_config: Config
    ) -> None:
        """Test checking if database is at head revision."""
        # Start from clean state
>       command.downgrade(alembic_config, "base")

tests/integration/database/test_migration_validator_integration.py:193: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
venv/lib/python3.12/site-packages/alembic/command.py:449: in downgrade
    script.run_env()
venv/lib/python3.12/site-packages/alembic/script/base.py:583: in run_env
    util.load_python_file(self.dir, "env.py")
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:95: in load_python_file
    module = load_module_py(module_id, path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:113: in load_module_py
    spec.loader.exec_module(module)  # type: ignore
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
<frozen importlib._bootstrap_external>:995: in exec_module
    ???
<frozen importlib._bootstrap>:488: in _call_with_frames_removed
    ???
migrations/env.py:93: in <module>
    run_migrations_online()
migrations/env.py:87: in run_migrations_online
    context.run_migrations()
<string>:8: in run_migrations
    ???
venv/lib/python3.12/site-packages/alembic/runtime/environment.py:948: in run_migrations
    self.get_context().run_migrations(**kw)
venv/lib/python3.12/site-packages/alembic/runtime/migration.py:627: in run_migrations
    step.migration_fn(**kw)
migrations/versions/001_initial_schema.py:129: in downgrade
    op.execute("DROP EXTENSION IF EXISTS vector")
<string>:8: in execute
    ???
<string>:3: in execute
    ???
venv/lib/python3.12/site-packages/alembic/operations/ops.py:2537: in execute
    return operations.invoke(op)
           ^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/base.py:445: in invoke
    return fn(self, operation)
           ^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/toimpl.py:224: in execute_sql
    operations.migration_context.impl.execute(
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:214: in execute
    self._exec(sql, execution_options)
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:207: in _exec
    return conn.execute(construct, multiparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1416: in execute
    return meth(
venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py:516: in _execute_on_connection
    return connection._execute_clauseelement(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1639: in _execute_clauseelement
    ret = self._execute_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1848: in _execute_context
    return self._exec_single_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1988: in _exec_single_context
    self._handle_dbapi_exception(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2343: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: in _exec_single_context
    self.dialect.do_execute(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x788cd8d5b440>
cursor = <cursor object at 0x788cc9a905e0; closed: -1>
statement = 'DROP EXTENSION IF EXISTS vector', parameters = {}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x788cd8d5ae10>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.InternalError: (psycopg2.errors.DependentObjectsStillExist) cannot drop extension vector because other objects depend on it
E       DETAIL:  column embedding of table test_chunks_real depends on type vector
E       HINT:  Use DROP ... CASCADE to drop the dependent objects too.
E       
E       [SQL: DROP EXTENSION IF EXISTS vector]
E       (Background on this error at: https://sqlalche.me/e/20/2j85)

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: InternalError
----------------------------- Captured stderr call -----------------------------
INFO  [alembic.runtime.migration] Context impl PostgresqlImpl.
INFO  [alembic.runtime.migration] Will assume transactional DDL.
INFO  [alembic.runtime.migration] Running downgrade 001 -> , Initial schema with documents and chunks tables
_________ TestMigrationValidatorIntegration.test_error_message_details _________

self = <sqlalchemy.engine.base.Connection object at 0x788cd8d5b8f0>
dialect = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x788cc99bd910>
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x788cc9ae1160>
statement = <sqlalchemy.dialects.postgresql.base.PGCompiler object at 0x788cc9ae10a0>
parameters = [{}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x788cc99bd910>
cursor = <cursor object at 0x788cc9a913f0; closed: -1>
statement = 'DROP EXTENSION IF EXISTS vector', parameters = {}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x788cc9ae1160>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       psycopg2.errors.DependentObjectsStillExist: cannot drop extension vector because other objects depend on it
E       DETAIL:  column embedding of table test_chunks_real depends on type vector
E       HINT:  Use DROP ... CASCADE to drop the dependent objects too.

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: DependentObjectsStillExist

The above exception was the direct cause of the following exception:

self = <tests.integration.database.test_migration_validator_integration.TestMigrationValidatorIntegration object at 0x788cd9f87110>
validator = <rag_factory.services.database.migration_validator.MigrationValidator object at 0x788cc876dbe0>
alembic_config = <alembic.config.Config object at 0x788cc99bc560>

    @pytest.mark.asyncio
    async def test_error_message_details(
        self,
        validator: MigrationValidator,
        alembic_config: Config
    ) -> None:
        """Test that error messages include migration details."""
        # Start from clean state
>       command.downgrade(alembic_config, "base")

tests/integration/database/test_migration_validator_integration.py:214: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
venv/lib/python3.12/site-packages/alembic/command.py:449: in downgrade
    script.run_env()
venv/lib/python3.12/site-packages/alembic/script/base.py:583: in run_env
    util.load_python_file(self.dir, "env.py")
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:95: in load_python_file
    module = load_module_py(module_id, path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:113: in load_module_py
    spec.loader.exec_module(module)  # type: ignore
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
<frozen importlib._bootstrap_external>:995: in exec_module
    ???
<frozen importlib._bootstrap>:488: in _call_with_frames_removed
    ???
migrations/env.py:93: in <module>
    run_migrations_online()
migrations/env.py:87: in run_migrations_online
    context.run_migrations()
<string>:8: in run_migrations
    ???
venv/lib/python3.12/site-packages/alembic/runtime/environment.py:948: in run_migrations
    self.get_context().run_migrations(**kw)
venv/lib/python3.12/site-packages/alembic/runtime/migration.py:627: in run_migrations
    step.migration_fn(**kw)
migrations/versions/001_initial_schema.py:129: in downgrade
    op.execute("DROP EXTENSION IF EXISTS vector")
<string>:8: in execute
    ???
<string>:3: in execute
    ???
venv/lib/python3.12/site-packages/alembic/operations/ops.py:2537: in execute
    return operations.invoke(op)
           ^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/base.py:445: in invoke
    return fn(self, operation)
           ^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/toimpl.py:224: in execute_sql
    operations.migration_context.impl.execute(
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:214: in execute
    self._exec(sql, execution_options)
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:207: in _exec
    return conn.execute(construct, multiparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1416: in execute
    return meth(
venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py:516: in _execute_on_connection
    return connection._execute_clauseelement(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1639: in _execute_clauseelement
    ret = self._execute_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1848: in _execute_context
    return self._exec_single_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1988: in _exec_single_context
    self._handle_dbapi_exception(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2343: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: in _exec_single_context
    self.dialect.do_execute(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x788cc99bd910>
cursor = <cursor object at 0x788cc9a913f0; closed: -1>
statement = 'DROP EXTENSION IF EXISTS vector', parameters = {}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x788cc9ae1160>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.InternalError: (psycopg2.errors.DependentObjectsStillExist) cannot drop extension vector because other objects depend on it
E       DETAIL:  column embedding of table test_chunks_real depends on type vector
E       HINT:  Use DROP ... CASCADE to drop the dependent objects too.
E       
E       [SQL: DROP EXTENSION IF EXISTS vector]
E       (Background on this error at: https://sqlalche.me/e/20/2j85)

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: InternalError
----------------------------- Captured stderr call -----------------------------
INFO  [alembic.runtime.migration] Context impl PostgresqlImpl.
INFO  [alembic.runtime.migration] Will assume transactional DDL.
INFO  [alembic.runtime.migration] Running downgrade 001 -> , Initial schema with documents and chunks tables
_______ TestMigrationValidatorIntegration.test_validate_single_migration _______

self = <sqlalchemy.engine.base.Connection object at 0x788cc9ae0320>
dialect = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x788cc9a39430>
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x788cd8edb7a0>
statement = <sqlalchemy.dialects.postgresql.base.PGDDLCompiler object at 0x788cc9ae3b60>
parameters = [immutabledict({})]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x788cc9a39430>
cursor = <cursor object at 0x788cc9a925c0; closed: -1>
statement = 'ALTER TABLE chunks ADD COLUMN parent_chunk_id UUID'
parameters = immutabledict({})
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x788cd8edb7a0>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       psycopg2.errors.UndefinedTable: relation "chunks" does not exist

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: UndefinedTable

The above exception was the direct cause of the following exception:

self = <tests.integration.database.test_migration_validator_integration.TestMigrationValidatorIntegration object at 0x788cd9f86a50>
validator = <rag_factory.services.database.migration_validator.MigrationValidator object at 0x788cc9ae3d10>
alembic_config = <alembic.config.Config object at 0x788cc9ae39b0>

    @pytest.mark.asyncio
    async def test_validate_single_migration(
        self,
        validator: MigrationValidator,
        alembic_config: Config
    ) -> None:
        """Test validating a single migration requirement."""
        # Apply all migrations
>       command.upgrade(alembic_config, "head")

tests/integration/database/test_migration_validator_integration.py:240: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
venv/lib/python3.12/site-packages/alembic/command.py:403: in upgrade
    script.run_env()
venv/lib/python3.12/site-packages/alembic/script/base.py:583: in run_env
    util.load_python_file(self.dir, "env.py")
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:95: in load_python_file
    module = load_module_py(module_id, path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:113: in load_module_py
    spec.loader.exec_module(module)  # type: ignore
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
<frozen importlib._bootstrap_external>:995: in exec_module
    ???
<frozen importlib._bootstrap>:488: in _call_with_frames_removed
    ???
migrations/env.py:93: in <module>
    run_migrations_online()
migrations/env.py:87: in run_migrations_online
    context.run_migrations()
<string>:8: in run_migrations
    ???
venv/lib/python3.12/site-packages/alembic/runtime/environment.py:948: in run_migrations
    self.get_context().run_migrations(**kw)
venv/lib/python3.12/site-packages/alembic/runtime/migration.py:627: in run_migrations
    step.migration_fn(**kw)
migrations/versions/002_add_hierarchy_support.py:26: in upgrade
    op.add_column(
<string>:8: in add_column
    ???
<string>:3: in add_column
    ???
venv/lib/python3.12/site-packages/alembic/operations/ops.py:2142: in add_column
    return operations.invoke(op)
           ^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/base.py:445: in invoke
    return fn(self, operation)
           ^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/toimpl.py:171: in add_column
    operations.impl.add_column(table_name, column, schema=schema, **kw)
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:334: in add_column
    self._exec(base.AddColumn(table_name, column, schema=schema))
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:207: in _exec
    return conn.execute(construct, multiparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1416: in execute
    return meth(
venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:181: in _execute_on_connection
    return connection._execute_ddl(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1528: in _execute_ddl
    ret = self._execute_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1848: in _execute_context
    return self._exec_single_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1988: in _exec_single_context
    self._handle_dbapi_exception(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2343: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: in _exec_single_context
    self.dialect.do_execute(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x788cc9a39430>
cursor = <cursor object at 0x788cc9a925c0; closed: -1>
statement = 'ALTER TABLE chunks ADD COLUMN parent_chunk_id UUID'
parameters = immutabledict({})
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x788cd8edb7a0>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "chunks" does not exist
E       
E       [SQL: ALTER TABLE chunks ADD COLUMN parent_chunk_id UUID]
E       (Background on this error at: https://sqlalche.me/e/20/f405)

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: ProgrammingError
----------------------------- Captured stderr call -----------------------------
INFO  [alembic.runtime.migration] Context impl PostgresqlImpl.
INFO  [alembic.runtime.migration] Will assume transactional DDL.
INFO  [alembic.runtime.migration] Running upgrade 001 -> 002, Add hierarchy support to chunks table
____ TestMigrationValidatorIntegration.test_validate_nonexistent_migration _____

self = <sqlalchemy.engine.base.Connection object at 0x788cc9a39ac0>
dialect = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x788cd89dbcb0>
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x788cd89d1d60>
statement = <sqlalchemy.dialects.postgresql.base.PGDDLCompiler object at 0x788cd89dbb60>
parameters = [immutabledict({})]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x788cd89dbcb0>
cursor = <cursor object at 0x788cc9a93880; closed: -1>
statement = 'ALTER TABLE chunks ADD COLUMN parent_chunk_id UUID'
parameters = immutabledict({})
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x788cd89d1d60>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       psycopg2.errors.UndefinedTable: relation "chunks" does not exist

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: UndefinedTable

The above exception was the direct cause of the following exception:

self = <tests.integration.database.test_migration_validator_integration.TestMigrationValidatorIntegration object at 0x788cd9f864b0>
validator = <rag_factory.services.database.migration_validator.MigrationValidator object at 0x788cd89daab0>
alembic_config = <alembic.config.Config object at 0x788cd89dbf20>

    @pytest.mark.asyncio
    async def test_validate_nonexistent_migration(
        self,
        validator: MigrationValidator,
        alembic_config: Config
    ) -> None:
        """Test validating a migration that doesn't exist."""
        # Apply all migrations
>       command.upgrade(alembic_config, "head")

tests/integration/database/test_migration_validator_integration.py:256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
venv/lib/python3.12/site-packages/alembic/command.py:403: in upgrade
    script.run_env()
venv/lib/python3.12/site-packages/alembic/script/base.py:583: in run_env
    util.load_python_file(self.dir, "env.py")
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:95: in load_python_file
    module = load_module_py(module_id, path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:113: in load_module_py
    spec.loader.exec_module(module)  # type: ignore
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
<frozen importlib._bootstrap_external>:995: in exec_module
    ???
<frozen importlib._bootstrap>:488: in _call_with_frames_removed
    ???
migrations/env.py:93: in <module>
    run_migrations_online()
migrations/env.py:87: in run_migrations_online
    context.run_migrations()
<string>:8: in run_migrations
    ???
venv/lib/python3.12/site-packages/alembic/runtime/environment.py:948: in run_migrations
    self.get_context().run_migrations(**kw)
venv/lib/python3.12/site-packages/alembic/runtime/migration.py:627: in run_migrations
    step.migration_fn(**kw)
migrations/versions/002_add_hierarchy_support.py:26: in upgrade
    op.add_column(
<string>:8: in add_column
    ???
<string>:3: in add_column
    ???
venv/lib/python3.12/site-packages/alembic/operations/ops.py:2142: in add_column
    return operations.invoke(op)
           ^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/base.py:445: in invoke
    return fn(self, operation)
           ^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/toimpl.py:171: in add_column
    operations.impl.add_column(table_name, column, schema=schema, **kw)
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:334: in add_column
    self._exec(base.AddColumn(table_name, column, schema=schema))
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:207: in _exec
    return conn.execute(construct, multiparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1416: in execute
    return meth(
venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:181: in _execute_on_connection
    return connection._execute_ddl(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1528: in _execute_ddl
    ret = self._execute_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1848: in _execute_context
    return self._exec_single_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1988: in _exec_single_context
    self._handle_dbapi_exception(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2343: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: in _exec_single_context
    self.dialect.do_execute(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x788cd89dbcb0>
cursor = <cursor object at 0x788cc9a93880; closed: -1>
statement = 'ALTER TABLE chunks ADD COLUMN parent_chunk_id UUID'
parameters = immutabledict({})
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x788cd89d1d60>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "chunks" does not exist
E       
E       [SQL: ALTER TABLE chunks ADD COLUMN parent_chunk_id UUID]
E       (Background on this error at: https://sqlalche.me/e/20/f405)

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: ProgrammingError
----------------------------- Captured stderr call -----------------------------
INFO  [alembic.runtime.migration] Context impl PostgresqlImpl.
INFO  [alembic.runtime.migration] Will assume transactional DDL.
INFO  [alembic.runtime.migration] Running upgrade 001 -> 002, Add hierarchy support to chunks table
_______ TestMigrationValidatorIntegration.test_validate_after_downgrade ________

self = <sqlalchemy.engine.base.Connection object at 0x788cd89dbb90>
dialect = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x788cd90a3bc0>
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x788cd8eda510>
statement = <sqlalchemy.dialects.postgresql.base.PGDDLCompiler object at 0x788cd8ed8ef0>
parameters = [immutabledict({})]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x788cd90a3bc0>
cursor = <cursor object at 0x788cc8a6db70; closed: -1>
statement = 'ALTER TABLE chunks ADD COLUMN parent_chunk_id UUID'
parameters = immutabledict({})
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x788cd8eda510>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       psycopg2.errors.UndefinedTable: relation "chunks" does not exist

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: UndefinedTable

The above exception was the direct cause of the following exception:

self = <tests.integration.database.test_migration_validator_integration.TestMigrationValidatorIntegration object at 0x788cd9f85d60>
validator = <rag_factory.services.database.migration_validator.MigrationValidator object at 0x788cc9ae3c50>
alembic_config = <alembic.config.Config object at 0x788cc9ae07a0>

    @pytest.mark.asyncio
    async def test_validate_after_downgrade(
        self,
        validator: MigrationValidator,
        alembic_config: Config
    ) -> None:
        """Test validation after downgrading migrations."""
        # Apply all migrations
>       command.upgrade(alembic_config, "head")

tests/integration/database/test_migration_validator_integration.py:272: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
venv/lib/python3.12/site-packages/alembic/command.py:403: in upgrade
    script.run_env()
venv/lib/python3.12/site-packages/alembic/script/base.py:583: in run_env
    util.load_python_file(self.dir, "env.py")
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:95: in load_python_file
    module = load_module_py(module_id, path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:113: in load_module_py
    spec.loader.exec_module(module)  # type: ignore
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
<frozen importlib._bootstrap_external>:995: in exec_module
    ???
<frozen importlib._bootstrap>:488: in _call_with_frames_removed
    ???
migrations/env.py:93: in <module>
    run_migrations_online()
migrations/env.py:87: in run_migrations_online
    context.run_migrations()
<string>:8: in run_migrations
    ???
venv/lib/python3.12/site-packages/alembic/runtime/environment.py:948: in run_migrations
    self.get_context().run_migrations(**kw)
venv/lib/python3.12/site-packages/alembic/runtime/migration.py:627: in run_migrations
    step.migration_fn(**kw)
migrations/versions/002_add_hierarchy_support.py:26: in upgrade
    op.add_column(
<string>:8: in add_column
    ???
<string>:3: in add_column
    ???
venv/lib/python3.12/site-packages/alembic/operations/ops.py:2142: in add_column
    return operations.invoke(op)
           ^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/base.py:445: in invoke
    return fn(self, operation)
           ^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/toimpl.py:171: in add_column
    operations.impl.add_column(table_name, column, schema=schema, **kw)
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:334: in add_column
    self._exec(base.AddColumn(table_name, column, schema=schema))
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:207: in _exec
    return conn.execute(construct, multiparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1416: in execute
    return meth(
venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:181: in _execute_on_connection
    return connection._execute_ddl(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1528: in _execute_ddl
    ret = self._execute_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1848: in _execute_context
    return self._exec_single_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1988: in _exec_single_context
    self._handle_dbapi_exception(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2343: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: in _exec_single_context
    self.dialect.do_execute(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x788cd90a3bc0>
cursor = <cursor object at 0x788cc8a6db70; closed: -1>
statement = 'ALTER TABLE chunks ADD COLUMN parent_chunk_id UUID'
parameters = immutabledict({})
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x788cd8eda510>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "chunks" does not exist
E       
E       [SQL: ALTER TABLE chunks ADD COLUMN parent_chunk_id UUID]
E       (Background on this error at: https://sqlalche.me/e/20/f405)

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: ProgrammingError
----------------------------- Captured stderr call -----------------------------
INFO  [alembic.runtime.migration] Context impl PostgresqlImpl.
INFO  [alembic.runtime.migration] Will assume transactional DDL.
INFO  [alembic.runtime.migration] Running upgrade 001 -> 002, Add hierarchy support to chunks table
___ TestMigrationValidatorIntegration.test_multiple_validators_same_database ___

self = <sqlalchemy.engine.base.Connection object at 0x788cd90a15e0>
dialect = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x788cc87f6cf0>
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x788cd8d22210>
statement = <sqlalchemy.dialects.postgresql.base.PGDDLCompiler object at 0x788cd8d20bc0>
parameters = [immutabledict({})]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x788cc87f6cf0>
cursor = <cursor object at 0x788cd8e27790; closed: -1>
statement = 'ALTER TABLE chunks ADD COLUMN parent_chunk_id UUID'
parameters = immutabledict({})
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x788cd8d22210>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       psycopg2.errors.UndefinedTable: relation "chunks" does not exist

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: UndefinedTable

The above exception was the direct cause of the following exception:

self = <tests.integration.database.test_migration_validator_integration.TestMigrationValidatorIntegration object at 0x788cd9f84410>
db_service = <rag_factory.services.database.postgres.PostgresqlDatabaseService object at 0x788cc87f7e30>
alembic_config = <alembic.config.Config object at 0x788cc87f64e0>

    @pytest.mark.asyncio
    async def test_multiple_validators_same_database(
        self,
        db_service: PostgresqlDatabaseService,
        alembic_config: Config
    ) -> None:
        """Test multiple validators on the same database."""
        # Apply migrations
>       command.upgrade(alembic_config, "head")

tests/integration/database/test_migration_validator_integration.py:295: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
venv/lib/python3.12/site-packages/alembic/command.py:403: in upgrade
    script.run_env()
venv/lib/python3.12/site-packages/alembic/script/base.py:583: in run_env
    util.load_python_file(self.dir, "env.py")
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:95: in load_python_file
    module = load_module_py(module_id, path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:113: in load_module_py
    spec.loader.exec_module(module)  # type: ignore
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
<frozen importlib._bootstrap_external>:995: in exec_module
    ???
<frozen importlib._bootstrap>:488: in _call_with_frames_removed
    ???
migrations/env.py:93: in <module>
    run_migrations_online()
migrations/env.py:87: in run_migrations_online
    context.run_migrations()
<string>:8: in run_migrations
    ???
venv/lib/python3.12/site-packages/alembic/runtime/environment.py:948: in run_migrations
    self.get_context().run_migrations(**kw)
venv/lib/python3.12/site-packages/alembic/runtime/migration.py:627: in run_migrations
    step.migration_fn(**kw)
migrations/versions/002_add_hierarchy_support.py:26: in upgrade
    op.add_column(
<string>:8: in add_column
    ???
<string>:3: in add_column
    ???
venv/lib/python3.12/site-packages/alembic/operations/ops.py:2142: in add_column
    return operations.invoke(op)
           ^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/base.py:445: in invoke
    return fn(self, operation)
           ^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/toimpl.py:171: in add_column
    operations.impl.add_column(table_name, column, schema=schema, **kw)
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:334: in add_column
    self._exec(base.AddColumn(table_name, column, schema=schema))
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:207: in _exec
    return conn.execute(construct, multiparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1416: in execute
    return meth(
venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:181: in _execute_on_connection
    return connection._execute_ddl(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1528: in _execute_ddl
    ret = self._execute_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1848: in _execute_context
    return self._exec_single_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1988: in _exec_single_context
    self._handle_dbapi_exception(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2343: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: in _exec_single_context
    self.dialect.do_execute(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x788cc87f6cf0>
cursor = <cursor object at 0x788cd8e27790; closed: -1>
statement = 'ALTER TABLE chunks ADD COLUMN parent_chunk_id UUID'
parameters = immutabledict({})
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x788cd8d22210>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "chunks" does not exist
E       
E       [SQL: ALTER TABLE chunks ADD COLUMN parent_chunk_id UUID]
E       (Background on this error at: https://sqlalche.me/e/20/f405)

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: ProgrammingError
----------------------------- Captured stderr call -----------------------------
INFO  [alembic.runtime.migration] Context impl PostgresqlImpl.
INFO  [alembic.runtime.migration] Will assume transactional DDL.
INFO  [alembic.runtime.migration] Running upgrade 001 -> 002, Add hierarchy support to chunks table
=============================== warnings summary ===============================
rag_factory/services/llm/config.py:8
  /mnt/MCPProyects/ragTools/rag_factory/services/llm/config.py:8: PydanticDeprecatedSince20: Support for class-based `config` is deprecated, use ConfigDict instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    class LLMServiceConfig(BaseModel):

rag_factory/database/config.py:12
  /mnt/MCPProyects/ragTools/rag_factory/database/config.py:12: PydanticDeprecatedSince20: Support for class-based `config` is deprecated, use ConfigDict instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    class DatabaseConfig(BaseSettings):

rag_factory/strategies/late_chunking/models.py:21
  /mnt/MCPProyects/ragTools/rag_factory/strategies/late_chunking/models.py:21: PydanticDeprecatedSince20: Support for class-based `config` is deprecated, use ConfigDict instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    class TokenEmbedding(BaseModel):

rag_factory/strategies/late_chunking/models.py:34
  /mnt/MCPProyects/ragTools/rag_factory/strategies/late_chunking/models.py:34: PydanticDeprecatedSince20: Support for class-based `config` is deprecated, use ConfigDict instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    class DocumentEmbedding(BaseModel):

rag_factory/strategies/late_chunking/models.py:49
  /mnt/MCPProyects/ragTools/rag_factory/strategies/late_chunking/models.py:49: PydanticDeprecatedSince20: Support for class-based `config` is deprecated, use ConfigDict instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    class EmbeddingChunk(BaseModel):

tests/unit/strategies/self_reflective/test_strategy.py: 12 warnings
  /mnt/MCPProyects/ragTools/rag_factory/strategies/self_reflective/strategy.py:179: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    result["refinements"] = [r.dict() for r in refinements]

tests/integration/database/test_migration_validator_integration.py: 13 warnings
  /mnt/MCPProyects/ragTools/tests/integration/database/test_migration_validator_integration.py:50: RuntimeWarning: coroutine 'PostgresqlDatabaseService.close' was never awaited
    service.close()
  Enable tracemalloc to get traceback where the object was allocated.
  See https://docs.pytest.org/en/stable/how-to/capture-warnings.html#resource-warnings for more info.

tests/integration/database/test_migration_validator_integration.py::TestMigrationValidatorEdgeCases::test_validator_with_auto_discovered_config
tests/integration/database/test_migration_validator_integration.py::TestMigrationValidatorEdgeCases::test_validate_empty_requirements
  /mnt/MCPProyects/ragTools/tests/integration/database/test_migration_validator_integration.py:336: RuntimeWarning: coroutine 'PostgresqlDatabaseService.close' was never awaited
    service.close()
  Enable tracemalloc to get traceback where the object was allocated.
  See https://docs.pytest.org/en/stable/how-to/capture-warnings.html#resource-warnings for more info.

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
================================ tests coverage ================================
_______________ coverage: platform linux, python 3.12.3-final-0 ________________

Name                                                               Stmts   Miss  Cover   Missing
------------------------------------------------------------------------------------------------
rag_factory/__init__.py                                                3      0   100%
rag_factory/__version__.py                                             1      0   100%
rag_factory/cli/__init__.py                                            2      0   100%
rag_factory/cli/commands/__init__.py                                   1      0   100%
rag_factory/cli/commands/benchmark.py                                 96     81    16%   40-53, 64-84, 148-263
rag_factory/cli/commands/check_consistency.py                         43     33    23%   64-120
rag_factory/cli/commands/config.py                                    78     68    13%   26-64, 102-188
rag_factory/cli/commands/index.py                                     65     52    20%   29-39, 93-185
rag_factory/cli/commands/query.py                                     47     36    23%   73-149
rag_factory/cli/commands/repl.py                                     152    130    14%   29-56, 63-108, 112-120, 124-133, 137-155, 159-172, 176-186, 190-207, 211-220, 253-260
rag_factory/cli/commands/strategies.py                                45     36    20%   48-120
rag_factory/cli/commands/validate_e2e.py                              91     69    24%   37-38, 42-142, 145-156
rag_factory/cli/commands/validate_pipeline.py                         70     57    19%   57-156
rag_factory/cli/formatters/__init__.py                                 4      0   100%
rag_factory/cli/formatters/consistency.py                             61     55    10%   21-69, 79-103, 108-138
rag_factory/cli/formatters/output.py                                  20      9    55%   23-24, 43-44, 63-64, 74, 79, 84
rag_factory/cli/formatters/results.py                                 71     62    13%   28-55, 72-99, 116-144, 157-181
rag_factory/cli/formatters/validation.py                              63     53    16%   25-43, 48-56, 65-77, 86-98, 103-129, 134-137
rag_factory/cli/main.py                                               31     10    68%   25-28, 48-49, 76-78, 82
rag_factory/cli/utils/__init__.py                                      3      0   100%
rag_factory/cli/utils/progress.py                                     14      8    43%   34-47, 73-76
rag_factory/cli/utils/validation.py                                   53     42    21%   30-41, 57-77, 93-118, 135
rag_factory/config/__init__.py                                         4      0   100%
rag_factory/config/env_resolver.py                                    52     21    60%   52, 81-86, 110, 129-147
rag_factory/config/schemas/__init__.py                                 2      0   100%
rag_factory/config/schemas/version.py                                 10      6    40%   29-38
rag_factory/config/strategy_loader.py                                 54     36    33%   32-41, 45-60, 75-89, 101-104
rag_factory/config/strategy_pair_manager.py                          105     23    78%   57-58, 66-70, 93, 114, 156-157, 191-196, 210-215, 274-275
rag_factory/config/validator.py                                       93     32    66%   70, 177-198, 271-295, 333-354
rag_factory/core/__init__.py                                           4      4     0%   7-23
rag_factory/core/capabilities.py                                      61     16    74%   129, 155, 173-174, 239-253
rag_factory/core/indexing_interface.py                                54     28    48%   144, 164, 208, 260, 272, 292-313, 341-364
rag_factory/core/pipeline.py                                          49     35    29%   22-24, 33-40, 55-77, 95-96, 105-108, 117-120, 137-146
rag_factory/core/retrieval_interface.py                               38     16    58%   56-58, 138, 158, 196, 247, 259, 285-309
rag_factory/database/__init__.py                                       4      0   100%
rag_factory/database/config.py                                        17      0   100%
rag_factory/database/connection.py                                    80     54    32%   40-48, 61-86, 96, 107, 126-137, 150-157, 165-170, 178-183, 196-197, 209-214, 218, 222
rag_factory/database/env_validator.py                                 38     18    53%   46-54, 66-77, 86-88, 118, 126, 139
rag_factory/database/models.py                                        85     32    62%   31-34, 37-45, 48-54, 66-69, 72-77, 80-85, 181, 323-325
rag_factory/database/vector_indexing.py                               38     38     0%   7-114
rag_factory/evaluation/__init__.py                                     4      4     0%   29-41
rag_factory/evaluation/analysis/__init__.py                            3      3     0%   8-11
rag_factory/evaluation/analysis/comparison.py                        135    135     0%   8-323
rag_factory/evaluation/analysis/statistics.py                         81     81     0%   8-320
rag_factory/evaluation/benchmarks/__init__.py                          3      3     0%   8-14
rag_factory/evaluation/benchmarks/config.py                           25     25     0%   7-64
rag_factory/evaluation/benchmarks/runner.py                          155    155     0%   8-423
rag_factory/evaluation/datasets/__init__.py                            3      3     0%   8-14
rag_factory/evaluation/datasets/loader.py                             88     88     0%   8-281
rag_factory/evaluation/datasets/schema.py                             52     52     0%   8-160
rag_factory/evaluation/datasets/statistics.py                         65     65     0%   8-226
rag_factory/evaluation/exporters/__init__.py                           4      4     0%   8-12
rag_factory/evaluation/exporters/csv_exporter.py                      52     52     0%   3-124
rag_factory/evaluation/exporters/html_exporter.py                     47     47     0%   3-293
rag_factory/evaluation/exporters/json_exporter.py                     19     19     0%   3-68
rag_factory/evaluation/metrics/__init__.py                             3      3     0%   12-25
rag_factory/evaluation/metrics/base.py                                31     31     0%   8-115
rag_factory/evaluation/metrics/cost.py                                65     65     0%   8-313
rag_factory/evaluation/metrics/performance.py                         42     42     0%   8-202
rag_factory/evaluation/metrics/quality.py                             84     84     0%   8-377
rag_factory/evaluation/metrics/retrieval.py                           77     77     0%   9-401
rag_factory/exceptions.py                                             13      0   100%
rag_factory/factory.py                                               187    132    29%   144, 165-170, 209-230, 256-270, 300-324, 347-348, 365, 384, 401, 418, 435, 451-460, 480-502, 528-545, 568-611, 644-699, 703-715
rag_factory/legacy_config.py                                         155    155     0%   22-542
rag_factory/models/__init__.py                                         6      6     0%   3-14
rag_factory/models/embedding/__init__.py                               4      4     0%   3-12
rag_factory/models/embedding/loader.py                               179    179     0%   3-367
rag_factory/models/embedding/models.py                                47     47     0%   3-106
rag_factory/models/embedding/registry.py                             128    128     0%   3-282
rag_factory/models/evaluation/__init__.py                              3      3     0%   3-6
rag_factory/models/evaluation/ab_testing.py                           98     98     0%   3-281
rag_factory/models/evaluation/models.py                               29     29     0%   3-74
rag_factory/observability/__init__.py                                  3      3     0%   3-10
rag_factory/observability/integrations/__init__.py                     1      1     0%   3
rag_factory/observability/integrations/prometheus.py                  47     47     0%   3-229
rag_factory/observability/logging/__init__.py                          2      2     0%   3-5
rag_factory/observability/logging/config.py                           16     16     0%   3-37
rag_factory/observability/logging/filters.py                          41     41     0%   3-103
rag_factory/observability/logging/logger.py                           86     86     0%   3-396
rag_factory/observability/metrics/__init__.py                          2      2     0%   3-9
rag_factory/observability/metrics/collector.py                       143    143     0%   3-459
rag_factory/observability/metrics/cost.py                             39     39     0%   3-221
rag_factory/observability/metrics/performance.py                      64     64     0%   3-196
rag_factory/observability/monitoring/__init__.py                       1      1     0%   3
rag_factory/observability/monitoring/api.py                          101    101     0%   3-328
rag_factory/pipeline.py                                              156    156     0%   34-507
rag_factory/registry/__init__.py                                       4      0   100%
rag_factory/registry/exceptions.py                                     6      0   100%
rag_factory/registry/service_factory.py                               62     10    84%   166-176, 184-191
rag_factory/registry/service_registry.py                              91     14    85%   114, 118, 123-124, 188-192, 214-218
rag_factory/repositories/__init__.py                                   5      0   100%
rag_factory/repositories/base.py                                      42     21    50%   38, 53, 70, 87, 103, 114-118, 125, 136-139, 159-164
rag_factory/repositories/chunk.py                                    206    180    13%   40-45, 68-76, 90-95, 120-133, 155-171, 187-202, 221-231, 250-261, 287-328, 355-396, 422-474, 489-499, 513-521, 537-543, 557-563, 577-587, 604-626, 639-670
rag_factory/repositories/document.py                                  93     74    20%   41-46, 63-68, 98-118, 140-156, 172-187, 206, 223-233, 247-255, 272-279, 290-293, 307-312
rag_factory/repositories/exceptions.py                                18      7    61%   34-36, 56-59
rag_factory/services/__init__.py                                       4      0   100%
rag_factory/services/api/__init__.py                                   4      0   100%
rag_factory/services/api/anthropic.py                                 27     18    33%   46-52, 76-94, 118-141
rag_factory/services/api/cohere.py                                    30     19    37%   14-15, 49-59, 82-113
rag_factory/services/api/openai.py                                    46     27    41%   75-93, 117-140, 189-199, 216-227, 235
rag_factory/services/consistency.py                                   32     24    25%   80-113, 144-170
rag_factory/services/database/__init__.py                              5      0   100%
rag_factory/services/database/database_context.py                    181    159    12%   58-64, 88-106, 123, 140-150, 179-200, 223-240, 256-266, 305-330, 338-339, 343-406, 414-415, 430-510, 516-517, 521-546
rag_factory/services/database/migration_validator.py                  85     28    67%   29-30, 88, 112, 137-141, 152-181, 197, 202-204, 234, 268-271
rag_factory/services/database/neo4j.py                                54     36    33%   14, 60-71, 79-84, 103-114, 134-150, 172-181, 188-191, 195, 199
rag_factory/services/database/postgres.py                            177     58    67%   17-18, 26-27, 85, 91-103, 187, 211, 213, 217-218, 294-297, 326-341, 392-407, 439-457, 472, 547-565, 590, 594
rag_factory/services/dependencies.py                                  41     12    71%   99, 101, 103, 105, 107, 134-140, 179-180
rag_factory/services/embedding/__init__.py                             4      0   100%
rag_factory/services/embedding/base.py                                31      6    81%   44, 59, 68, 77, 86, 98
rag_factory/services/embedding/cache.py                               43     33    23%   26-32, 43-58, 67-76, 80-82, 90-94
rag_factory/services/embedding/config.py                              29     13    55%   37-43, 50-68, 80
rag_factory/services/embedding/providers/__init__.py                   5      0   100%
rag_factory/services/embedding/providers/cohere.py                    53     36    32%   10-20, 55-75, 90-117, 125, 133, 141, 152-153
rag_factory/services/embedding/providers/local.py                     43     27    37%   8-9, 46-67, 83-109, 117, 125, 133, 146
rag_factory/services/embedding/providers/onnx_local.py               114     30    74%   18-19, 114, 143-147, 158, 170-175, 248-250, 273, 289-308
rag_factory/services/embedding/providers/openai.py                    51     27    47%   10-20, 54, 64, 70, 87-108, 116, 124, 132, 143-144
rag_factory/services/embedding/rate_limiter.py                        20      1    95%   32
rag_factory/services/embedding/service.py                            100     83    17%   50-62, 79-93, 117-198, 220-222, 233-239, 248-266, 273-275
rag_factory/services/interfaces.py                                    35      0   100%
rag_factory/services/llm/__init__.py                                   5      0   100%
rag_factory/services/llm/base.py                                      43      0   100%
rag_factory/services/llm/config.py                                    23      6    74%   46-48, 51-53
rag_factory/services/llm/prompt_template.py                           43     24    44%   47-82, 97-100, 111-115
rag_factory/services/llm/providers/__init__.py                        12     10    17%   10-22
rag_factory/services/llm/providers/anthropic.py                       57     42    26%   44-50, 64-97, 120-147, 171-172, 184-189, 197, 205
rag_factory/services/llm/providers/ollama.py                          55     42    24%   22-24, 37-67, 93-122, 142-143, 157, 165, 174, 185-196
rag_factory/services/llm/providers/openai.py                          57     19    67%   56, 101-105, 133-158, 189-194, 202, 210
rag_factory/services/llm/service.py                                   66     24    64%   68, 127-129, 154-175, 186, 194-198, 215-216
rag_factory/services/llm/token_counter.py                             27      4    85%   56-57, 71-72
rag_factory/services/local/__init__.py                                 2      2     0%   7-9
rag_factory/services/local/reranker.py                                32     32     0%   7-116
rag_factory/services/onnx/__init__.py                                  2      0   100%
rag_factory/services/onnx/embedding.py                                29     12    59%   61, 65, 83-93, 110-121
rag_factory/services/utils/__init__.py                                 2      0   100%
rag_factory/services/utils/model_converter.py                        104    104     0%   8-291
rag_factory/services/utils/onnx_utils.py                             133     38    71%   22-23, 37, 79-84, 96-97, 142-146, 175, 189-190, 194, 198-201, 216-218, 258, 265-268, 361-362, 376, 392-404
rag_factory/services/utils/reranker_selector.py                       68     68     0%   8-249
rag_factory/strategies/__init__.py                                     2      0   100%
rag_factory/strategies/agentic/__init__.py                             7      7     0%   8-20
rag_factory/strategies/agentic/agent.py                              151    151     0%   8-420
rag_factory/strategies/agentic/config.py                              12     12     0%   5-31
rag_factory/strategies/agentic/frameworks/__init__.py                  1      1     0%   9
rag_factory/strategies/agentic/query_analyzer.py                      89     89     0%   8-278
rag_factory/strategies/agentic/strategy.py                            87     87     0%   8-284
rag_factory/strategies/agentic/tool_implementations.py               135    135     0%   11-511
rag_factory/strategies/agentic/tools.py                               40     40     0%   8-142
rag_factory/strategies/base.py                                        55     10    82%   81, 83, 85, 169-178
rag_factory/strategies/chunking/__init__.py                           15     15     0%   28-67
rag_factory/strategies/chunking/base.py                               91     91     0%   3-256
rag_factory/strategies/chunking/docling_chunker.py                    45     45     0%   13-188
rag_factory/strategies/chunking/fixed_size_chunker.py                 74     74     0%   3-204
rag_factory/strategies/chunking/hybrid_chunker.py                     70     70     0%   3-192
rag_factory/strategies/chunking/semantic_chunker.py                  195    195     0%   3-534
rag_factory/strategies/chunking/structural_chunker.py                147    147     0%   3-425
rag_factory/strategies/chunking/utils.py                              89     89     0%   3-264
rag_factory/strategies/contextual/__init__.py                          7      7     0%   8-19
rag_factory/strategies/contextual/batch_processor.py                  91     91     0%   8-266
rag_factory/strategies/contextual/config.py                           46     46     0%   8-195
rag_factory/strategies/contextual/context_generator.py                84     84     0%   8-234
rag_factory/strategies/contextual/cost_tracker.py                     32     32     0%   8-126
rag_factory/strategies/contextual/prompts.py                          25     25     0%   8-119
rag_factory/strategies/contextual/storage.py                          44     44     0%   8-118
rag_factory/strategies/contextual/strategy.py                         78     78     0%   8-298
rag_factory/strategies/fine_tuned/__init__.py                          4      4     0%   1-5
rag_factory/strategies/fine_tuned/ab_testing.py                       78     78     0%   1-134
rag_factory/strategies/fine_tuned/config.py                           11     11     0%   1-30
rag_factory/strategies/fine_tuned/custom_loader.py                    40     40     0%   1-88
rag_factory/strategies/fine_tuned/model_registry.py                  126    126     0%   1-303
rag_factory/strategies/hierarchical/__init__.py                        5      0   100%
rag_factory/strategies/hierarchical/hierarchy_builder.py              79     25    68%   73, 117, 149, 220, 249-281, 310-335
rag_factory/strategies/hierarchical/models.py                         58      0   100%
rag_factory/strategies/hierarchical/parent_retriever.py               89     47    47%   66-74, 85, 88, 109-111, 141-142, 166-196, 213-227, 250-257, 268-278
rag_factory/strategies/hierarchical/strategy.py                       76     19    75%   77, 92-93, 101, 112-144, 254, 268-269
rag_factory/strategies/indexing/__init__.py                            6      0   100%
rag_factory/strategies/indexing/context_aware.py                     108     11    90%   74, 81, 89-91, 115, 126-128, 162, 197
rag_factory/strategies/indexing/hierarchical.py                       90     73    19%   50, 63, 88-134, 156-185, 201-236, 253-278, 292-293
rag_factory/strategies/indexing/in_memory.py                          41     25    39%   54, 65, 93-121, 143, 160, 173, 194-200
rag_factory/strategies/indexing/keyword_indexing.py                   42     42     0%   8-157
rag_factory/strategies/indexing/knowledge_graph_indexing.py           46     33    28%   18, 27, 48-89, 108-129
rag_factory/strategies/indexing/vector_embedding.py                   98     12    88%   25, 64-65, 76-77, 114-116, 149-150, 174-175, 213
rag_factory/strategies/knowledge_graph/__init__.py                     4      4     0%   8-19
rag_factory/strategies/knowledge_graph/config.py                      21     21     0%   8-129
rag_factory/strategies/knowledge_graph/entity_extractor.py            70     70     0%   7-205
rag_factory/strategies/knowledge_graph/graph_store.py                 31     31     0%   8-124
rag_factory/strategies/knowledge_graph/hybrid_retriever.py            56     56     0%   8-164
rag_factory/strategies/knowledge_graph/memory_graph_store.py          97     97     0%   8-196
rag_factory/strategies/knowledge_graph/models.py                      53     53     0%   8-122
rag_factory/strategies/knowledge_graph/relationship_extractor.py      62     62     0%   8-189
rag_factory/strategies/knowledge_graph/strategy.py                    80     80     0%   8-256
rag_factory/strategies/late_chunking/__init__.py                       6      0   100%
rag_factory/strategies/late_chunking/coherence_analyzer.py            27      5    81%   59, 82-96
rag_factory/strategies/late_chunking/document_embedder.py            104     34    67%   35, 56, 62-63, 72, 227-235, 256-279, 296-303
rag_factory/strategies/late_chunking/embedding_chunker.py            117     11    91%   53, 57, 145, 191-192, 215-225, 298
rag_factory/strategies/late_chunking/models.py                        62      0   100%
rag_factory/strategies/late_chunking/strategy.py                      70     12    83%   58, 77, 88, 107-122
rag_factory/strategies/multi_query/__init__.py                         7      7     0%   8-19
rag_factory/strategies/multi_query/config.py                          36     36     0%   3-138
rag_factory/strategies/multi_query/deduplicator.py                    87     87     0%   3-197
rag_factory/strategies/multi_query/parallel_executor.py               52     52     0%   3-163
rag_factory/strategies/multi_query/prompts.py                         10     10     0%   3-84
rag_factory/strategies/multi_query/ranker.py                          80     80     0%   3-201
rag_factory/strategies/multi_query/strategy.py                        68     68     0%   3-184
rag_factory/strategies/multi_query/variant_generator.py               62     62     0%   3-187
rag_factory/strategies/query_expansion/__init__.py                     8      0   100%
rag_factory/strategies/query_expansion/base.py                        66     10    85%   90, 103, 114-118, 130-133
rag_factory/strategies/query_expansion/cache.py                       52     40    23%   20-22, 38-55, 64-66, 70-73, 81-97, 105-112
rag_factory/strategies/query_expansion/expander_service.py            92     71    23%   36-40, 55-58, 75-148, 159-180, 204-215, 233-234, 242-246, 254, 265-273, 283-284
rag_factory/strategies/query_expansion/hyde_expander.py               19     12    37%   25-27, 41-65
rag_factory/strategies/query_expansion/llm_expander.py                25     16    36%   23-25, 39-71, 99
rag_factory/strategies/query_expansion/metrics.py                     66     30    55%   44-45, 53-57, 76-109, 130, 134, 146-152, 160
rag_factory/strategies/query_expansion/prompts.py                     13      7    46%   16, 28-56, 68-107
rag_factory/strategies/reranking/__init__.py                           7      7     0%   8-21
rag_factory/strategies/reranking/base.py                              68     68     0%   8-130
rag_factory/strategies/reranking/bge_reranker.py                      51     51     0%   8-151
rag_factory/strategies/reranking/cache.py                             48     48     0%   8-138
rag_factory/strategies/reranking/cohere_reranker.py                   34     34     0%   8-119
rag_factory/strategies/reranking/cosine_reranker.py                   62     62     0%   8-249
rag_factory/strategies/reranking/cross_encoder_reranker.py            40     40     0%   8-124
rag_factory/strategies/reranking/metrics.py                           67     67     0%   8-264
rag_factory/strategies/reranking/reranker_service.py                 115    115     0%   8-310
rag_factory/strategies/retrieval/__init__.py                           6      0   100%
rag_factory/strategies/retrieval/keyword_retriever.py                 56     41    27%   41, 52, 71-113, 126-133, 153-172
rag_factory/strategies/retrieval/knowledge_graph_retriever.py         22      9    59%   19, 27, 48-70
rag_factory/strategies/retrieval/multi_query_retriever.py             22      9    59%   19, 26, 44-66
rag_factory/strategies/retrieval/query_expansion_retriever.py         24      9    62%   20, 27, 45-67
rag_factory/strategies/retrieval/semantic_retriever.py                20      8    60%   23, 61-81
rag_factory/strategies/self_reflective/__init__.py                     6      0   100%
rag_factory/strategies/self_reflective/config.py                      20      8    60%   29-42
rag_factory/strategies/self_reflective/grader.py                      80     60    25%   51-67, 83-109, 135-171, 187-258
rag_factory/strategies/self_reflective/models.py                      48      0   100%
rag_factory/strategies/self_reflective/refiner.py                     69     18    74%   78-91, 114, 125, 127, 129, 131, 209-228
rag_factory/strategies/self_reflective/strategy.py                    92      2    98%   84-85
rag_factory/utils/__init__.py                                          3      0   100%
rag_factory/utils/token_counter.py                                    45     30    33%   36-40, 52-62, 74-82, 86, 90, 105-106, 124-135, 153-158
rag_factory/utils/tokenization.py                                     95     73    23%   36-40, 53-64, 87-114, 126-129, 141-144, 156, 175-190, 209-228, 241-243, 251-252, 270-271, 292-293, 314-315
------------------------------------------------------------------------------------------------
TOTAL                                                              12304   9145    26%
=========================== short test summary info ============================
FAILED tests/integration_real/test_database_real.py::test_database_context_table_mapping
FAILED tests/integration_real/test_end_to_end_real.py::test_document_indexing_pipeline
FAILED tests/integration_real/test_end_to_end_real.py::test_retrieval_pipeline
FAILED tests/integration_real/test_end_to_end_real.py::test_full_rag_pipeline
FAILED tests/integration_real/test_end_to_end_real.py::test_multiple_document_batches
FAILED tests/integration_real/test_end_to_end_real.py::test_large_document_indexing
FAILED tests/integration_real/test_llm_real.py::test_llm_streaming - TypeErro...
FAILED tests/integration/registry/test_registry_integration.py::TestRealServiceInstantiation::test_multiple_service_instantiation
FAILED tests/integration/registry/test_registry_integration.py::TestErrorHandling::test_invalid_service_config
FAILED tests/integration/registry/test_registry_integration.py::TestConfigurationValidation::test_configuration_warnings
FAILED tests/integration/strategies/test_self_reflective_integration.py::TestSelfReflectiveIntegration::test_end_to_end_workflow
FAILED tests/integration/strategies/test_self_reflective_integration.py::TestSelfReflectiveIntegration::test_retry_with_poor_results
FAILED tests/integration/strategies/test_self_reflective_integration.py::TestSelfReflectiveIntegration::test_performance_within_limits
FAILED tests/integration/strategies/test_self_reflective_integration.py::TestSelfReflectiveWithLMStudio::test_with_real_llm
FAILED tests/integration/test_package_integration.py::TestSmokeTest::test_basic_usage_smoke_test
FAILED tests/integration/test_package_integration.py::TestFullWorkflow::test_full_workflow_with_installed_package
FAILED tests/unit/config/test_strategy_pair_manager.py::test_load_pair_success
FAILED tests/unit/config/test_strategy_pair_manager.py::test_db_context_creation
FAILED tests/unit/database/test_migrations.py::TestAlembicMigrations::test_migration_upgrade_to_head
FAILED tests/unit/database/test_migrations.py::TestAlembicMigrations::test_migration_downgrade
FAILED tests/unit/database/test_migrations.py::TestAlembicMigrations::test_migration_idempotency
FAILED tests/unit/database/test_migrations.py::TestAlembicMigrations::test_get_current_version
FAILED tests/unit/database/test_migrations.py::TestAlembicMigrations::test_migration_creates_tables
FAILED tests/unit/database/test_migrations.py::TestAlembicMigrations::test_migration_creates_indexes
FAILED tests/unit/documentation/test_code_examples.py::TestCodeExamples::test_all_code_examples_have_valid_syntax
FAILED tests/unit/documentation/test_links.py::TestDocumentationLinks::test_no_broken_internal_links
FAILED tests/unit/registry/test_service_factory.py::TestLLMServiceCreation::test_create_llm_service_openai
FAILED tests/unit/registry/test_service_factory.py::TestEmbeddingServiceCreation::test_create_embedding_service_onnx
FAILED tests/unit/registry/test_service_factory.py::TestEmbeddingServiceCreation::test_create_embedding_service_onnx_with_defaults
FAILED tests/unit/registry/test_service_factory.py::TestEmbeddingServiceCreation::test_create_embedding_service_openai
FAILED tests/unit/registry/test_service_factory.py::TestDatabaseServiceCreation::test_create_database_service_postgres_with_connection_string
FAILED tests/unit/registry/test_service_factory.py::TestDatabaseServiceCreation::test_create_database_service_postgres_with_components
FAILED tests/unit/registry/test_service_factory.py::TestDatabaseServiceCreation::test_create_database_service_postgres_with_defaults
FAILED tests/unit/registry/test_service_factory.py::TestDatabaseServiceCreation::test_create_database_service_neo4j
FAILED tests/unit/registry/test_service_factory.py::TestDatabaseServiceCreation::test_create_database_service_neo4j_with_defaults
FAILED tests/unit/services/embedding/test_onnx_local_provider.py::test_calculate_cost_is_zero
FAILED tests/unit/strategies/indexing/test_context_aware.py::test_capabilities
FAILED tests/unit/test_package.py::TestImports::test_import_factory - ImportE...
FAILED tests/unit/test_package.py::TestImports::test_import_pipeline - Import...
FAILED tests/unit/test_package.py::TestImports::test_import_config - ImportEr...
FAILED tests/unit/test_package.py::TestPackageStructure::test_no_circular_imports
FAILED tests/unit/test_package.py::TestDependencies::test_optional_dependencies_handled
FAILED tests/integration/database/test_migration_integration.py::TestMigrationIntegration::test_real_migration_execution
FAILED tests/integration/database/test_migration_integration.py::TestMigrationIntegration::test_migration_with_existing_data
FAILED tests/integration/database/test_migration_integration.py::TestMigrationIntegration::test_rollback_functionality
FAILED tests/integration/database/test_migration_integration.py::TestMigrationIntegration::test_pgvector_extension_installed
FAILED tests/integration/database/test_migration_validator_integration.py::TestMigrationValidatorIntegration::test_validate_with_no_migrations
FAILED tests/integration/database/test_migration_validator_integration.py::TestMigrationValidatorIntegration::test_validate_with_partial_migrations
FAILED tests/integration/database/test_migration_validator_integration.py::TestMigrationValidatorIntegration::test_validate_with_all_migrations
FAILED tests/integration/database/test_migration_validator_integration.py::TestMigrationValidatorIntegration::test_validate_or_raise_success
FAILED tests/integration/database/test_migration_validator_integration.py::TestMigrationValidatorIntegration::test_validate_or_raise_failure
FAILED tests/integration/database/test_migration_validator_integration.py::TestMigrationValidatorIntegration::test_get_current_revision
FAILED tests/integration/database/test_migration_validator_integration.py::TestMigrationValidatorIntegration::test_is_at_head
FAILED tests/integration/database/test_migration_validator_integration.py::TestMigrationValidatorIntegration::test_error_message_details
FAILED tests/integration/database/test_migration_validator_integration.py::TestMigrationValidatorIntegration::test_validate_single_migration
FAILED tests/integration/database/test_migration_validator_integration.py::TestMigrationValidatorIntegration::test_validate_nonexistent_migration
FAILED tests/integration/database/test_migration_validator_integration.py::TestMigrationValidatorIntegration::test_validate_after_downgrade
FAILED tests/integration/database/test_migration_validator_integration.py::TestMigrationValidatorIntegration::test_multiple_validators_same_database
====== 58 failed, 127 passed, 3 skipped, 32 warnings in 451.67s (0:07:31) ======

========================================
Test run completed at 2025-12-17 21:28:40
========================================
