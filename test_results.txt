========================================
Test Results - 2025-12-17 23:32:54
========================================
Environment Configuration:
  EMBEDDING_MODEL_NAME: Xenova/all-MiniLM-L6-v2
  EMBEDDING_MODEL_PATH: models/embeddings
  LM_STUDIO_BASE_URL: http://192.168.56.1:1234/v1
  LM_STUDIO_MODEL: phi-4-mini-instruct

Command: pytest tests/benchmarks/test_late_chunking_performance.py tests/integration_real/test_database_real.py tests/integration_real/test_end_to_end_real.py tests/integration_real/test_llm_real.py tests/integration/registry/test_registry_integration.py tests/integration/strategies/test_hierarchical_integration.py tests/integration/strategies/test_late_chunking_integration.py tests/integration/strategies/test_self_reflective_integration.py tests/integration/test_package_integration.py tests/test_mock_registry.py tests/unit/config/test_strategy_pair_manager.py tests/unit/database/test_migrations.py tests/unit/documentation/test_code_examples.py tests/unit/documentation/test_links.py tests/unit/registry/test_service_factory.py tests/unit/services/embeddings/test_onnx_local.py tests/unit/services/embedding/test_onnx_local_provider.py tests/unit/strategies/indexing/test_context_aware.py tests/unit/strategies/self_reflective/test_strategy.py tests/unit/test_package.py tests/integration/database/test_migration_integration.py tests/integration/database/test_migration_validator_integration.py
========================================

============================= test session starts ==============================
platform linux -- Python 3.12.3, pytest-9.0.1, pluggy-1.6.0 -- /mnt/MCPProyects/ragTools/venv/bin/python3
cachedir: .pytest_cache
rootdir: /mnt/MCPProyects/ragTools
configfile: pytest.ini (WARNING: ignoring pytest config in pyproject.toml!)
plugins: anyio-4.12.0, cov-7.0.0, asyncio-1.3.0
asyncio: mode=Mode.STRICT, debug=False, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function
collecting ... collected 188 items

tests/benchmarks/test_late_chunking_performance.py::test_document_embedding_speed PASSED [  0%]
tests/benchmarks/test_late_chunking_performance.py::test_embedding_chunking_speed PASSED [  1%]
tests/benchmarks/test_late_chunking_performance.py::test_semantic_boundary_speed PASSED [  1%]
tests/benchmarks/test_late_chunking_performance.py::test_end_to_end_latency PASSED [  2%]
tests/benchmarks/test_late_chunking_performance.py::test_coherence_analysis_overhead PASSED [  2%]
tests/benchmarks/test_late_chunking_performance.py::test_batch_processing_speed PASSED [  3%]
tests/benchmarks/test_late_chunking_performance.py::test_adaptive_chunking_speed PASSED [  3%]
tests/benchmarks/test_late_chunking_performance.py::test_memory_efficiency PASSED [  4%]
tests/integration_real/test_database_real.py::test_postgres_connection PASSED [  4%]
tests/integration_real/test_database_real.py::test_table_creation PASSED [  5%]
tests/integration_real/test_database_real.py::test_store_and_retrieve_chunks PASSED [  5%]
tests/integration_real/test_database_real.py::test_vector_similarity_search PASSED [  6%]
tests/integration_real/test_database_real.py::test_batch_embedding_and_storage PASSED [  6%]
tests/integration_real/test_database_real.py::test_chunk_metadata_persistence PASSED [  7%]
tests/integration_real/test_database_real.py::test_database_context_table_mapping PASSED [  7%]
tests/integration_real/test_database_real.py::test_connection_pooling PASSED [  8%]
tests/integration_real/test_end_to_end_real.py::test_document_indexing_pipeline PASSED [  9%]
tests/integration_real/test_end_to_end_real.py::test_retrieval_pipeline PASSED [  9%]
tests/integration_real/test_end_to_end_real.py::test_full_rag_pipeline PASSED [ 10%]
tests/integration_real/test_end_to_end_real.py::test_multiple_document_batches PASSED [ 10%]
tests/integration_real/test_end_to_end_real.py::test_retrieval_with_metadata_filtering PASSED [ 11%]
tests/integration_real/test_end_to_end_real.py::test_large_document_indexing PASSED [ 11%]
tests/integration_real/test_end_to_end_real.py::test_retrieval_accuracy PASSED [ 12%]
tests/integration_real/test_llm_real.py::test_llm_basic_generation PASSED [ 12%]
tests/integration_real/test_llm_real.py::test_llm_conversation PASSED    [ 13%]
tests/integration_real/test_llm_real.py::test_llm_token_counting PASSED  [ 13%]
tests/integration_real/test_llm_real.py::test_llm_with_system_prompt PASSED [ 14%]
tests/integration_real/test_llm_real.py::test_llm_json_response PASSED   [ 14%]
tests/integration_real/test_llm_real.py::test_llm_max_tokens PASSED      [ 15%]
tests/integration_real/test_llm_real.py::test_llm_temperature PASSED     [ 15%]
tests/integration_real/test_llm_real.py::test_llm_streaming FAILED       [ 16%]
tests/integration_real/test_llm_real.py::test_llm_rag_context PASSED     [ 17%]
tests/integration_real/test_llm_real.py::test_llm_error_handling PASSED  [ 17%]
tests/integration/registry/test_registry_integration.py::TestRealServiceInstantiation::test_instantiate_onnx_embedding_service PASSED [ 18%]
tests/integration/registry/test_registry_integration.py::TestRealServiceInstantiation::test_embedding_service_functionality PASSED [ 18%]
tests/integration/registry/test_registry_integration.py::TestRealServiceInstantiation::test_multiple_service_instantiation FAILED [ 19%]
tests/integration/registry/test_registry_integration.py::TestEnvironmentVariableResolution::test_env_var_resolution PASSED [ 19%]
tests/integration/registry/test_registry_integration.py::TestEnvironmentVariableResolution::test_env_var_defaults PASSED [ 20%]
tests/integration/registry/test_registry_integration.py::TestServiceLifecycle::test_context_manager_cleanup PASSED [ 20%]
tests/integration/registry/test_registry_integration.py::TestServiceLifecycle::test_reload_service PASSED [ 21%]
tests/integration/registry/test_registry_integration.py::TestServiceLifecycle::test_shutdown_cleanup PASSED [ 21%]
tests/integration/registry/test_registry_integration.py::TestServiceSharing::test_service_instance_sharing PASSED [ 22%]
tests/integration/registry/test_registry_integration.py::TestServiceSharing::test_service_sharing_memory_efficiency PASSED [ 22%]
tests/integration/registry/test_registry_integration.py::TestErrorHandling::test_invalid_service_config FAILED [ 23%]
tests/integration/registry/test_registry_integration.py::TestErrorHandling::test_missing_service_file PASSED [ 23%]
tests/integration/registry/test_registry_integration.py::TestOpenAIServices::test_openai_llm_instantiation PASSED [ 24%]
tests/integration/registry/test_registry_integration.py::TestOpenAIServices::test_openai_embedding_instantiation PASSED [ 25%]
tests/integration/registry/test_registry_integration.py::TestConfigurationValidation::test_valid_configuration_loads PASSED [ 25%]
tests/integration/registry/test_registry_integration.py::TestConfigurationValidation::test_configuration_warnings FAILED [ 26%]
tests/integration/strategies/test_hierarchical_integration.py::TestHierarchicalIntegration::test_end_to_end_workflow PASSED [ 26%]
tests/integration/strategies/test_hierarchical_integration.py::TestHierarchicalIntegration::test_expansion_strategy_comparison PASSED [ 27%]
tests/integration/strategies/test_hierarchical_integration.py::TestHierarchicalIntegration::test_hierarchy_validation PASSED [ 27%]
tests/integration/strategies/test_hierarchical_integration.py::TestHierarchicalIntegration::test_multiple_documents PASSED [ 28%]
tests/integration/strategies/test_late_chunking_integration.py::test_late_chunking_workflow PASSED [ 28%]
tests/integration/strategies/test_late_chunking_integration.py::test_fixed_size_chunking_integration PASSED [ 29%]
tests/integration/strategies/test_late_chunking_integration.py::test_adaptive_chunking_integration PASSED [ 29%]
tests/integration/strategies/test_late_chunking_integration.py::test_multiple_documents PASSED [ 30%]
tests/integration/strategies/test_late_chunking_integration.py::test_strategy_properties PASSED [ 30%]
tests/integration/strategies/test_late_chunking_integration.py::test_coherence_scores_computed PASSED [ 31%]
tests/integration/strategies/test_late_chunking_integration.py::test_short_document PASSED [ 31%]
tests/integration/strategies/test_late_chunking_integration.py::test_chunk_embeddings_valid PASSED [ 32%]
tests/integration/strategies/test_late_chunking_integration.py::test_embedding_quality PASSED [ 32%]
tests/integration/strategies/test_self_reflective_integration.py::TestSelfReflectiveIntegration::test_end_to_end_workflow FAILED [ 33%]
tests/integration/strategies/test_self_reflective_integration.py::TestSelfReflectiveIntegration::test_retry_with_poor_results FAILED [ 34%]
tests/integration/strategies/test_self_reflective_integration.py::TestSelfReflectiveIntegration::test_performance_within_limits FAILED [ 34%]
tests/integration/strategies/test_self_reflective_integration.py::TestSelfReflectiveWithLMStudio::test_with_real_llm FAILED [ 35%]
tests/integration/test_package_integration.py::TestPackageInstallation::test_package_installable PASSED [ 35%]
tests/integration/test_package_integration.py::TestSmokeTest::test_basic_usage_smoke_test FAILED [ 36%]
tests/integration/test_package_integration.py::TestFullWorkflow::test_full_workflow_with_installed_package FAILED [ 36%]
tests/integration/test_package_integration.py::TestBuildAndDistribution::test_package_can_be_built SKIPPED [ 37%]
tests/unit/config/test_strategy_pair_manager.py::test_load_pair_success FAILED [ 37%]
tests/unit/config/test_strategy_pair_manager.py::test_load_pair_compatibility_error PASSED [ 38%]
tests/unit/config/test_strategy_pair_manager.py::test_migration_error PASSED [ 38%]
tests/unit/config/test_strategy_pair_manager.py::test_db_context_creation FAILED [ 39%]
tests/unit/database/test_migrations.py::TestAlembicMigrations::test_migration_upgrade_to_head FAILED [ 39%]
tests/unit/database/test_migrations.py::TestAlembicMigrations::test_migration_downgrade FAILED [ 40%]
tests/unit/database/test_migrations.py::TestAlembicMigrations::test_migration_history PASSED [ 40%]
tests/unit/database/test_migrations.py::TestAlembicMigrations::test_migration_idempotency FAILED [ 41%]
tests/unit/database/test_migrations.py::TestAlembicMigrations::test_get_current_version FAILED [ 42%]
tests/unit/database/test_migrations.py::TestAlembicMigrations::test_migration_creates_tables FAILED [ 42%]
tests/unit/database/test_migrations.py::TestAlembicMigrations::test_migration_creates_indexes FAILED [ 43%]
tests/unit/documentation/test_code_examples.py::TestCodeExamples::test_all_code_examples_have_valid_syntax FAILED [ 43%]
tests/unit/documentation/test_code_examples.py::TestCodeExamples::test_strategy_examples_have_imports PASSED [ 44%]
tests/unit/documentation/test_code_examples.py::TestCodeExamples::test_configuration_examples_valid SKIPPED [ 44%]
tests/unit/documentation/test_code_examples.py::TestCodeExamples::test_quick_start_example_complete PASSED [ 45%]
tests/unit/documentation/test_code_examples.py::TestCodeExamples::test_no_placeholder_code PASSED [ 45%]
tests/unit/documentation/test_links.py::TestDocumentationLinks::test_no_broken_internal_links FAILED [ 46%]
tests/unit/documentation/test_links.py::TestDocumentationLinks::test_all_diagrams_valid PASSED [ 46%]
tests/unit/documentation/test_links.py::TestDocumentationLinks::test_no_todo_links PASSED [ 47%]
tests/unit/documentation/test_links.py::TestDocumentationLinks::test_external_links_valid SKIPPED [ 47%]
tests/unit/registry/test_service_factory.py::TestServiceTypeDetection::test_is_llm_service PASSED [ 48%]
tests/unit/registry/test_service_factory.py::TestServiceTypeDetection::test_is_llm_service_missing_url PASSED [ 48%]
tests/unit/registry/test_service_factory.py::TestServiceTypeDetection::test_is_llm_service_missing_model PASSED [ 49%]
tests/unit/registry/test_service_factory.py::TestServiceTypeDetection::test_is_embedding_service PASSED [ 50%]
tests/unit/registry/test_service_factory.py::TestServiceTypeDetection::test_is_embedding_service_missing_provider PASSED [ 50%]
tests/unit/registry/test_service_factory.py::TestServiceTypeDetection::test_is_database_service_postgres PASSED [ 51%]
tests/unit/registry/test_service_factory.py::TestServiceTypeDetection::test_is_database_service_neo4j PASSED [ 51%]
tests/unit/registry/test_service_factory.py::TestServiceTypeDetection::test_is_database_service_unknown_type PASSED [ 52%]
tests/unit/registry/test_service_factory.py::TestLLMServiceCreation::test_create_llm_service_openai FAILED [ 52%]
tests/unit/registry/test_service_factory.py::TestLLMServiceCreation::test_create_llm_service_lm_studio PASSED [ 53%]
tests/unit/registry/test_service_factory.py::TestLLMServiceCreation::test_create_llm_service_with_defaults PASSED [ 53%]
tests/unit/registry/test_service_factory.py::TestEmbeddingServiceCreation::test_create_embedding_service_onnx FAILED [ 54%]
tests/unit/registry/test_service_factory.py::TestEmbeddingServiceCreation::test_create_embedding_service_onnx_with_defaults FAILED [ 54%]
tests/unit/registry/test_service_factory.py::TestEmbeddingServiceCreation::test_create_embedding_service_openai FAILED [ 55%]
tests/unit/registry/test_service_factory.py::TestEmbeddingServiceCreation::test_create_embedding_service_cohere_not_implemented PASSED [ 55%]
tests/unit/registry/test_service_factory.py::TestEmbeddingServiceCreation::test_create_embedding_service_unknown_provider PASSED [ 56%]
tests/unit/registry/test_service_factory.py::TestDatabaseServiceCreation::test_create_database_service_postgres_with_connection_string FAILED [ 56%]
tests/unit/registry/test_service_factory.py::TestDatabaseServiceCreation::test_create_database_service_postgres_with_components FAILED [ 57%]
tests/unit/registry/test_service_factory.py::TestDatabaseServiceCreation::test_create_database_service_postgres_with_defaults FAILED [ 57%]
tests/unit/registry/test_service_factory.py::TestDatabaseServiceCreation::test_create_database_service_neo4j FAILED [ 58%]
tests/unit/registry/test_service_factory.py::TestDatabaseServiceCreation::test_create_database_service_neo4j_with_defaults FAILED [ 59%]
tests/unit/registry/test_service_factory.py::TestDatabaseServiceCreation::test_create_database_service_unknown_type PASSED [ 59%]
tests/unit/registry/test_service_factory.py::TestServiceCreation::test_create_service_llm PASSED [ 60%]
tests/unit/registry/test_service_factory.py::TestServiceCreation::test_create_service_embedding PASSED [ 60%]
tests/unit/registry/test_service_factory.py::TestServiceCreation::test_create_service_database PASSED [ 61%]
tests/unit/registry/test_service_factory.py::TestServiceCreation::test_create_service_unknown_type PASSED [ 61%]
tests/unit/services/embeddings/test_onnx_local.py::TestONNXLocalProvider::test_initialization PASSED [ 62%]
tests/unit/services/embeddings/test_onnx_local.py::TestONNXLocalProvider::test_initialization_with_custom_config PASSED [ 62%]
tests/unit/services/embeddings/test_onnx_local.py::TestONNXLocalProvider::test_get_embeddings_single_text PASSED [ 63%]
tests/unit/services/embeddings/test_onnx_local.py::TestONNXLocalProvider::test_get_embeddings_multiple_texts PASSED [ 63%]
tests/unit/services/embeddings/test_onnx_local.py::TestONNXLocalProvider::test_get_embeddings_empty_list PASSED [ 64%]
tests/unit/services/embeddings/test_onnx_local.py::TestONNXLocalProvider::test_embedding_normalization PASSED [ 64%]
tests/unit/services/embeddings/test_onnx_local.py::TestONNXLocalProvider::test_get_dimensions PASSED [ 65%]
tests/unit/services/embeddings/test_onnx_local.py::TestONNXLocalProvider::test_get_max_batch_size PASSED [ 65%]
tests/unit/services/embeddings/test_onnx_local.py::TestONNXLocalProvider::test_get_model_name PASSED [ 66%]
tests/unit/services/embeddings/test_onnx_local.py::TestONNXLocalProvider::test_calculate_cost PASSED [ 67%]
tests/unit/services/embeddings/test_onnx_local.py::TestONNXLocalProvider::test_known_models PASSED [ 67%]
tests/unit/services/embeddings/test_onnx_local.py::TestONNXLocalProvider::test_missing_onnx_runtime PASSED [ 68%]
tests/unit/services/embeddings/test_onnx_local.py::TestONNXLocalProvider::test_model_loading_failure PASSED [ 68%]
tests/unit/services/embeddings/test_onnx_local.py::TestONNXLocalProvider::test_session_creation_failure PASSED [ 69%]
tests/unit/services/embedding/test_onnx_local_provider.py::test_provider_not_available_raises_error PASSED [ 69%]
tests/unit/services/embedding/test_onnx_local_provider.py::test_provider_initialization PASSED [ 70%]
tests/unit/services/embedding/test_onnx_local_provider.py::test_get_embeddings PASSED [ 70%]
tests/unit/services/embedding/test_onnx_local_provider.py::test_calculate_cost_is_zero FAILED [ 71%]
tests/unit/services/embedding/test_onnx_local_provider.py::test_known_model_dimensions PASSED [ 71%]
tests/unit/services/embedding/test_onnx_local_provider.py::test_unknown_model_uses_output_shape PASSED [ 72%]
tests/unit/services/embedding/test_onnx_local_provider.py::test_custom_batch_size PASSED [ 72%]
tests/unit/services/embedding/test_onnx_local_provider.py::test_model_loading_failure PASSED [ 73%]
tests/unit/services/embedding/test_onnx_local_provider.py::test_get_model_name PASSED [ 73%]
tests/unit/services/embedding/test_onnx_local_provider.py::test_mean_pooling PASSED [ 74%]
tests/unit/strategies/indexing/test_context_aware.py::test_capabilities FAILED [ 75%]
tests/unit/strategies/indexing/test_context_aware.py::test_requirements PASSED [ 75%]
tests/unit/strategies/indexing/test_context_aware.py::test_split_into_sentences PASSED [ 76%]
tests/unit/strategies/indexing/test_context_aware.py::test_create_windows PASSED [ 76%]
tests/unit/strategies/indexing/test_context_aware.py::test_find_boundaries PASSED [ 77%]
tests/unit/strategies/indexing/test_context_aware.py::test_create_chunks_respects_boundaries PASSED [ 77%]
tests/unit/strategies/indexing/test_context_aware.py::test_create_chunks_respects_min_size PASSED [ 78%]
tests/unit/strategies/indexing/test_context_aware.py::test_create_chunks_respects_max_size PASSED [ 78%]
tests/unit/strategies/indexing/test_context_aware.py::test_process_flow PASSED [ 79%]
tests/unit/strategies/self_reflective/test_strategy.py::test_retrieve_good_results_no_retry PASSED [ 79%]
tests/unit/strategies/self_reflective/test_strategy.py::test_retrieve_poor_results_triggers_retry PASSED [ 80%]
tests/unit/strategies/self_reflective/test_strategy.py::test_max_retries_enforced PASSED [ 80%]
tests/unit/strategies/self_reflective/test_strategy.py::test_result_aggregation PASSED [ 81%]
tests/unit/strategies/self_reflective/test_strategy.py::test_timeout_protection PASSED [ 81%]
tests/unit/strategies/self_reflective/test_strategy.py::test_same_query_prevention PASSED [ 82%]
tests/unit/strategies/self_reflective/test_strategy.py::test_normalize_results PASSED [ 82%]
tests/unit/strategies/self_reflective/test_strategy.py::test_strategy_properties PASSED [ 83%]
tests/unit/test_package.py::TestImports::test_import_main_package PASSED [ 84%]
tests/unit/test_package.py::TestImports::test_import_factory FAILED      [ 84%]
tests/unit/test_package.py::TestImports::test_import_pipeline FAILED     [ 85%]
tests/unit/test_package.py::TestImports::test_import_config FAILED       [ 85%]
tests/unit/test_package.py::TestImports::test_import_base_strategy PASSED [ 86%]
tests/unit/test_package.py::TestImports::test_import_all_exports PASSED  [ 86%]
tests/unit/test_package.py::TestVersion::test_version_format PASSED      [ 87%]
tests/unit/test_package.py::TestVersion::test_version_accessible PASSED  [ 87%]
tests/unit/test_package.py::TestPackageStructure::test_strategies_subpackage_exists PASSED [ 88%]
tests/unit/test_package.py::TestPackageStructure::test_no_circular_imports FAILED [ 88%]
tests/unit/test_package.py::TestDependencies::test_required_dependencies_installed PASSED [ 89%]
tests/unit/test_package.py::TestDependencies::test_optional_dependencies_handled FAILED [ 89%]
tests/integration/database/test_migration_integration.py::TestMigrationIntegration::test_real_migration_execution FAILED [ 90%]
tests/integration/database/test_migration_integration.py::TestMigrationIntegration::test_migration_with_existing_data FAILED [ 90%]
tests/integration/database/test_migration_integration.py::TestMigrationIntegration::test_rollback_functionality FAILED [ 91%]
tests/integration/database/test_migration_integration.py::TestMigrationIntegration::test_pgvector_extension_installed FAILED [ 92%]
tests/integration/database/test_migration_validator_integration.py::TestMigrationValidatorIntegration::test_validate_with_no_migrations FAILED [ 92%]
tests/integration/database/test_migration_validator_integration.py::TestMigrationValidatorIntegration::test_validate_with_partial_migrations FAILED [ 93%]
tests/integration/database/test_migration_validator_integration.py::TestMigrationValidatorIntegration::test_validate_with_all_migrations FAILED [ 93%]
tests/integration/database/test_migration_validator_integration.py::TestMigrationValidatorIntegration::test_validate_or_raise_success FAILED [ 94%]
tests/integration/database/test_migration_validator_integration.py::TestMigrationValidatorIntegration::test_validate_or_raise_failure FAILED [ 94%]
tests/integration/database/test_migration_validator_integration.py::TestMigrationValidatorIntegration::test_get_current_revision FAILED [ 95%]
tests/integration/database/test_migration_validator_integration.py::TestMigrationValidatorIntegration::test_get_all_revisions PASSED [ 95%]
tests/integration/database/test_migration_validator_integration.py::TestMigrationValidatorIntegration::test_is_at_head FAILED [ 96%]
tests/integration/database/test_migration_validator_integration.py::TestMigrationValidatorIntegration::test_error_message_details FAILED [ 96%]
tests/integration/database/test_migration_validator_integration.py::TestMigrationValidatorIntegration::test_validate_single_migration FAILED [ 97%]
tests/integration/database/test_migration_validator_integration.py::TestMigrationValidatorIntegration::test_validate_nonexistent_migration FAILED [ 97%]
tests/integration/database/test_migration_validator_integration.py::TestMigrationValidatorIntegration::test_validate_after_downgrade FAILED [ 98%]
tests/integration/database/test_migration_validator_integration.py::TestMigrationValidatorIntegration::test_multiple_validators_same_database FAILED [ 98%]
tests/integration/database/test_migration_validator_integration.py::TestMigrationValidatorEdgeCases::test_validator_with_auto_discovered_config PASSED [ 99%]
tests/integration/database/test_migration_validator_integration.py::TestMigrationValidatorEdgeCases::test_validate_empty_requirements PASSED [100%]

=================================== FAILURES ===================================
______________________________ test_llm_streaming ______________________________

real_llm_service = <rag_factory.services.llm.service.LLMService object at 0x77cf5860a3f0>

    @pytest.mark.real_integration
    @pytest.mark.requires_llm
    @pytest.mark.asyncio
    async def test_llm_streaming(real_llm_service):
        """Test LLM streaming responses."""
        from rag_factory.services.llm.base import Message, MessageRole
    
        messages = [
            Message(
                role=MessageRole.USER,
                content="Count from 1 to 5."
            )
        ]
    
        # Check if service supports streaming
        if hasattr(real_llm_service, 'stream'):
            chunks = []
>           async for chunk in real_llm_service.stream(messages):
E           TypeError: 'async for' requires an object with __aiter__ method, got generator

tests/integration_real/test_llm_real.py:197: TypeError
---------------------------- Captured stderr setup -----------------------------
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 192.168.56.1:1234
DEBUG:urllib3.connectionpool:http://192.168.56.1:1234 "GET /v1/models HTTP/1.1" 200 1082
DEBUG:asyncio:Using selector: EpollSelector
------------------------------ Captured log setup ------------------------------
DEBUG    urllib3.connectionpool:connectionpool.py:241 Starting new HTTP connection (1): 192.168.56.1:1234
DEBUG    urllib3.connectionpool:connectionpool.py:544 http://192.168.56.1:1234 "GET /v1/models HTTP/1.1" 200 1082
DEBUG    asyncio:selector_events.py:64 Using selector: EpollSelector
--------------------------- Captured stderr teardown ---------------------------
DEBUG:httpcore.connection:close.started
DEBUG:httpcore.connection:close.complete
DEBUG:httpcore.connection:close.started
DEBUG:httpcore.connection:close.complete
DEBUG:httpcore.connection:close.started
DEBUG:httpcore.connection:close.complete
DEBUG:httpcore.connection:close.started
DEBUG:httpcore.connection:close.complete
_______ TestRealServiceInstantiation.test_multiple_service_instantiation _______

self = <rag_factory.registry.service_registry.ServiceRegistry object at 0x77cf586513a0>
service_ref = 'embedding_local'

    def get(self, service_ref: str) -> Any:
        """Get or create a service instance.
    
        Args:
            service_ref: Service reference like "$llm1" or "llm1"
    
        Returns:
            Service instance implementing appropriate interface
    
        Raises:
            ServiceNotFoundError: If service not found in registry
            ServiceInstantiationError: If service creation fails
        """
        # Strip $ prefix if present
        service_name = service_ref.lstrip('$')
    
        # Return cached instance if exists
        if service_name in self._instances:
            logger.debug(f"Service '{service_name}' returned from cache")
            return self._instances[service_name]
    
        # Thread-safe instantiation
        with self._locks[service_name]:
            # Double-check after acquiring lock
            if service_name in self._instances:
                return self._instances[service_name]
    
            # Validate service exists
            if 'services' not in self.config:
                raise ServiceNotFoundError(
                    f"No services defined in registry configuration"
                )
    
            if service_name not in self.config['services']:
                available = list(self.config['services'].keys())
                raise ServiceNotFoundError(
                    f"Service '{service_name}' not found in registry. "
                    f"Available services: {available}"
                )
    
            # Get service configuration
            service_config = self.config['services'][service_name]
    
            # Create service instance
            logger.info(f"Instantiating service: {service_name}")
            start_time = time.time()
    
            try:
>               service_instance = self._factory.create_service(
                    service_name,
                    service_config
                )

rag_factory/registry/service_registry.py:137: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
rag_factory/registry/service_factory.py:48: in create_service
    return self._create_embedding_service(service_name, config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
rag_factory/registry/service_factory.py:127: in _create_embedding_service
    return ONNXEmbeddingService(
rag_factory/services/onnx/embedding.py:68: in __init__
    self._provider = ONNXLocalProvider(config)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
rag_factory/services/embedding/providers/onnx_local.py:116: in __init__
    self.model_path = get_onnx_model_path(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

model_name = 'Xenova/all-MiniLM-L6-v2', cache_dir = PosixPath('models')
filename = 'model.onnx'

    def get_onnx_model_path(
        model_name: str,
        cache_dir: Optional[Path] = None,
        filename: str = "model.onnx",
    ) -> Path:
        """Get path to local ONNX model.
    
        This function checks:
        1. Local model paths (if model exists locally)
        2. Local cache directory
    
        Args:
            model_name: Model identifier or local path
            cache_dir: Directory for model caching
            filename: Name of the ONNX model file
    
        Returns:
            Path to ONNX model file
    
        Raises:
            FileNotFoundError: If model is not found locally
        """
        import os
    
        check_dependencies()
    
        # Check for environment variable configuration
        env_model_path = os.getenv("EMBEDDING_MODEL_PATH")
        env_model_name = os.getenv("EMBEDDING_MODEL_NAME")
    
        # Use environment variable for cache_dir if not specified
        if cache_dir is None:
            if env_model_path:
                cache_dir = Path(env_model_path)
            elif Path("models/embeddings").exists():
                cache_dir = Path("models/embeddings").resolve()
                logger.info(f"Using local project cache: {cache_dir}")
            else:
                # Default to standard location, but don't create it if we're not downloading
                cache_dir = Path.home() / ".cache" / "rag_factory" / "onnx_models"
    
        cache_dir = Path(cache_dir)
    
        # Use environment variable for model_name if it matches default
        if env_model_name and model_name == "Xenova/all-MiniLM-L6-v2":
            logger.info(f"Using model from EMBEDDING_MODEL_NAME env: {env_model_name}")
            model_name = env_model_name
    
        # Check if model_name is a local path
        potential_local_path = Path(model_name)
        if potential_local_path.exists() and potential_local_path.is_file():
            logger.info(f"Using local ONNX model: {potential_local_path}")
            return potential_local_path
    
        # Check if model exists in cache directory
        # Try both naming conventions: underscore (old) and double-dash (HF standard)
        model_dir_name_underscore = model_name.replace("/", "_")
        model_dir_name_dash = model_name.replace("/", "--")
    
        for model_dir_name in [model_dir_name_dash, model_dir_name_underscore]:
            local_model_dir = cache_dir / model_dir_name
    
            if local_model_dir.exists():
                # Look for ONNX files in the directory (recursively, Xenova models have onnx/ subdirectory)
                onnx_files = list(local_model_dir.rglob("*.onnx"))
                if onnx_files:
                    # Prefer the main model.onnx if available, otherwise use first one
                    main_model = next((f for f in onnx_files if f.name == "model.onnx"), onnx_files[0])
                    logger.info(f"Using cached ONNX model: {main_model}")
                    return main_model
    
        # Model not found locally
        error_msg = (
            f"ONNX model '{model_name}' not found locally.\n"
            f"Checked path: {cache_dir}\n"
            f"Automatic downloading is disabled. Please ensure the model is available directly in the infrastructure.\n"
            f"Set EMBEDDING_MODEL_PATH environment variable to the directory containing the model."
        )
>       raise FileNotFoundError(error_msg)
E       FileNotFoundError: ONNX model 'Xenova/all-MiniLM-L6-v2' not found locally.
E       Checked path: models
E       Automatic downloading is disabled. Please ensure the model is available directly in the infrastructure.
E       Set EMBEDDING_MODEL_PATH environment variable to the directory containing the model.

rag_factory/services/utils/onnx_utils.py:123: FileNotFoundError

During handling of the above exception, another exception occurred:

self = <tests.integration.registry.test_registry_integration.TestRealServiceInstantiation object at 0x77cf5be4a570>
test_services_yaml_with_env = '/tmp/pytest-of-admindevmac/pytest-53/test_multiple_service_instanti0/services.yaml'

    def test_multiple_service_instantiation(self, test_services_yaml_with_env):
        """Test instantiating multiple services."""
        registry = ServiceRegistry(test_services_yaml_with_env)
    
        # Get both services
>       embedding = registry.get("embedding_local")
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/integration/registry/test_registry_integration.py:95: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <rag_factory.registry.service_registry.ServiceRegistry object at 0x77cf586513a0>
service_ref = 'embedding_local'

    def get(self, service_ref: str) -> Any:
        """Get or create a service instance.
    
        Args:
            service_ref: Service reference like "$llm1" or "llm1"
    
        Returns:
            Service instance implementing appropriate interface
    
        Raises:
            ServiceNotFoundError: If service not found in registry
            ServiceInstantiationError: If service creation fails
        """
        # Strip $ prefix if present
        service_name = service_ref.lstrip('$')
    
        # Return cached instance if exists
        if service_name in self._instances:
            logger.debug(f"Service '{service_name}' returned from cache")
            return self._instances[service_name]
    
        # Thread-safe instantiation
        with self._locks[service_name]:
            # Double-check after acquiring lock
            if service_name in self._instances:
                return self._instances[service_name]
    
            # Validate service exists
            if 'services' not in self.config:
                raise ServiceNotFoundError(
                    f"No services defined in registry configuration"
                )
    
            if service_name not in self.config['services']:
                available = list(self.config['services'].keys())
                raise ServiceNotFoundError(
                    f"Service '{service_name}' not found in registry. "
                    f"Available services: {available}"
                )
    
            # Get service configuration
            service_config = self.config['services'][service_name]
    
            # Create service instance
            logger.info(f"Instantiating service: {service_name}")
            start_time = time.time()
    
            try:
                service_instance = self._factory.create_service(
                    service_name,
                    service_config
                )
                instantiation_time = time.time() - start_time
    
                logger.info(
                    f"Service '{service_name}' instantiated successfully "
                    f"in {instantiation_time:.2f}s"
                )
    
            except Exception as e:
                logger.error(f"Failed to instantiate service '{service_name}': {e}")
>               raise ServiceInstantiationError(
                    f"Service instantiation failed for '{service_name}': {e}"
                )
E               rag_factory.registry.exceptions.ServiceInstantiationError: Service instantiation failed for 'embedding_local': ONNX model 'Xenova/all-MiniLM-L6-v2' not found locally.
E               Checked path: models
E               Automatic downloading is disabled. Please ensure the model is available directly in the infrastructure.
E               Set EMBEDDING_MODEL_PATH environment variable to the directory containing the model.

rag_factory/registry/service_registry.py:150: ServiceInstantiationError
----------------------------- Captured stderr call -----------------------------
INFO:rag_factory.registry.service_registry:Loading service registry from: /tmp/pytest-of-admindevmac/pytest-53/test_multiple_service_instanti0/services.yaml
DEBUG:httpcore.connection:close.started
DEBUG:httpcore.connection:close.complete
WARNING:rag_factory.registry.service_registry:WARNING: Potential plaintext secret in services.llm_local.api_key. Consider using environment variable: ${ENV_VAR}
INFO:rag_factory.registry.service_registry:Service registry loaded: 2 services available
INFO:rag_factory.registry.service_registry:Instantiating service: embedding_local
DEBUG:rag_factory.registry.service_factory:Creating embedding service: embedding_local
INFO:rag_factory.services.embedding.providers.onnx_local:Loading ONNX model: Xenova/all-MiniLM-L6-v2
INFO:rag_factory.services.utils.onnx_utils:Using model from EMBEDDING_MODEL_NAME env: Xenova/all-MiniLM-L6-v2
ERROR:rag_factory.registry.service_registry:Failed to instantiate service 'embedding_local': ONNX model 'Xenova/all-MiniLM-L6-v2' not found locally.
Checked path: models
Automatic downloading is disabled. Please ensure the model is available directly in the infrastructure.
Set EMBEDDING_MODEL_PATH environment variable to the directory containing the model.
------------------------------ Captured log call -------------------------------
INFO     rag_factory.registry.service_registry:service_registry.py:55 Loading service registry from: /tmp/pytest-of-admindevmac/pytest-53/test_multiple_service_instanti0/services.yaml
DEBUG    httpcore.connection:_trace.py:47 close.started
DEBUG    httpcore.connection:_trace.py:47 close.complete
WARNING  rag_factory.registry.service_registry:service_registry.py:70 WARNING: Potential plaintext secret in services.llm_local.api_key. Consider using environment variable: ${ENV_VAR}
INFO     rag_factory.registry.service_registry:service_registry.py:75 Service registry loaded: 2 services available
INFO     rag_factory.registry.service_registry:service_registry.py:133 Instantiating service: embedding_local
DEBUG    rag_factory.registry.service_factory:service_factory.py:121 Creating embedding service: embedding_local
INFO     rag_factory.services.embedding.providers.onnx_local:onnx_local.py:111 Loading ONNX model: Xenova/all-MiniLM-L6-v2
INFO     rag_factory.services.utils.onnx_utils:onnx_utils.py:90 Using model from EMBEDDING_MODEL_NAME env: Xenova/all-MiniLM-L6-v2
ERROR    rag_factory.registry.service_registry:service_registry.py:149 Failed to instantiate service 'embedding_local': ONNX model 'Xenova/all-MiniLM-L6-v2' not found locally.
Checked path: models
Automatic downloading is disabled. Please ensure the model is available directly in the infrastructure.
Set EMBEDDING_MODEL_PATH environment variable to the directory containing the model.
________________ TestErrorHandling.test_invalid_service_config _________________

self = <rag_factory.config.validator.ConfigValidator object at 0x77cf44f49d60>
config = {'services': {'invalid_service': {'unknown_field': 'value'}}}
file_path = '/tmp/pytest-of-admindevmac/pytest-53/test_invalid_service_config0/services.yaml'

    def validate_services_yaml(
        self,
        config: Dict[str, Any],
        file_path: Optional[str] = None
    ) -> List[str]:
        """
        Validate services.yaml configuration.
    
        Args:
            config: Parsed YAML configuration
            file_path: Path to YAML file (for error messages)
    
        Returns:
            List of warning messages (empty if no warnings)
    
        Raises:
            ConfigValidationError: If validation fails
    
        Examples:
            >>> validator = ConfigValidator()
            >>> config = {
            ...     "services": {
            ...         "llm1": {
            ...             "name": "test-llm",
            ...             "type": "llm",
            ...             "url": "http://localhost:1234/v1",
            ...             "api_key": "${API_KEY}",
            ...             "model": "test-model"
            ...         }
            ...     }
            ... }
            >>> warnings = validator.validate_services_yaml(config)
            >>> len(warnings)
            0
        """
        try:
            # JSON Schema validation
>           jsonschema.validate(
                instance=config,
                schema=self._schemas["service_registry"]
            )

rag_factory/config/validator.py:113: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

instance = {'services': {'invalid_service': {'unknown_field': 'value'}}}
schema = {'$schema': 'http://json-schema.org/draft-07/schema#', 'definitions': {'database_service': {'properties': {'connection...tion': 'Schema version (semver)', 'pattern': '^\\d+\\.\\d+\\.\\d+$', 'type': 'string'}}, 'required': ['services'], ...}
cls = <class 'jsonschema.validators.Draft7Validator'>, args = (), kwargs = {}
validator = Draft7Validator(schema={'$schema': 'http://json-...ft-07/schema#', 'definitions': {'database_service': {'properties': ... (semver)', 'pattern': '^\\d+\\.\\d+\\.\\d+$', 'type': 'string'}}, 'required': ['services'], ...}, format_checker=None)
error = <ValidationError: "{'unknown_field': 'value'} is not valid under any of the given schemas">

    def validate(instance, schema, cls=None, *args, **kwargs):  # noqa: D417
        """
        Validate an instance under the given schema.
    
            >>> validate([2, 3, 4], {"maxItems": 2})
            Traceback (most recent call last):
                ...
            ValidationError: [2, 3, 4] is too long
    
        :func:`~jsonschema.validators.validate` will first verify that the
        provided schema is itself valid, since not doing so can lead to less
        obvious error messages and fail in less obvious or consistent ways.
    
        If you know you have a valid schema already, especially
        if you intend to validate multiple instances with
        the same schema, you likely would prefer using the
        `jsonschema.protocols.Validator.validate` method directly on a
        specific validator (e.g. ``Draft202012Validator.validate``).
    
    
        Arguments:
    
            instance:
    
                The instance to validate
    
            schema:
    
                The schema to validate with
    
            cls (jsonschema.protocols.Validator):
    
                The class that will be used to validate the instance.
    
        If the ``cls`` argument is not provided, two things will happen
        in accordance with the specification. First, if the schema has a
        :kw:`$schema` keyword containing a known meta-schema [#]_ then the
        proper validator will be used. The specification recommends that
        all schemas contain :kw:`$schema` properties for this reason. If no
        :kw:`$schema` property is found, the default validator class is the
        latest released draft.
    
        Any other provided positional and keyword arguments will be passed
        on when instantiating the ``cls``.
    
        Raises:
    
            `jsonschema.exceptions.ValidationError`:
    
                if the instance is invalid
    
            `jsonschema.exceptions.SchemaError`:
    
                if the schema itself is invalid
    
        .. rubric:: Footnotes
        .. [#] known by a validator registered with
            `jsonschema.validators.validates`
    
        """
        if cls is None:
            cls = validator_for(schema)
    
        cls.check_schema(schema)
        validator = cls(schema, *args, **kwargs)
        error = exceptions.best_match(validator.iter_errors(instance))
        if error is not None:
>           raise error
E           jsonschema.exceptions.ValidationError: {'unknown_field': 'value'} is not valid under any of the given schemas
E           
E           Failed validating 'oneOf' in schema['properties']['services']['patternProperties']['^[a-zA-Z0-9_]+$']:
E               {'oneOf': [{'$ref': '#/definitions/llm_service'},
E                          {'$ref': '#/definitions/embedding_service'},
E                          {'$ref': '#/definitions/database_service'}]}
E           
E           On instance['services']['invalid_service']:
E               {'unknown_field': 'value'}

venv/lib/python3.12/site-packages/jsonschema/validators.py:1332: ValidationError

During handling of the above exception, another exception occurred:

self = <rag_factory.registry.service_registry.ServiceRegistry object at 0x77cf44f48440>

    def _load_config(self) -> None:
        """Load and validate services.yaml configuration."""
        logger.info(f"Loading service registry from: {self.config_path}")
    
        try:
            # Load YAML
            with open(self.config_path, 'r') as f:
                raw_config = yaml.safe_load(f)
    
            # Validate schema
>           warnings = self._validator.validate_services_yaml(
                raw_config,
                file_path=self.config_path
            )

rag_factory/registry/service_registry.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <rag_factory.config.validator.ConfigValidator object at 0x77cf44f49d60>
config = {'services': {'invalid_service': {'unknown_field': 'value'}}}
file_path = '/tmp/pytest-of-admindevmac/pytest-53/test_invalid_service_config0/services.yaml'

    def validate_services_yaml(
        self,
        config: Dict[str, Any],
        file_path: Optional[str] = None
    ) -> List[str]:
        """
        Validate services.yaml configuration.
    
        Args:
            config: Parsed YAML configuration
            file_path: Path to YAML file (for error messages)
    
        Returns:
            List of warning messages (empty if no warnings)
    
        Raises:
            ConfigValidationError: If validation fails
    
        Examples:
            >>> validator = ConfigValidator()
            >>> config = {
            ...     "services": {
            ...         "llm1": {
            ...             "name": "test-llm",
            ...             "type": "llm",
            ...             "url": "http://localhost:1234/v1",
            ...             "api_key": "${API_KEY}",
            ...             "model": "test-model"
            ...         }
            ...     }
            ... }
            >>> warnings = validator.validate_services_yaml(config)
            >>> len(warnings)
            0
        """
        try:
            # JSON Schema validation
            jsonschema.validate(
                instance=config,
                schema=self._schemas["service_registry"]
            )
        except jsonschema.ValidationError as e:
>           raise ConfigValidationError(
                message=f"Schema validation failed: {e.message}",
                file_path=file_path,
                field=".".join(str(p) for p in e.path)
            )
E           rag_factory.config.validator.ConfigValidationError: Schema validation failed: {'unknown_field': 'value'} is not valid under any of the given schemas
E           File: /tmp/pytest-of-admindevmac/pytest-53/test_invalid_service_config0/services.yaml
E           Field: services.invalid_service

rag_factory/config/validator.py:118: ConfigValidationError

During handling of the above exception, another exception occurred:

self = <tests.integration.registry.test_registry_integration.TestErrorHandling object at 0x77cf5be66240>
tmp_path = PosixPath('/tmp/pytest-of-admindevmac/pytest-53/test_invalid_service_config0')

        def test_invalid_service_config(self, tmp_path):
            """Test handling of invalid service configuration."""
            content = """
    services:
      invalid_service:
        unknown_field: "value"
    """
            services_file = tmp_path / "services.yaml"
            services_file.write_text(content)
    
>           registry = ServiceRegistry(str(services_file))
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/integration/registry/test_registry_integration.py:230: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
rag_factory/registry/service_registry.py:51: in __init__
    self._load_config()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <rag_factory.registry.service_registry.ServiceRegistry object at 0x77cf44f48440>

    def _load_config(self) -> None:
        """Load and validate services.yaml configuration."""
        logger.info(f"Loading service registry from: {self.config_path}")
    
        try:
            # Load YAML
            with open(self.config_path, 'r') as f:
                raw_config = yaml.safe_load(f)
    
            # Validate schema
            warnings = self._validator.validate_services_yaml(
                raw_config,
                file_path=self.config_path
            )
    
            # Print warnings
            for warning in warnings:
                logger.warning(warning)
    
            # Resolve environment variables
            self.config = EnvResolver.resolve(raw_config)
    
            logger.info(
                f"Service registry loaded: "
                f"{len(self.config.get('services', {}))} services available"
            )
    
        except FileNotFoundError:
            raise ServiceInstantiationError(
                f"Service registry configuration not found: {self.config_path}"
            )
        except Exception as e:
>           raise ServiceInstantiationError(
                f"Failed to load service registry: {e}"
            )
E           rag_factory.registry.exceptions.ServiceInstantiationError: Failed to load service registry: Schema validation failed: {'unknown_field': 'value'} is not valid under any of the given schemas
E           File: /tmp/pytest-of-admindevmac/pytest-53/test_invalid_service_config0/services.yaml
E           Field: services.invalid_service

rag_factory/registry/service_registry.py:85: ServiceInstantiationError
----------------------------- Captured stderr call -----------------------------
INFO:rag_factory.registry.service_registry:Loading service registry from: /tmp/pytest-of-admindevmac/pytest-53/test_invalid_service_config0/services.yaml
------------------------------ Captured log call -------------------------------
INFO     rag_factory.registry.service_registry:service_registry.py:55 Loading service registry from: /tmp/pytest-of-admindevmac/pytest-53/test_invalid_service_config0/services.yaml
___________ TestConfigurationValidation.test_configuration_warnings ____________

self = <rag_factory.config.validator.ConfigValidator object at 0x77cf58619d00>
config = {'services': {'test_service': {'api_key': 'plaintext-secret', 'model': 'test-model', 'provider': 'onnx'}}}
file_path = '/tmp/pytest-of-admindevmac/pytest-53/test_configuration_warnings0/services.yaml'

    def validate_services_yaml(
        self,
        config: Dict[str, Any],
        file_path: Optional[str] = None
    ) -> List[str]:
        """
        Validate services.yaml configuration.
    
        Args:
            config: Parsed YAML configuration
            file_path: Path to YAML file (for error messages)
    
        Returns:
            List of warning messages (empty if no warnings)
    
        Raises:
            ConfigValidationError: If validation fails
    
        Examples:
            >>> validator = ConfigValidator()
            >>> config = {
            ...     "services": {
            ...         "llm1": {
            ...             "name": "test-llm",
            ...             "type": "llm",
            ...             "url": "http://localhost:1234/v1",
            ...             "api_key": "${API_KEY}",
            ...             "model": "test-model"
            ...         }
            ...     }
            ... }
            >>> warnings = validator.validate_services_yaml(config)
            >>> len(warnings)
            0
        """
        try:
            # JSON Schema validation
>           jsonschema.validate(
                instance=config,
                schema=self._schemas["service_registry"]
            )

rag_factory/config/validator.py:113: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

instance = {'services': {'test_service': {'api_key': 'plaintext-secret', 'model': 'test-model', 'provider': 'onnx'}}}
schema = {'$schema': 'http://json-schema.org/draft-07/schema#', 'definitions': {'database_service': {'properties': {'connection...tion': 'Schema version (semver)', 'pattern': '^\\d+\\.\\d+\\.\\d+$', 'type': 'string'}}, 'required': ['services'], ...}
cls = <class 'jsonschema.validators.Draft7Validator'>, args = (), kwargs = {}
validator = Draft7Validator(schema={'$schema': 'http://json-...ft-07/schema#', 'definitions': {'database_service': {'properties': ... (semver)', 'pattern': '^\\d+\\.\\d+\\.\\d+$', 'type': 'string'}}, 'required': ['services'], ...}, format_checker=None)
error = <ValidationError: "{'provider': 'onnx', 'model': 'test-model', 'api_key': 'plaintext-secret'} is not valid under any of the given schemas">

    def validate(instance, schema, cls=None, *args, **kwargs):  # noqa: D417
        """
        Validate an instance under the given schema.
    
            >>> validate([2, 3, 4], {"maxItems": 2})
            Traceback (most recent call last):
                ...
            ValidationError: [2, 3, 4] is too long
    
        :func:`~jsonschema.validators.validate` will first verify that the
        provided schema is itself valid, since not doing so can lead to less
        obvious error messages and fail in less obvious or consistent ways.
    
        If you know you have a valid schema already, especially
        if you intend to validate multiple instances with
        the same schema, you likely would prefer using the
        `jsonschema.protocols.Validator.validate` method directly on a
        specific validator (e.g. ``Draft202012Validator.validate``).
    
    
        Arguments:
    
            instance:
    
                The instance to validate
    
            schema:
    
                The schema to validate with
    
            cls (jsonschema.protocols.Validator):
    
                The class that will be used to validate the instance.
    
        If the ``cls`` argument is not provided, two things will happen
        in accordance with the specification. First, if the schema has a
        :kw:`$schema` keyword containing a known meta-schema [#]_ then the
        proper validator will be used. The specification recommends that
        all schemas contain :kw:`$schema` properties for this reason. If no
        :kw:`$schema` property is found, the default validator class is the
        latest released draft.
    
        Any other provided positional and keyword arguments will be passed
        on when instantiating the ``cls``.
    
        Raises:
    
            `jsonschema.exceptions.ValidationError`:
    
                if the instance is invalid
    
            `jsonschema.exceptions.SchemaError`:
    
                if the schema itself is invalid
    
        .. rubric:: Footnotes
        .. [#] known by a validator registered with
            `jsonschema.validators.validates`
    
        """
        if cls is None:
            cls = validator_for(schema)
    
        cls.check_schema(schema)
        validator = cls(schema, *args, **kwargs)
        error = exceptions.best_match(validator.iter_errors(instance))
        if error is not None:
>           raise error
E           jsonschema.exceptions.ValidationError: {'provider': 'onnx', 'model': 'test-model', 'api_key': 'plaintext-secret'} is not valid under any of the given schemas
E           
E           Failed validating 'oneOf' in schema['properties']['services']['patternProperties']['^[a-zA-Z0-9_]+$']:
E               {'oneOf': [{'$ref': '#/definitions/llm_service'},
E                          {'$ref': '#/definitions/embedding_service'},
E                          {'$ref': '#/definitions/database_service'}]}
E           
E           On instance['services']['test_service']:
E               {'provider': 'onnx',
E                'model': 'test-model',
E                'api_key': 'plaintext-secret'}

venv/lib/python3.12/site-packages/jsonschema/validators.py:1332: ValidationError

During handling of the above exception, another exception occurred:

self = <rag_factory.registry.service_registry.ServiceRegistry object at 0x77cf5861ba70>

    def _load_config(self) -> None:
        """Load and validate services.yaml configuration."""
        logger.info(f"Loading service registry from: {self.config_path}")
    
        try:
            # Load YAML
            with open(self.config_path, 'r') as f:
                raw_config = yaml.safe_load(f)
    
            # Validate schema
>           warnings = self._validator.validate_services_yaml(
                raw_config,
                file_path=self.config_path
            )

rag_factory/registry/service_registry.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <rag_factory.config.validator.ConfigValidator object at 0x77cf58619d00>
config = {'services': {'test_service': {'api_key': 'plaintext-secret', 'model': 'test-model', 'provider': 'onnx'}}}
file_path = '/tmp/pytest-of-admindevmac/pytest-53/test_configuration_warnings0/services.yaml'

    def validate_services_yaml(
        self,
        config: Dict[str, Any],
        file_path: Optional[str] = None
    ) -> List[str]:
        """
        Validate services.yaml configuration.
    
        Args:
            config: Parsed YAML configuration
            file_path: Path to YAML file (for error messages)
    
        Returns:
            List of warning messages (empty if no warnings)
    
        Raises:
            ConfigValidationError: If validation fails
    
        Examples:
            >>> validator = ConfigValidator()
            >>> config = {
            ...     "services": {
            ...         "llm1": {
            ...             "name": "test-llm",
            ...             "type": "llm",
            ...             "url": "http://localhost:1234/v1",
            ...             "api_key": "${API_KEY}",
            ...             "model": "test-model"
            ...         }
            ...     }
            ... }
            >>> warnings = validator.validate_services_yaml(config)
            >>> len(warnings)
            0
        """
        try:
            # JSON Schema validation
            jsonschema.validate(
                instance=config,
                schema=self._schemas["service_registry"]
            )
        except jsonschema.ValidationError as e:
>           raise ConfigValidationError(
                message=f"Schema validation failed: {e.message}",
                file_path=file_path,
                field=".".join(str(p) for p in e.path)
            )
E           rag_factory.config.validator.ConfigValidationError: Schema validation failed: {'provider': 'onnx', 'model': 'test-model', 'api_key': 'plaintext-secret'} is not valid under any of the given schemas
E           File: /tmp/pytest-of-admindevmac/pytest-53/test_configuration_warnings0/services.yaml
E           Field: services.test_service

rag_factory/config/validator.py:118: ConfigValidationError

During handling of the above exception, another exception occurred:

self = <tests.integration.registry.test_registry_integration.TestConfigurationValidation object at 0x77cf5be66990>
tmp_path = PosixPath('/tmp/pytest-of-admindevmac/pytest-53/test_configuration_warnings0')
caplog = <_pytest.logging.LogCaptureFixture object at 0x77cf5861a9c0>

        def test_configuration_warnings(self, tmp_path, caplog):
            """Test that configuration warnings are logged."""
            import logging
            caplog.set_level(logging.WARNING)
    
            content = """
    services:
      test_service:
        provider: "onnx"
        model: "test-model"
        api_key: "plaintext-secret"  # Should trigger warning
    """
            services_file = tmp_path / "services.yaml"
            services_file.write_text(content)
    
>           registry = ServiceRegistry(str(services_file))
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/integration/registry/test_registry_integration.py:332: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
rag_factory/registry/service_registry.py:51: in __init__
    self._load_config()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <rag_factory.registry.service_registry.ServiceRegistry object at 0x77cf5861ba70>

    def _load_config(self) -> None:
        """Load and validate services.yaml configuration."""
        logger.info(f"Loading service registry from: {self.config_path}")
    
        try:
            # Load YAML
            with open(self.config_path, 'r') as f:
                raw_config = yaml.safe_load(f)
    
            # Validate schema
            warnings = self._validator.validate_services_yaml(
                raw_config,
                file_path=self.config_path
            )
    
            # Print warnings
            for warning in warnings:
                logger.warning(warning)
    
            # Resolve environment variables
            self.config = EnvResolver.resolve(raw_config)
    
            logger.info(
                f"Service registry loaded: "
                f"{len(self.config.get('services', {}))} services available"
            )
    
        except FileNotFoundError:
            raise ServiceInstantiationError(
                f"Service registry configuration not found: {self.config_path}"
            )
        except Exception as e:
>           raise ServiceInstantiationError(
                f"Failed to load service registry: {e}"
            )
E           rag_factory.registry.exceptions.ServiceInstantiationError: Failed to load service registry: Schema validation failed: {'provider': 'onnx', 'model': 'test-model', 'api_key': 'plaintext-secret'} is not valid under any of the given schemas
E           File: /tmp/pytest-of-admindevmac/pytest-53/test_configuration_warnings0/services.yaml
E           Field: services.test_service

rag_factory/registry/service_registry.py:85: ServiceInstantiationError
____________ TestSelfReflectiveIntegration.test_end_to_end_workflow ____________

self = <tests.integration.strategies.test_self_reflective_integration.TestSelfReflectiveIntegration object at 0x77cf5bebc290>
mock_base_strategy = <Mock id='131732130481504'>
mock_llm_service = <Mock id='131732130481552'>

    def test_end_to_end_workflow(self, mock_base_strategy, mock_llm_service):
        """Test complete self-reflective retrieval workflow."""
        # Create strategy
>       strategy = SelfReflectiveRAGStrategy(
            base_retrieval_strategy=mock_base_strategy,
            llm_service=mock_llm_service,
            config={"grade_threshold": 4.0, "max_retries": 2}
        )
E       TypeError: SelfReflectiveRAGStrategy.__init__() got an unexpected keyword argument 'base_retrieval_strategy'

tests/integration/strategies/test_self_reflective_integration.py:80: TypeError
__________ TestSelfReflectiveIntegration.test_retry_with_poor_results __________

self = <tests.integration.strategies.test_self_reflective_integration.TestSelfReflectiveIntegration object at 0x77cf5bebc530>
mock_base_strategy = <Mock id='131732130483328'>
mock_llm_service = <Mock id='131732130483520'>

    def test_retry_with_poor_results(self, mock_base_strategy, mock_llm_service):
        """Test that retry is triggered for poor results."""
>       strategy = SelfReflectiveRAGStrategy(
            base_retrieval_strategy=mock_base_strategy,
            llm_service=mock_llm_service,
            config={"grade_threshold": 4.0, "max_retries": 2}
        )
E       TypeError: SelfReflectiveRAGStrategy.__init__() got an unexpected keyword argument 'base_retrieval_strategy'

tests/integration/strategies/test_self_reflective_integration.py:100: TypeError
_________ TestSelfReflectiveIntegration.test_performance_within_limits _________

self = <tests.integration.strategies.test_self_reflective_integration.TestSelfReflectiveIntegration object at 0x77cf5bebc8f0>
mock_base_strategy = <Mock id='131732130496144'>
mock_llm_service = <Mock id='131732130495952'>

    def test_performance_within_limits(self, mock_base_strategy, mock_llm_service):
        """Test that self-reflective retrieval completes within timeout."""
        import time
    
>       strategy = SelfReflectiveRAGStrategy(
            base_retrieval_strategy=mock_base_strategy,
            llm_service=mock_llm_service,
            config={"grade_threshold": 4.0, "max_retries": 2, "timeout_seconds": 10}
        )
E       TypeError: SelfReflectiveRAGStrategy.__init__() got an unexpected keyword argument 'base_retrieval_strategy'

tests/integration/strategies/test_self_reflective_integration.py:119: TypeError
______________ TestSelfReflectiveWithLMStudio.test_with_real_llm _______________

self = <tests.integration.strategies.test_self_reflective_integration.TestSelfReflectiveWithLMStudio object at 0x77cf5bebcc80>
llm_service_from_env = <rag_factory.services.llm.service.LLMService object at 0x77cf46d7f350>

    def test_with_real_llm(self, llm_service_from_env):
        """Test with real LLM service from environment (LM Studio)."""
        from unittest.mock import Mock
    
        # Mock base strategy
        base_strategy = Mock()
        base_strategy.retrieve.return_value = [
            {"chunk_id": "c1", "text": "Sample result", "score": 0.9}
        ]
    
        # Create self-reflective strategy
>       strategy = SelfReflectiveRAGStrategy(
            base_retrieval_strategy=base_strategy,
            llm_service=llm_service_from_env,
            config={"grade_threshold": 4.0, "max_retries": 1}
        )
E       TypeError: SelfReflectiveRAGStrategy.__init__() got an unexpected keyword argument 'base_retrieval_strategy'

tests/integration/strategies/test_self_reflective_integration.py:149: TypeError
__________________ TestSmokeTest.test_basic_usage_smoke_test ___________________

self = <tests.integration.test_package_integration.TestSmokeTest object at 0x77cf5bebdf10>

    def test_basic_usage_smoke_test(self) -> None:
        """Test basic usage works after import."""
>       from rag_factory import RAGFactory, StrategyPipeline, ConfigManager
E       ImportError: cannot import name 'RAGFactory' from 'rag_factory' (/mnt/MCPProyects/ragTools/rag_factory/__init__.py)

tests/integration/test_package_integration.py:60: ImportError
__________ TestFullWorkflow.test_full_workflow_with_installed_package __________

self = <tests.integration.test_package_integration.TestFullWorkflow object at 0x77cf5bebe270>

    def test_full_workflow_with_installed_package(self) -> None:
        """Test complete workflow using installed package."""
>       from rag_factory import RAGFactory, StrategyPipeline
E       ImportError: cannot import name 'RAGFactory' from 'rag_factory' (/mnt/MCPProyects/ragTools/rag_factory/__init__.py)

tests/integration/test_package_integration.py:90: ImportError
____________________________ test_load_pair_success ____________________________

manager = <rag_factory.config.strategy_pair_manager.StrategyPairManager object at 0x77cf46f003b0>
mock_loader = <MagicMock name='StrategyPairLoader()' id='131732130158816'>
mock_registry = <MagicMock spec='ServiceRegistry' id='131732130168416'>

    def test_load_pair_success(manager, mock_loader, mock_registry):
        # Setup Loader return
        mock_config = {
            "strategy_name": "test-pair",
            "indexer": {
                "strategy": "indexer.module.Class",
                "services": {"llm": "$gpt4", "db": "$db1"},
                "config": {"some": "param"}
            },
            "retriever": {
                "strategy": "retriever.module.Class",
                "services": {"embedding": "$embed1"},
                "config": {"top_k": 5}
            },
            "migrations": {
                "required_revisions": ["1234"]
            }
        }
        mock_loader.load_config.return_value = mock_config
    
        # Mock _import_strategy_class
        with patch.object(manager, "_import_strategy_class") as mock_import:
            mock_import.side_effect = lambda x: MockIndexingStrategy if "indexer" in x else MockRetrievalStrategy
    
            # Run
            idx, ret = manager.load_pair("test-pair")
    
            # Assertions
            assert isinstance(idx, MockIndexingStrategy)
            assert isinstance(ret, MockRetrievalStrategy)
    
            # Verify loader usage
            mock_loader.load_config.assert_called_with(Path("/tmp/strategies/test-pair.yaml"))
    
            # Verify Migration Validation
            manager.migration_validator.validate.assert_called_with(["1234"])
    
            # Verify Service Resolution
>           mock_registry.get.assert_any_call("$gpt4")

tests/unit/config/test_strategy_pair_manager.py:100: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MagicMock name='mock.get' id='131732466876336'>, args = ('$gpt4',)
kwargs = {}, expected = call('$gpt4'), cause = None
actual = [call('db_main'), call('gpt4'), call('db1'), call('embed1')]
expected_string = "get('$gpt4')"

    def assert_any_call(self, /, *args, **kwargs):
        """assert the mock has been called with the specified arguments.
    
        The assert passes if the mock has *ever* been called, unlike
        `assert_called_with` and `assert_called_once_with` that only pass if
        the call is the most recent one."""
        expected = self._call_matcher(_Call((args, kwargs), two=True))
        cause = expected if isinstance(expected, Exception) else None
        actual = [self._call_matcher(c) for c in self.call_args_list]
        if cause or expected not in _AnyComparer(actual):
            expected_string = self._format_mock_call_signature(args, kwargs)
>           raise AssertionError(
                '%s call not found' % expected_string
            ) from cause
E           AssertionError: get('$gpt4') call not found

/usr/lib/python3.12/unittest/mock.py:1015: AssertionError
----------------------------- Captured stderr call -----------------------------
INFO:rag_factory.config.strategy_pair_manager:Loading strategy pair from /tmp/strategies/test-pair.yaml
------------------------------ Captured log call -------------------------------
INFO     rag_factory.config.strategy_pair_manager:strategy_pair_manager.py:96 Loading strategy pair from /tmp/strategies/test-pair.yaml
___________________________ test_db_context_creation ___________________________

manager = <rag_factory.config.strategy_pair_manager.StrategyPairManager object at 0x77cf46fb4050>
mock_loader = <MagicMock name='StrategyPairLoader()' id='131732132814224'>
mock_registry = <MagicMock spec='ServiceRegistry' id='131732132840080'>

    def test_db_context_creation(manager, mock_loader, mock_registry):
        mock_config = {
            "strategy_name": "db-context-pair",
            "indexer": {
                "strategy": "indexer.module.Class",
                "services": {"db": "$db1"},
                "db_config": {
                    "tables": {"logical": "physical"},
                    "fields": {"f1": "col1"}
                }
            },
            "retriever": { "strategy": "retriever.module.Class" }
        }
        mock_loader.load_config.return_value = mock_config
    
        # Mock DB service with get_context
        mock_db = MagicMock()
        mock_context = MagicMock()
        mock_db.get_context.return_value = mock_context
    
        # Configure registry to return mock_db
        def get_service(ref):
            if ref == "$db1": return mock_db
            return MagicMock()
        mock_registry.get.side_effect = get_service
    
        with patch.object(manager, "_import_strategy_class") as mock_import:
            mock_import.return_value = MagicMock() # Generic mock strategy
    
            manager.load_pair("db-context-pair")
    
            # Verify get_context called
>           mock_db.get_context.assert_called_with(
                table_mapping={"logical": "physical"},
                field_mapping={"f1": "col1"}
            )

tests/unit/config/test_strategy_pair_manager.py:172: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MagicMock name='mock.get_context' id='131732132600704'>, args = ()
kwargs = {'field_mapping': {'f1': 'col1'}, 'table_mapping': {'logical': 'physical'}}
expected = "get_context(table_mapping={'logical': 'physical'}, field_mapping={'f1': 'col1'})"
actual = 'not called.'
error_message = "expected call not found.\nExpected: get_context(table_mapping={'logical': 'physical'}, field_mapping={'f1': 'col1'})\n  Actual: not called."

    def assert_called_with(self, /, *args, **kwargs):
        """assert that the last call was made with the specified arguments.
    
        Raises an AssertionError if the args and keyword args passed in are
        different to the last call to the mock."""
        if self.call_args is None:
            expected = self._format_mock_call_signature(args, kwargs)
            actual = 'not called.'
            error_message = ('expected call not found.\nExpected: %s\n  Actual: %s'
                    % (expected, actual))
>           raise AssertionError(error_message)
E           AssertionError: expected call not found.
E           Expected: get_context(table_mapping={'logical': 'physical'}, field_mapping={'f1': 'col1'})
E             Actual: not called.

/usr/lib/python3.12/unittest/mock.py:935: AssertionError
----------------------------- Captured stderr call -----------------------------
INFO:rag_factory.config.strategy_pair_manager:Loading strategy pair from /tmp/strategies/db-context-pair.yaml
------------------------------ Captured log call -------------------------------
INFO     rag_factory.config.strategy_pair_manager:strategy_pair_manager.py:96 Loading strategy pair from /tmp/strategies/db-context-pair.yaml
_____________ TestAlembicMigrations.test_migration_upgrade_to_head _____________

self = <sqlalchemy.engine.base.Connection object at 0x77cf5ae12990>
dialect = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x77cf44f844d0>
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x77cf46d9d6d0>
statement = <sqlalchemy.dialects.postgresql.base.PGCompiler object at 0x77cf46d9d7f0>
parameters = [{}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x77cf44f844d0>
cursor = <cursor object at 0x77cf44f1c310; closed: -1>
statement = 'DROP EXTENSION IF EXISTS vector', parameters = {}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x77cf46d9d6d0>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       psycopg2.errors.DependentObjectsStillExist: cannot drop extension vector because other objects depend on it
E       DETAIL:  column embedding of table test_chunks_real depends on type vector
E       HINT:  Use DROP ... CASCADE to drop the dependent objects too.

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: DependentObjectsStillExist

The above exception was the direct cause of the following exception:

self = <tests.unit.database.test_migrations.TestAlembicMigrations object at 0x77cf5bedb110>
alembic_config = <alembic.config.Config object at 0x77cf46db6510>
test_db_url = 'postgresql://rag_user:rag_password@192.168.56.1:5432/rag_test'

    def test_migration_upgrade_to_head(self, alembic_config: Config, test_db_url: str) -> None:
        """Test upgrading migrations to head."""
        # Start from clean state
>       command.downgrade(alembic_config, "base")

tests/unit/database/test_migrations.py:39: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
venv/lib/python3.12/site-packages/alembic/command.py:449: in downgrade
    script.run_env()
venv/lib/python3.12/site-packages/alembic/script/base.py:583: in run_env
    util.load_python_file(self.dir, "env.py")
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:95: in load_python_file
    module = load_module_py(module_id, path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:113: in load_module_py
    spec.loader.exec_module(module)  # type: ignore
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
<frozen importlib._bootstrap_external>:995: in exec_module
    ???
<frozen importlib._bootstrap>:488: in _call_with_frames_removed
    ???
migrations/env.py:93: in <module>
    run_migrations_online()
migrations/env.py:87: in run_migrations_online
    context.run_migrations()
<string>:8: in run_migrations
    ???
venv/lib/python3.12/site-packages/alembic/runtime/environment.py:948: in run_migrations
    self.get_context().run_migrations(**kw)
venv/lib/python3.12/site-packages/alembic/runtime/migration.py:627: in run_migrations
    step.migration_fn(**kw)
migrations/versions/001_initial_schema.py:129: in downgrade
    op.execute("DROP EXTENSION IF EXISTS vector")
<string>:8: in execute
    ???
<string>:3: in execute
    ???
venv/lib/python3.12/site-packages/alembic/operations/ops.py:2537: in execute
    return operations.invoke(op)
           ^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/base.py:445: in invoke
    return fn(self, operation)
           ^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/toimpl.py:224: in execute_sql
    operations.migration_context.impl.execute(
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:214: in execute
    self._exec(sql, execution_options)
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:207: in _exec
    return conn.execute(construct, multiparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1416: in execute
    return meth(
venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py:516: in _execute_on_connection
    return connection._execute_clauseelement(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1639: in _execute_clauseelement
    ret = self._execute_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1848: in _execute_context
    return self._exec_single_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1988: in _exec_single_context
    self._handle_dbapi_exception(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2343: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: in _exec_single_context
    self.dialect.do_execute(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x77cf44f844d0>
cursor = <cursor object at 0x77cf44f1c310; closed: -1>
statement = 'DROP EXTENSION IF EXISTS vector', parameters = {}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x77cf46d9d6d0>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.InternalError: (psycopg2.errors.DependentObjectsStillExist) cannot drop extension vector because other objects depend on it
E       DETAIL:  column embedding of table test_chunks_real depends on type vector
E       HINT:  Use DROP ... CASCADE to drop the dependent objects too.
E       
E       [SQL: DROP EXTENSION IF EXISTS vector]
E       (Background on this error at: https://sqlalche.me/e/20/2j85)

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: InternalError
----------------------------- Captured stderr call -----------------------------
INFO  [alembic.runtime.migration] Context impl PostgresqlImpl.
INFO  [alembic.runtime.migration] Will assume transactional DDL.
INFO  [alembic.runtime.migration] Running downgrade 001 -> , Initial schema with documents and chunks tables
________________ TestAlembicMigrations.test_migration_downgrade ________________

self = <sqlalchemy.engine.base.Connection object at 0x77cf46df2d80>
dialect = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x77cf46f81c10>
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x77cf46f67b60>
statement = <sqlalchemy.dialects.postgresql.base.PGCompiler object at 0x77cf46f648f0>
parameters = [{}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x77cf46f81c10>
cursor = <cursor object at 0x77cf44f1c7c0; closed: -1>
statement = 'DROP EXTENSION IF EXISTS vector', parameters = {}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x77cf46f67b60>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       psycopg2.errors.DependentObjectsStillExist: cannot drop extension vector because other objects depend on it
E       DETAIL:  column embedding of table test_chunks_real depends on type vector
E       HINT:  Use DROP ... CASCADE to drop the dependent objects too.

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: DependentObjectsStillExist

The above exception was the direct cause of the following exception:

self = <tests.unit.database.test_migrations.TestAlembicMigrations object at 0x77cf5bedb3b0>
alembic_config = <alembic.config.Config object at 0x77cf46f827e0>
test_db_url = 'postgresql://rag_user:rag_password@192.168.56.1:5432/rag_test'

    def test_migration_downgrade(self, alembic_config: Config, test_db_url: str) -> None:
        """Test downgrading migrations."""
        # Start from clean state
>       command.downgrade(alembic_config, "base")

tests/unit/database/test_migrations.py:60: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
venv/lib/python3.12/site-packages/alembic/command.py:449: in downgrade
    script.run_env()
venv/lib/python3.12/site-packages/alembic/script/base.py:583: in run_env
    util.load_python_file(self.dir, "env.py")
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:95: in load_python_file
    module = load_module_py(module_id, path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:113: in load_module_py
    spec.loader.exec_module(module)  # type: ignore
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
<frozen importlib._bootstrap_external>:995: in exec_module
    ???
<frozen importlib._bootstrap>:488: in _call_with_frames_removed
    ???
migrations/env.py:93: in <module>
    run_migrations_online()
migrations/env.py:87: in run_migrations_online
    context.run_migrations()
<string>:8: in run_migrations
    ???
venv/lib/python3.12/site-packages/alembic/runtime/environment.py:948: in run_migrations
    self.get_context().run_migrations(**kw)
venv/lib/python3.12/site-packages/alembic/runtime/migration.py:627: in run_migrations
    step.migration_fn(**kw)
migrations/versions/001_initial_schema.py:129: in downgrade
    op.execute("DROP EXTENSION IF EXISTS vector")
<string>:8: in execute
    ???
<string>:3: in execute
    ???
venv/lib/python3.12/site-packages/alembic/operations/ops.py:2537: in execute
    return operations.invoke(op)
           ^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/base.py:445: in invoke
    return fn(self, operation)
           ^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/toimpl.py:224: in execute_sql
    operations.migration_context.impl.execute(
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:214: in execute
    self._exec(sql, execution_options)
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:207: in _exec
    return conn.execute(construct, multiparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1416: in execute
    return meth(
venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py:516: in _execute_on_connection
    return connection._execute_clauseelement(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1639: in _execute_clauseelement
    ret = self._execute_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1848: in _execute_context
    return self._exec_single_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1988: in _exec_single_context
    self._handle_dbapi_exception(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2343: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: in _exec_single_context
    self.dialect.do_execute(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x77cf46f81c10>
cursor = <cursor object at 0x77cf44f1c7c0; closed: -1>
statement = 'DROP EXTENSION IF EXISTS vector', parameters = {}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x77cf46f67b60>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.InternalError: (psycopg2.errors.DependentObjectsStillExist) cannot drop extension vector because other objects depend on it
E       DETAIL:  column embedding of table test_chunks_real depends on type vector
E       HINT:  Use DROP ... CASCADE to drop the dependent objects too.
E       
E       [SQL: DROP EXTENSION IF EXISTS vector]
E       (Background on this error at: https://sqlalche.me/e/20/2j85)

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: InternalError
----------------------------- Captured stderr call -----------------------------
INFO  [alembic.runtime.migration] Context impl PostgresqlImpl.
INFO  [alembic.runtime.migration] Will assume transactional DDL.
INFO  [alembic.runtime.migration] Running downgrade 001 -> , Initial schema with documents and chunks tables
_______________ TestAlembicMigrations.test_migration_idempotency _______________

self = <sqlalchemy.engine.base.Connection object at 0x77cf46f81e20>
dialect = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x77cf46fae780>
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x77cf46faf890>
statement = <sqlalchemy.dialects.postgresql.base.PGCompiler object at 0x77cf46fae750>
parameters = [{}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x77cf46fae780>
cursor = <cursor object at 0x77cf44f1e6b0; closed: -1>
statement = 'DROP EXTENSION IF EXISTS vector', parameters = {}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x77cf46faf890>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       psycopg2.errors.DependentObjectsStillExist: cannot drop extension vector because other objects depend on it
E       DETAIL:  column embedding of table test_chunks_real depends on type vector
E       HINT:  Use DROP ... CASCADE to drop the dependent objects too.

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: DependentObjectsStillExist

The above exception was the direct cause of the following exception:

self = <tests.unit.database.test_migrations.TestAlembicMigrations object at 0x77cf5bedba10>
alembic_config = <alembic.config.Config object at 0x77cf46f65940>
test_db_url = 'postgresql://rag_user:rag_password@192.168.56.1:5432/rag_test'

    def test_migration_idempotency(self, alembic_config: Config, test_db_url: str) -> None:
        """Test that running migrations twice doesn't cause errors."""
        # Start from clean state
>       command.downgrade(alembic_config, "base")

tests/unit/database/test_migrations.py:102: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
venv/lib/python3.12/site-packages/alembic/command.py:449: in downgrade
    script.run_env()
venv/lib/python3.12/site-packages/alembic/script/base.py:583: in run_env
    util.load_python_file(self.dir, "env.py")
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:95: in load_python_file
    module = load_module_py(module_id, path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:113: in load_module_py
    spec.loader.exec_module(module)  # type: ignore
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
<frozen importlib._bootstrap_external>:995: in exec_module
    ???
<frozen importlib._bootstrap>:488: in _call_with_frames_removed
    ???
migrations/env.py:93: in <module>
    run_migrations_online()
migrations/env.py:87: in run_migrations_online
    context.run_migrations()
<string>:8: in run_migrations
    ???
venv/lib/python3.12/site-packages/alembic/runtime/environment.py:948: in run_migrations
    self.get_context().run_migrations(**kw)
venv/lib/python3.12/site-packages/alembic/runtime/migration.py:627: in run_migrations
    step.migration_fn(**kw)
migrations/versions/001_initial_schema.py:129: in downgrade
    op.execute("DROP EXTENSION IF EXISTS vector")
<string>:8: in execute
    ???
<string>:3: in execute
    ???
venv/lib/python3.12/site-packages/alembic/operations/ops.py:2537: in execute
    return operations.invoke(op)
           ^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/base.py:445: in invoke
    return fn(self, operation)
           ^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/toimpl.py:224: in execute_sql
    operations.migration_context.impl.execute(
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:214: in execute
    self._exec(sql, execution_options)
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:207: in _exec
    return conn.execute(construct, multiparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1416: in execute
    return meth(
venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py:516: in _execute_on_connection
    return connection._execute_clauseelement(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1639: in _execute_clauseelement
    ret = self._execute_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1848: in _execute_context
    return self._exec_single_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1988: in _exec_single_context
    self._handle_dbapi_exception(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2343: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: in _exec_single_context
    self.dialect.do_execute(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x77cf46fae780>
cursor = <cursor object at 0x77cf44f1e6b0; closed: -1>
statement = 'DROP EXTENSION IF EXISTS vector', parameters = {}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x77cf46faf890>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.InternalError: (psycopg2.errors.DependentObjectsStillExist) cannot drop extension vector because other objects depend on it
E       DETAIL:  column embedding of table test_chunks_real depends on type vector
E       HINT:  Use DROP ... CASCADE to drop the dependent objects too.
E       
E       [SQL: DROP EXTENSION IF EXISTS vector]
E       (Background on this error at: https://sqlalche.me/e/20/2j85)

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: InternalError
----------------------------- Captured stderr call -----------------------------
INFO  [alembic.runtime.migration] Context impl PostgresqlImpl.
INFO  [alembic.runtime.migration] Will assume transactional DDL.
INFO  [alembic.runtime.migration] Running downgrade 001 -> , Initial schema with documents and chunks tables
________________ TestAlembicMigrations.test_get_current_version ________________

self = <sqlalchemy.engine.base.Connection object at 0x77cf46faf380>
dialect = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x77cf46fbe6f0>
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x77cf46fbc350>
statement = <sqlalchemy.dialects.postgresql.base.PGCompiler object at 0x77cf46fbff80>
parameters = [{}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x77cf46fbe6f0>
cursor = <cursor object at 0x77cf44f1f4c0; closed: -1>
statement = 'DROP EXTENSION IF EXISTS vector', parameters = {}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x77cf46fbc350>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       psycopg2.errors.DependentObjectsStillExist: cannot drop extension vector because other objects depend on it
E       DETAIL:  column embedding of table test_chunks_real depends on type vector
E       HINT:  Use DROP ... CASCADE to drop the dependent objects too.

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: DependentObjectsStillExist

The above exception was the direct cause of the following exception:

self = <tests.unit.database.test_migrations.TestAlembicMigrations object at 0x77cf5bedbd40>
alembic_config = <alembic.config.Config object at 0x77cf46fad100>
test_db_url = 'postgresql://rag_user:rag_password@192.168.56.1:5432/rag_test'

    def test_get_current_version(self, alembic_config: Config, test_db_url: str) -> None:
        """Test retrieving current schema version."""
        # Start from clean state
>       command.downgrade(alembic_config, "base")

tests/unit/database/test_migrations.py:129: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
venv/lib/python3.12/site-packages/alembic/command.py:449: in downgrade
    script.run_env()
venv/lib/python3.12/site-packages/alembic/script/base.py:583: in run_env
    util.load_python_file(self.dir, "env.py")
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:95: in load_python_file
    module = load_module_py(module_id, path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:113: in load_module_py
    spec.loader.exec_module(module)  # type: ignore
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
<frozen importlib._bootstrap_external>:995: in exec_module
    ???
<frozen importlib._bootstrap>:488: in _call_with_frames_removed
    ???
migrations/env.py:93: in <module>
    run_migrations_online()
migrations/env.py:87: in run_migrations_online
    context.run_migrations()
<string>:8: in run_migrations
    ???
venv/lib/python3.12/site-packages/alembic/runtime/environment.py:948: in run_migrations
    self.get_context().run_migrations(**kw)
venv/lib/python3.12/site-packages/alembic/runtime/migration.py:627: in run_migrations
    step.migration_fn(**kw)
migrations/versions/001_initial_schema.py:129: in downgrade
    op.execute("DROP EXTENSION IF EXISTS vector")
<string>:8: in execute
    ???
<string>:3: in execute
    ???
venv/lib/python3.12/site-packages/alembic/operations/ops.py:2537: in execute
    return operations.invoke(op)
           ^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/base.py:445: in invoke
    return fn(self, operation)
           ^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/toimpl.py:224: in execute_sql
    operations.migration_context.impl.execute(
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:214: in execute
    self._exec(sql, execution_options)
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:207: in _exec
    return conn.execute(construct, multiparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1416: in execute
    return meth(
venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py:516: in _execute_on_connection
    return connection._execute_clauseelement(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1639: in _execute_clauseelement
    ret = self._execute_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1848: in _execute_context
    return self._exec_single_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1988: in _exec_single_context
    self._handle_dbapi_exception(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2343: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: in _exec_single_context
    self.dialect.do_execute(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x77cf46fbe6f0>
cursor = <cursor object at 0x77cf44f1f4c0; closed: -1>
statement = 'DROP EXTENSION IF EXISTS vector', parameters = {}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x77cf46fbc350>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.InternalError: (psycopg2.errors.DependentObjectsStillExist) cannot drop extension vector because other objects depend on it
E       DETAIL:  column embedding of table test_chunks_real depends on type vector
E       HINT:  Use DROP ... CASCADE to drop the dependent objects too.
E       
E       [SQL: DROP EXTENSION IF EXISTS vector]
E       (Background on this error at: https://sqlalche.me/e/20/2j85)

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: InternalError
----------------------------- Captured stderr call -----------------------------
INFO  [alembic.runtime.migration] Context impl PostgresqlImpl.
INFO  [alembic.runtime.migration] Will assume transactional DDL.
INFO  [alembic.runtime.migration] Running downgrade 001 -> , Initial schema with documents and chunks tables
_____________ TestAlembicMigrations.test_migration_creates_tables ______________

self = <sqlalchemy.engine.base.Connection object at 0x77cf46fbfa40>
dialect = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x77cf46fb4530>
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x77cf46fb4e30>
statement = <sqlalchemy.dialects.postgresql.base.PGCompiler object at 0x77cf46fb4d40>
parameters = [{}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x77cf46fb4530>
cursor = <cursor object at 0x77cf44f4fb50; closed: -1>
statement = 'DROP EXTENSION IF EXISTS vector', parameters = {}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x77cf46fb4e30>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       psycopg2.errors.DependentObjectsStillExist: cannot drop extension vector because other objects depend on it
E       DETAIL:  column embedding of table test_chunks_real depends on type vector
E       HINT:  Use DROP ... CASCADE to drop the dependent objects too.

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: DependentObjectsStillExist

The above exception was the direct cause of the following exception:

self = <tests.unit.database.test_migrations.TestAlembicMigrations object at 0x77cf5bedb8f0>
alembic_config = <alembic.config.Config object at 0x77cf46fbdac0>
test_db_url = 'postgresql://rag_user:rag_password@192.168.56.1:5432/rag_test'

    def test_migration_creates_tables(self, alembic_config: Config, test_db_url: str) -> None:
        """Test that migrations create expected tables."""
        # Start from clean state
>       command.downgrade(alembic_config, "base")

tests/unit/database/test_migrations.py:147: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
venv/lib/python3.12/site-packages/alembic/command.py:449: in downgrade
    script.run_env()
venv/lib/python3.12/site-packages/alembic/script/base.py:583: in run_env
    util.load_python_file(self.dir, "env.py")
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:95: in load_python_file
    module = load_module_py(module_id, path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:113: in load_module_py
    spec.loader.exec_module(module)  # type: ignore
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
<frozen importlib._bootstrap_external>:995: in exec_module
    ???
<frozen importlib._bootstrap>:488: in _call_with_frames_removed
    ???
migrations/env.py:93: in <module>
    run_migrations_online()
migrations/env.py:87: in run_migrations_online
    context.run_migrations()
<string>:8: in run_migrations
    ???
venv/lib/python3.12/site-packages/alembic/runtime/environment.py:948: in run_migrations
    self.get_context().run_migrations(**kw)
venv/lib/python3.12/site-packages/alembic/runtime/migration.py:627: in run_migrations
    step.migration_fn(**kw)
migrations/versions/001_initial_schema.py:129: in downgrade
    op.execute("DROP EXTENSION IF EXISTS vector")
<string>:8: in execute
    ???
<string>:3: in execute
    ???
venv/lib/python3.12/site-packages/alembic/operations/ops.py:2537: in execute
    return operations.invoke(op)
           ^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/base.py:445: in invoke
    return fn(self, operation)
           ^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/toimpl.py:224: in execute_sql
    operations.migration_context.impl.execute(
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:214: in execute
    self._exec(sql, execution_options)
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:207: in _exec
    return conn.execute(construct, multiparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1416: in execute
    return meth(
venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py:516: in _execute_on_connection
    return connection._execute_clauseelement(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1639: in _execute_clauseelement
    ret = self._execute_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1848: in _execute_context
    return self._exec_single_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1988: in _exec_single_context
    self._handle_dbapi_exception(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2343: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: in _exec_single_context
    self.dialect.do_execute(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x77cf46fb4530>
cursor = <cursor object at 0x77cf44f4fb50; closed: -1>
statement = 'DROP EXTENSION IF EXISTS vector', parameters = {}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x77cf46fb4e30>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.InternalError: (psycopg2.errors.DependentObjectsStillExist) cannot drop extension vector because other objects depend on it
E       DETAIL:  column embedding of table test_chunks_real depends on type vector
E       HINT:  Use DROP ... CASCADE to drop the dependent objects too.
E       
E       [SQL: DROP EXTENSION IF EXISTS vector]
E       (Background on this error at: https://sqlalche.me/e/20/2j85)

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: InternalError
----------------------------- Captured stderr call -----------------------------
INFO  [alembic.runtime.migration] Context impl PostgresqlImpl.
INFO  [alembic.runtime.migration] Will assume transactional DDL.
INFO  [alembic.runtime.migration] Running downgrade 001 -> , Initial schema with documents and chunks tables
_____________ TestAlembicMigrations.test_migration_creates_indexes _____________

self = <sqlalchemy.engine.base.Connection object at 0x77cf44f86660>
dialect = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x77cf44f87cb0>
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x77cf46fb6f30>
statement = <sqlalchemy.dialects.postgresql.base.PGCompiler object at 0x77cf46fb71a0>
parameters = [{}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x77cf44f87cb0>
cursor = <cursor object at 0x77cf44f4d030; closed: -1>
statement = 'DROP EXTENSION IF EXISTS vector', parameters = {}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x77cf46fb6f30>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       psycopg2.errors.DependentObjectsStillExist: cannot drop extension vector because other objects depend on it
E       DETAIL:  column embedding of table test_chunks_real depends on type vector
E       HINT:  Use DROP ... CASCADE to drop the dependent objects too.

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: DependentObjectsStillExist

The above exception was the direct cause of the following exception:

self = <tests.unit.database.test_migrations.TestAlembicMigrations object at 0x77cf5bedb5f0>
alembic_config = <alembic.config.Config object at 0x77cf44f43830>
test_db_url = 'postgresql://rag_user:rag_password@192.168.56.1:5432/rag_test'

    def test_migration_creates_indexes(self, alembic_config: Config, test_db_url: str) -> None:
        """Test that migrations create expected indexes."""
        # Start from clean state
>       command.downgrade(alembic_config, "base")

tests/unit/database/test_migrations.py:167: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
venv/lib/python3.12/site-packages/alembic/command.py:449: in downgrade
    script.run_env()
venv/lib/python3.12/site-packages/alembic/script/base.py:583: in run_env
    util.load_python_file(self.dir, "env.py")
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:95: in load_python_file
    module = load_module_py(module_id, path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:113: in load_module_py
    spec.loader.exec_module(module)  # type: ignore
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
<frozen importlib._bootstrap_external>:995: in exec_module
    ???
<frozen importlib._bootstrap>:488: in _call_with_frames_removed
    ???
migrations/env.py:93: in <module>
    run_migrations_online()
migrations/env.py:87: in run_migrations_online
    context.run_migrations()
<string>:8: in run_migrations
    ???
venv/lib/python3.12/site-packages/alembic/runtime/environment.py:948: in run_migrations
    self.get_context().run_migrations(**kw)
venv/lib/python3.12/site-packages/alembic/runtime/migration.py:627: in run_migrations
    step.migration_fn(**kw)
migrations/versions/001_initial_schema.py:129: in downgrade
    op.execute("DROP EXTENSION IF EXISTS vector")
<string>:8: in execute
    ???
<string>:3: in execute
    ???
venv/lib/python3.12/site-packages/alembic/operations/ops.py:2537: in execute
    return operations.invoke(op)
           ^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/base.py:445: in invoke
    return fn(self, operation)
           ^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/toimpl.py:224: in execute_sql
    operations.migration_context.impl.execute(
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:214: in execute
    self._exec(sql, execution_options)
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:207: in _exec
    return conn.execute(construct, multiparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1416: in execute
    return meth(
venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py:516: in _execute_on_connection
    return connection._execute_clauseelement(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1639: in _execute_clauseelement
    ret = self._execute_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1848: in _execute_context
    return self._exec_single_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1988: in _exec_single_context
    self._handle_dbapi_exception(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2343: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: in _exec_single_context
    self.dialect.do_execute(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x77cf44f87cb0>
cursor = <cursor object at 0x77cf44f4d030; closed: -1>
statement = 'DROP EXTENSION IF EXISTS vector', parameters = {}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x77cf46fb6f30>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.InternalError: (psycopg2.errors.DependentObjectsStillExist) cannot drop extension vector because other objects depend on it
E       DETAIL:  column embedding of table test_chunks_real depends on type vector
E       HINT:  Use DROP ... CASCADE to drop the dependent objects too.
E       
E       [SQL: DROP EXTENSION IF EXISTS vector]
E       (Background on this error at: https://sqlalche.me/e/20/2j85)

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: InternalError
----------------------------- Captured stderr call -----------------------------
INFO  [alembic.runtime.migration] Context impl PostgresqlImpl.
INFO  [alembic.runtime.migration] Will assume transactional DDL.
INFO  [alembic.runtime.migration] Running downgrade 001 -> , Initial schema with documents and chunks tables
__________ TestCodeExamples.test_all_code_examples_have_valid_syntax ___________

self = <test_code_examples.TestCodeExamples object at 0x77cf5bd141a0>
docs_root = PosixPath('/mnt/MCPProyects/ragTools/docs')

    def test_all_code_examples_have_valid_syntax(self, docs_root):
        """Test that all Python code examples have valid syntax."""
        errors = []
    
        for md_file in docs_root.rglob("*.md"):
            # Skip project planning documents (epics, stories, verification docs)
            # and internal/migration documentation
            file_str = str(md_file).lower()
            skip_patterns = ['epic', 'stor', 'verification', 'completion-summary',
                           'onnx', 'migration', 'project-plan', 'readme']
            if any(skip in file_str for skip in skip_patterns):
                continue
    
            examples = self.extract_python_examples(md_file)
    
            for i, code in enumerate(examples):
                try:
                    # Try to compile the code
                    compile(code, f"{md_file.name}:example_{i}", "exec")
                except SyntaxError as e:
                    errors.append(f"{md_file.name}:example_{i}: {e}")
    
>       assert len(errors) == 0, \
            f"Syntax errors in code examples:\n" + "\n".join(errors)
E       AssertionError: Syntax errors in code examples:
E         semantic-local-pair-guide.md:example_0: 'await' outside function (semantic-local-pair-guide.md:example_0, line 21)
E         environment-variables.md:example_3: invalid syntax (environment-variables.md:example_3, line 13)
E         QUICK-REFERENCE.md:example_2: unexpected indent (QUICK-REFERENCE.md:example_2, line 1)
E       assert 3 == 0
E        +  where 3 = len(["semantic-local-pair-guide.md:example_0: 'await' outside function (semantic-local-pair-guide.md:example_0, line 21)", 'environment-variables.md:example_3: invalid syntax (environment-variables.md:example_3, line 13)', 'QUICK-REFERENCE.md:example_2: unexpected indent (QUICK-REFERENCE.md:example_2, line 1)'])

tests/unit/documentation/test_code_examples.py:57: AssertionError
_____________ TestDocumentationLinks.test_no_broken_internal_links _____________

self = <test_links.TestDocumentationLinks object at 0x77cf5bd15550>
docs_root = PosixPath('/mnt/MCPProyects/ragTools/docs')

    def test_no_broken_internal_links(self, docs_root):
        """Test that all internal links are valid."""
        broken_links = []
    
        for md_file in docs_root.rglob("*.md"):
            links = self.extract_links(md_file)
    
            for text, link in links:
                # Skip external links
                if link.startswith("http"):
                    continue
    
                # Skip anchors
                if link.startswith("#"):
                    continue
    
                # Skip file:// links (used in implementation plan)
                if link.startswith("file://"):
                    continue
    
                # Resolve relative path
                target = (md_file.parent / link).resolve()
    
                if not target.exists():
                    broken_links.append(f"{md_file.name} -> {link}")
    
>       assert len(broken_links) == 0, \
            f"Broken internal links:\n" + "\n".join(broken_links)
E       AssertionError: Broken internal links:
E         MIGRATION_MANAGER_REMOVAL.md -> ../stories/epic-16/story-16.5-remove-migration-manager.md
E         README.md -> ./story-17.1-service-registry-configuration-schema.md
E         README.md -> ./story-17.2-service-registry-implementation.md
E         README.md -> ./story-17.4-migration-validator-alembic.md
E         README.md -> ./story-17.6-first-strategy-pair-testing.md
E         README.md -> ./story-17.7-remaining-strategy-pairs.md
E         README.md -> ./story-17.8-cli-validation-sample-docs.md
E         README.md -> ../../epics/epic-16-database-consolidation.md
E         README.md -> ../../epics/epic-16-database-consolidation.md
E         README.md -> ../../database/README.md
E         README.md -> ../../getting-started/installation.md
E       assert 11 == 0
E        +  where 11 = len(['MIGRATION_MANAGER_REMOVAL.md -> ../stories/epic-16/story-16.5-remove-migration-manager.md', 'README.md -> ./story-17.1-service-registry-configuration-schema.md', 'README.md -> ./story-17.2-service-registry-implementation.md', 'README.md -> ./story-17.4-migration-validator-alembic.md', 'README.md -> ./story-17.6-first-strategy-pair-testing.md', 'README.md -> ./story-17.7-remaining-strategy-pairs.md', ...])

tests/unit/documentation/test_links.py:60: AssertionError
____________ TestLLMServiceCreation.test_create_llm_service_openai _____________

self = <tests.unit.registry.test_service_factory.TestLLMServiceCreation object at 0x77cf5bd17530>
factory = <rag_factory.registry.service_factory.ServiceFactory object at 0x77cf46f2f680>

    def test_create_llm_service_openai(self, factory):
        """Test creating OpenAI LLM service."""
        config = {
            "name": "openai-llm",
            "url": "https://api.openai.com/v1",
            "api_key": "sk-test",
            "model": "gpt-4",
            "temperature": 0.8,
            "max_tokens": 2000
        }
    
>       with patch('rag_factory.registry.service_factory.OpenAILLMService') as mock_class:

tests/unit/registry/test_service_factory.py:73: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.12/unittest/mock.py:1458: in __enter__
    original, local = self.get_original()
                      ^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x77cf46f2fdd0>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'rag_factory.registry.service_factory' from '/mnt/MCPProyects/ragTools/rag_factory/registry/service_factory.py'> does not have the attribute 'OpenAILLMService'

/usr/lib/python3.12/unittest/mock.py:1431: AttributeError
_______ TestEmbeddingServiceCreation.test_create_embedding_service_onnx ________

self = <tests.unit.registry.test_service_factory.TestEmbeddingServiceCreation object at 0x77cf5bd44230>
factory = <rag_factory.registry.service_factory.ServiceFactory object at 0x77cf46f2d880>

    def test_create_embedding_service_onnx(self, factory):
        """Test creating ONNX embedding service."""
        config = {
            "name": "onnx-embed",
            "provider": "onnx",
            "model": "Xenova/all-MiniLM-L6-v2",
            "cache_dir": "./models",
            "batch_size": 32
        }
    
>       with patch('rag_factory.registry.service_factory.ONNXEmbeddingService') as mock_class:

tests/unit/registry/test_service_factory.py:128: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.12/unittest/mock.py:1458: in __enter__
    original, local = self.get_original()
                      ^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x77cf46f2e2a0>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'rag_factory.registry.service_factory' from '/mnt/MCPProyects/ragTools/rag_factory/registry/service_factory.py'> does not have the attribute 'ONNXEmbeddingService'

/usr/lib/python3.12/unittest/mock.py:1431: AttributeError
_ TestEmbeddingServiceCreation.test_create_embedding_service_onnx_with_defaults _

self = <tests.unit.registry.test_service_factory.TestEmbeddingServiceCreation object at 0x77cf5bd44560>
factory = <rag_factory.registry.service_factory.ServiceFactory object at 0x77cf46f2e1b0>

    def test_create_embedding_service_onnx_with_defaults(self, factory):
        """Test creating ONNX embedding service with defaults."""
        config = {
            "provider": "onnx",
            "model": "Xenova/all-MiniLM-L6-v2"
        }
    
>       with patch('rag_factory.registry.service_factory.ONNXEmbeddingService') as mock_class:

tests/unit/registry/test_service_factory.py:148: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.12/unittest/mock.py:1458: in __enter__
    original, local = self.get_original()
                      ^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x77cf46f2fd40>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'rag_factory.registry.service_factory' from '/mnt/MCPProyects/ragTools/rag_factory/registry/service_factory.py'> does not have the attribute 'ONNXEmbeddingService'

/usr/lib/python3.12/unittest/mock.py:1431: AttributeError
______ TestEmbeddingServiceCreation.test_create_embedding_service_openai _______

self = <tests.unit.registry.test_service_factory.TestEmbeddingServiceCreation object at 0x77cf5bd17f50>
factory = <rag_factory.registry.service_factory.ServiceFactory object at 0x77cf46f2da00>

    def test_create_embedding_service_openai(self, factory):
        """Test creating OpenAI embedding service."""
        config = {
            "provider": "openai",
            "api_key": "sk-test",
            "model": "text-embedding-ada-002"
        }
    
>       with patch('rag_factory.registry.service_factory.OpenAIEmbeddingService') as mock_class:

tests/unit/registry/test_service_factory.py:167: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.12/unittest/mock.py:1458: in __enter__
    original, local = self.get_original()
                      ^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x77cf46f2e180>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'rag_factory.registry.service_factory' from '/mnt/MCPProyects/ragTools/rag_factory/registry/service_factory.py'> does not have the attribute 'OpenAIEmbeddingService'

/usr/lib/python3.12/unittest/mock.py:1431: AttributeError
_ TestDatabaseServiceCreation.test_create_database_service_postgres_with_connection_string _

self = <tests.unit.registry.test_service_factory.TestDatabaseServiceCreation object at 0x77cf5bd14290>
factory = <rag_factory.registry.service_factory.ServiceFactory object at 0x77cf46f2ce60>

    def test_create_database_service_postgres_with_connection_string(self, factory):
        """Test creating PostgreSQL database service with connection string."""
        config = {
            "name": "postgres-db",
            "type": "postgres",
            "connection_string": "postgresql://user:pass@localhost:5432/db",
            "pool_size": 10,
            "max_overflow": 20
        }
    
>       with patch('rag_factory.registry.service_factory.PostgresqlDatabaseService') as mock_class:

tests/unit/registry/test_service_factory.py:218: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.12/unittest/mock.py:1458: in __enter__
    original, local = self.get_original()
                      ^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x77cf46f2de80>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'rag_factory.registry.service_factory' from '/mnt/MCPProyects/ragTools/rag_factory/registry/service_factory.py'> does not have the attribute 'PostgresqlDatabaseService'

/usr/lib/python3.12/unittest/mock.py:1431: AttributeError
_ TestDatabaseServiceCreation.test_create_database_service_postgres_with_components _

self = <tests.unit.registry.test_service_factory.TestDatabaseServiceCreation object at 0x77cf5bd14890>
factory = <rag_factory.registry.service_factory.ServiceFactory object at 0x77cf46f2d910>

    def test_create_database_service_postgres_with_components(self, factory):
        """Test creating PostgreSQL database service with connection components."""
        config = {
            "type": "postgres",
            "user": "testuser",
            "password": "testpass",
            "host": "localhost",
            "port": 5432,
            "database": "testdb",
            "pool_size": 5
        }
    
>       with patch('rag_factory.registry.service_factory.PostgresqlDatabaseService') as mock_class:

tests/unit/registry/test_service_factory.py:243: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.12/unittest/mock.py:1458: in __enter__
    original, local = self.get_original()
                      ^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x77cf46f2f740>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'rag_factory.registry.service_factory' from '/mnt/MCPProyects/ragTools/rag_factory/registry/service_factory.py'> does not have the attribute 'PostgresqlDatabaseService'

/usr/lib/python3.12/unittest/mock.py:1431: AttributeError
_ TestDatabaseServiceCreation.test_create_database_service_postgres_with_defaults _

self = <tests.unit.registry.test_service_factory.TestDatabaseServiceCreation object at 0x77cf5bd158b0>
factory = <rag_factory.registry.service_factory.ServiceFactory object at 0x77cf46f2d5b0>

    def test_create_database_service_postgres_with_defaults(self, factory):
        """Test creating PostgreSQL database service with default values."""
        config = {
            "type": "postgres",
            "user": "testuser",
            "password": "testpass",
            "host": "localhost",
            "database": "testdb"
        }
    
>       with patch('rag_factory.registry.service_factory.PostgresqlDatabaseService') as mock_class:

tests/unit/registry/test_service_factory.py:264: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.12/unittest/mock.py:1458: in __enter__
    original, local = self.get_original()
                      ^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x77cf46f2c260>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'rag_factory.registry.service_factory' from '/mnt/MCPProyects/ragTools/rag_factory/registry/service_factory.py'> does not have the attribute 'PostgresqlDatabaseService'

/usr/lib/python3.12/unittest/mock.py:1431: AttributeError
________ TestDatabaseServiceCreation.test_create_database_service_neo4j ________

self = <tests.unit.registry.test_service_factory.TestDatabaseServiceCreation object at 0x77cf5bedbdd0>
factory = <rag_factory.registry.service_factory.ServiceFactory object at 0x77cf46f2dca0>

    def test_create_database_service_neo4j(self, factory):
        """Test creating Neo4j database service."""
        config = {
            "type": "neo4j",
            "uri": "bolt://localhost:7687",
            "user": "neo4j",
            "password": "testpass"
        }
    
>       with patch('rag_factory.registry.service_factory.Neo4jGraphService') as mock_class:

tests/unit/registry/test_service_factory.py:287: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.12/unittest/mock.py:1458: in __enter__
    original, local = self.get_original()
                      ^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x77cf46f2d8e0>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'rag_factory.registry.service_factory' from '/mnt/MCPProyects/ragTools/rag_factory/registry/service_factory.py'> does not have the attribute 'Neo4jGraphService'

/usr/lib/python3.12/unittest/mock.py:1431: AttributeError
_ TestDatabaseServiceCreation.test_create_database_service_neo4j_with_defaults _

self = <tests.unit.registry.test_service_factory.TestDatabaseServiceCreation object at 0x77cf5bd440e0>
factory = <rag_factory.registry.service_factory.ServiceFactory object at 0x77cf46f00bf0>

    def test_create_database_service_neo4j_with_defaults(self, factory):
        """Test creating Neo4j database service with default URI."""
        config = {
            "type": "neo4j",
            "host": "localhost",
            "port": 7687,
            "user": "neo4j",
            "password": "testpass"
        }
    
>       with patch('rag_factory.registry.service_factory.Neo4jGraphService') as mock_class:

tests/unit/registry/test_service_factory.py:310: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.12/unittest/mock.py:1458: in __enter__
    original, local = self.get_original()
                      ^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x77cf46f00b60>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'rag_factory.registry.service_factory' from '/mnt/MCPProyects/ragTools/rag_factory/registry/service_factory.py'> does not have the attribute 'Neo4jGraphService'

/usr/lib/python3.12/unittest/mock.py:1431: AttributeError
_________________________ test_calculate_cost_is_zero __________________________

onnx_config = {'max_batch_size': 32, 'model': 'Xenova/all-MiniLM-L6-v2'}
mock_onnx_env = <function create_mock_onnx_environment at 0x77cf5c0796c0>

    def test_calculate_cost_is_zero(onnx_config, mock_onnx_env):
        """Test that local ONNX provider has zero cost.
    
        Uses centralized mock_onnx_env to handle all ONNX mocking.
        """
        with mock_onnx_env(dimension=384):
            from rag_factory.services.embedding.providers.onnx_local import ONNXLocalProvider
    
            provider = ONNXLocalProvider(onnx_config)
>           cost = provider.calculate_cost(num_texts=100)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E           TypeError: ONNXLocalProvider.calculate_cost() got an unexpected keyword argument 'num_texts'

tests/unit/services/embedding/test_onnx_local_provider.py:78: TypeError
______________________________ test_capabilities _______________________________

strategy = <rag_factory.strategies.indexing.context_aware.ContextAwareChunkingIndexing object at 0x77cf4b8ae480>

    def test_capabilities(strategy):
        """Test produces capabilities."""
>       assert strategy.produces() == {
            IndexCapability.CHUNKS,
            IndexCapability.DATABASE
        }
E       AssertionError: assert {<IndexCapabi...DATABASE: 10>} == {<IndexCapabi...DATABASE: 10>}
E         
E         Extra items in the left set:
E         <IndexCapability.VECTORS: 1>
E         
E         Full diff:
E           {
E         +     <IndexCapability.VECTORS: 1>,...
E         
E         ...Full output truncated (3 lines hidden), use '-vv' to show

tests/unit/strategies/indexing/test_context_aware.py:33: AssertionError
_______________________ TestImports.test_import_factory ________________________

self = <tests.unit.test_package.TestImports object at 0x77cf5bd634a0>

    def test_import_factory(self) -> None:
        """Test RAGFactory can be imported."""
>       from rag_factory import RAGFactory
E       ImportError: cannot import name 'RAGFactory' from 'rag_factory' (/mnt/MCPProyects/ragTools/rag_factory/__init__.py)

tests/unit/test_package.py:18: ImportError
_______________________ TestImports.test_import_pipeline _______________________

self = <tests.unit.test_package.TestImports object at 0x77cf5bd634d0>

    def test_import_pipeline(self) -> None:
        """Test StrategyPipeline can be imported."""
>       from rag_factory import StrategyPipeline
E       ImportError: cannot import name 'StrategyPipeline' from 'rag_factory' (/mnt/MCPProyects/ragTools/rag_factory/__init__.py)

tests/unit/test_package.py:24: ImportError
________________________ TestImports.test_import_config ________________________

self = <tests.unit.test_package.TestImports object at 0x77cf5bd62ba0>

    def test_import_config(self) -> None:
        """Test ConfigManager can be imported."""
>       from rag_factory import ConfigManager
E       ImportError: cannot import name 'ConfigManager' from 'rag_factory' (/mnt/MCPProyects/ragTools/rag_factory/__init__.py)

tests/unit/test_package.py:30: ImportError
________________ TestPackageStructure.test_no_circular_imports _________________

self = <tests.unit.test_package.TestPackageStructure object at 0x77cf5bd88050>

    def test_no_circular_imports(self) -> None:
        """Test importing doesn't cause circular import errors."""
        try:
>           from rag_factory import RAGFactory
E           ImportError: cannot import name 'RAGFactory' from 'rag_factory' (/mnt/MCPProyects/ragTools/rag_factory/__init__.py)

tests/unit/test_package.py:81: ImportError

During handling of the above exception, another exception occurred:

self = <tests.unit.test_package.TestPackageStructure object at 0x77cf5bd88050>

    def test_no_circular_imports(self) -> None:
        """Test importing doesn't cause circular import errors."""
        try:
            from rag_factory import RAGFactory
            from rag_factory import StrategyPipeline
            from rag_factory import ConfigManager
            from rag_factory.strategies import IRAGStrategy
    
            # If we get here, no circular imports
            assert RAGFactory is not None
            assert StrategyPipeline is not None
            assert ConfigManager is not None
            assert IRAGStrategy is not None
        except ImportError as e:
>           pytest.fail(f"Circular import detected: {e}")
E           Failed: Circular import detected: cannot import name 'RAGFactory' from 'rag_factory' (/mnt/MCPProyects/ragTools/rag_factory/__init__.py)

tests/unit/test_package.py:92: Failed
_____________ TestDependencies.test_optional_dependencies_handled ______________

self = <tests.unit.test_package.TestDependencies object at 0x77cf5bd883b0>

    def test_optional_dependencies_handled(self) -> None:
        """Test package works without optional dependencies."""
        # Should not fail if optional dependencies missing
>       from rag_factory import RAGFactory
E       ImportError: cannot import name 'RAGFactory' from 'rag_factory' (/mnt/MCPProyects/ragTools/rag_factory/__init__.py)

tests/unit/test_package.py:111: ImportError
____________ TestMigrationIntegration.test_real_migration_execution ____________

self = <sqlalchemy.engine.base.Connection object at 0x77cf4b8ac320>
dialect = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x77cf4b8ac620>
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x77cf46fbe3c0>
statement = <sqlalchemy.dialects.postgresql.base.PGCompiler object at 0x77cf46fbd1f0>
parameters = [{}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x77cf4b8ac620>
cursor = <cursor object at 0x77cf44f1f6a0; closed: -1>
statement = 'DROP EXTENSION IF EXISTS vector', parameters = {}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x77cf46fbe3c0>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       psycopg2.errors.DependentObjectsStillExist: cannot drop extension vector because other objects depend on it
E       DETAIL:  column embedding of table test_chunks_real depends on type vector
E       HINT:  Use DROP ... CASCADE to drop the dependent objects too.

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: DependentObjectsStillExist

The above exception was the direct cause of the following exception:

self = <tests.integration.database.test_migration_integration.TestMigrationIntegration object at 0x77cf5bd88e60>
alembic_config = <alembic.config.Config object at 0x77cf4b8ae030>
test_db_url = 'postgresql://rag_user:rag_password@192.168.56.1:5432/rag_test'

    @pytest.mark.asyncio
    async def test_real_migration_execution(self, alembic_config: Config, test_db_url: str) -> None:
        """Test running migrations against real database."""
        # Start from clean state
>       command.downgrade(alembic_config, "base")

tests/integration/database/test_migration_integration.py:29: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
venv/lib/python3.12/site-packages/alembic/command.py:449: in downgrade
    script.run_env()
venv/lib/python3.12/site-packages/alembic/script/base.py:583: in run_env
    util.load_python_file(self.dir, "env.py")
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:95: in load_python_file
    module = load_module_py(module_id, path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:113: in load_module_py
    spec.loader.exec_module(module)  # type: ignore
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
<frozen importlib._bootstrap_external>:995: in exec_module
    ???
<frozen importlib._bootstrap>:488: in _call_with_frames_removed
    ???
migrations/env.py:93: in <module>
    run_migrations_online()
migrations/env.py:87: in run_migrations_online
    context.run_migrations()
<string>:8: in run_migrations
    ???
venv/lib/python3.12/site-packages/alembic/runtime/environment.py:948: in run_migrations
    self.get_context().run_migrations(**kw)
venv/lib/python3.12/site-packages/alembic/runtime/migration.py:627: in run_migrations
    step.migration_fn(**kw)
migrations/versions/001_initial_schema.py:129: in downgrade
    op.execute("DROP EXTENSION IF EXISTS vector")
<string>:8: in execute
    ???
<string>:3: in execute
    ???
venv/lib/python3.12/site-packages/alembic/operations/ops.py:2537: in execute
    return operations.invoke(op)
           ^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/base.py:445: in invoke
    return fn(self, operation)
           ^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/toimpl.py:224: in execute_sql
    operations.migration_context.impl.execute(
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:214: in execute
    self._exec(sql, execution_options)
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:207: in _exec
    return conn.execute(construct, multiparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1416: in execute
    return meth(
venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py:516: in _execute_on_connection
    return connection._execute_clauseelement(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1639: in _execute_clauseelement
    ret = self._execute_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1848: in _execute_context
    return self._exec_single_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1988: in _exec_single_context
    self._handle_dbapi_exception(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2343: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: in _exec_single_context
    self.dialect.do_execute(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x77cf4b8ac620>
cursor = <cursor object at 0x77cf44f1f6a0; closed: -1>
statement = 'DROP EXTENSION IF EXISTS vector', parameters = {}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x77cf46fbe3c0>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.InternalError: (psycopg2.errors.DependentObjectsStillExist) cannot drop extension vector because other objects depend on it
E       DETAIL:  column embedding of table test_chunks_real depends on type vector
E       HINT:  Use DROP ... CASCADE to drop the dependent objects too.
E       
E       [SQL: DROP EXTENSION IF EXISTS vector]
E       (Background on this error at: https://sqlalche.me/e/20/2j85)

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: InternalError
----------------------------- Captured stderr call -----------------------------
INFO  [alembic.runtime.migration] Context impl PostgresqlImpl.
INFO  [alembic.runtime.migration] Will assume transactional DDL.
INFO  [alembic.runtime.migration] Running downgrade 001 -> , Initial schema with documents and chunks tables
__________ TestMigrationIntegration.test_migration_with_existing_data __________

self = <sqlalchemy.engine.base.Connection object at 0x77cf4b8ac290>
dialect = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x77cf46f02c60>
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x77cf46fb6a50>
statement = <sqlalchemy.dialects.postgresql.base.PGCompiler object at 0x77cf46fb41a0>
parameters = [{}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x77cf46f02c60>
cursor = <cursor object at 0x77cf44f1d8a0; closed: -1>
statement = 'DROP EXTENSION IF EXISTS vector', parameters = {}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x77cf46fb6a50>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       psycopg2.errors.DependentObjectsStillExist: cannot drop extension vector because other objects depend on it
E       DETAIL:  column embedding of table test_chunks_real depends on type vector
E       HINT:  Use DROP ... CASCADE to drop the dependent objects too.

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: DependentObjectsStillExist

The above exception was the direct cause of the following exception:

self = <tests.integration.database.test_migration_integration.TestMigrationIntegration object at 0x77cf5bd89100>
alembic_config = <alembic.config.Config object at 0x77cf5bd63a10>
test_db_url = 'postgresql://rag_user:rag_password@192.168.56.1:5432/rag_test'

    @pytest.mark.asyncio
    async def test_migration_with_existing_data(self, alembic_config: Config, test_db_url: str) -> None:
        """Test migration with existing data in database."""
        # Start from clean state
>       command.downgrade(alembic_config, "base")

tests/integration/database/test_migration_integration.py:48: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
venv/lib/python3.12/site-packages/alembic/command.py:449: in downgrade
    script.run_env()
venv/lib/python3.12/site-packages/alembic/script/base.py:583: in run_env
    util.load_python_file(self.dir, "env.py")
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:95: in load_python_file
    module = load_module_py(module_id, path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:113: in load_module_py
    spec.loader.exec_module(module)  # type: ignore
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
<frozen importlib._bootstrap_external>:995: in exec_module
    ???
<frozen importlib._bootstrap>:488: in _call_with_frames_removed
    ???
migrations/env.py:93: in <module>
    run_migrations_online()
migrations/env.py:87: in run_migrations_online
    context.run_migrations()
<string>:8: in run_migrations
    ???
venv/lib/python3.12/site-packages/alembic/runtime/environment.py:948: in run_migrations
    self.get_context().run_migrations(**kw)
venv/lib/python3.12/site-packages/alembic/runtime/migration.py:627: in run_migrations
    step.migration_fn(**kw)
migrations/versions/001_initial_schema.py:129: in downgrade
    op.execute("DROP EXTENSION IF EXISTS vector")
<string>:8: in execute
    ???
<string>:3: in execute
    ???
venv/lib/python3.12/site-packages/alembic/operations/ops.py:2537: in execute
    return operations.invoke(op)
           ^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/base.py:445: in invoke
    return fn(self, operation)
           ^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/toimpl.py:224: in execute_sql
    operations.migration_context.impl.execute(
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:214: in execute
    self._exec(sql, execution_options)
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:207: in _exec
    return conn.execute(construct, multiparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1416: in execute
    return meth(
venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py:516: in _execute_on_connection
    return connection._execute_clauseelement(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1639: in _execute_clauseelement
    ret = self._execute_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1848: in _execute_context
    return self._exec_single_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1988: in _exec_single_context
    self._handle_dbapi_exception(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2343: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: in _exec_single_context
    self.dialect.do_execute(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x77cf46f02c60>
cursor = <cursor object at 0x77cf44f1d8a0; closed: -1>
statement = 'DROP EXTENSION IF EXISTS vector', parameters = {}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x77cf46fb6a50>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.InternalError: (psycopg2.errors.DependentObjectsStillExist) cannot drop extension vector because other objects depend on it
E       DETAIL:  column embedding of table test_chunks_real depends on type vector
E       HINT:  Use DROP ... CASCADE to drop the dependent objects too.
E       
E       [SQL: DROP EXTENSION IF EXISTS vector]
E       (Background on this error at: https://sqlalche.me/e/20/2j85)

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: InternalError
----------------------------- Captured stderr call -----------------------------
INFO  [alembic.runtime.migration] Context impl PostgresqlImpl.
INFO  [alembic.runtime.migration] Will assume transactional DDL.
INFO  [alembic.runtime.migration] Running downgrade 001 -> , Initial schema with documents and chunks tables
_____________ TestMigrationIntegration.test_rollback_functionality _____________

self = <sqlalchemy.engine.base.Connection object at 0x77cf46f83ce0>
dialect = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x77cf44f49a00>
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x77cf5861bb00>
statement = <sqlalchemy.dialects.postgresql.base.PGCompiler object at 0x77cf5861a7e0>
parameters = [{}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x77cf44f49a00>
cursor = <cursor object at 0x77cf587b5b70; closed: -1>
statement = 'DROP EXTENSION IF EXISTS vector', parameters = {}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x77cf5861bb00>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       psycopg2.errors.DependentObjectsStillExist: cannot drop extension vector because other objects depend on it
E       DETAIL:  column embedding of table test_chunks_real depends on type vector
E       HINT:  Use DROP ... CASCADE to drop the dependent objects too.

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: DependentObjectsStillExist

The above exception was the direct cause of the following exception:

self = <tests.integration.database.test_migration_integration.TestMigrationIntegration object at 0x77cf5bd89520>
alembic_config = <alembic.config.Config object at 0x77cf46fb4860>
test_db_url = 'postgresql://rag_user:rag_password@192.168.56.1:5432/rag_test'

    @pytest.mark.asyncio
    async def test_rollback_functionality(self, alembic_config: Config, test_db_url: str) -> None:
        """Test rolling back migrations."""
        # Start from clean state
>       command.downgrade(alembic_config, "base")

tests/integration/database/test_migration_integration.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
venv/lib/python3.12/site-packages/alembic/command.py:449: in downgrade
    script.run_env()
venv/lib/python3.12/site-packages/alembic/script/base.py:583: in run_env
    util.load_python_file(self.dir, "env.py")
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:95: in load_python_file
    module = load_module_py(module_id, path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:113: in load_module_py
    spec.loader.exec_module(module)  # type: ignore
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
<frozen importlib._bootstrap_external>:995: in exec_module
    ???
<frozen importlib._bootstrap>:488: in _call_with_frames_removed
    ???
migrations/env.py:93: in <module>
    run_migrations_online()
migrations/env.py:87: in run_migrations_online
    context.run_migrations()
<string>:8: in run_migrations
    ???
venv/lib/python3.12/site-packages/alembic/runtime/environment.py:948: in run_migrations
    self.get_context().run_migrations(**kw)
venv/lib/python3.12/site-packages/alembic/runtime/migration.py:627: in run_migrations
    step.migration_fn(**kw)
migrations/versions/001_initial_schema.py:129: in downgrade
    op.execute("DROP EXTENSION IF EXISTS vector")
<string>:8: in execute
    ???
<string>:3: in execute
    ???
venv/lib/python3.12/site-packages/alembic/operations/ops.py:2537: in execute
    return operations.invoke(op)
           ^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/base.py:445: in invoke
    return fn(self, operation)
           ^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/toimpl.py:224: in execute_sql
    operations.migration_context.impl.execute(
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:214: in execute
    self._exec(sql, execution_options)
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:207: in _exec
    return conn.execute(construct, multiparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1416: in execute
    return meth(
venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py:516: in _execute_on_connection
    return connection._execute_clauseelement(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1639: in _execute_clauseelement
    ret = self._execute_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1848: in _execute_context
    return self._exec_single_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1988: in _exec_single_context
    self._handle_dbapi_exception(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2343: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: in _exec_single_context
    self.dialect.do_execute(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x77cf44f49a00>
cursor = <cursor object at 0x77cf587b5b70; closed: -1>
statement = 'DROP EXTENSION IF EXISTS vector', parameters = {}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x77cf5861bb00>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.InternalError: (psycopg2.errors.DependentObjectsStillExist) cannot drop extension vector because other objects depend on it
E       DETAIL:  column embedding of table test_chunks_real depends on type vector
E       HINT:  Use DROP ... CASCADE to drop the dependent objects too.
E       
E       [SQL: DROP EXTENSION IF EXISTS vector]
E       (Background on this error at: https://sqlalche.me/e/20/2j85)

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: InternalError
----------------------------- Captured stderr call -----------------------------
INFO  [alembic.runtime.migration] Context impl PostgresqlImpl.
INFO  [alembic.runtime.migration] Will assume transactional DDL.
INFO  [alembic.runtime.migration] Running downgrade 001 -> , Initial schema with documents and chunks tables
__________ TestMigrationIntegration.test_pgvector_extension_installed __________

self = <sqlalchemy.engine.base.Connection object at 0x77cf46f82240>
dialect = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x77cf5aea4e00>
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x77cf46d2c950>
statement = <sqlalchemy.dialects.postgresql.base.PGDDLCompiler object at 0x77cf46d2e720>
parameters = [immutabledict({})]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x77cf5aea4e00>
cursor = <cursor object at 0x77cf44f4f010; closed: -1>
statement = 'ALTER TABLE chunks ADD COLUMN parent_chunk_id UUID'
parameters = immutabledict({})
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x77cf46d2c950>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       psycopg2.errors.UndefinedTable: relation "chunks" does not exist

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: UndefinedTable

The above exception was the direct cause of the following exception:

self = <tests.integration.database.test_migration_integration.TestMigrationIntegration object at 0x77cf5bd63da0>
alembic_config = <alembic.config.Config object at 0x77cf46fac4d0>
test_db_url = 'postgresql://rag_user:rag_password@192.168.56.1:5432/rag_test'

    @pytest.mark.asyncio
    async def test_pgvector_extension_installed(self, alembic_config: Config, test_db_url: str) -> None:
        """Test that pgvector extension is installed by migrations."""
        # Upgrade to head
>       command.upgrade(alembic_config, "head")

tests/integration/database/test_migration_integration.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
venv/lib/python3.12/site-packages/alembic/command.py:403: in upgrade
    script.run_env()
venv/lib/python3.12/site-packages/alembic/script/base.py:583: in run_env
    util.load_python_file(self.dir, "env.py")
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:95: in load_python_file
    module = load_module_py(module_id, path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:113: in load_module_py
    spec.loader.exec_module(module)  # type: ignore
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
<frozen importlib._bootstrap_external>:995: in exec_module
    ???
<frozen importlib._bootstrap>:488: in _call_with_frames_removed
    ???
migrations/env.py:93: in <module>
    run_migrations_online()
migrations/env.py:87: in run_migrations_online
    context.run_migrations()
<string>:8: in run_migrations
    ???
venv/lib/python3.12/site-packages/alembic/runtime/environment.py:948: in run_migrations
    self.get_context().run_migrations(**kw)
venv/lib/python3.12/site-packages/alembic/runtime/migration.py:627: in run_migrations
    step.migration_fn(**kw)
migrations/versions/002_add_hierarchy_support.py:26: in upgrade
    op.add_column(
<string>:8: in add_column
    ???
<string>:3: in add_column
    ???
venv/lib/python3.12/site-packages/alembic/operations/ops.py:2142: in add_column
    return operations.invoke(op)
           ^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/base.py:445: in invoke
    return fn(self, operation)
           ^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/toimpl.py:171: in add_column
    operations.impl.add_column(table_name, column, schema=schema, **kw)
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:334: in add_column
    self._exec(base.AddColumn(table_name, column, schema=schema))
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:207: in _exec
    return conn.execute(construct, multiparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1416: in execute
    return meth(
venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:181: in _execute_on_connection
    return connection._execute_ddl(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1528: in _execute_ddl
    ret = self._execute_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1848: in _execute_context
    return self._exec_single_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1988: in _exec_single_context
    self._handle_dbapi_exception(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2343: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: in _exec_single_context
    self.dialect.do_execute(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x77cf5aea4e00>
cursor = <cursor object at 0x77cf44f4f010; closed: -1>
statement = 'ALTER TABLE chunks ADD COLUMN parent_chunk_id UUID'
parameters = immutabledict({})
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x77cf46d2c950>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "chunks" does not exist
E       
E       [SQL: ALTER TABLE chunks ADD COLUMN parent_chunk_id UUID]
E       (Background on this error at: https://sqlalche.me/e/20/f405)

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: ProgrammingError
----------------------------- Captured stderr call -----------------------------
INFO  [alembic.runtime.migration] Context impl PostgresqlImpl.
INFO  [alembic.runtime.migration] Will assume transactional DDL.
INFO  [alembic.runtime.migration] Running upgrade 001 -> 002, Add hierarchy support to chunks table
______ TestMigrationValidatorIntegration.test_validate_with_no_migrations ______

self = <sqlalchemy.engine.base.Connection object at 0x77cf5aea5c40>
dialect = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x77cf44fa1430>
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x77cf44f31070>
statement = <sqlalchemy.dialects.postgresql.base.PGCompiler object at 0x77cf44f30e30>
parameters = [{}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x77cf44fa1430>
cursor = <cursor object at 0x77cf44f4ce50; closed: -1>
statement = 'DROP EXTENSION IF EXISTS vector', parameters = {}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x77cf44f31070>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       psycopg2.errors.DependentObjectsStillExist: cannot drop extension vector because other objects depend on it
E       DETAIL:  column embedding of table test_chunks_real depends on type vector
E       HINT:  Use DROP ... CASCADE to drop the dependent objects too.

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: DependentObjectsStillExist

The above exception was the direct cause of the following exception:

self = <tests.integration.database.test_migration_validator_integration.TestMigrationValidatorIntegration object at 0x77cf5bd88440>
validator = <rag_factory.services.database.migration_validator.MigrationValidator object at 0x77cf46d2e330>
alembic_config = <alembic.config.Config object at 0x77cf46d2eb10>

    @pytest.mark.asyncio
    async def test_validate_with_no_migrations(
        self,
        validator: MigrationValidator,
        alembic_config: Config
    ) -> None:
        """Test validation when no migrations are applied."""
        # Start from clean state
>       command.downgrade(alembic_config, "base")

tests/integration/database/test_migration_validator_integration.py:68: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
venv/lib/python3.12/site-packages/alembic/command.py:449: in downgrade
    script.run_env()
venv/lib/python3.12/site-packages/alembic/script/base.py:583: in run_env
    util.load_python_file(self.dir, "env.py")
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:95: in load_python_file
    module = load_module_py(module_id, path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:113: in load_module_py
    spec.loader.exec_module(module)  # type: ignore
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
<frozen importlib._bootstrap_external>:995: in exec_module
    ???
<frozen importlib._bootstrap>:488: in _call_with_frames_removed
    ???
migrations/env.py:93: in <module>
    run_migrations_online()
migrations/env.py:87: in run_migrations_online
    context.run_migrations()
<string>:8: in run_migrations
    ???
venv/lib/python3.12/site-packages/alembic/runtime/environment.py:948: in run_migrations
    self.get_context().run_migrations(**kw)
venv/lib/python3.12/site-packages/alembic/runtime/migration.py:627: in run_migrations
    step.migration_fn(**kw)
migrations/versions/001_initial_schema.py:129: in downgrade
    op.execute("DROP EXTENSION IF EXISTS vector")
<string>:8: in execute
    ???
<string>:3: in execute
    ???
venv/lib/python3.12/site-packages/alembic/operations/ops.py:2537: in execute
    return operations.invoke(op)
           ^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/base.py:445: in invoke
    return fn(self, operation)
           ^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/toimpl.py:224: in execute_sql
    operations.migration_context.impl.execute(
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:214: in execute
    self._exec(sql, execution_options)
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:207: in _exec
    return conn.execute(construct, multiparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1416: in execute
    return meth(
venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py:516: in _execute_on_connection
    return connection._execute_clauseelement(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1639: in _execute_clauseelement
    ret = self._execute_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1848: in _execute_context
    return self._exec_single_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1988: in _exec_single_context
    self._handle_dbapi_exception(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2343: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: in _exec_single_context
    self.dialect.do_execute(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x77cf44fa1430>
cursor = <cursor object at 0x77cf44f4ce50; closed: -1>
statement = 'DROP EXTENSION IF EXISTS vector', parameters = {}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x77cf44f31070>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.InternalError: (psycopg2.errors.DependentObjectsStillExist) cannot drop extension vector because other objects depend on it
E       DETAIL:  column embedding of table test_chunks_real depends on type vector
E       HINT:  Use DROP ... CASCADE to drop the dependent objects too.
E       
E       [SQL: DROP EXTENSION IF EXISTS vector]
E       (Background on this error at: https://sqlalche.me/e/20/2j85)

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: InternalError
----------------------------- Captured stderr call -----------------------------
INFO  [alembic.runtime.migration] Context impl PostgresqlImpl.
INFO  [alembic.runtime.migration] Will assume transactional DDL.
INFO  [alembic.runtime.migration] Running downgrade 001 -> , Initial schema with documents and chunks tables
___ TestMigrationValidatorIntegration.test_validate_with_partial_migrations ____

self = <sqlalchemy.engine.base.Connection object at 0x77cf44fa21e0>
dialect = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x77cf46d7d370>
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x77cf46d9fc20>
statement = <sqlalchemy.dialects.postgresql.base.PGCompiler object at 0x77cf46d9e8d0>
parameters = [{}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x77cf46d7d370>
cursor = <cursor object at 0x77cf44f4eb60; closed: -1>
statement = 'DROP EXTENSION IF EXISTS vector', parameters = {}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x77cf46d9fc20>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       psycopg2.errors.DependentObjectsStillExist: cannot drop extension vector because other objects depend on it
E       DETAIL:  column embedding of table test_chunks_real depends on type vector
E       HINT:  Use DROP ... CASCADE to drop the dependent objects too.

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: DependentObjectsStillExist

The above exception was the direct cause of the following exception:

self = <tests.integration.database.test_migration_validator_integration.TestMigrationValidatorIntegration object at 0x77cf5bd89a00>
validator = <rag_factory.services.database.migration_validator.MigrationValidator object at 0x77cf46db42c0>
alembic_config = <alembic.config.Config object at 0x77cf46db4f50>

    @pytest.mark.asyncio
    async def test_validate_with_partial_migrations(
        self,
        validator: MigrationValidator,
        alembic_config: Config
    ) -> None:
        """Test validation when only some migrations are applied."""
        # Start from clean state
>       command.downgrade(alembic_config, "base")

tests/integration/database/test_migration_validator_integration.py:85: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
venv/lib/python3.12/site-packages/alembic/command.py:449: in downgrade
    script.run_env()
venv/lib/python3.12/site-packages/alembic/script/base.py:583: in run_env
    util.load_python_file(self.dir, "env.py")
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:95: in load_python_file
    module = load_module_py(module_id, path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:113: in load_module_py
    spec.loader.exec_module(module)  # type: ignore
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
<frozen importlib._bootstrap_external>:995: in exec_module
    ???
<frozen importlib._bootstrap>:488: in _call_with_frames_removed
    ???
migrations/env.py:93: in <module>
    run_migrations_online()
migrations/env.py:87: in run_migrations_online
    context.run_migrations()
<string>:8: in run_migrations
    ???
venv/lib/python3.12/site-packages/alembic/runtime/environment.py:948: in run_migrations
    self.get_context().run_migrations(**kw)
venv/lib/python3.12/site-packages/alembic/runtime/migration.py:627: in run_migrations
    step.migration_fn(**kw)
migrations/versions/001_initial_schema.py:129: in downgrade
    op.execute("DROP EXTENSION IF EXISTS vector")
<string>:8: in execute
    ???
<string>:3: in execute
    ???
venv/lib/python3.12/site-packages/alembic/operations/ops.py:2537: in execute
    return operations.invoke(op)
           ^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/base.py:445: in invoke
    return fn(self, operation)
           ^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/toimpl.py:224: in execute_sql
    operations.migration_context.impl.execute(
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:214: in execute
    self._exec(sql, execution_options)
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:207: in _exec
    return conn.execute(construct, multiparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1416: in execute
    return meth(
venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py:516: in _execute_on_connection
    return connection._execute_clauseelement(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1639: in _execute_clauseelement
    ret = self._execute_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1848: in _execute_context
    return self._exec_single_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1988: in _exec_single_context
    self._handle_dbapi_exception(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2343: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: in _exec_single_context
    self.dialect.do_execute(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x77cf46d7d370>
cursor = <cursor object at 0x77cf44f4eb60; closed: -1>
statement = 'DROP EXTENSION IF EXISTS vector', parameters = {}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x77cf46d9fc20>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.InternalError: (psycopg2.errors.DependentObjectsStillExist) cannot drop extension vector because other objects depend on it
E       DETAIL:  column embedding of table test_chunks_real depends on type vector
E       HINT:  Use DROP ... CASCADE to drop the dependent objects too.
E       
E       [SQL: DROP EXTENSION IF EXISTS vector]
E       (Background on this error at: https://sqlalche.me/e/20/2j85)

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: InternalError
----------------------------- Captured stderr call -----------------------------
INFO  [alembic.runtime.migration] Context impl PostgresqlImpl.
INFO  [alembic.runtime.migration] Will assume transactional DDL.
INFO  [alembic.runtime.migration] Running downgrade 001 -> , Initial schema with documents and chunks tables
_____ TestMigrationValidatorIntegration.test_validate_with_all_migrations ______

self = <sqlalchemy.engine.base.Connection object at 0x77cf46fac740>
dialect = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x77cf46faf0e0>
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x77cf4b8af0e0>
statement = <sqlalchemy.dialects.postgresql.base.PGDDLCompiler object at 0x77cf4b8ad640>
parameters = [immutabledict({})]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x77cf46faf0e0>
cursor = <cursor object at 0x77cf587b5c60; closed: -1>
statement = 'ALTER TABLE chunks ADD COLUMN parent_chunk_id UUID'
parameters = immutabledict({})
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x77cf4b8af0e0>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       psycopg2.errors.UndefinedTable: relation "chunks" does not exist

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: UndefinedTable

The above exception was the direct cause of the following exception:

self = <tests.integration.database.test_migration_validator_integration.TestMigrationValidatorIntegration object at 0x77cf5bd89e20>
validator = <rag_factory.services.database.migration_validator.MigrationValidator object at 0x77cf46f81b20>
alembic_config = <alembic.config.Config object at 0x77cf46f82450>

    @pytest.mark.asyncio
    async def test_validate_with_all_migrations(
        self,
        validator: MigrationValidator,
        alembic_config: Config
    ) -> None:
        """Test validation when all required migrations are applied."""
        # Apply all migrations
>       command.upgrade(alembic_config, "head")

tests/integration/database/test_migration_validator_integration.py:105: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
venv/lib/python3.12/site-packages/alembic/command.py:403: in upgrade
    script.run_env()
venv/lib/python3.12/site-packages/alembic/script/base.py:583: in run_env
    util.load_python_file(self.dir, "env.py")
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:95: in load_python_file
    module = load_module_py(module_id, path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:113: in load_module_py
    spec.loader.exec_module(module)  # type: ignore
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
<frozen importlib._bootstrap_external>:995: in exec_module
    ???
<frozen importlib._bootstrap>:488: in _call_with_frames_removed
    ???
migrations/env.py:93: in <module>
    run_migrations_online()
migrations/env.py:87: in run_migrations_online
    context.run_migrations()
<string>:8: in run_migrations
    ???
venv/lib/python3.12/site-packages/alembic/runtime/environment.py:948: in run_migrations
    self.get_context().run_migrations(**kw)
venv/lib/python3.12/site-packages/alembic/runtime/migration.py:627: in run_migrations
    step.migration_fn(**kw)
migrations/versions/002_add_hierarchy_support.py:26: in upgrade
    op.add_column(
<string>:8: in add_column
    ???
<string>:3: in add_column
    ???
venv/lib/python3.12/site-packages/alembic/operations/ops.py:2142: in add_column
    return operations.invoke(op)
           ^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/base.py:445: in invoke
    return fn(self, operation)
           ^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/toimpl.py:171: in add_column
    operations.impl.add_column(table_name, column, schema=schema, **kw)
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:334: in add_column
    self._exec(base.AddColumn(table_name, column, schema=schema))
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:207: in _exec
    return conn.execute(construct, multiparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1416: in execute
    return meth(
venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:181: in _execute_on_connection
    return connection._execute_ddl(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1528: in _execute_ddl
    ret = self._execute_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1848: in _execute_context
    return self._exec_single_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1988: in _exec_single_context
    self._handle_dbapi_exception(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2343: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: in _exec_single_context
    self.dialect.do_execute(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x77cf46faf0e0>
cursor = <cursor object at 0x77cf587b5c60; closed: -1>
statement = 'ALTER TABLE chunks ADD COLUMN parent_chunk_id UUID'
parameters = immutabledict({})
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x77cf4b8af0e0>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "chunks" does not exist
E       
E       [SQL: ALTER TABLE chunks ADD COLUMN parent_chunk_id UUID]
E       (Background on this error at: https://sqlalche.me/e/20/f405)

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: ProgrammingError
----------------------------- Captured stderr call -----------------------------
INFO  [alembic.runtime.migration] Context impl PostgresqlImpl.
INFO  [alembic.runtime.migration] Will assume transactional DDL.
INFO  [alembic.runtime.migration] Running upgrade 001 -> 002, Add hierarchy support to chunks table
_______ TestMigrationValidatorIntegration.test_validate_or_raise_success _______

self = <sqlalchemy.engine.base.Connection object at 0x77cf46fae7b0>
dialect = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x77cf46f66cf0>
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x77cf44f427e0>
statement = <sqlalchemy.dialects.postgresql.base.PGDDLCompiler object at 0x77cf46f2ea20>
parameters = [immutabledict({})]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x77cf46f66cf0>
cursor = <cursor object at 0x77cf44f1e980; closed: -1>
statement = 'ALTER TABLE chunks ADD COLUMN parent_chunk_id UUID'
parameters = immutabledict({})
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x77cf44f427e0>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       psycopg2.errors.UndefinedTable: relation "chunks" does not exist

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: UndefinedTable

The above exception was the direct cause of the following exception:

self = <tests.integration.database.test_migration_validator_integration.TestMigrationValidatorIntegration object at 0x77cf5bd8a210>
validator = <rag_factory.services.database.migration_validator.MigrationValidator object at 0x77cf4b8afbc0>
alembic_config = <alembic.config.Config object at 0x77cf46f2ef30>

    @pytest.mark.asyncio
    async def test_validate_or_raise_success(
        self,
        validator: MigrationValidator,
        alembic_config: Config
    ) -> None:
        """Test validate_or_raise when all migrations are applied."""
        # Apply all migrations
>       command.upgrade(alembic_config, "head")

tests/integration/database/test_migration_validator_integration.py:121: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
venv/lib/python3.12/site-packages/alembic/command.py:403: in upgrade
    script.run_env()
venv/lib/python3.12/site-packages/alembic/script/base.py:583: in run_env
    util.load_python_file(self.dir, "env.py")
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:95: in load_python_file
    module = load_module_py(module_id, path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:113: in load_module_py
    spec.loader.exec_module(module)  # type: ignore
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
<frozen importlib._bootstrap_external>:995: in exec_module
    ???
<frozen importlib._bootstrap>:488: in _call_with_frames_removed
    ???
migrations/env.py:93: in <module>
    run_migrations_online()
migrations/env.py:87: in run_migrations_online
    context.run_migrations()
<string>:8: in run_migrations
    ???
venv/lib/python3.12/site-packages/alembic/runtime/environment.py:948: in run_migrations
    self.get_context().run_migrations(**kw)
venv/lib/python3.12/site-packages/alembic/runtime/migration.py:627: in run_migrations
    step.migration_fn(**kw)
migrations/versions/002_add_hierarchy_support.py:26: in upgrade
    op.add_column(
<string>:8: in add_column
    ???
<string>:3: in add_column
    ???
venv/lib/python3.12/site-packages/alembic/operations/ops.py:2142: in add_column
    return operations.invoke(op)
           ^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/base.py:445: in invoke
    return fn(self, operation)
           ^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/toimpl.py:171: in add_column
    operations.impl.add_column(table_name, column, schema=schema, **kw)
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:334: in add_column
    self._exec(base.AddColumn(table_name, column, schema=schema))
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:207: in _exec
    return conn.execute(construct, multiparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1416: in execute
    return meth(
venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:181: in _execute_on_connection
    return connection._execute_ddl(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1528: in _execute_ddl
    ret = self._execute_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1848: in _execute_context
    return self._exec_single_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1988: in _exec_single_context
    self._handle_dbapi_exception(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2343: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: in _exec_single_context
    self.dialect.do_execute(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x77cf46f66cf0>
cursor = <cursor object at 0x77cf44f1e980; closed: -1>
statement = 'ALTER TABLE chunks ADD COLUMN parent_chunk_id UUID'
parameters = immutabledict({})
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x77cf44f427e0>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "chunks" does not exist
E       
E       [SQL: ALTER TABLE chunks ADD COLUMN parent_chunk_id UUID]
E       (Background on this error at: https://sqlalche.me/e/20/f405)

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: ProgrammingError
----------------------------- Captured stderr call -----------------------------
INFO  [alembic.runtime.migration] Context impl PostgresqlImpl.
INFO  [alembic.runtime.migration] Will assume transactional DDL.
INFO  [alembic.runtime.migration] Running upgrade 001 -> 002, Add hierarchy support to chunks table
_______ TestMigrationValidatorIntegration.test_validate_or_raise_failure _______

self = <sqlalchemy.engine.base.Connection object at 0x77cf46fb6450>
dialect = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x77cf5aea7f50>
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x77cf44f48890>
statement = <sqlalchemy.dialects.postgresql.base.PGCompiler object at 0x77cf44f4a8d0>
parameters = [{}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x77cf5aea7f50>
cursor = <cursor object at 0x77cf44f1ec50; closed: -1>
statement = 'DROP EXTENSION IF EXISTS vector', parameters = {}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x77cf44f48890>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       psycopg2.errors.DependentObjectsStillExist: cannot drop extension vector because other objects depend on it
E       DETAIL:  column embedding of table test_chunks_real depends on type vector
E       HINT:  Use DROP ... CASCADE to drop the dependent objects too.

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: DependentObjectsStillExist

The above exception was the direct cause of the following exception:

self = <tests.integration.database.test_migration_validator_integration.TestMigrationValidatorIntegration object at 0x77cf5bd8a600>
validator = <rag_factory.services.database.migration_validator.MigrationValidator object at 0x77cf5861a900>
alembic_config = <alembic.config.Config object at 0x77cf44fa18e0>

    @pytest.mark.asyncio
    async def test_validate_or_raise_failure(
        self,
        validator: MigrationValidator,
        alembic_config: Config
    ) -> None:
        """Test validate_or_raise when migrations are missing."""
        # Start from clean state
>       command.downgrade(alembic_config, "base")

tests/integration/database/test_migration_validator_integration.py:134: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
venv/lib/python3.12/site-packages/alembic/command.py:449: in downgrade
    script.run_env()
venv/lib/python3.12/site-packages/alembic/script/base.py:583: in run_env
    util.load_python_file(self.dir, "env.py")
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:95: in load_python_file
    module = load_module_py(module_id, path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:113: in load_module_py
    spec.loader.exec_module(module)  # type: ignore
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
<frozen importlib._bootstrap_external>:995: in exec_module
    ???
<frozen importlib._bootstrap>:488: in _call_with_frames_removed
    ???
migrations/env.py:93: in <module>
    run_migrations_online()
migrations/env.py:87: in run_migrations_online
    context.run_migrations()
<string>:8: in run_migrations
    ???
venv/lib/python3.12/site-packages/alembic/runtime/environment.py:948: in run_migrations
    self.get_context().run_migrations(**kw)
venv/lib/python3.12/site-packages/alembic/runtime/migration.py:627: in run_migrations
    step.migration_fn(**kw)
migrations/versions/001_initial_schema.py:129: in downgrade
    op.execute("DROP EXTENSION IF EXISTS vector")
<string>:8: in execute
    ???
<string>:3: in execute
    ???
venv/lib/python3.12/site-packages/alembic/operations/ops.py:2537: in execute
    return operations.invoke(op)
           ^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/base.py:445: in invoke
    return fn(self, operation)
           ^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/toimpl.py:224: in execute_sql
    operations.migration_context.impl.execute(
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:214: in execute
    self._exec(sql, execution_options)
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:207: in _exec
    return conn.execute(construct, multiparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1416: in execute
    return meth(
venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py:516: in _execute_on_connection
    return connection._execute_clauseelement(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1639: in _execute_clauseelement
    ret = self._execute_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1848: in _execute_context
    return self._exec_single_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1988: in _exec_single_context
    self._handle_dbapi_exception(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2343: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: in _exec_single_context
    self.dialect.do_execute(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x77cf5aea7f50>
cursor = <cursor object at 0x77cf44f1ec50; closed: -1>
statement = 'DROP EXTENSION IF EXISTS vector', parameters = {}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x77cf44f48890>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.InternalError: (psycopg2.errors.DependentObjectsStillExist) cannot drop extension vector because other objects depend on it
E       DETAIL:  column embedding of table test_chunks_real depends on type vector
E       HINT:  Use DROP ... CASCADE to drop the dependent objects too.
E       
E       [SQL: DROP EXTENSION IF EXISTS vector]
E       (Background on this error at: https://sqlalche.me/e/20/2j85)

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: InternalError
----------------------------- Captured stderr call -----------------------------
INFO  [alembic.runtime.migration] Context impl PostgresqlImpl.
INFO  [alembic.runtime.migration] Will assume transactional DDL.
INFO  [alembic.runtime.migration] Running downgrade 001 -> , Initial schema with documents and chunks tables
_________ TestMigrationValidatorIntegration.test_get_current_revision __________

self = <sqlalchemy.engine.base.Connection object at 0x77cf44f87d10>
dialect = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x77cf44f879b0>
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x77cf44f87620>
statement = <sqlalchemy.dialects.postgresql.base.PGCompiler object at 0x77cf44f84e30>
parameters = [{}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x77cf44f879b0>
cursor = <cursor object at 0x77cf44f4d120; closed: -1>
statement = 'DROP EXTENSION IF EXISTS vector', parameters = {}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x77cf44f87620>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       psycopg2.errors.DependentObjectsStillExist: cannot drop extension vector because other objects depend on it
E       DETAIL:  column embedding of table test_chunks_real depends on type vector
E       HINT:  Use DROP ... CASCADE to drop the dependent objects too.

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: DependentObjectsStillExist

The above exception was the direct cause of the following exception:

self = <tests.integration.database.test_migration_validator_integration.TestMigrationValidatorIntegration object at 0x77cf5bd8a9f0>
validator = <rag_factory.services.database.migration_validator.MigrationValidator object at 0x77cf46fbf470>
alembic_config = <alembic.config.Config object at 0x77cf46fafa10>

    @pytest.mark.asyncio
    async def test_get_current_revision(
        self,
        validator: MigrationValidator,
        alembic_config: Config
    ) -> None:
        """Test getting current revision from database."""
        # Start from clean state
>       command.downgrade(alembic_config, "base")

tests/integration/database/test_migration_validator_integration.py:153: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
venv/lib/python3.12/site-packages/alembic/command.py:449: in downgrade
    script.run_env()
venv/lib/python3.12/site-packages/alembic/script/base.py:583: in run_env
    util.load_python_file(self.dir, "env.py")
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:95: in load_python_file
    module = load_module_py(module_id, path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:113: in load_module_py
    spec.loader.exec_module(module)  # type: ignore
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
<frozen importlib._bootstrap_external>:995: in exec_module
    ???
<frozen importlib._bootstrap>:488: in _call_with_frames_removed
    ???
migrations/env.py:93: in <module>
    run_migrations_online()
migrations/env.py:87: in run_migrations_online
    context.run_migrations()
<string>:8: in run_migrations
    ???
venv/lib/python3.12/site-packages/alembic/runtime/environment.py:948: in run_migrations
    self.get_context().run_migrations(**kw)
venv/lib/python3.12/site-packages/alembic/runtime/migration.py:627: in run_migrations
    step.migration_fn(**kw)
migrations/versions/001_initial_schema.py:129: in downgrade
    op.execute("DROP EXTENSION IF EXISTS vector")
<string>:8: in execute
    ???
<string>:3: in execute
    ???
venv/lib/python3.12/site-packages/alembic/operations/ops.py:2537: in execute
    return operations.invoke(op)
           ^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/base.py:445: in invoke
    return fn(self, operation)
           ^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/toimpl.py:224: in execute_sql
    operations.migration_context.impl.execute(
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:214: in execute
    self._exec(sql, execution_options)
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:207: in _exec
    return conn.execute(construct, multiparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1416: in execute
    return meth(
venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py:516: in _execute_on_connection
    return connection._execute_clauseelement(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1639: in _execute_clauseelement
    ret = self._execute_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1848: in _execute_context
    return self._exec_single_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1988: in _exec_single_context
    self._handle_dbapi_exception(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2343: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: in _exec_single_context
    self.dialect.do_execute(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x77cf44f879b0>
cursor = <cursor object at 0x77cf44f4d120; closed: -1>
statement = 'DROP EXTENSION IF EXISTS vector', parameters = {}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x77cf44f87620>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.InternalError: (psycopg2.errors.DependentObjectsStillExist) cannot drop extension vector because other objects depend on it
E       DETAIL:  column embedding of table test_chunks_real depends on type vector
E       HINT:  Use DROP ... CASCADE to drop the dependent objects too.
E       
E       [SQL: DROP EXTENSION IF EXISTS vector]
E       (Background on this error at: https://sqlalche.me/e/20/2j85)

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: InternalError
----------------------------- Captured stderr call -----------------------------
INFO  [alembic.runtime.migration] Context impl PostgresqlImpl.
INFO  [alembic.runtime.migration] Will assume transactional DDL.
INFO  [alembic.runtime.migration] Running downgrade 001 -> , Initial schema with documents and chunks tables
______________ TestMigrationValidatorIntegration.test_is_at_head _______________

self = <sqlalchemy.engine.base.Connection object at 0x77cf44f85820>
dialect = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x77cf4b826cf0>
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x77cf4b91ede0>
statement = <sqlalchemy.dialects.postgresql.base.PGCompiler object at 0x77cf4b91ed20>
parameters = [{}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x77cf4b826cf0>
cursor = <cursor object at 0x77cf44f4f970; closed: -1>
statement = 'DROP EXTENSION IF EXISTS vector', parameters = {}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x77cf4b91ede0>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       psycopg2.errors.DependentObjectsStillExist: cannot drop extension vector because other objects depend on it
E       DETAIL:  column embedding of table test_chunks_real depends on type vector
E       HINT:  Use DROP ... CASCADE to drop the dependent objects too.

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: DependentObjectsStillExist

The above exception was the direct cause of the following exception:

self = <tests.integration.database.test_migration_validator_integration.TestMigrationValidatorIntegration object at 0x77cf5bd8b170>
validator = <rag_factory.services.database.migration_validator.MigrationValidator object at 0x77cf4b827d40>
alembic_config = <alembic.config.Config object at 0x77cf4b824770>

    @pytest.mark.asyncio
    async def test_is_at_head(
        self,
        validator: MigrationValidator,
        alembic_config: Config
    ) -> None:
        """Test checking if database is at head revision."""
        # Start from clean state
>       command.downgrade(alembic_config, "base")

tests/integration/database/test_migration_validator_integration.py:193: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
venv/lib/python3.12/site-packages/alembic/command.py:449: in downgrade
    script.run_env()
venv/lib/python3.12/site-packages/alembic/script/base.py:583: in run_env
    util.load_python_file(self.dir, "env.py")
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:95: in load_python_file
    module = load_module_py(module_id, path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:113: in load_module_py
    spec.loader.exec_module(module)  # type: ignore
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
<frozen importlib._bootstrap_external>:995: in exec_module
    ???
<frozen importlib._bootstrap>:488: in _call_with_frames_removed
    ???
migrations/env.py:93: in <module>
    run_migrations_online()
migrations/env.py:87: in run_migrations_online
    context.run_migrations()
<string>:8: in run_migrations
    ???
venv/lib/python3.12/site-packages/alembic/runtime/environment.py:948: in run_migrations
    self.get_context().run_migrations(**kw)
venv/lib/python3.12/site-packages/alembic/runtime/migration.py:627: in run_migrations
    step.migration_fn(**kw)
migrations/versions/001_initial_schema.py:129: in downgrade
    op.execute("DROP EXTENSION IF EXISTS vector")
<string>:8: in execute
    ???
<string>:3: in execute
    ???
venv/lib/python3.12/site-packages/alembic/operations/ops.py:2537: in execute
    return operations.invoke(op)
           ^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/base.py:445: in invoke
    return fn(self, operation)
           ^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/toimpl.py:224: in execute_sql
    operations.migration_context.impl.execute(
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:214: in execute
    self._exec(sql, execution_options)
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:207: in _exec
    return conn.execute(construct, multiparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1416: in execute
    return meth(
venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py:516: in _execute_on_connection
    return connection._execute_clauseelement(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1639: in _execute_clauseelement
    ret = self._execute_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1848: in _execute_context
    return self._exec_single_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1988: in _exec_single_context
    self._handle_dbapi_exception(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2343: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: in _exec_single_context
    self.dialect.do_execute(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x77cf4b826cf0>
cursor = <cursor object at 0x77cf44f4f970; closed: -1>
statement = 'DROP EXTENSION IF EXISTS vector', parameters = {}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x77cf4b91ede0>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.InternalError: (psycopg2.errors.DependentObjectsStillExist) cannot drop extension vector because other objects depend on it
E       DETAIL:  column embedding of table test_chunks_real depends on type vector
E       HINT:  Use DROP ... CASCADE to drop the dependent objects too.
E       
E       [SQL: DROP EXTENSION IF EXISTS vector]
E       (Background on this error at: https://sqlalche.me/e/20/2j85)

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: InternalError
----------------------------- Captured stderr call -----------------------------
INFO  [alembic.runtime.migration] Context impl PostgresqlImpl.
INFO  [alembic.runtime.migration] Will assume transactional DDL.
INFO  [alembic.runtime.migration] Running downgrade 001 -> , Initial schema with documents and chunks tables
_________ TestMigrationValidatorIntegration.test_error_message_details _________

self = <sqlalchemy.engine.base.Connection object at 0x77cf4b91c470>
dialect = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x77cf4b5debd0>
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x77cf4b5aa1e0>
statement = <sqlalchemy.dialects.postgresql.base.PGCompiler object at 0x77cf4b5aa120>
parameters = [{}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x77cf4b5debd0>
cursor = <cursor object at 0x77cf4b578b80; closed: -1>
statement = 'DROP EXTENSION IF EXISTS vector', parameters = {}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x77cf4b5aa1e0>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       psycopg2.errors.DependentObjectsStillExist: cannot drop extension vector because other objects depend on it
E       DETAIL:  column embedding of table test_chunks_real depends on type vector
E       HINT:  Use DROP ... CASCADE to drop the dependent objects too.

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: DependentObjectsStillExist

The above exception was the direct cause of the following exception:

self = <tests.integration.database.test_migration_validator_integration.TestMigrationValidatorIntegration object at 0x77cf5bd8b320>
validator = <rag_factory.services.database.migration_validator.MigrationValidator object at 0x77cf4b5de810>
alembic_config = <alembic.config.Config object at 0x77cf4b5de5d0>

    @pytest.mark.asyncio
    async def test_error_message_details(
        self,
        validator: MigrationValidator,
        alembic_config: Config
    ) -> None:
        """Test that error messages include migration details."""
        # Start from clean state
>       command.downgrade(alembic_config, "base")

tests/integration/database/test_migration_validator_integration.py:214: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
venv/lib/python3.12/site-packages/alembic/command.py:449: in downgrade
    script.run_env()
venv/lib/python3.12/site-packages/alembic/script/base.py:583: in run_env
    util.load_python_file(self.dir, "env.py")
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:95: in load_python_file
    module = load_module_py(module_id, path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:113: in load_module_py
    spec.loader.exec_module(module)  # type: ignore
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
<frozen importlib._bootstrap_external>:995: in exec_module
    ???
<frozen importlib._bootstrap>:488: in _call_with_frames_removed
    ???
migrations/env.py:93: in <module>
    run_migrations_online()
migrations/env.py:87: in run_migrations_online
    context.run_migrations()
<string>:8: in run_migrations
    ???
venv/lib/python3.12/site-packages/alembic/runtime/environment.py:948: in run_migrations
    self.get_context().run_migrations(**kw)
venv/lib/python3.12/site-packages/alembic/runtime/migration.py:627: in run_migrations
    step.migration_fn(**kw)
migrations/versions/001_initial_schema.py:129: in downgrade
    op.execute("DROP EXTENSION IF EXISTS vector")
<string>:8: in execute
    ???
<string>:3: in execute
    ???
venv/lib/python3.12/site-packages/alembic/operations/ops.py:2537: in execute
    return operations.invoke(op)
           ^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/base.py:445: in invoke
    return fn(self, operation)
           ^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/toimpl.py:224: in execute_sql
    operations.migration_context.impl.execute(
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:214: in execute
    self._exec(sql, execution_options)
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:207: in _exec
    return conn.execute(construct, multiparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1416: in execute
    return meth(
venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py:516: in _execute_on_connection
    return connection._execute_clauseelement(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1639: in _execute_clauseelement
    ret = self._execute_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1848: in _execute_context
    return self._exec_single_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1988: in _exec_single_context
    self._handle_dbapi_exception(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2343: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: in _exec_single_context
    self.dialect.do_execute(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x77cf4b5debd0>
cursor = <cursor object at 0x77cf4b578b80; closed: -1>
statement = 'DROP EXTENSION IF EXISTS vector', parameters = {}
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x77cf4b5aa1e0>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.InternalError: (psycopg2.errors.DependentObjectsStillExist) cannot drop extension vector because other objects depend on it
E       DETAIL:  column embedding of table test_chunks_real depends on type vector
E       HINT:  Use DROP ... CASCADE to drop the dependent objects too.
E       
E       [SQL: DROP EXTENSION IF EXISTS vector]
E       (Background on this error at: https://sqlalche.me/e/20/2j85)

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: InternalError
----------------------------- Captured stderr call -----------------------------
INFO  [alembic.runtime.migration] Context impl PostgresqlImpl.
INFO  [alembic.runtime.migration] Will assume transactional DDL.
INFO  [alembic.runtime.migration] Running downgrade 001 -> , Initial schema with documents and chunks tables
_______ TestMigrationValidatorIntegration.test_validate_single_migration _______

self = <sqlalchemy.engine.base.Connection object at 0x77cf4b5df650>
dialect = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x77cf4b576cf0>
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x77cf4b5cc200>
statement = <sqlalchemy.dialects.postgresql.base.PGDDLCompiler object at 0x77cf4b5cc1a0>
parameters = [immutabledict({})]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x77cf4b576cf0>
cursor = <cursor object at 0x77cf4b579d50; closed: -1>
statement = 'ALTER TABLE chunks ADD COLUMN parent_chunk_id UUID'
parameters = immutabledict({})
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x77cf4b5cc200>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       psycopg2.errors.UndefinedTable: relation "chunks" does not exist

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: UndefinedTable

The above exception was the direct cause of the following exception:

self = <tests.integration.database.test_migration_validator_integration.TestMigrationValidatorIntegration object at 0x77cf5bd8ac60>
validator = <rag_factory.services.database.migration_validator.MigrationValidator object at 0x77cf4b5769f0>
alembic_config = <alembic.config.Config object at 0x77cf4b576480>

    @pytest.mark.asyncio
    async def test_validate_single_migration(
        self,
        validator: MigrationValidator,
        alembic_config: Config
    ) -> None:
        """Test validating a single migration requirement."""
        # Apply all migrations
>       command.upgrade(alembic_config, "head")

tests/integration/database/test_migration_validator_integration.py:240: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
venv/lib/python3.12/site-packages/alembic/command.py:403: in upgrade
    script.run_env()
venv/lib/python3.12/site-packages/alembic/script/base.py:583: in run_env
    util.load_python_file(self.dir, "env.py")
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:95: in load_python_file
    module = load_module_py(module_id, path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:113: in load_module_py
    spec.loader.exec_module(module)  # type: ignore
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
<frozen importlib._bootstrap_external>:995: in exec_module
    ???
<frozen importlib._bootstrap>:488: in _call_with_frames_removed
    ???
migrations/env.py:93: in <module>
    run_migrations_online()
migrations/env.py:87: in run_migrations_online
    context.run_migrations()
<string>:8: in run_migrations
    ???
venv/lib/python3.12/site-packages/alembic/runtime/environment.py:948: in run_migrations
    self.get_context().run_migrations(**kw)
venv/lib/python3.12/site-packages/alembic/runtime/migration.py:627: in run_migrations
    step.migration_fn(**kw)
migrations/versions/002_add_hierarchy_support.py:26: in upgrade
    op.add_column(
<string>:8: in add_column
    ???
<string>:3: in add_column
    ???
venv/lib/python3.12/site-packages/alembic/operations/ops.py:2142: in add_column
    return operations.invoke(op)
           ^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/base.py:445: in invoke
    return fn(self, operation)
           ^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/toimpl.py:171: in add_column
    operations.impl.add_column(table_name, column, schema=schema, **kw)
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:334: in add_column
    self._exec(base.AddColumn(table_name, column, schema=schema))
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:207: in _exec
    return conn.execute(construct, multiparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1416: in execute
    return meth(
venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:181: in _execute_on_connection
    return connection._execute_ddl(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1528: in _execute_ddl
    ret = self._execute_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1848: in _execute_context
    return self._exec_single_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1988: in _exec_single_context
    self._handle_dbapi_exception(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2343: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: in _exec_single_context
    self.dialect.do_execute(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x77cf4b576cf0>
cursor = <cursor object at 0x77cf4b579d50; closed: -1>
statement = 'ALTER TABLE chunks ADD COLUMN parent_chunk_id UUID'
parameters = immutabledict({})
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x77cf4b5cc200>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "chunks" does not exist
E       
E       [SQL: ALTER TABLE chunks ADD COLUMN parent_chunk_id UUID]
E       (Background on this error at: https://sqlalche.me/e/20/f405)

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: ProgrammingError
----------------------------- Captured stderr call -----------------------------
INFO  [alembic.runtime.migration] Context impl PostgresqlImpl.
INFO  [alembic.runtime.migration] Will assume transactional DDL.
INFO  [alembic.runtime.migration] Running upgrade 001 -> 002, Add hierarchy support to chunks table
____ TestMigrationValidatorIntegration.test_validate_nonexistent_migration _____

self = <sqlalchemy.engine.base.Connection object at 0x77cf4b577650>
dialect = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x77cf4b548860>
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x77cf4b54aa80>
statement = <sqlalchemy.dialects.postgresql.base.PGDDLCompiler object at 0x77cf4b54a9c0>
parameters = [immutabledict({})]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x77cf4b548860>
cursor = <cursor object at 0x77cf4b57b010; closed: -1>
statement = 'ALTER TABLE chunks ADD COLUMN parent_chunk_id UUID'
parameters = immutabledict({})
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x77cf4b54aa80>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       psycopg2.errors.UndefinedTable: relation "chunks" does not exist

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: UndefinedTable

The above exception was the direct cause of the following exception:

self = <tests.integration.database.test_migration_validator_integration.TestMigrationValidatorIntegration object at 0x77cf5bd8a6c0>
validator = <rag_factory.services.database.migration_validator.MigrationValidator object at 0x77cf4b5cedb0>
alembic_config = <alembic.config.Config object at 0x77cf4b5cc5f0>

    @pytest.mark.asyncio
    async def test_validate_nonexistent_migration(
        self,
        validator: MigrationValidator,
        alembic_config: Config
    ) -> None:
        """Test validating a migration that doesn't exist."""
        # Apply all migrations
>       command.upgrade(alembic_config, "head")

tests/integration/database/test_migration_validator_integration.py:256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
venv/lib/python3.12/site-packages/alembic/command.py:403: in upgrade
    script.run_env()
venv/lib/python3.12/site-packages/alembic/script/base.py:583: in run_env
    util.load_python_file(self.dir, "env.py")
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:95: in load_python_file
    module = load_module_py(module_id, path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:113: in load_module_py
    spec.loader.exec_module(module)  # type: ignore
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
<frozen importlib._bootstrap_external>:995: in exec_module
    ???
<frozen importlib._bootstrap>:488: in _call_with_frames_removed
    ???
migrations/env.py:93: in <module>
    run_migrations_online()
migrations/env.py:87: in run_migrations_online
    context.run_migrations()
<string>:8: in run_migrations
    ???
venv/lib/python3.12/site-packages/alembic/runtime/environment.py:948: in run_migrations
    self.get_context().run_migrations(**kw)
venv/lib/python3.12/site-packages/alembic/runtime/migration.py:627: in run_migrations
    step.migration_fn(**kw)
migrations/versions/002_add_hierarchy_support.py:26: in upgrade
    op.add_column(
<string>:8: in add_column
    ???
<string>:3: in add_column
    ???
venv/lib/python3.12/site-packages/alembic/operations/ops.py:2142: in add_column
    return operations.invoke(op)
           ^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/base.py:445: in invoke
    return fn(self, operation)
           ^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/toimpl.py:171: in add_column
    operations.impl.add_column(table_name, column, schema=schema, **kw)
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:334: in add_column
    self._exec(base.AddColumn(table_name, column, schema=schema))
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:207: in _exec
    return conn.execute(construct, multiparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1416: in execute
    return meth(
venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:181: in _execute_on_connection
    return connection._execute_ddl(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1528: in _execute_ddl
    ret = self._execute_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1848: in _execute_context
    return self._exec_single_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1988: in _exec_single_context
    self._handle_dbapi_exception(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2343: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: in _exec_single_context
    self.dialect.do_execute(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x77cf4b548860>
cursor = <cursor object at 0x77cf4b57b010; closed: -1>
statement = 'ALTER TABLE chunks ADD COLUMN parent_chunk_id UUID'
parameters = immutabledict({})
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x77cf4b54aa80>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "chunks" does not exist
E       
E       [SQL: ALTER TABLE chunks ADD COLUMN parent_chunk_id UUID]
E       (Background on this error at: https://sqlalche.me/e/20/f405)

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: ProgrammingError
----------------------------- Captured stderr call -----------------------------
INFO  [alembic.runtime.migration] Context impl PostgresqlImpl.
INFO  [alembic.runtime.migration] Will assume transactional DDL.
INFO  [alembic.runtime.migration] Running upgrade 001 -> 002, Add hierarchy support to chunks table
_______ TestMigrationValidatorIntegration.test_validate_after_downgrade ________

self = <sqlalchemy.engine.base.Connection object at 0x77cf4b5dddf0>
dialect = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x77cf4b5ddc10>
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x77cf4b8250a0>
statement = <sqlalchemy.dialects.postgresql.base.PGDDLCompiler object at 0x77cf4b8277a0>
parameters = [immutabledict({})]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x77cf4b5ddc10>
cursor = <cursor object at 0x77cf44f1fe20; closed: -1>
statement = 'ALTER TABLE chunks ADD COLUMN parent_chunk_id UUID'
parameters = immutabledict({})
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x77cf4b8250a0>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       psycopg2.errors.UndefinedTable: relation "chunks" does not exist

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: UndefinedTable

The above exception was the direct cause of the following exception:

self = <tests.integration.database.test_migration_validator_integration.TestMigrationValidatorIntegration object at 0x77cf5bd89f70>
validator = <rag_factory.services.database.migration_validator.MigrationValidator object at 0x77cf4b575430>
alembic_config = <alembic.config.Config object at 0x77cf4b577320>

    @pytest.mark.asyncio
    async def test_validate_after_downgrade(
        self,
        validator: MigrationValidator,
        alembic_config: Config
    ) -> None:
        """Test validation after downgrading migrations."""
        # Apply all migrations
>       command.upgrade(alembic_config, "head")

tests/integration/database/test_migration_validator_integration.py:272: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
venv/lib/python3.12/site-packages/alembic/command.py:403: in upgrade
    script.run_env()
venv/lib/python3.12/site-packages/alembic/script/base.py:583: in run_env
    util.load_python_file(self.dir, "env.py")
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:95: in load_python_file
    module = load_module_py(module_id, path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:113: in load_module_py
    spec.loader.exec_module(module)  # type: ignore
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
<frozen importlib._bootstrap_external>:995: in exec_module
    ???
<frozen importlib._bootstrap>:488: in _call_with_frames_removed
    ???
migrations/env.py:93: in <module>
    run_migrations_online()
migrations/env.py:87: in run_migrations_online
    context.run_migrations()
<string>:8: in run_migrations
    ???
venv/lib/python3.12/site-packages/alembic/runtime/environment.py:948: in run_migrations
    self.get_context().run_migrations(**kw)
venv/lib/python3.12/site-packages/alembic/runtime/migration.py:627: in run_migrations
    step.migration_fn(**kw)
migrations/versions/002_add_hierarchy_support.py:26: in upgrade
    op.add_column(
<string>:8: in add_column
    ???
<string>:3: in add_column
    ???
venv/lib/python3.12/site-packages/alembic/operations/ops.py:2142: in add_column
    return operations.invoke(op)
           ^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/base.py:445: in invoke
    return fn(self, operation)
           ^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/toimpl.py:171: in add_column
    operations.impl.add_column(table_name, column, schema=schema, **kw)
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:334: in add_column
    self._exec(base.AddColumn(table_name, column, schema=schema))
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:207: in _exec
    return conn.execute(construct, multiparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1416: in execute
    return meth(
venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:181: in _execute_on_connection
    return connection._execute_ddl(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1528: in _execute_ddl
    ret = self._execute_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1848: in _execute_context
    return self._exec_single_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1988: in _exec_single_context
    self._handle_dbapi_exception(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2343: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: in _exec_single_context
    self.dialect.do_execute(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x77cf4b5ddc10>
cursor = <cursor object at 0x77cf44f1fe20; closed: -1>
statement = 'ALTER TABLE chunks ADD COLUMN parent_chunk_id UUID'
parameters = immutabledict({})
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x77cf4b8250a0>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "chunks" does not exist
E       
E       [SQL: ALTER TABLE chunks ADD COLUMN parent_chunk_id UUID]
E       (Background on this error at: https://sqlalche.me/e/20/f405)

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: ProgrammingError
----------------------------- Captured stderr call -----------------------------
INFO  [alembic.runtime.migration] Context impl PostgresqlImpl.
INFO  [alembic.runtime.migration] Will assume transactional DDL.
INFO  [alembic.runtime.migration] Running upgrade 001 -> 002, Add hierarchy support to chunks table
___ TestMigrationValidatorIntegration.test_multiple_validators_same_database ___

self = <sqlalchemy.engine.base.Connection object at 0x77cf4b5ddf70>
dialect = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x77cf46f66f00>
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x77cf4b810980>
statement = <sqlalchemy.dialects.postgresql.base.PGDDLCompiler object at 0x77cf4b810b00>
parameters = [immutabledict({})]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x77cf46f66f00>
cursor = <cursor object at 0x77cf587b5990; closed: -1>
statement = 'ALTER TABLE chunks ADD COLUMN parent_chunk_id UUID'
parameters = immutabledict({})
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x77cf4b810980>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       psycopg2.errors.UndefinedTable: relation "chunks" does not exist

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: UndefinedTable

The above exception was the direct cause of the following exception:

self = <tests.integration.database.test_migration_validator_integration.TestMigrationValidatorIntegration object at 0x77cf5bd88260>
db_service = <rag_factory.services.database.postgres.PostgresqlDatabaseService object at 0x77cf46ef4b90>
alembic_config = <alembic.config.Config object at 0x77cf46ef70b0>

    @pytest.mark.asyncio
    async def test_multiple_validators_same_database(
        self,
        db_service: PostgresqlDatabaseService,
        alembic_config: Config
    ) -> None:
        """Test multiple validators on the same database."""
        # Apply migrations
>       command.upgrade(alembic_config, "head")

tests/integration/database/test_migration_validator_integration.py:295: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
venv/lib/python3.12/site-packages/alembic/command.py:403: in upgrade
    script.run_env()
venv/lib/python3.12/site-packages/alembic/script/base.py:583: in run_env
    util.load_python_file(self.dir, "env.py")
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:95: in load_python_file
    module = load_module_py(module_id, path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:113: in load_module_py
    spec.loader.exec_module(module)  # type: ignore
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
<frozen importlib._bootstrap_external>:995: in exec_module
    ???
<frozen importlib._bootstrap>:488: in _call_with_frames_removed
    ???
migrations/env.py:93: in <module>
    run_migrations_online()
migrations/env.py:87: in run_migrations_online
    context.run_migrations()
<string>:8: in run_migrations
    ???
venv/lib/python3.12/site-packages/alembic/runtime/environment.py:948: in run_migrations
    self.get_context().run_migrations(**kw)
venv/lib/python3.12/site-packages/alembic/runtime/migration.py:627: in run_migrations
    step.migration_fn(**kw)
migrations/versions/002_add_hierarchy_support.py:26: in upgrade
    op.add_column(
<string>:8: in add_column
    ???
<string>:3: in add_column
    ???
venv/lib/python3.12/site-packages/alembic/operations/ops.py:2142: in add_column
    return operations.invoke(op)
           ^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/base.py:445: in invoke
    return fn(self, operation)
           ^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/toimpl.py:171: in add_column
    operations.impl.add_column(table_name, column, schema=schema, **kw)
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:334: in add_column
    self._exec(base.AddColumn(table_name, column, schema=schema))
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:207: in _exec
    return conn.execute(construct, multiparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1416: in execute
    return meth(
venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:181: in _execute_on_connection
    return connection._execute_ddl(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1528: in _execute_ddl
    ret = self._execute_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1848: in _execute_context
    return self._exec_single_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1988: in _exec_single_context
    self._handle_dbapi_exception(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2343: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: in _exec_single_context
    self.dialect.do_execute(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x77cf46f66f00>
cursor = <cursor object at 0x77cf587b5990; closed: -1>
statement = 'ALTER TABLE chunks ADD COLUMN parent_chunk_id UUID'
parameters = immutabledict({})
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x77cf4b810980>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "chunks" does not exist
E       
E       [SQL: ALTER TABLE chunks ADD COLUMN parent_chunk_id UUID]
E       (Background on this error at: https://sqlalche.me/e/20/f405)

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: ProgrammingError
----------------------------- Captured stderr call -----------------------------
INFO  [alembic.runtime.migration] Context impl PostgresqlImpl.
INFO  [alembic.runtime.migration] Will assume transactional DDL.
INFO  [alembic.runtime.migration] Running upgrade 001 -> 002, Add hierarchy support to chunks table
=============================== warnings summary ===============================
rag_factory/services/llm/config.py:8
  /mnt/MCPProyects/ragTools/rag_factory/services/llm/config.py:8: PydanticDeprecatedSince20: Support for class-based `config` is deprecated, use ConfigDict instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    class LLMServiceConfig(BaseModel):

rag_factory/database/config.py:12
  /mnt/MCPProyects/ragTools/rag_factory/database/config.py:12: PydanticDeprecatedSince20: Support for class-based `config` is deprecated, use ConfigDict instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    class DatabaseConfig(BaseSettings):

rag_factory/strategies/late_chunking/models.py:21
  /mnt/MCPProyects/ragTools/rag_factory/strategies/late_chunking/models.py:21: PydanticDeprecatedSince20: Support for class-based `config` is deprecated, use ConfigDict instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    class TokenEmbedding(BaseModel):

rag_factory/strategies/late_chunking/models.py:34
  /mnt/MCPProyects/ragTools/rag_factory/strategies/late_chunking/models.py:34: PydanticDeprecatedSince20: Support for class-based `config` is deprecated, use ConfigDict instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    class DocumentEmbedding(BaseModel):

rag_factory/strategies/late_chunking/models.py:49
  /mnt/MCPProyects/ragTools/rag_factory/strategies/late_chunking/models.py:49: PydanticDeprecatedSince20: Support for class-based `config` is deprecated, use ConfigDict instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    class EmbeddingChunk(BaseModel):

tests/unit/strategies/self_reflective/test_strategy.py: 12 warnings
  /mnt/MCPProyects/ragTools/rag_factory/strategies/self_reflective/strategy.py:179: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    result["refinements"] = [r.dict() for r in refinements]

tests/integration/database/test_migration_validator_integration.py: 13 warnings
  /mnt/MCPProyects/ragTools/tests/integration/database/test_migration_validator_integration.py:50: RuntimeWarning: coroutine 'PostgresqlDatabaseService.close' was never awaited
    service.close()
  Enable tracemalloc to get traceback where the object was allocated.
  See https://docs.pytest.org/en/stable/how-to/capture-warnings.html#resource-warnings for more info.

tests/integration/database/test_migration_validator_integration.py::TestMigrationValidatorEdgeCases::test_validator_with_auto_discovered_config
tests/integration/database/test_migration_validator_integration.py::TestMigrationValidatorEdgeCases::test_validate_empty_requirements
  /mnt/MCPProyects/ragTools/tests/integration/database/test_migration_validator_integration.py:336: RuntimeWarning: coroutine 'PostgresqlDatabaseService.close' was never awaited
    service.close()
  Enable tracemalloc to get traceback where the object was allocated.
  See https://docs.pytest.org/en/stable/how-to/capture-warnings.html#resource-warnings for more info.

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
================================ tests coverage ================================
_______________ coverage: platform linux, python 3.12.3-final-0 ________________

Name                                                               Stmts   Miss  Cover   Missing
------------------------------------------------------------------------------------------------
rag_factory/__init__.py                                                3      0   100%
rag_factory/__version__.py                                             1      0   100%
rag_factory/cli/__init__.py                                            2      0   100%
rag_factory/cli/commands/__init__.py                                   1      0   100%
rag_factory/cli/commands/benchmark.py                                 96     81    16%   40-53, 64-84, 148-263
rag_factory/cli/commands/check_consistency.py                         43     33    23%   64-120
rag_factory/cli/commands/config.py                                    78     68    13%   26-64, 102-188
rag_factory/cli/commands/index.py                                     65     52    20%   29-39, 93-185
rag_factory/cli/commands/query.py                                     47     36    23%   73-149
rag_factory/cli/commands/repl.py                                     152    130    14%   29-56, 63-108, 112-120, 124-133, 137-155, 159-172, 176-186, 190-207, 211-220, 253-260
rag_factory/cli/commands/strategies.py                                45     36    20%   48-120
rag_factory/cli/commands/validate_e2e.py                              91     69    24%   37-38, 42-142, 145-156
rag_factory/cli/commands/validate_pipeline.py                         70     57    19%   57-156
rag_factory/cli/formatters/__init__.py                                 4      0   100%
rag_factory/cli/formatters/consistency.py                             61     55    10%   21-69, 79-103, 108-138
rag_factory/cli/formatters/output.py                                  20      9    55%   23-24, 43-44, 63-64, 74, 79, 84
rag_factory/cli/formatters/results.py                                 71     62    13%   28-55, 72-99, 116-144, 157-181
rag_factory/cli/formatters/validation.py                              63     53    16%   25-43, 48-56, 65-77, 86-98, 103-129, 134-137
rag_factory/cli/main.py                                               31     10    68%   25-28, 48-49, 76-78, 82
rag_factory/cli/utils/__init__.py                                      3      0   100%
rag_factory/cli/utils/progress.py                                     14      8    43%   34-47, 73-76
rag_factory/cli/utils/validation.py                                   53     42    21%   30-41, 57-77, 93-118, 135
rag_factory/config/__init__.py                                         4      0   100%
rag_factory/config/env_resolver.py                                    52     21    60%   52, 81-86, 110, 129-147
rag_factory/config/schemas/__init__.py                                 2      0   100%
rag_factory/config/schemas/version.py                                 10      6    40%   29-38
rag_factory/config/strategy_loader.py                                 54     36    33%   32-41, 45-60, 75-89, 101-104
rag_factory/config/strategy_pair_manager.py                          105     23    78%   57-58, 66-70, 93, 114, 156-157, 191-196, 210-215, 274-275
rag_factory/config/validator.py                                       93     32    66%   70, 177-198, 271-295, 333-354
rag_factory/core/__init__.py                                           4      4     0%   7-23
rag_factory/core/capabilities.py                                      61     16    74%   129, 155, 173-174, 239-253
rag_factory/core/indexing_interface.py                                54     28    48%   144, 164, 208, 260, 272, 292-313, 341-364
rag_factory/core/pipeline.py                                          49     35    29%   22-24, 33-40, 55-77, 95-96, 105-108, 117-120, 137-146
rag_factory/core/retrieval_interface.py                               38     13    66%   138, 158, 196, 247, 259, 285-309
rag_factory/database/__init__.py                                       4      0   100%
rag_factory/database/config.py                                        17      0   100%
rag_factory/database/connection.py                                    80     54    32%   40-48, 61-86, 96, 107, 126-137, 150-157, 165-170, 178-183, 196-197, 209-214, 218, 222
rag_factory/database/env_validator.py                                 38     18    53%   46-54, 66-77, 86-88, 118, 126, 139
rag_factory/database/models.py                                        85     32    62%   31-34, 37-45, 48-54, 66-69, 72-77, 80-85, 181, 323-325
rag_factory/database/vector_indexing.py                               38     38     0%   7-114
rag_factory/evaluation/__init__.py                                     4      4     0%   29-41
rag_factory/evaluation/analysis/__init__.py                            3      3     0%   8-11
rag_factory/evaluation/analysis/comparison.py                        135    135     0%   8-323
rag_factory/evaluation/analysis/statistics.py                         81     81     0%   8-320
rag_factory/evaluation/benchmarks/__init__.py                          3      3     0%   8-14
rag_factory/evaluation/benchmarks/config.py                           25     25     0%   7-64
rag_factory/evaluation/benchmarks/runner.py                          155    155     0%   8-423
rag_factory/evaluation/datasets/__init__.py                            3      3     0%   8-14
rag_factory/evaluation/datasets/loader.py                             88     88     0%   8-281
rag_factory/evaluation/datasets/schema.py                             52     52     0%   8-160
rag_factory/evaluation/datasets/statistics.py                         65     65     0%   8-226
rag_factory/evaluation/exporters/__init__.py                           4      4     0%   8-12
rag_factory/evaluation/exporters/csv_exporter.py                      52     52     0%   3-124
rag_factory/evaluation/exporters/html_exporter.py                     47     47     0%   3-293
rag_factory/evaluation/exporters/json_exporter.py                     19     19     0%   3-68
rag_factory/evaluation/metrics/__init__.py                             3      3     0%   12-25
rag_factory/evaluation/metrics/base.py                                31     31     0%   8-115
rag_factory/evaluation/metrics/cost.py                                65     65     0%   8-313
rag_factory/evaluation/metrics/performance.py                         42     42     0%   8-202
rag_factory/evaluation/metrics/quality.py                             84     84     0%   8-377
rag_factory/evaluation/metrics/retrieval.py                           77     77     0%   9-401
rag_factory/exceptions.py                                             13      0   100%
rag_factory/factory.py                                               187    132    29%   144, 165-170, 209-230, 256-270, 300-324, 347-348, 365, 384, 401, 418, 435, 451-460, 480-502, 528-545, 568-611, 644-699, 703-715
rag_factory/legacy_config.py                                         155    155     0%   22-542
rag_factory/models/__init__.py                                         6      6     0%   3-14
rag_factory/models/embedding/__init__.py                               4      4     0%   3-12
rag_factory/models/embedding/loader.py                               179    179     0%   3-367
rag_factory/models/embedding/models.py                                47     47     0%   3-106
rag_factory/models/embedding/registry.py                             128    128     0%   3-282
rag_factory/models/evaluation/__init__.py                              3      3     0%   3-6
rag_factory/models/evaluation/ab_testing.py                           98     98     0%   3-281
rag_factory/models/evaluation/models.py                               29     29     0%   3-74
rag_factory/observability/__init__.py                                  3      3     0%   3-10
rag_factory/observability/integrations/__init__.py                     1      1     0%   3
rag_factory/observability/integrations/prometheus.py                  47     47     0%   3-229
rag_factory/observability/logging/__init__.py                          2      2     0%   3-5
rag_factory/observability/logging/config.py                           16     16     0%   3-37
rag_factory/observability/logging/filters.py                          41     41     0%   3-103
rag_factory/observability/logging/logger.py                           86     86     0%   3-396
rag_factory/observability/metrics/__init__.py                          2      2     0%   3-9
rag_factory/observability/metrics/collector.py                       143    143     0%   3-459
rag_factory/observability/metrics/cost.py                             39     39     0%   3-221
rag_factory/observability/metrics/performance.py                      64     64     0%   3-196
rag_factory/observability/monitoring/__init__.py                       1      1     0%   3
rag_factory/observability/monitoring/api.py                          101    101     0%   3-328
rag_factory/pipeline.py                                              156    156     0%   34-507
rag_factory/registry/__init__.py                                       4      0   100%
rag_factory/registry/exceptions.py                                     6      0   100%
rag_factory/registry/service_factory.py                               62     10    84%   166-176, 184-191
rag_factory/registry/service_registry.py                              91     14    85%   114, 118, 123-124, 188-192, 214-218
rag_factory/repositories/__init__.py                                   5      0   100%
rag_factory/repositories/base.py                                      42     21    50%   38, 53, 70, 87, 103, 114-118, 125, 136-139, 159-164
rag_factory/repositories/chunk.py                                    206    180    13%   40-45, 68-76, 90-95, 120-133, 155-171, 187-202, 221-231, 250-261, 287-328, 355-396, 422-474, 489-499, 513-521, 537-543, 557-563, 577-587, 604-626, 639-670
rag_factory/repositories/document.py                                  93     74    20%   41-46, 63-68, 98-118, 140-156, 172-187, 206, 223-233, 247-255, 272-279, 290-293, 307-312
rag_factory/repositories/exceptions.py                                18      7    61%   34-36, 56-59
rag_factory/services/__init__.py                                       4      0   100%
rag_factory/services/api/__init__.py                                   4      0   100%
rag_factory/services/api/anthropic.py                                 27     18    33%   46-52, 76-94, 118-141
rag_factory/services/api/cohere.py                                    30     19    37%   14-15, 49-59, 82-113
rag_factory/services/api/openai.py                                    46     27    41%   75-93, 117-140, 189-199, 216-227, 235
rag_factory/services/consistency.py                                   32     24    25%   80-113, 144-170
rag_factory/services/database/__init__.py                              5      0   100%
rag_factory/services/database/database_context.py                    181    153    15%   88-106, 123, 140-150, 179-200, 223-240, 256-266, 305-330, 338-339, 343-406, 414-415, 430-510, 516-517, 521-546
rag_factory/services/database/migration_validator.py                  85     28    67%   29-30, 88, 112, 137-141, 152-181, 197, 202-204, 234, 268-271
rag_factory/services/database/neo4j.py                                54     36    33%   14, 60-71, 79-84, 103-114, 134-150, 172-181, 188-191, 195, 199
rag_factory/services/database/postgres.py                            177     50    72%   17-18, 26-27, 85, 91-103, 187, 211, 213, 217-218, 294-297, 326-341, 392-407, 439-457, 472, 563, 590, 594
rag_factory/services/dependencies.py                                  41     12    71%   99, 101, 103, 105, 107, 134-140, 179-180
rag_factory/services/embedding/__init__.py                             4      0   100%
rag_factory/services/embedding/base.py                                31      6    81%   44, 59, 68, 77, 86, 98
rag_factory/services/embedding/cache.py                               43     33    23%   26-32, 43-58, 67-76, 80-82, 90-94
rag_factory/services/embedding/config.py                              29     13    55%   37-43, 50-68, 80
rag_factory/services/embedding/providers/__init__.py                   5      0   100%
rag_factory/services/embedding/providers/cohere.py                    53     36    32%   10-20, 55-75, 90-117, 125, 133, 141, 152-153
rag_factory/services/embedding/providers/local.py                     43     27    37%   8-9, 46-67, 83-109, 117, 125, 133, 146
rag_factory/services/embedding/providers/onnx_local.py               114     30    74%   18-19, 114, 143-147, 158, 170-175, 248-250, 273, 289-308
rag_factory/services/embedding/providers/openai.py                    51     27    47%   10-20, 54, 64, 70, 87-108, 116, 124, 132, 143-144
rag_factory/services/embedding/rate_limiter.py                        20      1    95%   32
rag_factory/services/embedding/service.py                            100     83    17%   50-62, 79-93, 117-198, 220-222, 233-239, 248-266, 273-275
rag_factory/services/interfaces.py                                    35      0   100%
rag_factory/services/llm/__init__.py                                   5      0   100%
rag_factory/services/llm/base.py                                      43      0   100%
rag_factory/services/llm/config.py                                    23      6    74%   46-48, 51-53
rag_factory/services/llm/prompt_template.py                           43     24    44%   47-82, 97-100, 111-115
rag_factory/services/llm/providers/__init__.py                        12     10    17%   10-22
rag_factory/services/llm/providers/anthropic.py                       57     42    26%   44-50, 64-97, 120-147, 171-172, 184-189, 197, 205
rag_factory/services/llm/providers/ollama.py                          55     42    24%   22-24, 37-67, 93-122, 142-143, 157, 165, 174, 185-196
rag_factory/services/llm/providers/openai.py                          57     19    67%   56, 101-105, 133-158, 189-194, 202, 210
rag_factory/services/llm/service.py                                   66     24    64%   68, 127-129, 154-175, 186, 194-198, 215-216
rag_factory/services/llm/token_counter.py                             27      4    85%   56-57, 71-72
rag_factory/services/local/__init__.py                                 2      2     0%   7-9
rag_factory/services/local/reranker.py                                32     32     0%   7-116
rag_factory/services/onnx/__init__.py                                  2      0   100%
rag_factory/services/onnx/embedding.py                                29     12    59%   61, 65, 83-93, 110-121
rag_factory/services/utils/__init__.py                                 2      0   100%
rag_factory/services/utils/model_converter.py                        104    104     0%   8-291
rag_factory/services/utils/onnx_utils.py                             133     38    71%   22-23, 37, 79-84, 96-97, 142-146, 175, 189-190, 194, 198-201, 216-218, 258, 265-268, 361-362, 376, 392-404
rag_factory/services/utils/reranker_selector.py                       68     68     0%   8-249
rag_factory/strategies/__init__.py                                     2      0   100%
rag_factory/strategies/agentic/__init__.py                             7      7     0%   8-20
rag_factory/strategies/agentic/agent.py                              151    151     0%   8-420
rag_factory/strategies/agentic/config.py                              12     12     0%   5-31
rag_factory/strategies/agentic/frameworks/__init__.py                  1      1     0%   9
rag_factory/strategies/agentic/query_analyzer.py                      89     89     0%   8-278
rag_factory/strategies/agentic/strategy.py                            87     87     0%   8-284
rag_factory/strategies/agentic/tool_implementations.py               135    135     0%   11-511
rag_factory/strategies/agentic/tools.py                               40     40     0%   8-142
rag_factory/strategies/base.py                                        55     10    82%   81, 83, 85, 169-178
rag_factory/strategies/chunking/__init__.py                           15     15     0%   28-67
rag_factory/strategies/chunking/base.py                               91     91     0%   3-256
rag_factory/strategies/chunking/docling_chunker.py                    45     45     0%   13-188
rag_factory/strategies/chunking/fixed_size_chunker.py                 74     74     0%   3-204
rag_factory/strategies/chunking/hybrid_chunker.py                     70     70     0%   3-192
rag_factory/strategies/chunking/semantic_chunker.py                  195    195     0%   3-534
rag_factory/strategies/chunking/structural_chunker.py                147    147     0%   3-425
rag_factory/strategies/chunking/utils.py                              89     89     0%   3-264
rag_factory/strategies/contextual/__init__.py                          7      7     0%   8-19
rag_factory/strategies/contextual/batch_processor.py                  91     91     0%   8-266
rag_factory/strategies/contextual/config.py                           46     46     0%   8-195
rag_factory/strategies/contextual/context_generator.py                84     84     0%   8-234
rag_factory/strategies/contextual/cost_tracker.py                     32     32     0%   8-126
rag_factory/strategies/contextual/prompts.py                          25     25     0%   8-119
rag_factory/strategies/contextual/storage.py                          44     44     0%   8-118
rag_factory/strategies/contextual/strategy.py                         78     78     0%   8-298
rag_factory/strategies/fine_tuned/__init__.py                          4      4     0%   1-5
rag_factory/strategies/fine_tuned/ab_testing.py                       78     78     0%   1-134
rag_factory/strategies/fine_tuned/config.py                           11     11     0%   1-30
rag_factory/strategies/fine_tuned/custom_loader.py                    40     40     0%   1-88
rag_factory/strategies/fine_tuned/model_registry.py                  126    126     0%   1-303
rag_factory/strategies/hierarchical/__init__.py                        5      0   100%
rag_factory/strategies/hierarchical/hierarchy_builder.py              79     25    68%   73, 117, 149, 220, 249-281, 310-335
rag_factory/strategies/hierarchical/models.py                         58      0   100%
rag_factory/strategies/hierarchical/parent_retriever.py               89     47    47%   66-74, 85, 88, 109-111, 141-142, 166-196, 213-227, 250-257, 268-278
rag_factory/strategies/hierarchical/strategy.py                       76     19    75%   77, 92-93, 101, 112-144, 254, 268-269
rag_factory/strategies/indexing/__init__.py                            6      0   100%
rag_factory/strategies/indexing/context_aware.py                     108     11    90%   74, 81, 89-91, 115, 126-128, 162, 197
rag_factory/strategies/indexing/hierarchical.py                       90     73    19%   50, 63, 88-134, 156-185, 201-236, 253-278, 292-293
rag_factory/strategies/indexing/in_memory.py                          41     25    39%   54, 65, 93-121, 143, 160, 173, 194-200
rag_factory/strategies/indexing/keyword_indexing.py                   42     42     0%   8-157
rag_factory/strategies/indexing/knowledge_graph_indexing.py           46     33    28%   18, 27, 48-89, 108-129
rag_factory/strategies/indexing/vector_embedding.py                   98      9    91%   64-65, 76-77, 149-150, 174-175, 213
rag_factory/strategies/knowledge_graph/__init__.py                     4      4     0%   8-19
rag_factory/strategies/knowledge_graph/config.py                      21     21     0%   8-129
rag_factory/strategies/knowledge_graph/entity_extractor.py            70     70     0%   7-205
rag_factory/strategies/knowledge_graph/graph_store.py                 31     31     0%   8-124
rag_factory/strategies/knowledge_graph/hybrid_retriever.py            56     56     0%   8-164
rag_factory/strategies/knowledge_graph/memory_graph_store.py          97     97     0%   8-196
rag_factory/strategies/knowledge_graph/models.py                      53     53     0%   8-122
rag_factory/strategies/knowledge_graph/relationship_extractor.py      62     62     0%   8-189
rag_factory/strategies/knowledge_graph/strategy.py                    80     80     0%   8-256
rag_factory/strategies/late_chunking/__init__.py                       6      0   100%
rag_factory/strategies/late_chunking/coherence_analyzer.py            27      5    81%   59, 82-96
rag_factory/strategies/late_chunking/document_embedder.py            104     34    67%   35, 56, 62-63, 72, 227-235, 256-279, 296-303
rag_factory/strategies/late_chunking/embedding_chunker.py            117     11    91%   53, 57, 145, 191-192, 215-225, 298
rag_factory/strategies/late_chunking/models.py                        62      0   100%
rag_factory/strategies/late_chunking/strategy.py                      70     12    83%   58, 77, 88, 107-122
rag_factory/strategies/multi_query/__init__.py                         7      7     0%   8-19
rag_factory/strategies/multi_query/config.py                          36     36     0%   3-138
rag_factory/strategies/multi_query/deduplicator.py                    87     87     0%   3-197
rag_factory/strategies/multi_query/parallel_executor.py               52     52     0%   3-163
rag_factory/strategies/multi_query/prompts.py                         10     10     0%   3-84
rag_factory/strategies/multi_query/ranker.py                          80     80     0%   3-201
rag_factory/strategies/multi_query/strategy.py                        68     68     0%   3-184
rag_factory/strategies/multi_query/variant_generator.py               62     62     0%   3-187
rag_factory/strategies/query_expansion/__init__.py                     8      0   100%
rag_factory/strategies/query_expansion/base.py                        66     10    85%   90, 103, 114-118, 130-133
rag_factory/strategies/query_expansion/cache.py                       52     40    23%   20-22, 38-55, 64-66, 70-73, 81-97, 105-112
rag_factory/strategies/query_expansion/expander_service.py            92     71    23%   36-40, 55-58, 75-148, 159-180, 204-215, 233-234, 242-246, 254, 265-273, 283-284
rag_factory/strategies/query_expansion/hyde_expander.py               19     12    37%   25-27, 41-65
rag_factory/strategies/query_expansion/llm_expander.py                25     16    36%   23-25, 39-71, 99
rag_factory/strategies/query_expansion/metrics.py                     66     30    55%   44-45, 53-57, 76-109, 130, 134, 146-152, 160
rag_factory/strategies/query_expansion/prompts.py                     13      7    46%   16, 28-56, 68-107
rag_factory/strategies/reranking/__init__.py                           7      7     0%   8-21
rag_factory/strategies/reranking/base.py                              68     68     0%   8-130
rag_factory/strategies/reranking/bge_reranker.py                      51     51     0%   8-151
rag_factory/strategies/reranking/cache.py                             48     48     0%   8-138
rag_factory/strategies/reranking/cohere_reranker.py                   34     34     0%   8-119
rag_factory/strategies/reranking/cosine_reranker.py                   62     62     0%   8-249
rag_factory/strategies/reranking/cross_encoder_reranker.py            40     40     0%   8-124
rag_factory/strategies/reranking/metrics.py                           67     67     0%   8-264
rag_factory/strategies/reranking/reranker_service.py                 115    115     0%   8-310
rag_factory/strategies/retrieval/__init__.py                           6      0   100%
rag_factory/strategies/retrieval/keyword_retriever.py                 56     41    27%   41, 52, 71-113, 126-133, 153-172
rag_factory/strategies/retrieval/knowledge_graph_retriever.py         22      9    59%   19, 27, 48-70
rag_factory/strategies/retrieval/multi_query_retriever.py             22      9    59%   19, 26, 44-66
rag_factory/strategies/retrieval/query_expansion_retriever.py         24      9    62%   20, 27, 45-67
rag_factory/strategies/retrieval/semantic_retriever.py                23      2    91%   23, 77
rag_factory/strategies/self_reflective/__init__.py                     6      0   100%
rag_factory/strategies/self_reflective/config.py                      20      8    60%   29-42
rag_factory/strategies/self_reflective/grader.py                      80     60    25%   51-67, 83-109, 135-171, 187-258
rag_factory/strategies/self_reflective/models.py                      48      0   100%
rag_factory/strategies/self_reflective/refiner.py                     69     18    74%   78-91, 114, 125, 127, 129, 131, 209-228
rag_factory/strategies/self_reflective/strategy.py                    92      2    98%   84-85
rag_factory/utils/__init__.py                                          3      0   100%
rag_factory/utils/token_counter.py                                    45     30    33%   36-40, 52-62, 74-82, 86, 90, 105-106, 124-135, 153-158
rag_factory/utils/tokenization.py                                     95     73    23%   36-40, 53-64, 87-114, 126-129, 141-144, 156, 175-190, 209-228, 241-243, 251-252, 270-271, 292-293, 314-315
------------------------------------------------------------------------------------------------
TOTAL                                                              12307   9119    26%
=========================== short test summary info ============================
FAILED tests/integration_real/test_llm_real.py::test_llm_streaming - TypeErro...
FAILED tests/integration/registry/test_registry_integration.py::TestRealServiceInstantiation::test_multiple_service_instantiation
FAILED tests/integration/registry/test_registry_integration.py::TestErrorHandling::test_invalid_service_config
FAILED tests/integration/registry/test_registry_integration.py::TestConfigurationValidation::test_configuration_warnings
FAILED tests/integration/strategies/test_self_reflective_integration.py::TestSelfReflectiveIntegration::test_end_to_end_workflow
FAILED tests/integration/strategies/test_self_reflective_integration.py::TestSelfReflectiveIntegration::test_retry_with_poor_results
FAILED tests/integration/strategies/test_self_reflective_integration.py::TestSelfReflectiveIntegration::test_performance_within_limits
FAILED tests/integration/strategies/test_self_reflective_integration.py::TestSelfReflectiveWithLMStudio::test_with_real_llm
FAILED tests/integration/test_package_integration.py::TestSmokeTest::test_basic_usage_smoke_test
FAILED tests/integration/test_package_integration.py::TestFullWorkflow::test_full_workflow_with_installed_package
FAILED tests/unit/config/test_strategy_pair_manager.py::test_load_pair_success
FAILED tests/unit/config/test_strategy_pair_manager.py::test_db_context_creation
FAILED tests/unit/database/test_migrations.py::TestAlembicMigrations::test_migration_upgrade_to_head
FAILED tests/unit/database/test_migrations.py::TestAlembicMigrations::test_migration_downgrade
FAILED tests/unit/database/test_migrations.py::TestAlembicMigrations::test_migration_idempotency
FAILED tests/unit/database/test_migrations.py::TestAlembicMigrations::test_get_current_version
FAILED tests/unit/database/test_migrations.py::TestAlembicMigrations::test_migration_creates_tables
FAILED tests/unit/database/test_migrations.py::TestAlembicMigrations::test_migration_creates_indexes
FAILED tests/unit/documentation/test_code_examples.py::TestCodeExamples::test_all_code_examples_have_valid_syntax
FAILED tests/unit/documentation/test_links.py::TestDocumentationLinks::test_no_broken_internal_links
FAILED tests/unit/registry/test_service_factory.py::TestLLMServiceCreation::test_create_llm_service_openai
FAILED tests/unit/registry/test_service_factory.py::TestEmbeddingServiceCreation::test_create_embedding_service_onnx
FAILED tests/unit/registry/test_service_factory.py::TestEmbeddingServiceCreation::test_create_embedding_service_onnx_with_defaults
FAILED tests/unit/registry/test_service_factory.py::TestEmbeddingServiceCreation::test_create_embedding_service_openai
FAILED tests/unit/registry/test_service_factory.py::TestDatabaseServiceCreation::test_create_database_service_postgres_with_connection_string
FAILED tests/unit/registry/test_service_factory.py::TestDatabaseServiceCreation::test_create_database_service_postgres_with_components
FAILED tests/unit/registry/test_service_factory.py::TestDatabaseServiceCreation::test_create_database_service_postgres_with_defaults
FAILED tests/unit/registry/test_service_factory.py::TestDatabaseServiceCreation::test_create_database_service_neo4j
FAILED tests/unit/registry/test_service_factory.py::TestDatabaseServiceCreation::test_create_database_service_neo4j_with_defaults
FAILED tests/unit/services/embedding/test_onnx_local_provider.py::test_calculate_cost_is_zero
FAILED tests/unit/strategies/indexing/test_context_aware.py::test_capabilities
FAILED tests/unit/test_package.py::TestImports::test_import_factory - ImportE...
FAILED tests/unit/test_package.py::TestImports::test_import_pipeline - Import...
FAILED tests/unit/test_package.py::TestImports::test_import_config - ImportEr...
FAILED tests/unit/test_package.py::TestPackageStructure::test_no_circular_imports
FAILED tests/unit/test_package.py::TestDependencies::test_optional_dependencies_handled
FAILED tests/integration/database/test_migration_integration.py::TestMigrationIntegration::test_real_migration_execution
FAILED tests/integration/database/test_migration_integration.py::TestMigrationIntegration::test_migration_with_existing_data
FAILED tests/integration/database/test_migration_integration.py::TestMigrationIntegration::test_rollback_functionality
FAILED tests/integration/database/test_migration_integration.py::TestMigrationIntegration::test_pgvector_extension_installed
FAILED tests/integration/database/test_migration_validator_integration.py::TestMigrationValidatorIntegration::test_validate_with_no_migrations
FAILED tests/integration/database/test_migration_validator_integration.py::TestMigrationValidatorIntegration::test_validate_with_partial_migrations
FAILED tests/integration/database/test_migration_validator_integration.py::TestMigrationValidatorIntegration::test_validate_with_all_migrations
FAILED tests/integration/database/test_migration_validator_integration.py::TestMigrationValidatorIntegration::test_validate_or_raise_success
FAILED tests/integration/database/test_migration_validator_integration.py::TestMigrationValidatorIntegration::test_validate_or_raise_failure
FAILED tests/integration/database/test_migration_validator_integration.py::TestMigrationValidatorIntegration::test_get_current_revision
FAILED tests/integration/database/test_migration_validator_integration.py::TestMigrationValidatorIntegration::test_is_at_head
FAILED tests/integration/database/test_migration_validator_integration.py::TestMigrationValidatorIntegration::test_error_message_details
FAILED tests/integration/database/test_migration_validator_integration.py::TestMigrationValidatorIntegration::test_validate_single_migration
FAILED tests/integration/database/test_migration_validator_integration.py::TestMigrationValidatorIntegration::test_validate_nonexistent_migration
FAILED tests/integration/database/test_migration_validator_integration.py::TestMigrationValidatorIntegration::test_validate_after_downgrade
FAILED tests/integration/database/test_migration_validator_integration.py::TestMigrationValidatorIntegration::test_multiple_validators_same_database
====== 52 failed, 133 passed, 3 skipped, 32 warnings in 400.31s (0:06:40) ======

========================================
Test run completed at 2025-12-17 23:40:04
========================================
