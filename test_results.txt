========================================
Test Results - 2025-12-14 23:32:08
========================================
Environment Configuration:
  EMBEDDING_MODEL_NAME: Xenova/all-mpnet-base-v2
  EMBEDDING_MODEL_PATH: models/embedding
  LM_STUDIO_BASE_URL: http://192.168.56.1:1234/v1
  LM_STUDIO_MODEL: phi-4-mini-instruct

Command: pytest tests/integration/database/test_migration_integration.py tests/integration/models/test_fine_tuned_embeddings_integration.py tests/integration/services/test_onnx_embeddings_integration.py tests/integration/services/test_service_implementations.py tests/integration/services/test_service_integration.py tests/integration/strategies/test_contextual_integration.py tests/integration/strategies/test_hierarchical_integration.py tests/integration/strategies/test_knowledge_graph_integration.py tests/integration/strategies/test_late_chunking_integration.py tests/integration/strategies/test_multi_query_integration.py tests/integration/strategies/test_query_expansion_integration.py tests/integration/test_config_integration.py tests/integration/test_factory_integration.py tests/integration/test_package_integration.py tests/integration/test_pipeline_integration.py tests/unit/test_pipeline.py tests/unit/strategies/agentic/test_strategy.py tests/unit/documentation/test_links.py tests/unit/documentation/test_code_examples.py tests/unit/cli/test_check_consistency_command.py tests/unit/cli/test_repl_command.py tests/unit/services/test_interfaces.py tests/unit/services/test_database_service.py tests/unit/documentation/test_documentation_completeness.py tests/unit/database/test_migrations.py tests/unit/repositories/test_chunk_repository.py tests/unit/services/embeddings/test_onnx_local.py tests/unit/services/embedding/test_onnx_local_provider.py tests/unit/strategies/late_chunking/test_document_embedder.py
========================================

============================= test session starts ==============================
platform linux -- Python 3.12.3, pytest-9.0.1, pluggy-1.6.0 -- /mnt/MCPProyects/ragTools/venv/bin/python3
cachedir: .pytest_cache
rootdir: /mnt/MCPProyects/ragTools
configfile: pytest.ini (WARNING: ignoring pytest config in pyproject.toml!)
plugins: anyio-4.12.0, cov-7.0.0, asyncio-1.3.0
asyncio: mode=Mode.STRICT, debug=False, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function
collecting ... collected 292 items

tests/integration/database/test_migration_integration.py::TestMigrationIntegration::test_real_migration_execution FAILED [  0%]
tests/integration/database/test_migration_integration.py::TestMigrationIntegration::test_migration_with_existing_data FAILED [  0%]
tests/integration/database/test_migration_integration.py::TestMigrationIntegration::test_rollback_functionality FAILED [  1%]
tests/integration/database/test_migration_integration.py::TestMigrationIntegration::test_pgvector_extension_installed PASSED [  1%]
tests/integration/models/test_fine_tuned_embeddings_integration.py::test_register_and_load_model PASSED [  1%]
tests/integration/models/test_fine_tuned_embeddings_integration.py::test_ab_testing_workflow FAILED [  2%]
tests/integration/models/test_fine_tuned_embeddings_integration.py::test_model_registry_persistence_workflow PASSED [  2%]
tests/integration/models/test_fine_tuned_embeddings_integration.py::test_model_comparison_workflow FAILED [  2%]
tests/integration/models/test_fine_tuned_embeddings_integration.py::test_multiple_models_registry PASSED [  3%]
tests/integration/services/test_onnx_embeddings_integration.py::TestONNXEmbeddingsIntegration::test_embed_single_document PASSED [  3%]
tests/integration/services/test_onnx_embeddings_integration.py::TestONNXEmbeddingsIntegration::test_embed_multiple_documents PASSED [  3%]
tests/integration/services/test_onnx_embeddings_integration.py::TestONNXEmbeddingsIntegration::test_semantic_similarity PASSED [  4%]
tests/integration/services/test_onnx_embeddings_integration.py::TestONNXEmbeddingsIntegration::test_batch_consistency PASSED [  4%]
tests/integration/services/test_onnx_embeddings_integration.py::TestONNXEmbeddingsIntegration::test_empty_input PASSED [  4%]
tests/integration/services/test_onnx_embeddings_integration.py::TestONNXEmbeddingsIntegration::test_long_text_handling PASSED [  5%]
tests/integration/services/test_onnx_embeddings_integration.py::TestONNXEmbeddingsIntegration::test_special_characters PASSED [  5%]
tests/integration/services/test_onnx_embeddings_integration.py::TestONNXEmbeddingsIntegration::test_performance_target FAILED [  5%]
tests/integration/services/test_onnx_embeddings_integration.py::TestONNXEmbeddingsIntegration::test_provider_metadata PASSED [  6%]
tests/integration/services/test_onnx_embeddings_integration.py::TestONNXEmbeddingsIntegration::test_result_metadata PASSED [  6%]
tests/integration/services/test_service_implementations.py::TestONNXServices::test_onnx_embedding_service_implements_interface PASSED [  6%]
tests/integration/services/test_service_implementations.py::TestONNXServices::test_onnx_embedding_service_basic_functionality PASSED [  7%]
tests/integration/services/test_service_implementations.py::TestAPIServices::test_anthropic_llm_service_implements_interface PASSED [  7%]
tests/integration/services/test_service_implementations.py::TestAPIServices::test_anthropic_llm_service_basic_functionality PASSED [  7%]
tests/integration/services/test_service_implementations.py::TestAPIServices::test_openai_llm_service_implements_interface PASSED [  8%]
tests/integration/services/test_service_implementations.py::TestAPIServices::test_openai_embedding_service_implements_interface PASSED [  8%]
tests/integration/services/test_service_implementations.py::TestAPIServices::test_cohere_reranking_service_implements_interface PASSED [  8%]
tests/integration/services/test_service_implementations.py::TestAPIServices::test_cohere_reranking_service_basic_functionality PASSED [  9%]
tests/integration/services/test_service_implementations.py::TestDatabaseServices::test_neo4j_graph_service_implements_interface PASSED [  9%]
tests/integration/services/test_service_implementations.py::TestDatabaseServices::test_neo4j_graph_service_basic_functionality SKIPPED [  9%]
tests/integration/services/test_service_implementations.py::TestDatabaseServices::test_postgresql_database_service_implements_interface PASSED [ 10%]
tests/integration/services/test_service_implementations.py::TestDatabaseServices::test_postgresql_database_service_basic_functionality PASSED [ 10%]
tests/integration/services/test_service_implementations.py::TestLocalServices::test_cosine_reranking_service_implements_interface PASSED [ 10%]
tests/integration/services/test_service_implementations.py::TestLocalServices::test_cosine_reranking_service_basic_functionality PASSED [ 11%]
tests/integration/services/test_service_implementations.py::TestInterfaceCompliance::test_all_llm_services_implement_interface PASSED [ 11%]
tests/integration/services/test_service_implementations.py::TestInterfaceCompliance::test_all_embedding_services_implement_interface PASSED [ 11%]
tests/integration/services/test_service_implementations.py::TestInterfaceCompliance::test_all_reranking_services_implement_interface PASSED [ 12%]
tests/integration/services/test_service_implementations.py::TestInterfaceCompliance::test_all_graph_services_implement_interface PASSED [ 12%]
tests/integration/services/test_service_implementations.py::TestInterfaceCompliance::test_all_database_services_implement_interface PASSED [ 13%]
tests/integration/services/test_service_integration.py::test_rag_workflow ERROR [ 13%]
tests/integration/services/test_service_integration.py::test_embedding_database_consistency FAILED [ 13%]
tests/integration/strategies/test_contextual_integration.py::test_contextual_retrieval_complete_workflow FAILED [ 14%]
tests/integration/strategies/test_contextual_integration.py::test_cost_tracking_accuracy FAILED [ 14%]
tests/integration/strategies/test_contextual_integration.py::test_retrieval_with_different_formats FAILED [ 14%]
tests/integration/strategies/test_contextual_integration.py::test_error_recovery FAILED [ 15%]
tests/integration/strategies/test_contextual_integration.py::test_synchronous_indexing FAILED [ 15%]
tests/integration/strategies/test_contextual_integration.py::test_large_document_processing FAILED [ 15%]
tests/integration/strategies/test_hierarchical_integration.py::TestHierarchicalIntegration::test_end_to_end_workflow FAILED [ 16%]
tests/integration/strategies/test_hierarchical_integration.py::TestHierarchicalIntegration::test_expansion_strategy_comparison FAILED [ 16%]
tests/integration/strategies/test_hierarchical_integration.py::TestHierarchicalIntegration::test_hierarchy_validation FAILED [ 16%]
tests/integration/strategies/test_hierarchical_integration.py::TestHierarchicalIntegration::test_multiple_documents FAILED [ 17%]
tests/integration/strategies/test_knowledge_graph_integration.py::test_knowledge_graph_workflow PASSED [ 17%]
tests/integration/strategies/test_knowledge_graph_integration.py::test_hybrid_retrieval FAILED [ 17%]
tests/integration/strategies/test_knowledge_graph_integration.py::test_relationship_queries FAILED [ 18%]
tests/integration/strategies/test_knowledge_graph_integration.py::test_graph_statistics PASSED [ 18%]
tests/integration/strategies/test_late_chunking_integration.py::test_late_chunking_workflow FAILED [ 18%]
tests/integration/strategies/test_late_chunking_integration.py::test_fixed_size_chunking_integration PASSED [ 19%]
tests/integration/strategies/test_late_chunking_integration.py::test_adaptive_chunking_integration PASSED [ 19%]
tests/integration/strategies/test_late_chunking_integration.py::test_multiple_documents FAILED [ 19%]
tests/integration/strategies/test_late_chunking_integration.py::test_strategy_properties PASSED [ 20%]
tests/integration/strategies/test_late_chunking_integration.py::test_coherence_scores_computed PASSED [ 20%]
tests/integration/strategies/test_late_chunking_integration.py::test_short_document FAILED [ 20%]
tests/integration/strategies/test_late_chunking_integration.py::test_chunk_embeddings_valid PASSED [ 21%]
tests/integration/strategies/test_late_chunking_integration.py::test_embedding_quality PASSED [ 21%]
tests/integration/strategies/test_multi_query_integration.py::TestMultiQueryIntegration::test_multi_query_complete_workflow FAILED [ 21%]
tests/integration/strategies/test_multi_query_integration.py::TestMultiQueryIntegration::test_multi_query_async_workflow FAILED [ 22%]
tests/integration/strategies/test_multi_query_integration.py::TestMultiQueryIntegration::test_variant_diversity FAILED [ 22%]
tests/integration/strategies/test_multi_query_integration.py::TestMultiQueryIntegration::test_performance_requirements FAILED [ 22%]
tests/integration/strategies/test_multi_query_integration.py::TestMultiQueryIntegration::test_fallback_on_failure FAILED [ 23%]
tests/integration/strategies/test_multi_query_integration.py::TestMultiQueryIntegration::test_ranking_strategy_comparison FAILED [ 23%]
tests/integration/strategies/test_multi_query_integration.py::TestMultiQueryIntegration::test_deduplication_across_variants PASSED [ 23%]
tests/integration/strategies/test_multi_query_integration.py::TestMultiQueryIntegration::test_strategy_properties PASSED [ 24%]
tests/integration/strategies/test_multi_query_integration.py::TestMultiQueryWithLMStudio::test_with_real_llm FAILED [ 24%]
tests/integration/strategies/test_query_expansion_integration.py::TestQueryExpansionIntegration::test_keyword_expansion_real_llm PASSED [ 25%]
tests/integration/strategies/test_query_expansion_integration.py::TestQueryExpansionIntegration::test_query_reformulation PASSED [ 25%]
tests/integration/strategies/test_query_expansion_integration.py::TestQueryExpansionIntegration::test_question_generation PASSED [ 25%]
tests/integration/strategies/test_query_expansion_integration.py::TestQueryExpansionIntegration::test_hyde_expansion PASSED [ 26%]
tests/integration/strategies/test_query_expansion_integration.py::TestQueryExpansionIntegration::test_multi_query_generation PASSED [ 26%]
tests/integration/strategies/test_query_expansion_integration.py::TestQueryExpansionIntegration::test_expansion_performance PASSED [ 26%]
tests/integration/strategies/test_query_expansion_integration.py::TestQueryExpansionIntegration::test_cache_functionality PASSED [ 27%]
tests/integration/strategies/test_query_expansion_integration.py::TestQueryExpansionIntegration::test_ab_testing_functionality PASSED [ 27%]
tests/integration/strategies/test_query_expansion_integration.py::TestQueryExpansionIntegration::test_domain_context PASSED [ 27%]
tests/integration/strategies/test_query_expansion_integration.py::TestQueryExpansionIntegration::test_error_handling_fallback PASSED [ 28%]
tests/integration/strategies/test_query_expansion_integration.py::TestQueryExpansionIntegration::test_stats_tracking PASSED [ 28%]
tests/integration/test_config_integration.py::test_load_validate_use_config PASSED [ 28%]
tests/integration/test_config_integration.py::test_multi_environment_configuration PASSED [ 29%]
tests/integration/test_config_integration.py::test_config_with_factory FAILED [ 29%]
tests/integration/test_config_integration.py::test_config_with_pipeline PASSED [ 29%]
tests/integration/test_config_integration.py::test_complete_real_world_scenario PASSED [ 30%]
tests/integration/test_config_integration.py::test_config_export_and_reimport PASSED [ 30%]
tests/integration/test_config_integration.py::test_json_configuration_integration PASSED [ 30%]
tests/integration/test_config_integration.py::test_deeply_nested_configuration_access PASSED [ 31%]
tests/integration/test_factory_integration.py::test_register_create_use_strategy FAILED [ 31%]
tests/integration/test_factory_integration.py::test_create_multiple_different_strategies PASSED [ 31%]
tests/integration/test_factory_integration.py::test_create_multiple_instances_of_same_strategy FAILED [ 32%]
tests/integration/test_factory_integration.py::test_dependency_injection PASSED [ 32%]
tests/integration/test_factory_integration.py::test_config_file_with_yaml FAILED [ 32%]
tests/integration/test_factory_integration.py::test_config_file_with_json FAILED [ 33%]
tests/integration/test_factory_integration.py::test_factory_error_recovery FAILED [ 33%]
tests/integration/test_factory_integration.py::test_factory_state_after_failed_creation FAILED [ 33%]
tests/integration/test_factory_integration.py::test_decorator_integration PASSED [ 34%]
tests/integration/test_factory_integration.py::test_full_rag_workflow PASSED [ 34%]
tests/integration/test_factory_integration.py::test_async_retrieve_integration PASSED [ 34%]
tests/integration/test_package_integration.py::TestPackageInstallation::test_package_installable FAILED [ 35%]
tests/integration/test_package_integration.py::TestSmokeTest::test_basic_usage_smoke_test PASSED [ 35%]
tests/integration/test_package_integration.py::TestFullWorkflow::test_full_workflow_with_installed_package FAILED [ 35%]
tests/integration/test_package_integration.py::TestBuildAndDistribution::test_package_can_be_built SKIPPED [ 36%]
tests/integration/test_pipeline_integration.py::test_three_strategy_pipeline PASSED [ 36%]
tests/integration/test_pipeline_integration.py::test_parallel_faster_than_sequential PASSED [ 36%]
tests/integration/test_pipeline_integration.py::test_pipeline_continues_after_non_critical_failure FAILED [ 37%]
tests/integration/test_pipeline_integration.py::test_load_pipeline_from_yaml PASSED [ 37%]
tests/integration/test_pipeline_integration.py::test_async_sequential_execution PASSED [ 38%]
tests/integration/test_pipeline_integration.py::test_async_fallback_execution FAILED [ 38%]
tests/integration/test_pipeline_integration.py::test_parallel_execution_with_failures FAILED [ 38%]
tests/unit/test_pipeline.py::test_pipeline_can_be_created PASSED         [ 39%]
tests/unit/test_pipeline.py::test_pipeline_add_stage PASSED              [ 39%]
tests/unit/test_pipeline.py::test_pipeline_chaining PASSED               [ 39%]
tests/unit/test_pipeline.py::test_sequential_execution_order PASSED      [ 40%]
tests/unit/test_pipeline.py::test_sequential_execution_collects_results PASSED [ 40%]
tests/unit/test_pipeline.py::test_parallel_execution PASSED              [ 40%]
tests/unit/test_pipeline.py::test_strategy_error_caught PASSED           [ 41%]
tests/unit/test_pipeline.py::test_fallback_strategy_executed PASSED      [ 41%]
tests/unit/test_pipeline.py::test_duplicate_results_removed PASSED       [ 41%]
tests/unit/test_pipeline.py::test_results_sorted_by_score PASSED         [ 42%]
tests/unit/test_pipeline.py::test_performance_metrics_collected PASSED   [ 42%]
tests/unit/test_pipeline.py::test_from_config_creates_pipeline PASSED    [ 42%]
tests/unit/test_pipeline.py::test_cascade_mode_not_implemented PASSED    [ 43%]
tests/unit/test_pipeline.py::test_cascade_mode_not_implemented_async PASSED [ 43%]
tests/unit/test_pipeline.py::test_required_stage_failure_raises_exception PASSED [ 43%]
tests/unit/test_pipeline.py::test_required_stage_failure_raises_exception_async PASSED [ 44%]
tests/unit/test_pipeline.py::test_fallback_failure_when_required PASSED  [ 44%]
tests/unit/test_pipeline.py::test_fallback_failure_when_required_async PASSED [ 44%]
tests/unit/test_pipeline.py::test_parallel_required_stage_failure PASSED [ 45%]
tests/unit/test_pipeline.py::test_parallel_required_fallback_failure PASSED [ 45%]
tests/unit/test_pipeline.py::test_non_required_fallback_failure_continues PASSED [ 45%]
tests/unit/test_pipeline.py::test_non_required_fallback_failure_continues_async PASSED [ 46%]
tests/unit/test_pipeline.py::test_parallel_non_required_fallback_success PASSED [ 46%]
tests/unit/test_pipeline.py::test_parallel_non_required_both_fail PASSED [ 46%]
tests/unit/strategies/agentic/test_strategy.py::test_config_defaults PASSED [ 47%]
tests/unit/strategies/agentic/test_strategy.py::test_config_custom_values PASSED [ 47%]
tests/unit/strategies/agentic/test_strategy.py::test_config_validation PASSED [ 47%]
tests/unit/strategies/agentic/test_strategy.py::test_strategy_initialization PASSED [ 48%]
tests/unit/strategies/agentic/test_strategy.py::test_strategy_initialization_with_config PASSED [ 48%]
tests/unit/strategies/agentic/test_strategy.py::test_strategy_retrieve PASSED [ 48%]
tests/unit/strategies/agentic/test_strategy.py::test_strategy_retrieve_with_query_analysis PASSED [ 49%]
tests/unit/strategies/agentic/test_strategy.py::test_strategy_fallback_on_error PASSED [ 49%]
tests/unit/strategies/agentic/test_strategy.py::test_strategy_no_fallback_raises_error PASSED [ 50%]
tests/unit/strategies/agentic/test_strategy.py::test_strategy_get_stats PASSED [ 50%]
tests/unit/strategies/agentic/test_strategy.py::test_strategy_top_k_limit PASSED [ 50%]
tests/unit/documentation/test_links.py::TestDocumentationLinks::test_no_broken_internal_links PASSED [ 51%]
tests/unit/documentation/test_links.py::TestDocumentationLinks::test_all_diagrams_valid PASSED [ 51%]
tests/unit/documentation/test_links.py::TestDocumentationLinks::test_no_todo_links PASSED [ 51%]
tests/unit/documentation/test_links.py::TestDocumentationLinks::test_external_links_valid SKIPPED [ 52%]
tests/unit/documentation/test_code_examples.py::TestCodeExamples::test_all_code_examples_have_valid_syntax PASSED [ 52%]
tests/unit/documentation/test_code_examples.py::TestCodeExamples::test_strategy_examples_have_imports PASSED [ 52%]
tests/unit/documentation/test_code_examples.py::TestCodeExamples::test_configuration_examples_valid SKIPPED [ 53%]
tests/unit/documentation/test_code_examples.py::TestCodeExamples::test_quick_start_example_complete PASSED [ 53%]
tests/unit/documentation/test_code_examples.py::TestCodeExamples::test_no_placeholder_code PASSED [ 53%]
tests/unit/cli/test_check_consistency_command.py::TestCheckConsistencyCommand::test_command_help PASSED [ 54%]
tests/unit/cli/test_check_consistency_command.py::TestCheckConsistencyCommand::test_all_strategies_consistent PASSED [ 54%]
tests/unit/cli/test_check_consistency_command.py::TestCheckConsistencyCommand::test_strategies_with_warnings PASSED [ 54%]
tests/unit/cli/test_check_consistency_command.py::TestCheckConsistencyCommand::test_type_filter_indexing PASSED [ 55%]
tests/unit/cli/test_check_consistency_command.py::TestCheckConsistencyCommand::test_type_filter_retrieval PASSED [ 55%]
tests/unit/cli/test_check_consistency_command.py::TestCheckConsistencyCommand::test_invalid_type_filter PASSED [ 55%]
tests/unit/cli/test_check_consistency_command.py::TestCheckConsistencyCommand::test_strategy_filter PASSED [ 56%]
tests/unit/cli/test_check_consistency_command.py::TestCheckConsistencyCommand::test_verbose_mode PASSED [ 56%]
tests/unit/cli/test_check_consistency_command.py::TestCheckConsistencyCommand::test_config_file_loading PASSED [ 56%]
tests/unit/cli/test_check_consistency_command.py::TestCheckConsistencyCommand::test_system_error_returns_exit_code_1 PASSED [ 57%]
tests/unit/cli/test_check_consistency_command.py::TestCheckConsistencyCommand::test_strategies_with_errors PASSED [ 57%]
tests/unit/cli/test_repl_command.py::TestREPLCommand::test_repl_start PASSED [ 57%]
tests/unit/cli/test_repl_command.py::TestREPLCommand::test_repl_with_config PASSED [ 58%]
tests/unit/cli/test_repl_command.py::TestREPLSession::test_repl_session_init PASSED [ 58%]
tests/unit/cli/test_repl_command.py::TestREPLSession::test_repl_set_command PASSED [ 58%]
tests/unit/services/test_interfaces.py::test_illm_service_requires_implementation PASSED [ 59%]
tests/unit/services/test_interfaces.py::test_illm_service_requires_complete_method PASSED [ 59%]
tests/unit/services/test_interfaces.py::test_illm_service_requires_stream_complete_method PASSED [ 59%]
tests/unit/services/test_interfaces.py::test_illm_service_mock_implementation PASSED [ 60%]
tests/unit/services/test_interfaces.py::test_illm_service_has_docstring PASSED [ 60%]
tests/unit/services/test_interfaces.py::test_iembedding_service_requires_implementation PASSED [ 60%]
tests/unit/services/test_interfaces.py::test_iembedding_service_requires_embed_method PASSED [ 61%]
tests/unit/services/test_interfaces.py::test_iembedding_service_mock_implementation PASSED [ 61%]
tests/unit/services/test_interfaces.py::test_iembedding_service_has_docstring PASSED [ 61%]
tests/unit/services/test_interfaces.py::test_igraph_service_requires_implementation PASSED [ 62%]
tests/unit/services/test_interfaces.py::test_igraph_service_requires_create_node_method PASSED [ 62%]
tests/unit/services/test_interfaces.py::test_igraph_service_mock_implementation PASSED [ 63%]
tests/unit/services/test_interfaces.py::test_igraph_service_has_docstring PASSED [ 63%]
tests/unit/services/test_interfaces.py::test_ireranking_service_requires_implementation PASSED [ 63%]
tests/unit/services/test_interfaces.py::test_ireranking_service_mock_implementation PASSED [ 64%]
tests/unit/services/test_interfaces.py::test_ireranking_service_has_docstring PASSED [ 64%]
tests/unit/services/test_interfaces.py::test_idatabase_service_requires_implementation PASSED [ 64%]
tests/unit/services/test_interfaces.py::test_idatabase_service_requires_store_chunks_method PASSED [ 65%]
tests/unit/services/test_interfaces.py::test_idatabase_service_mock_implementation PASSED [ 65%]
tests/unit/services/test_interfaces.py::test_idatabase_service_has_docstring PASSED [ 65%]
tests/unit/services/test_interfaces.py::test_all_interfaces_have_type_hints PASSED [ 66%]
tests/unit/services/test_database_service.py::test_service_initialization PASSED [ 66%]
tests/unit/services/test_database_service.py::test_ensure_table PASSED   [ 66%]
tests/unit/services/test_database_service.py::test_store_chunks PASSED   [ 67%]
tests/unit/services/test_database_service.py::test_store_empty_chunks PASSED [ 67%]
tests/unit/services/test_database_service.py::test_search_chunks PASSED  [ 67%]
tests/unit/services/test_database_service.py::test_get_chunk PASSED      [ 68%]
tests/unit/services/test_database_service.py::test_get_chunk_not_found PASSED [ 68%]
tests/unit/services/test_database_service.py::test_get_chunks_for_documents PASSED [ 68%]
tests/unit/services/test_database_service.py::test_close PASSED          [ 69%]
tests/unit/services/test_database_service.py::test_context_manager PASSED [ 69%]
tests/unit/documentation/test_documentation_completeness.py::TestDocumentationCompleteness::test_required_doc_files_exist PASSED [ 69%]
tests/unit/documentation/test_documentation_completeness.py::TestDocumentationCompleteness::test_all_strategies_documented PASSED [ 70%]
tests/unit/documentation/test_documentation_completeness.py::TestDocumentationCompleteness::test_all_public_classes_documented PASSED [ 70%]
tests/unit/documentation/test_documentation_completeness.py::TestDocumentationCompleteness::test_all_public_methods_documented PASSED [ 70%]
tests/unit/documentation/test_documentation_completeness.py::TestDocumentationCompleteness::test_documentation_completeness_score PASSED [ 71%]
tests/unit/documentation/test_documentation_completeness.py::TestDocumentationCompleteness::test_mkdocs_config_valid PASSED [ 71%]
tests/unit/documentation/test_documentation_completeness.py::TestDocumentationCompleteness::test_readme_exists PASSED [ 71%]
tests/unit/documentation/test_documentation_completeness.py::TestDocumentationCompleteness::test_changelog_exists PASSED [ 72%]
tests/unit/database/test_migrations.py::TestAlembicMigrations::test_migration_upgrade_to_head PASSED [ 72%]
tests/unit/database/test_migrations.py::TestAlembicMigrations::test_migration_downgrade PASSED [ 72%]
tests/unit/database/test_migrations.py::TestAlembicMigrations::test_migration_history PASSED [ 73%]
tests/unit/database/test_migrations.py::TestAlembicMigrations::test_migration_idempotency PASSED [ 73%]
tests/unit/database/test_migrations.py::TestAlembicMigrations::test_get_current_version PASSED [ 73%]
tests/unit/database/test_migrations.py::TestAlembicMigrations::test_migration_creates_tables PASSED [ 74%]
tests/unit/database/test_migrations.py::TestAlembicMigrations::test_migration_creates_indexes PASSED [ 74%]
tests/unit/repositories/test_chunk_repository.py::TestChunkRepositoryCreate::test_create_chunk_success PASSED [ 75%]
tests/unit/repositories/test_chunk_repository.py::TestChunkRepositoryCreate::test_create_chunk_with_embedding PASSED [ 75%]
tests/unit/repositories/test_chunk_repository.py::TestChunkRepositoryCreate::test_create_chunk_with_metadata PASSED [ 75%]
tests/unit/repositories/test_chunk_repository.py::TestChunkRepositoryCreate::test_create_chunk_database_error PASSED [ 76%]
tests/unit/repositories/test_chunk_repository.py::TestChunkRepositoryCreate::test_bulk_create_chunks PASSED [ 76%]
tests/unit/repositories/test_chunk_repository.py::TestChunkRepositoryCreate::test_bulk_create_database_error PASSED [ 76%]
tests/unit/repositories/test_chunk_repository.py::TestChunkRepositoryRead::test_get_by_id_found PASSED [ 77%]
tests/unit/repositories/test_chunk_repository.py::TestChunkRepositoryRead::test_get_by_id_not_found PASSED [ 77%]
tests/unit/repositories/test_chunk_repository.py::TestChunkRepositoryRead::test_get_by_id_database_error PASSED [ 77%]
tests/unit/repositories/test_chunk_repository.py::TestChunkRepositoryRead::test_get_by_document PASSED [ 78%]
tests/unit/repositories/test_chunk_repository.py::TestChunkRepositoryRead::test_count_by_document PASSED [ 78%]
tests/unit/repositories/test_chunk_repository.py::TestChunkRepositoryUpdate::test_update_chunk_success PASSED [ 78%]
tests/unit/repositories/test_chunk_repository.py::TestChunkRepositoryUpdate::test_update_chunk_not_found PASSED [ 79%]
tests/unit/repositories/test_chunk_repository.py::TestChunkRepositoryUpdate::test_update_embedding PASSED [ 79%]
tests/unit/repositories/test_chunk_repository.py::TestChunkRepositoryUpdate::test_update_embedding_not_found PASSED [ 79%]
tests/unit/repositories/test_chunk_repository.py::TestChunkRepositoryUpdate::test_bulk_update_embeddings PASSED [ 80%]
tests/unit/repositories/test_chunk_repository.py::TestChunkRepositoryUpdate::test_bulk_update_embeddings_database_error PASSED [ 80%]
tests/unit/repositories/test_chunk_repository.py::TestChunkRepositoryDelete::test_delete_chunk_success PASSED [ 80%]
tests/unit/repositories/test_chunk_repository.py::TestChunkRepositoryDelete::test_delete_chunk_not_found PASSED [ 81%]
tests/unit/repositories/test_chunk_repository.py::TestChunkRepositoryDelete::test_delete_by_document PASSED [ 81%]
tests/unit/repositories/test_chunk_repository.py::TestChunkRepositoryDelete::test_delete_database_error PASSED [ 81%]
tests/unit/repositories/test_chunk_repository.py::TestChunkRepositoryVectorSearch::test_search_similar_validation_empty_embedding PASSED [ 82%]
tests/unit/repositories/test_chunk_repository.py::TestChunkRepositoryVectorSearch::test_search_similar_validation_invalid_top_k PASSED [ 82%]
tests/unit/repositories/test_chunk_repository.py::TestChunkRepositoryVectorSearch::test_search_similar_success PASSED [ 82%]
tests/unit/repositories/test_chunk_repository.py::TestChunkRepositoryVectorSearch::test_search_similar_with_threshold PASSED [ 83%]
tests/unit/repositories/test_chunk_repository.py::TestChunkRepositoryVectorSearch::test_search_similar_database_error PASSED [ 83%]
tests/unit/repositories/test_chunk_repository.py::TestChunkRepositoryVectorSearch::test_search_similar_with_filter_validation PASSED [ 83%]
tests/unit/repositories/test_chunk_repository.py::TestChunkRepositoryVectorSearch::test_search_similar_with_filter_success PASSED [ 84%]
tests/unit/repositories/test_chunk_repository.py::TestChunkRepositoryVectorSearch::test_search_similar_with_metadata_success PASSED [ 84%]
tests/unit/repositories/test_chunk_repository.py::TestChunkRepositoryVectorSearch::test_search_similar_with_metadata_validation PASSED [ 84%]
tests/unit/repositories/test_chunk_repository.py::TestChunkRepositoryEdgeCases::test_create_chunk_without_embedding PASSED [ 85%]
tests/unit/repositories/test_chunk_repository.py::TestChunkRepositoryEdgeCases::test_update_with_metadata_attribute PASSED [ 85%]
tests/unit/services/embeddings/test_onnx_local.py::TestONNXLocalProvider::test_initialization PASSED [ 85%]
tests/unit/services/embeddings/test_onnx_local.py::TestONNXLocalProvider::test_initialization_with_custom_config PASSED [ 86%]
tests/unit/services/embeddings/test_onnx_local.py::TestONNXLocalProvider::test_get_embeddings_single_text PASSED [ 86%]
tests/unit/services/embeddings/test_onnx_local.py::TestONNXLocalProvider::test_get_embeddings_multiple_texts PASSED [ 86%]
tests/unit/services/embeddings/test_onnx_local.py::TestONNXLocalProvider::test_get_embeddings_empty_list PASSED [ 87%]
tests/unit/services/embeddings/test_onnx_local.py::TestONNXLocalProvider::test_embedding_normalization PASSED [ 87%]
tests/unit/services/embeddings/test_onnx_local.py::TestONNXLocalProvider::test_tokenization_with_tiktoken PASSED [ 88%]
tests/unit/services/embeddings/test_onnx_local.py::TestONNXLocalProvider::test_tokenization_simple_fallback PASSED [ 88%]
tests/unit/services/embeddings/test_onnx_local.py::TestONNXLocalProvider::test_get_dimensions PASSED [ 88%]
tests/unit/services/embeddings/test_onnx_local.py::TestONNXLocalProvider::test_get_max_batch_size PASSED [ 89%]
tests/unit/services/embeddings/test_onnx_local.py::TestONNXLocalProvider::test_get_model_name PASSED [ 89%]
tests/unit/services/embeddings/test_onnx_local.py::TestONNXLocalProvider::test_calculate_cost PASSED [ 89%]
tests/unit/services/embeddings/test_onnx_local.py::TestONNXLocalProvider::test_known_models PASSED [ 90%]
tests/unit/services/embeddings/test_onnx_local.py::TestONNXLocalProvider::test_missing_onnx_runtime PASSED [ 90%]
tests/unit/services/embeddings/test_onnx_local.py::TestONNXLocalProvider::test_missing_huggingface_hub PASSED [ 90%]
tests/unit/services/embeddings/test_onnx_local.py::TestONNXLocalProvider::test_model_download_failure PASSED [ 91%]
tests/unit/services/embeddings/test_onnx_local.py::TestONNXLocalProvider::test_session_creation_failure PASSED [ 91%]
tests/unit/services/embeddings/test_onnx_local.py::TestONNXLocalProvider::test_embedding_error_handling PASSED [ 91%]
tests/unit/services/embeddings/test_onnx_local.py::TestONNXLocalProvider::test_batch_processing PASSED [ 92%]
tests/unit/services/embedding/test_onnx_local_provider.py::test_provider_not_available_raises_error PASSED [ 92%]
tests/unit/services/embedding/test_onnx_local_provider.py::test_provider_initialization PASSED [ 92%]
tests/unit/services/embedding/test_onnx_local_provider.py::test_get_embeddings PASSED [ 93%]
tests/unit/services/embedding/test_onnx_local_provider.py::test_calculate_cost_is_zero PASSED [ 93%]
tests/unit/services/embedding/test_onnx_local_provider.py::test_known_model_dimensions PASSED [ 93%]
tests/unit/services/embedding/test_onnx_local_provider.py::test_unknown_model_uses_output_shape PASSED [ 94%]
tests/unit/services/embedding/test_onnx_local_provider.py::test_custom_batch_size PASSED [ 94%]
tests/unit/services/embedding/test_onnx_local_provider.py::test_model_loading_failure PASSED [ 94%]
tests/unit/services/embedding/test_onnx_local_provider.py::test_get_model_name PASSED [ 95%]
tests/unit/services/embedding/test_onnx_local_provider.py::test_mean_pooling PASSED [ 95%]
tests/unit/strategies/late_chunking/test_document_embedder.py::test_document_embedding_basic PASSED [ 95%]
tests/unit/strategies/late_chunking/test_document_embedder.py::test_token_embeddings_extracted PASSED [ 96%]
tests/unit/strategies/late_chunking/test_document_embedder.py::test_mean_pooling PASSED [ 96%]
tests/unit/strategies/late_chunking/test_document_embedder.py::test_mean_pooling_with_mask PASSED [ 96%]
tests/unit/strategies/late_chunking/test_document_embedder.py::test_long_document_truncation PASSED [ 97%]
tests/unit/strategies/late_chunking/test_document_embedder.py::test_batch_processing PASSED [ 97%]
tests/unit/strategies/late_chunking/test_document_embedder.py::test_embedding_dimensions_consistent PASSED [ 97%]
tests/unit/strategies/late_chunking/test_document_embedder.py::test_model_name_stored PASSED [ 98%]
tests/unit/strategies/late_chunking/test_document_embedder.py::test_chunk_embeddings PASSED [ 98%]
tests/unit/strategies/late_chunking/test_document_embedder.py::test_pool_embeddings_mean PASSED [ 98%]
tests/unit/strategies/late_chunking/test_document_embedder.py::test_pool_embeddings_max PASSED [ 99%]
tests/unit/strategies/late_chunking/test_document_embedder.py::test_pool_embeddings_first PASSED [ 99%]
tests/unit/strategies/late_chunking/test_document_embedder.py::test_decode_tokens PASSED [100%]

==================================== ERRORS ====================================
_____________________ ERROR at setup of test_rag_workflow ______________________

    @pytest.fixture
    def llm_service():
        """Create LLM service."""
        config = LLMServiceConfig(
            provider="anthropic",
            model="claude-sonnet-4.5",
            enable_rate_limiting=False
        )
>       with patch("rag_factory.services.llm.service.AnthropicProvider") as mock_provider_cls:

tests/integration/services/test_service_integration.py:54: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.12/unittest/mock.py:1458: in __enter__
    original, local = self.get_original()
                      ^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x7283d60457f0>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'rag_factory.services.llm.service' from '/mnt/MCPProyects/ragTools/rag_factory/services/llm/service.py'> does not have the attribute 'AnthropicProvider'

/usr/lib/python3.12/unittest/mock.py:1431: AttributeError
=================================== FAILURES ===================================
____________ TestMigrationIntegration.test_real_migration_execution ____________

self = <sqlalchemy.engine.base.Connection object at 0x7283d89925d0>
dialect = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7283d8a4a600>
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x7283d8829d90>
statement = <sqlalchemy.dialects.postgresql.base.PGDDLCompiler object at 0x7283d8829c40>
parameters = [immutabledict({})]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7283d8a4a600>
cursor = <cursor object at 0x7283d8807e20; closed: -1>
statement = '\nDROP TABLE chunks', parameters = immutabledict({})
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x7283d8829d90>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       psycopg2.errors.UndefinedTable: table "chunks" does not exist

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: UndefinedTable

The above exception was the direct cause of the following exception:

self = <tests.integration.database.test_migration_integration.TestMigrationIntegration object at 0x7283e85abc20>
alembic_config = <alembic.config.Config object at 0x7283d8f31a90>
test_db_url = 'postgresql://rag_user:rag_password@192.168.56.1:5432/rag_test'

    @pytest.mark.asyncio
    async def test_real_migration_execution(self, alembic_config: Config, test_db_url: str) -> None:
        """Test running migrations against real database."""
        # Start from clean state
>       command.downgrade(alembic_config, "base")

tests/integration/database/test_migration_integration.py:29: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
venv/lib/python3.12/site-packages/alembic/command.py:449: in downgrade
    script.run_env()
venv/lib/python3.12/site-packages/alembic/script/base.py:583: in run_env
    util.load_python_file(self.dir, "env.py")
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:95: in load_python_file
    module = load_module_py(module_id, path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:113: in load_module_py
    spec.loader.exec_module(module)  # type: ignore
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
<frozen importlib._bootstrap_external>:995: in exec_module
    ???
<frozen importlib._bootstrap>:488: in _call_with_frames_removed
    ???
migrations/env.py:93: in <module>
    run_migrations_online()
migrations/env.py:87: in run_migrations_online
    context.run_migrations()
<string>:8: in run_migrations
    ???
venv/lib/python3.12/site-packages/alembic/runtime/environment.py:948: in run_migrations
    self.get_context().run_migrations(**kw)
venv/lib/python3.12/site-packages/alembic/runtime/migration.py:627: in run_migrations
    step.migration_fn(**kw)
migrations/versions/001_initial_schema.py:125: in downgrade
    op.drop_table("chunks")
<string>:8: in drop_table
    ???
<string>:3: in drop_table
    ???
venv/lib/python3.12/site-packages/alembic/operations/ops.py:1408: in drop_table
    operations.invoke(op)
venv/lib/python3.12/site-packages/alembic/operations/base.py:445: in invoke
    return fn(self, operation)
           ^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/toimpl.py:82: in drop_table
    operations.impl.drop_table(
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:389: in drop_table
    self._exec(schema.DropTable(table))
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:207: in _exec
    return conn.execute(construct, multiparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1416: in execute
    return meth(
venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:181: in _execute_on_connection
    return connection._execute_ddl(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1528: in _execute_ddl
    ret = self._execute_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1848: in _execute_context
    return self._exec_single_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1988: in _exec_single_context
    self._handle_dbapi_exception(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2343: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: in _exec_single_context
    self.dialect.do_execute(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7283d8a4a600>
cursor = <cursor object at 0x7283d8807e20; closed: -1>
statement = '\nDROP TABLE chunks', parameters = immutabledict({})
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x7283d8829d90>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) table "chunks" does not exist
E       
E       [SQL: 
E       DROP TABLE chunks]
E       (Background on this error at: https://sqlalche.me/e/20/f405)

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: ProgrammingError
----------------------------- Captured stderr call -----------------------------
INFO  [alembic.runtime.migration] Context impl PostgresqlImpl.
INFO  [alembic.runtime.migration] Will assume transactional DDL.
INFO  [alembic.runtime.migration] Running downgrade 002 -> 001, Add hierarchy support to chunks table
INFO  [alembic.runtime.migration] Running downgrade 001 -> , Initial schema with documents and chunks tables
__________ TestMigrationIntegration.test_migration_with_existing_data __________

self = <sqlalchemy.engine.base.Connection object at 0x7283d8917a70>
dialect = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7283d81864e0>
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x7283d81fd3a0>
statement = <sqlalchemy.dialects.postgresql.base.PGDDLCompiler object at 0x7283d81fd250>
parameters = [immutabledict({})]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7283d81864e0>
cursor = <cursor object at 0x7283d8102110; closed: -1>
statement = '\nDROP TABLE chunks', parameters = immutabledict({})
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x7283d81fd3a0>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       psycopg2.errors.UndefinedTable: table "chunks" does not exist

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: UndefinedTable

The above exception was the direct cause of the following exception:

self = <tests.integration.database.test_migration_integration.TestMigrationIntegration object at 0x7283e84a1400>
alembic_config = <alembic.config.Config object at 0x7283d882b380>
test_db_url = 'postgresql://rag_user:rag_password@192.168.56.1:5432/rag_test'

    @pytest.mark.asyncio
    async def test_migration_with_existing_data(self, alembic_config: Config, test_db_url: str) -> None:
        """Test migration with existing data in database."""
        # Start from clean state
>       command.downgrade(alembic_config, "base")

tests/integration/database/test_migration_integration.py:48: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
venv/lib/python3.12/site-packages/alembic/command.py:449: in downgrade
    script.run_env()
venv/lib/python3.12/site-packages/alembic/script/base.py:583: in run_env
    util.load_python_file(self.dir, "env.py")
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:95: in load_python_file
    module = load_module_py(module_id, path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:113: in load_module_py
    spec.loader.exec_module(module)  # type: ignore
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
<frozen importlib._bootstrap_external>:995: in exec_module
    ???
<frozen importlib._bootstrap>:488: in _call_with_frames_removed
    ???
migrations/env.py:93: in <module>
    run_migrations_online()
migrations/env.py:87: in run_migrations_online
    context.run_migrations()
<string>:8: in run_migrations
    ???
venv/lib/python3.12/site-packages/alembic/runtime/environment.py:948: in run_migrations
    self.get_context().run_migrations(**kw)
venv/lib/python3.12/site-packages/alembic/runtime/migration.py:627: in run_migrations
    step.migration_fn(**kw)
migrations/versions/001_initial_schema.py:125: in downgrade
    op.drop_table("chunks")
<string>:8: in drop_table
    ???
<string>:3: in drop_table
    ???
venv/lib/python3.12/site-packages/alembic/operations/ops.py:1408: in drop_table
    operations.invoke(op)
venv/lib/python3.12/site-packages/alembic/operations/base.py:445: in invoke
    return fn(self, operation)
           ^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/toimpl.py:82: in drop_table
    operations.impl.drop_table(
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:389: in drop_table
    self._exec(schema.DropTable(table))
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:207: in _exec
    return conn.execute(construct, multiparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1416: in execute
    return meth(
venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:181: in _execute_on_connection
    return connection._execute_ddl(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1528: in _execute_ddl
    ret = self._execute_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1848: in _execute_context
    return self._exec_single_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1988: in _exec_single_context
    self._handle_dbapi_exception(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2343: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: in _exec_single_context
    self.dialect.do_execute(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7283d81864e0>
cursor = <cursor object at 0x7283d8102110; closed: -1>
statement = '\nDROP TABLE chunks', parameters = immutabledict({})
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x7283d81fd3a0>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) table "chunks" does not exist
E       
E       [SQL: 
E       DROP TABLE chunks]
E       (Background on this error at: https://sqlalche.me/e/20/f405)

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: ProgrammingError
----------------------------- Captured stderr call -----------------------------
INFO  [alembic.runtime.migration] Context impl PostgresqlImpl.
INFO  [alembic.runtime.migration] Will assume transactional DDL.
INFO  [alembic.runtime.migration] Running downgrade 002 -> 001, Add hierarchy support to chunks table
INFO  [alembic.runtime.migration] Running downgrade 001 -> , Initial schema with documents and chunks tables
_____________ TestMigrationIntegration.test_rollback_functionality _____________

self = <sqlalchemy.engine.base.Connection object at 0x7283d81864b0>
dialect = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7283d81c8980>
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x7283d81cb770>
statement = <sqlalchemy.dialects.postgresql.base.PGDDLCompiler object at 0x7283d81cb530>
parameters = [immutabledict({})]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7283d81c8980>
cursor = <cursor object at 0x7283d81035b0; closed: -1>
statement = '\nDROP TABLE chunks', parameters = immutabledict({})
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x7283d81cb770>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       psycopg2.errors.UndefinedTable: table "chunks" does not exist

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: UndefinedTable

The above exception was the direct cause of the following exception:

self = <tests.integration.database.test_migration_integration.TestMigrationIntegration object at 0x7283e84a1730>
alembic_config = <alembic.config.Config object at 0x7283d81ffa70>
test_db_url = 'postgresql://rag_user:rag_password@192.168.56.1:5432/rag_test'

    @pytest.mark.asyncio
    async def test_rollback_functionality(self, alembic_config: Config, test_db_url: str) -> None:
        """Test rolling back migrations."""
        # Start from clean state
>       command.downgrade(alembic_config, "base")

tests/integration/database/test_migration_integration.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
venv/lib/python3.12/site-packages/alembic/command.py:449: in downgrade
    script.run_env()
venv/lib/python3.12/site-packages/alembic/script/base.py:583: in run_env
    util.load_python_file(self.dir, "env.py")
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:95: in load_python_file
    module = load_module_py(module_id, path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/util/pyfiles.py:113: in load_module_py
    spec.loader.exec_module(module)  # type: ignore
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
<frozen importlib._bootstrap_external>:995: in exec_module
    ???
<frozen importlib._bootstrap>:488: in _call_with_frames_removed
    ???
migrations/env.py:93: in <module>
    run_migrations_online()
migrations/env.py:87: in run_migrations_online
    context.run_migrations()
<string>:8: in run_migrations
    ???
venv/lib/python3.12/site-packages/alembic/runtime/environment.py:948: in run_migrations
    self.get_context().run_migrations(**kw)
venv/lib/python3.12/site-packages/alembic/runtime/migration.py:627: in run_migrations
    step.migration_fn(**kw)
migrations/versions/001_initial_schema.py:125: in downgrade
    op.drop_table("chunks")
<string>:8: in drop_table
    ???
<string>:3: in drop_table
    ???
venv/lib/python3.12/site-packages/alembic/operations/ops.py:1408: in drop_table
    operations.invoke(op)
venv/lib/python3.12/site-packages/alembic/operations/base.py:445: in invoke
    return fn(self, operation)
           ^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/alembic/operations/toimpl.py:82: in drop_table
    operations.impl.drop_table(
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:389: in drop_table
    self._exec(schema.DropTable(table))
venv/lib/python3.12/site-packages/alembic/ddl/impl.py:207: in _exec
    return conn.execute(construct, multiparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1416: in execute
    return meth(
venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:181: in _execute_on_connection
    return connection._execute_ddl(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1528: in _execute_ddl
    ret = self._execute_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1848: in _execute_context
    return self._exec_single_context(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1988: in _exec_single_context
    self._handle_dbapi_exception(
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2343: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1969: in _exec_single_context
    self.dialect.do_execute(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg2.PGDialect_psycopg2 object at 0x7283d81c8980>
cursor = <cursor object at 0x7283d81035b0; closed: -1>
statement = '\nDROP TABLE chunks', parameters = immutabledict({})
context = <sqlalchemy.dialects.postgresql.psycopg2.PGExecutionContext_psycopg2 object at 0x7283d81cb770>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) table "chunks" does not exist
E       
E       [SQL: 
E       DROP TABLE chunks]
E       (Background on this error at: https://sqlalche.me/e/20/f405)

venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:922: ProgrammingError
----------------------------- Captured stderr call -----------------------------
INFO  [alembic.runtime.migration] Context impl PostgresqlImpl.
INFO  [alembic.runtime.migration] Will assume transactional DDL.
INFO  [alembic.runtime.migration] Running downgrade 002 -> 001, Add hierarchy support to chunks table
INFO  [alembic.runtime.migration] Running downgrade 001 -> , Initial schema with documents and chunks tables
___________________________ test_ab_testing_workflow ___________________________

tmp_path = PosixPath('/tmp/pytest-of-admindevmac/pytest-103/test_ab_testing_workflow0')

    @pytest.mark.integration
    def test_ab_testing_workflow(tmp_path):
        """Test A/B testing with two models."""
        framework = ABTestingFramework()
    
        # Start A/B test
        config = ABTestConfig(
            test_name="model_comparison",
            model_a_id="base_model_a",
            model_b_id="fine_tuned",
            traffic_split=0.5,
            minimum_samples=50
        )
    
        framework.start_test(config)
    
        # Simulate requests with different performance
        np.random.seed(42)
    
        for i in range(100):
            if framework.should_use_model_b("model_comparison"):
                # Fine-tuned model: better performance
                framework.record_result(
                    "model_comparison",
                    "fine_tuned",
                    {
                        "latency": 45.0 + np.random.randn() * 2,
                        "accuracy": 0.88 + np.random.randn() * 0.02
                    }
                )
            else:
                # Base model: baseline performance
                framework.record_result(
                    "model_comparison",
                    "base_model",
                    {
                        "latency": 50.0 + np.random.randn() * 2,
                        "accuracy": 0.82 + np.random.randn() * 0.02
                    }
                )
    
        # Analyze results
        result = framework.analyze_test("model_comparison")
    
        # Verify results
        assert result.winner in ["model_b", "no_difference", "model_a"]
>       assert result.model_a_samples > 0
E       AssertionError: assert 0 > 0
E        +  where 0 = ABTestResult(test_name='model_comparison', model_a_id='base_model_a', model_b_id='fine_tuned', model_a_version=None, model_b_version=None, model_a_samples=0, model_b_samples=49, metrics={}, p_values={}, confidence_intervals={}, winner='no_difference', recommendation='No statistically significant difference detected', start_time=datetime.datetime(2025, 12, 14, 23, 33, 9, 613667), end_time=datetime.datetime(2025, 12, 14, 23, 33, 9, 615778)).model_a_samples

tests/integration/models/test_fine_tuned_embeddings_integration.py:121: AssertionError
________________________ test_model_comparison_workflow ________________________

tmp_path = PosixPath('/tmp/pytest-of-admindevmac/pytest-103/test_model_comparison_workflow0')

    def test_model_comparison_workflow(tmp_path):
        """Test comparing two models end-to-end.
    
        Note: Model loading is mocked to focus on testing the comparison infrastructure.
        """
        # Setup
        registry = ModelRegistry(registry_path=str(tmp_path / "registry"))
        loader = CustomModelLoader()
        ab_framework = ABTestingFramework()
    
        # Register base model (ONNX format)
        base_metadata = EmbeddingModelMetadata(
            model_id="base_model",
            model_name="Base Model",
            version="1.0.0",
            format=ModelFormat.ONNX,
            embedding_dim=384,
            max_seq_length=256
        )
        registry.register_model(base_metadata)
    
        # Mock model loading
        config = ModelConfig(
            model_path="Xenova/all-MiniLM-L6-v2",
            model_format=ModelFormat.ONNX,
            device="cpu",
            use_onnx=True
        )
    
        mock_model = Mock()
        mock_embeddings = np.random.randn(2, 384).tolist()
    
        with patch.object(loader, 'load_model', return_value=mock_model):
            with patch.object(loader, 'embed_texts', return_value=mock_embeddings):
                model = loader.load_model(config)
    
                # Start A/B test (comparing same model against itself for testing)
                test_config = ABTestConfig(
                    test_name="comparison",
                    model_a_id="base_model_a",
                    model_b_id="base_model_b",  # Different ID for A/B testing
                    traffic_split=0.5,
                    minimum_samples=10
                )
                ab_framework.start_test(test_config)
    
                # Simulate usage
                test_texts = ["Sample text 1", "Sample text 2"]
    
                for _ in range(20):
                    embeddings = loader.embed_texts(test_texts, model, config)
    
                    # Record metrics
                    model_id = "base_model"
                    ab_framework.record_result(
                        "comparison",
                        model_id,
                        {"latency": 50.0, "embedding_dim": len(embeddings[0])}
                    )
    
                # Analyze
                result = ab_framework.analyze_test("comparison")
    
                # Since it's the same model, should show no difference
                assert result.winner == "no_difference"
>               assert result.model_a_samples + result.model_b_samples == 20
E               AssertionError: assert (0 + 0) == 20
E                +  where 0 = ABTestResult(test_name='comparison', model_a_id='base_model_a', model_b_id='base_model_b', model_a_version=None, model_b_version=None, model_a_samples=0, model_b_samples=0, metrics={}, p_values={}, confidence_intervals={}, winner='no_difference', recommendation='No statistically significant difference detected', start_time=datetime.datetime(2025, 12, 14, 23, 33, 9, 734810), end_time=datetime.datetime(2025, 12, 14, 23, 33, 9, 735396)).model_a_samples
E                +  and   0 = ABTestResult(test_name='comparison', model_a_id='base_model_a', model_b_id='base_model_b', model_a_version=None, model_b_version=None, model_a_samples=0, model_b_samples=0, metrics={}, p_values={}, confidence_intervals={}, winner='no_difference', recommendation='No statistically significant difference detected', start_time=datetime.datetime(2025, 12, 14, 23, 33, 9, 734810), end_time=datetime.datetime(2025, 12, 14, 23, 33, 9, 735396)).model_b_samples

tests/integration/models/test_fine_tuned_embeddings_integration.py:282: AssertionError
____________ TestONNXEmbeddingsIntegration.test_performance_target _____________

self = <tests.integration.services.test_onnx_embeddings_integration.TestONNXEmbeddingsIntegration object at 0x7283d90e98e0>
embedding_provider = <rag_factory.services.embedding.providers.onnx_local.ONNXLocalProvider object at 0x7283d818dd00>

    def test_performance_target(self, embedding_provider):
        """Test that embedding speed meets performance target."""
        import time
    
        text = "This is a performance test document with reasonable length."
    
        # Warm up
        embedding_provider.get_embeddings([text])
    
        # Measure performance
        times = []
        for _ in range(10):
            start = time.perf_counter()
            embedding_provider.get_embeddings([text])
            elapsed = time.perf_counter() - start
            times.append(elapsed)
    
        avg_time = np.mean(times)
        p95_time = np.percentile(times, 95)
    
        # Should be < 100ms per document on CPU
>       assert avg_time < 0.1, f"Average time {avg_time*1000:.2f}ms exceeds 100ms target"
E       AssertionError: Average time 5830.60ms exceeds 100ms target
E       assert np.float64(5.830598435390857) < 0.1

tests/integration/services/test_onnx_embeddings_integration.py:167: AssertionError
_____________________ test_embedding_database_consistency ______________________

embedding_service = <rag_factory.services.embedding.service.EmbeddingService object at 0x7283d601f710>
database_service = (<rag_factory.services.database.postgres.PostgresqlDatabaseService object at 0x7283d6029220>, <AsyncMock name='create_pool().acquire().__aenter__()' id='125910556848976'>)

    @pytest.mark.asyncio
    async def test_embedding_database_consistency(embedding_service, database_service):
        """Test consistency between embedding dimensions and database storage."""
        db_service, db_conn = database_service
    
        # Get embedding dimension
        dim = embedding_service.provider.get_dimensions()
    
        # Create chunk with correct dimension
        embedding = [0.1] * dim
        chunk = {
            "chunk_id": "1",
            "text": "test",
            "embedding": embedding
        }
    
>       await db_service.store_chunks([chunk])

tests/integration/services/test_service_integration.py:158: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <rag_factory.services.database.postgres.PostgresqlDatabaseService object at 0x7283d6029220>
chunks = [{'chunk_id': '1', 'embedding': [0.1, 0.1, 0.1], 'text': 'test'}]

    async def store_chunks(self, chunks: List[Dict[str, Any]]) -> None:
        """Store document chunks.
    
        Args:
            chunks: List of chunk dictionaries. Each chunk should contain
                   at minimum: text content and embedding vector. Additional
                   fields like metadata, chunk_id, etc. are implementation-specific.
    
        Raises:
            Exception: If storage fails
        """
        if not chunks:
            return
    
        pool = await self._get_pool()
    
>       async with pool.acquire() as conn:
E       TypeError: 'coroutine' object does not support the asynchronous context manager protocol

rag_factory/services/database/postgres.py:157: TypeError
_________________ test_contextual_retrieval_complete_workflow __________________

mock_vector_store = <Mock id='125910556722528'>
mock_database = <Mock id='125910556894816'>
mock_llm_service = <Mock id='125910556894912'>
mock_embedding_service = <Mock id='125910556898800'>

    @pytest.mark.integration
    @pytest.mark.asyncio
    async def test_contextual_retrieval_complete_workflow(
        mock_vector_store,
        mock_database,
        mock_llm_service,
        mock_embedding_service
    ):
        """Test complete contextual retrieval workflow."""
        # Import StrategyDependencies
        from rag_factory.services.dependencies import StrategyDependencies
    
        # Setup strategy
        config = ContextualRetrievalConfig(
            enable_contextualization=True,
            batch_size=10
        )
    
        dependencies = StrategyDependencies(
            database_service=mock_database,
            llm_service=mock_llm_service,
            embedding_service=mock_embedding_service
        )
    
        strategy = ContextualRetrievalStrategy(
            config=config.dict(),
            dependencies=dependencies
        )
    
        # Prepare document chunks
        chunks = [
            {
                "chunk_id": f"chunk_{i}",
                "document_id": "doc_1",
                "text": f"This is chunk {i} about machine learning concepts.",
                "metadata": {"section_hierarchy": ["Chapter 1", f"Section {i}"]}
            }
            for i in range(20)
        ]
    
        # Index document
        result = await strategy.aindex_document(
            document="Full document text",
            document_id="doc_1",
            chunks=chunks,
            document_metadata={"title": "ML Guide"}
        )
    
        # Check indexing result
>       assert result["total_chunks"] == 20
E       assert 0 == 20

tests/integration/strategies/test_contextual_integration.py:119: AssertionError
_________________________ test_cost_tracking_accuracy __________________________

mock_vector_store = <Mock id='125910557571936'>
mock_database = <Mock id='125910557566128'>
mock_llm_service = <Mock id='125910557566896'>
mock_embedding_service = <Mock id='125910557568144'>

    @pytest.mark.integration
    @pytest.mark.asyncio
    async def test_cost_tracking_accuracy(
        mock_vector_store,
        mock_database,
        mock_llm_service,
        mock_embedding_service
    ):
        """Test accuracy of cost tracking."""
        from rag_factory.services.dependencies import StrategyDependencies
    
        config = ContextualRetrievalConfig(enable_cost_tracking=True)
    
        dependencies = StrategyDependencies(
            database_service=mock_database,
            llm_service=mock_llm_service,
            embedding_service=mock_embedding_service
        )
    
        strategy = ContextualRetrievalStrategy(
            config=config.dict(),
            dependencies=dependencies
        )
    
        chunks = [
            {"chunk_id": f"chunk_{i}", "text": f"Text {i} " * 20, "metadata": {}}
            for i in range(10)
        ]
    
        result = await strategy.aindex_document("doc", "doc_1", chunks)
    
        # Verify cost tracking
>       assert result["total_cost"] > 0
E       assert 0.0 > 0

tests/integration/strategies/test_contextual_integration.py:169: AssertionError
____________________ test_retrieval_with_different_formats _____________________

mock_vector_store = <Mock id='125910557570016'>
mock_database = <Mock id='125910557560368'>
mock_llm_service = <Mock id='125910557558880'>
mock_embedding_service = <Mock id='125910556891120'>

    @pytest.mark.integration
    @pytest.mark.asyncio
    async def test_retrieval_with_different_formats(
        mock_vector_store,
        mock_database,
        mock_llm_service,
        mock_embedding_service
    ):
        """Test retrieval with different return formats."""
        from rag_factory.services.dependencies import StrategyDependencies
    
        # Test with original text
        config_original = ContextualRetrievalConfig(
            return_original_text=True,
            return_context=False
        )
    
        dependencies = StrategyDependencies(
            database_service=mock_database,
            llm_service=mock_llm_service,
            embedding_service=mock_embedding_service
        )
    
        strategy = ContextualRetrievalStrategy(
            config=config_original.dict(),
            dependencies=dependencies
        )
    
        chunks = [{"chunk_id": f"c{i}", "text": f"Text {i}", "metadata": {}} for i in range(5)]
        await strategy.aindex_document("doc", "doc_1", chunks)
    
        results = strategy.retrieve("query", top_k=2)
>       assert len(results) == 2
E       assert 0 == 2
E        +  where 0 = len([])

tests/integration/strategies/test_contextual_integration.py:209: AssertionError
_____________________________ test_error_recovery ______________________________

mock_vector_store = <Mock id='125910591797248'>
mock_database = <Mock id='125910591797488'>
mock_llm_service = <Mock id='125910591798064'>
mock_embedding_service = <Mock id='125910570893536'>

    @pytest.mark.integration
    @pytest.mark.asyncio
    async def test_error_recovery(
        mock_vector_store,
        mock_database,
        mock_llm_service,
        mock_embedding_service
    ):
        """Test error recovery with fallback."""
        from rag_factory.services.dependencies import StrategyDependencies
    
        # Make LLM fail for some chunks
        call_count = 0
    
        async def flaky_generate(prompt, temperature, max_tokens):
            nonlocal call_count
            call_count += 1
            if call_count % 3 == 0:
                raise Exception("LLM error")
            response = Mock()
            response.text = "Context description"
            return response
    
        mock_llm_service.agenerate = flaky_generate
    
        config = ContextualRetrievalConfig(
            fallback_to_no_context=True,
            batch_size=5
        )
    
        dependencies = StrategyDependencies(
            database_service=mock_database,
            llm_service=mock_llm_service,
            embedding_service=mock_embedding_service
        )
    
        strategy = ContextualRetrievalStrategy(
            config=config.dict(),
            dependencies=dependencies
        )
    
        chunks = [{"chunk_id": f"c{i}", "text": f"Text {i}", "metadata": {}} for i in range(10)]
    
        # Should complete despite errors
        result = await strategy.aindex_document("doc", "doc_1", chunks)
    
>       assert result["total_chunks"] == 10
E       assert 0 == 10

tests/integration/strategies/test_contextual_integration.py:259: AssertionError
__________________________ test_synchronous_indexing ___________________________

mock_vector_store = <Mock id='125910570897040'>
mock_database = <Mock id='125910570900256'>
mock_llm_service = <Mock id='125910570899344'>
mock_embedding_service = <Mock id='125910570904144'>

    @pytest.mark.integration
    def test_synchronous_indexing(
        mock_vector_store,
        mock_database,
        mock_llm_service,
        mock_embedding_service
    ):
        """Test synchronous indexing wrapper."""
        from rag_factory.services.dependencies import StrategyDependencies
    
        config = ContextualRetrievalConfig(batch_size=5)
    
        dependencies = StrategyDependencies(
            database_service=mock_database,
            llm_service=mock_llm_service,
            embedding_service=mock_embedding_service
        )
    
        strategy = ContextualRetrievalStrategy(
            config=config.dict(),
            dependencies=dependencies
        )
    
        chunks = [{"chunk_id": f"c{i}", "text": f"Text {i}", "metadata": {}} for i in range(5)]
    
        # Use synchronous method
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
    
        result = loop.run_until_complete(
            strategy.aindex_document("doc", "doc_1", chunks)
        )
    
        loop.close()
    
>       assert result["total_chunks"] == 5
E       assert 0 == 5

tests/integration/strategies/test_contextual_integration.py:299: AssertionError
________________________ test_large_document_processing ________________________

mock_vector_store = <Mock id='125910570907120'>
mock_database = <Mock id='125910570906256'>
mock_llm_service = <Mock id='125910570905968'>
mock_embedding_service = <Mock id='125910571158272'>

    @pytest.mark.integration
    @pytest.mark.asyncio
    async def test_large_document_processing(
        mock_vector_store,
        mock_database,
        mock_llm_service,
        mock_embedding_service
    ):
        """Test processing large documents."""
        from rag_factory.services.dependencies import StrategyDependencies
    
        config = ContextualRetrievalConfig(
            batch_size=20,
            enable_parallel_batches=True,
            max_concurrent_batches=5
        )
    
        dependencies = StrategyDependencies(
            database_service=mock_database,
            llm_service=mock_llm_service,
            embedding_service=mock_embedding_service
        )
    
        strategy = ContextualRetrievalStrategy(
            config=config.dict(),
            dependencies=dependencies
        )
    
        # Large document with 100 chunks
        chunks = [
            {"chunk_id": f"c{i}", "text": f"Text {i} " * 20, "metadata": {}}
            for i in range(100)
        ]
    
        result = await strategy.aindex_document("doc", "doc_1", chunks)
    
>       assert result["total_chunks"] == 100
E       assert 0 == 100

tests/integration/strategies/test_contextual_integration.py:338: AssertionError
_____________ TestHierarchicalIntegration.test_end_to_end_workflow _____________

self = <tests.integration.strategies.test_hierarchical_integration.TestHierarchicalIntegration object at 0x7283d914dac0>
mock_vector_store = <tests.integration.strategies.test_hierarchical_integration.TestHierarchicalIntegration.mock_vector_store.<locals>.MockVectorStore object at 0x7283d6de3d10>
mock_database = <tests.integration.strategies.test_hierarchical_integration.TestHierarchicalIntegration.mock_database.<locals>.MockDatabase object at 0x7283d6de3dd0>

        def test_end_to_end_workflow(self, mock_vector_store, mock_database):
            """Test complete hierarchical retrieval workflow."""
            # Create strategy
            strategy = HierarchicalRAGStrategy(
                vector_store_service=mock_vector_store,
                database_service=mock_database,
                config={"expansion_strategy": ExpansionStrategy.IMMEDIATE_PARENT}
            )
    
            # Index a document
            markdown_doc = """# Test Document
    
    ## Section 1
    
    This is the first section with important information about machine learning.
    
    ## Section 2
    
    This section discusses deep learning and neural networks.
    """
    
>           strategy.index_document(markdown_doc, "test_doc_001")

tests/integration/strategies/test_hierarchical_integration.py:110: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
rag_factory/strategies/hierarchical/strategy.py:162: in index_document
    document_id=UUID(h_chunk.document_id),
                ^^^^^^^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'UUID' object has no attribute 'int'") raised in repr()] UUID object at 0x7283d89a0e90>
hex = 'test_doc_001', bytes = None, bytes_le = None, fields = None, int = None
version = None

    def __init__(self, hex=None, bytes=None, bytes_le=None, fields=None,
                       int=None, version=None,
                       *, is_safe=SafeUUID.unknown):
        r"""Create a UUID from either a string of 32 hexadecimal digits,
        a string of 16 bytes as the 'bytes' argument, a string of 16 bytes
        in little-endian order as the 'bytes_le' argument, a tuple of six
        integers (32-bit time_low, 16-bit time_mid, 16-bit time_hi_version,
        8-bit clock_seq_hi_variant, 8-bit clock_seq_low, 48-bit node) as
        the 'fields' argument, or a single 128-bit integer as the 'int'
        argument.  When a string of hex digits is given, curly braces,
        hyphens, and a URN prefix are all optional.  For example, these
        expressions all yield the same UUID:
    
        UUID('{12345678-1234-5678-1234-567812345678}')
        UUID('12345678123456781234567812345678')
        UUID('urn:uuid:12345678-1234-5678-1234-567812345678')
        UUID(bytes='\x12\x34\x56\x78'*4)
        UUID(bytes_le='\x78\x56\x34\x12\x34\x12\x78\x56' +
                      '\x12\x34\x56\x78\x12\x34\x56\x78')
        UUID(fields=(0x12345678, 0x1234, 0x5678, 0x12, 0x34, 0x567812345678))
        UUID(int=0x12345678123456781234567812345678)
    
        Exactly one of 'hex', 'bytes', 'bytes_le', 'fields', or 'int' must
        be given.  The 'version' argument is optional; if given, the resulting
        UUID will have its variant and version set according to RFC 4122,
        overriding the given 'hex', 'bytes', 'bytes_le', 'fields', or 'int'.
    
        is_safe is an enum exposed as an attribute on the instance.  It
        indicates whether the UUID has been generated in a way that is safe
        for multiprocessing applications, via uuid_generate_time_safe(3).
        """
    
        if [hex, bytes, bytes_le, fields, int].count(None) != 4:
            raise TypeError('one of the hex, bytes, bytes_le, fields, '
                            'or int arguments must be given')
        if hex is not None:
            hex = hex.replace('urn:', '').replace('uuid:', '')
            hex = hex.strip('{}').replace('-', '')
            if len(hex) != 32:
>               raise ValueError('badly formed hexadecimal UUID string')
E               ValueError: badly formed hexadecimal UUID string

/usr/lib/python3.12/uuid.py:178: ValueError
________ TestHierarchicalIntegration.test_expansion_strategy_comparison ________

self = <tests.integration.strategies.test_hierarchical_integration.TestHierarchicalIntegration object at 0x7283d914ddf0>
mock_vector_store = <tests.integration.strategies.test_hierarchical_integration.TestHierarchicalIntegration.mock_vector_store.<locals>.MockVectorStore object at 0x7283d6da3950>
mock_database = <tests.integration.strategies.test_hierarchical_integration.TestHierarchicalIntegration.mock_database.<locals>.MockDatabase object at 0x7283d6da3c20>

        def test_expansion_strategy_comparison(self, mock_vector_store, mock_database):
            """Test different expansion strategies produce different results."""
            strategy = HierarchicalRAGStrategy(
                vector_store_service=mock_vector_store,
                database_service=mock_database,
                config={"expansion_strategy": ExpansionStrategy.IMMEDIATE_PARENT}
            )
    
            doc = """# Title
    
    ## Section
    
    Paragraph 1 with content.
    
    Paragraph 2 with more content.
    """
    
>           strategy.index_document(doc, "test_doc")

tests/integration/strategies/test_hierarchical_integration.py:143: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
rag_factory/strategies/hierarchical/strategy.py:162: in index_document
    document_id=UUID(h_chunk.document_id),
                ^^^^^^^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'UUID' object has no attribute 'int'") raised in repr()] UUID object at 0x7283d75690d0>
hex = 'test_doc', bytes = None, bytes_le = None, fields = None, int = None
version = None

    def __init__(self, hex=None, bytes=None, bytes_le=None, fields=None,
                       int=None, version=None,
                       *, is_safe=SafeUUID.unknown):
        r"""Create a UUID from either a string of 32 hexadecimal digits,
        a string of 16 bytes as the 'bytes' argument, a string of 16 bytes
        in little-endian order as the 'bytes_le' argument, a tuple of six
        integers (32-bit time_low, 16-bit time_mid, 16-bit time_hi_version,
        8-bit clock_seq_hi_variant, 8-bit clock_seq_low, 48-bit node) as
        the 'fields' argument, or a single 128-bit integer as the 'int'
        argument.  When a string of hex digits is given, curly braces,
        hyphens, and a URN prefix are all optional.  For example, these
        expressions all yield the same UUID:
    
        UUID('{12345678-1234-5678-1234-567812345678}')
        UUID('12345678123456781234567812345678')
        UUID('urn:uuid:12345678-1234-5678-1234-567812345678')
        UUID(bytes='\x12\x34\x56\x78'*4)
        UUID(bytes_le='\x78\x56\x34\x12\x34\x12\x78\x56' +
                      '\x12\x34\x56\x78\x12\x34\x56\x78')
        UUID(fields=(0x12345678, 0x1234, 0x5678, 0x12, 0x34, 0x567812345678))
        UUID(int=0x12345678123456781234567812345678)
    
        Exactly one of 'hex', 'bytes', 'bytes_le', 'fields', or 'int' must
        be given.  The 'version' argument is optional; if given, the resulting
        UUID will have its variant and version set according to RFC 4122,
        overriding the given 'hex', 'bytes', 'bytes_le', 'fields', or 'int'.
    
        is_safe is an enum exposed as an attribute on the instance.  It
        indicates whether the UUID has been generated in a way that is safe
        for multiprocessing applications, via uuid_generate_time_safe(3).
        """
    
        if [hex, bytes, bytes_le, fields, int].count(None) != 4:
            raise TypeError('one of the hex, bytes, bytes_le, fields, '
                            'or int arguments must be given')
        if hex is not None:
            hex = hex.replace('urn:', '').replace('uuid:', '')
            hex = hex.strip('{}').replace('-', '')
            if len(hex) != 32:
>               raise ValueError('badly formed hexadecimal UUID string')
E               ValueError: badly formed hexadecimal UUID string

/usr/lib/python3.12/uuid.py:178: ValueError
____________ TestHierarchicalIntegration.test_hierarchy_validation _____________

self = <tests.integration.strategies.test_hierarchical_integration.TestHierarchicalIntegration object at 0x7283d914e120>
mock_vector_store = <tests.integration.strategies.test_hierarchical_integration.TestHierarchicalIntegration.mock_vector_store.<locals>.MockVectorStore object at 0x7283d6da2480>
mock_database = <tests.integration.strategies.test_hierarchical_integration.TestHierarchicalIntegration.mock_database.<locals>.MockDatabase object at 0x7283d6da26f0>

    def test_hierarchy_validation(self, mock_vector_store, mock_database):
        """Test hierarchy validation."""
        strategy = HierarchicalRAGStrategy(
            vector_store_service=mock_vector_store,
            database_service=mock_database
        )
    
        doc = "# Title\n\n## Section\n\nContent"
>       strategy.index_document(doc, "test_doc")

tests/integration/strategies/test_hierarchical_integration.py:171: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
rag_factory/strategies/hierarchical/strategy.py:162: in index_document
    document_id=UUID(h_chunk.document_id),
                ^^^^^^^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'UUID' object has no attribute 'int'") raised in repr()] UUID object at 0x7283d8189e10>
hex = 'test_doc', bytes = None, bytes_le = None, fields = None, int = None
version = None

    def __init__(self, hex=None, bytes=None, bytes_le=None, fields=None,
                       int=None, version=None,
                       *, is_safe=SafeUUID.unknown):
        r"""Create a UUID from either a string of 32 hexadecimal digits,
        a string of 16 bytes as the 'bytes' argument, a string of 16 bytes
        in little-endian order as the 'bytes_le' argument, a tuple of six
        integers (32-bit time_low, 16-bit time_mid, 16-bit time_hi_version,
        8-bit clock_seq_hi_variant, 8-bit clock_seq_low, 48-bit node) as
        the 'fields' argument, or a single 128-bit integer as the 'int'
        argument.  When a string of hex digits is given, curly braces,
        hyphens, and a URN prefix are all optional.  For example, these
        expressions all yield the same UUID:
    
        UUID('{12345678-1234-5678-1234-567812345678}')
        UUID('12345678123456781234567812345678')
        UUID('urn:uuid:12345678-1234-5678-1234-567812345678')
        UUID(bytes='\x12\x34\x56\x78'*4)
        UUID(bytes_le='\x78\x56\x34\x12\x34\x12\x78\x56' +
                      '\x12\x34\x56\x78\x12\x34\x56\x78')
        UUID(fields=(0x12345678, 0x1234, 0x5678, 0x12, 0x34, 0x567812345678))
        UUID(int=0x12345678123456781234567812345678)
    
        Exactly one of 'hex', 'bytes', 'bytes_le', 'fields', or 'int' must
        be given.  The 'version' argument is optional; if given, the resulting
        UUID will have its variant and version set according to RFC 4122,
        overriding the given 'hex', 'bytes', 'bytes_le', 'fields', or 'int'.
    
        is_safe is an enum exposed as an attribute on the instance.  It
        indicates whether the UUID has been generated in a way that is safe
        for multiprocessing applications, via uuid_generate_time_safe(3).
        """
    
        if [hex, bytes, bytes_le, fields, int].count(None) != 4:
            raise TypeError('one of the hex, bytes, bytes_le, fields, '
                            'or int arguments must be given')
        if hex is not None:
            hex = hex.replace('urn:', '').replace('uuid:', '')
            hex = hex.strip('{}').replace('-', '')
            if len(hex) != 32:
>               raise ValueError('badly formed hexadecimal UUID string')
E               ValueError: badly formed hexadecimal UUID string

/usr/lib/python3.12/uuid.py:178: ValueError
_____________ TestHierarchicalIntegration.test_multiple_documents ______________

self = <tests.integration.strategies.test_hierarchical_integration.TestHierarchicalIntegration object at 0x7283d914e450>
mock_vector_store = <tests.integration.strategies.test_hierarchical_integration.TestHierarchicalIntegration.mock_vector_store.<locals>.MockVectorStore object at 0x7283d602b350>
mock_database = <tests.integration.strategies.test_hierarchical_integration.TestHierarchicalIntegration.mock_database.<locals>.MockDatabase object at 0x7283d602b410>

    def test_multiple_documents(self, mock_vector_store, mock_database):
        """Test indexing multiple documents."""
        strategy = HierarchicalRAGStrategy(
            vector_store_service=mock_vector_store,
            database_service=mock_database
        )
    
        doc1 = "# Document 1\n\nContent about AI"
        doc2 = "# Document 2\n\nContent about ML"
    
>       strategy.index_document(doc1, "doc1")

tests/integration/strategies/test_hierarchical_integration.py:189: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
rag_factory/strategies/hierarchical/strategy.py:162: in index_document
    document_id=UUID(h_chunk.document_id),
                ^^^^^^^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'UUID' object has no attribute 'int'") raised in repr()] UUID object at 0x7283d61b5850>
hex = 'doc1', bytes = None, bytes_le = None, fields = None, int = None
version = None

    def __init__(self, hex=None, bytes=None, bytes_le=None, fields=None,
                       int=None, version=None,
                       *, is_safe=SafeUUID.unknown):
        r"""Create a UUID from either a string of 32 hexadecimal digits,
        a string of 16 bytes as the 'bytes' argument, a string of 16 bytes
        in little-endian order as the 'bytes_le' argument, a tuple of six
        integers (32-bit time_low, 16-bit time_mid, 16-bit time_hi_version,
        8-bit clock_seq_hi_variant, 8-bit clock_seq_low, 48-bit node) as
        the 'fields' argument, or a single 128-bit integer as the 'int'
        argument.  When a string of hex digits is given, curly braces,
        hyphens, and a URN prefix are all optional.  For example, these
        expressions all yield the same UUID:
    
        UUID('{12345678-1234-5678-1234-567812345678}')
        UUID('12345678123456781234567812345678')
        UUID('urn:uuid:12345678-1234-5678-1234-567812345678')
        UUID(bytes='\x12\x34\x56\x78'*4)
        UUID(bytes_le='\x78\x56\x34\x12\x34\x12\x78\x56' +
                      '\x12\x34\x56\x78\x12\x34\x56\x78')
        UUID(fields=(0x12345678, 0x1234, 0x5678, 0x12, 0x34, 0x567812345678))
        UUID(int=0x12345678123456781234567812345678)
    
        Exactly one of 'hex', 'bytes', 'bytes_le', 'fields', or 'int' must
        be given.  The 'version' argument is optional; if given, the resulting
        UUID will have its variant and version set according to RFC 4122,
        overriding the given 'hex', 'bytes', 'bytes_le', 'fields', or 'int'.
    
        is_safe is an enum exposed as an attribute on the instance.  It
        indicates whether the UUID has been generated in a way that is safe
        for multiprocessing applications, via uuid_generate_time_safe(3).
        """
    
        if [hex, bytes, bytes_le, fields, int].count(None) != 4:
            raise TypeError('one of the hex, bytes, bytes_le, fields, '
                            'or int arguments must be given')
        if hex is not None:
            hex = hex.replace('urn:', '').replace('uuid:', '')
            hex = hex.strip('{}').replace('-', '')
            if len(hex) != 32:
>               raise ValueError('badly formed hexadecimal UUID string')
E               ValueError: badly formed hexadecimal UUID string

/usr/lib/python3.12/uuid.py:178: ValueError
____________________________ test_hybrid_retrieval _____________________________

mock_vector_store = <Mock id='125910608007088'>
mock_llm = <Mock id='125910608006848'>
mock_embedding_service = <Mock id='125910608006512'>
mock_graph_service = <Mock id='125910608005984'>
config = KnowledgeGraphConfig(entity_types=[<EntityType.PERSON: 'person'>, <EntityType.PLACE: 'place'>, <EntityType.ORGANIZATIO...ship_confidence=0.5, min_relationship_strength=0.3, batch_size=10, enable_entity_deduplication=True, neo4j_config=None)

    @pytest.mark.integration
    def test_hybrid_retrieval(mock_vector_store, mock_llm, mock_embedding_service, mock_graph_service, config):
        """Test hybrid retrieval combining vector and graph."""
        from rag_factory.services.dependencies import StrategyDependencies
    
        dependencies = StrategyDependencies(
            llm_service=mock_llm,
            embedding_service=mock_embedding_service,
            graph_service=mock_graph_service
        )
    
        strategy = KnowledgeGraphRAGStrategy(
            config=config.dict() if hasattr(config, 'dict') else config.__dict__,
            dependencies=dependencies
        )
    
        # Index document
        document = """Python is a popular programming language for Machine Learning.
    
    Machine Learning is a subset of Artificial Intelligence."""
    
        strategy.index_document(document, "ml_doc")
    
        # Retrieve with hybrid search
>       results = strategy.retrieve("What is Machine Learning?", top_k=3)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/integration/strategies/test_knowledge_graph_integration.py:168: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
rag_factory/strategies/knowledge_graph/strategy.py:195: in retrieve
    results = self.hybrid_retriever.retrieve(query, top_k=top_k, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <rag_factory.strategies.knowledge_graph.hybrid_retriever.HybridRetriever object at 0x7283d9104950>
query = 'What is Machine Learning?', top_k = 3, kwargs = {}

    def retrieve(
        self,
        query: str,
        top_k: int = 5,
        **kwargs
    ) -> List[HybridSearchResult]:
        """
        Hybrid retrieval combining vector search and graph traversal.
    
        Args:
            query: Search query
            top_k: Number of results to return
            **kwargs: Additional parameters
    
        Returns:
            List of hybrid search results
        """
        logger.info(f"Hybrid retrieval for query: {query}")
    
        # Step 1: Vector search
>       vector_results = self.vector_store.search(query, top_k=top_k * 2)
                         ^^^^^^^^^^^^^^^^^^^^^^^^
E       AttributeError: 'NoneType' object has no attribute 'search'

rag_factory/strategies/knowledge_graph/hybrid_retriever.py:64: AttributeError
__________________________ test_relationship_queries ___________________________

mock_vector_store = <Mock id='125910867837392'>
mock_llm = <Mock id='125910867837680'>
mock_embedding_service = <Mock id='125910867842912'>
mock_graph_service = <Mock id='125910867838736'>
config = KnowledgeGraphConfig(entity_types=[<EntityType.PERSON: 'person'>, <EntityType.PLACE: 'place'>, <EntityType.ORGANIZATIO...ship_confidence=0.5, min_relationship_strength=0.3, batch_size=10, enable_entity_deduplication=True, neo4j_config=None)

    @pytest.mark.integration
    def test_relationship_queries(mock_vector_store, mock_llm, mock_embedding_service, mock_graph_service, config):
        """Test relationship-based queries."""
        from rag_factory.services.dependencies import StrategyDependencies
    
        dependencies = StrategyDependencies(
            llm_service=mock_llm,
            embedding_service=mock_embedding_service,
            graph_service=mock_graph_service
        )
    
        strategy = KnowledgeGraphRAGStrategy(
            config=config.dict() if hasattr(config, 'dict') else config.__dict__,
            dependencies=dependencies
        )
    
        document = """Climate change causes rising temperatures.
    
    Rising temperatures lead to glacier melting.
    
    Glacier melting results in sea level rise."""
    
        strategy.index_document(document, "climate_doc")
    
        # Query about causal relationships
>       results = strategy.retrieve("What causes sea level rise?", top_k=3)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/integration/strategies/test_knowledge_graph_integration.py:202: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
rag_factory/strategies/knowledge_graph/strategy.py:195: in retrieve
    results = self.hybrid_retriever.retrieve(query, top_k=top_k, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <rag_factory.strategies.knowledge_graph.hybrid_retriever.HybridRetriever object at 0x7283e88d3350>
query = 'What causes sea level rise?', top_k = 3, kwargs = {}

    def retrieve(
        self,
        query: str,
        top_k: int = 5,
        **kwargs
    ) -> List[HybridSearchResult]:
        """
        Hybrid retrieval combining vector search and graph traversal.
    
        Args:
            query: Search query
            top_k: Number of results to return
            **kwargs: Additional parameters
    
        Returns:
            List of hybrid search results
        """
        logger.info(f"Hybrid retrieval for query: {query}")
    
        # Step 1: Vector search
>       vector_results = self.vector_store.search(query, top_k=top_k * 2)
                         ^^^^^^^^^^^^^^^^^^^^^^^^
E       AttributeError: 'NoneType' object has no attribute 'search'

rag_factory/strategies/knowledge_graph/hybrid_retriever.py:64: AttributeError
_________________________ test_late_chunking_workflow __________________________

test_vector_store = <tests.integration.strategies.test_late_chunking_integration.MockVectorStore object at 0x7283e8877350>

    @pytest.mark.integration
    def test_late_chunking_workflow(test_vector_store):
        """Test complete late chunking workflow."""
        config = {
            "model_name": EMBEDDING_MODEL,
            "chunking_method": EmbeddingChunkingMethod.SEMANTIC_BOUNDARY.value,
            "target_chunk_size": 128,
            "compute_coherence_scores": True,
    
        }
    
        strategy = LateChunkingRAGStrategy(
            vector_store_service=test_vector_store,
            config=config
        )
    
        # Index document
        document = """
        Machine learning is a subset of artificial intelligence that enables systems to learn from data.
        Deep learning is a type of machine learning that uses neural networks with many layers.
        Neural networks are inspired by biological neurons in the human brain.
        The training process involves adjusting network weights to minimize error.
        """
    
        strategy.index_document(document, "ml_doc")
    
        # Verify chunks were indexed
>       assert len(test_vector_store.chunks) > 0
E       assert 0 > 0
E        +  where 0 = len([])
E        +    where [] = <tests.integration.strategies.test_late_chunking_integration.MockVectorStore object at 0x7283e8877350>.chunks

tests/integration/strategies/test_late_chunking_integration.py:77: AssertionError
___________________________ test_multiple_documents ____________________________

test_vector_store = <tests.integration.strategies.test_late_chunking_integration.MockVectorStore object at 0x7283d6160110>

    @pytest.mark.integration
    def test_multiple_documents(test_vector_store):
        """Test indexing multiple documents."""
        config = {
            "model_name": EMBEDDING_MODEL,
            "chunking_method": "semantic_boundary",
    
        }
    
        strategy = LateChunkingRAGStrategy(test_vector_store, config)
    
        documents = [
            ("First document about AI and machine learning.", "doc1"),
            ("Second document about neural networks and deep learning.", "doc2"),
            ("Third document about data science and analytics.", "doc3")
        ]
    
        for text, doc_id in documents:
            strategy.index_document(text, doc_id)
    
        # Should have chunks from all documents
>       assert len(test_vector_store.chunks) >= 3
E       assert 0 >= 3
E        +  where 0 = len([])
E        +    where [] = <tests.integration.strategies.test_late_chunking_integration.MockVectorStore object at 0x7283d6160110>.chunks

tests/integration/strategies/test_late_chunking_integration.py:165: AssertionError
_____________________________ test_short_document ______________________________

test_vector_store = <tests.integration.strategies.test_late_chunking_integration.MockVectorStore object at 0x7283d61b3e30>

    @pytest.mark.integration
    def test_short_document(test_vector_store):
        """Test handling of very short documents."""
        config = {
            "model_name": EMBEDDING_MODEL,
    
        }
    
        strategy = LateChunkingRAGStrategy(test_vector_store, config)
    
        short_doc = "Short."
    
        strategy.index_document(short_doc, "short_doc")
    
        # Should create at least one chunk
>       assert len(test_vector_store.chunks) >= 1
E       assert 0 >= 1
E        +  where 0 = len([])
E        +    where [] = <tests.integration.strategies.test_late_chunking_integration.MockVectorStore object at 0x7283d61b3e30>.chunks

tests/integration/strategies/test_late_chunking_integration.py:226: AssertionError
_________ TestMultiQueryIntegration.test_multi_query_complete_workflow _________

self = <tests.integration.strategies.test_multi_query_integration.TestMultiQueryIntegration object at 0x7283d8b50470>
mock_vector_store = <Mock id='125910557802320'>
mock_llm_service = <Mock id='125910557801504'>
mock_embedding_service = <Mock id='125910557801456'>
mock_database_service = <Mock id='125910557801264'>

    def test_multi_query_complete_workflow(self, mock_vector_store, mock_llm_service, mock_embedding_service, mock_database_service):
        """Test complete multi-query retrieval workflow."""
        # Create strategy
        config = MultiQueryConfig(
            num_variants=3,
            ranking_strategy=RankingStrategy.RECIPROCAL_RANK_FUSION,
            final_top_k=5
        )
        strategy = MultiQueryRAGStrategy(
            config=config,
            dependencies=StrategyDependencies(
                llm_service=mock_llm_service,
                embedding_service=mock_embedding_service,
                database_service=mock_database_service
            )
        )
    
        # Retrieve with multi-query
        results = strategy.retrieve("What is machine learning?")
    
        # Verify results
>       assert len(results) > 0
E       assert 0 > 0
E        +  where 0 = len([])

tests/integration/strategies/test_multi_query_integration.py:99: AssertionError
__________ TestMultiQueryIntegration.test_multi_query_async_workflow ___________

self = <tests.integration.strategies.test_multi_query_integration.TestMultiQueryIntegration object at 0x7283d8b50800>
mock_vector_store = <Mock id='125910557802224'>
mock_llm_service = <Mock id='125910557795408'>
mock_embedding_service = <Mock id='125910557795360'>
mock_database_service = <Mock id='125910557794976'>

    @pytest.mark.asyncio
    async def test_multi_query_async_workflow(self, mock_vector_store, mock_llm_service, mock_embedding_service, mock_database_service):
        """Test async multi-query retrieval workflow."""
        config = MultiQueryConfig(
            num_variants=3,
            ranking_strategy=RankingStrategy.FREQUENCY_BOOST,
            final_top_k=5
        )
        strategy = MultiQueryRAGStrategy(
            config=config,
            dependencies=StrategyDependencies(
                llm_service=mock_llm_service,
                embedding_service=mock_embedding_service,
                database_service=mock_database_service
            )
        )
    
        # Async retrieve
        results = await strategy.aretrieve("What is machine learning?")
    
        # Verify results
>       assert len(results) > 0
E       assert 0 > 0
E        +  where 0 = len([])

tests/integration/strategies/test_multi_query_integration.py:129: AssertionError
_______________ TestMultiQueryIntegration.test_variant_diversity _______________

self = <tests.integration.strategies.test_multi_query_integration.TestMultiQueryIntegration object at 0x7283d8b50bc0>
mock_vector_store = <Mock id='125910557787152'>
mock_llm_service = <Mock id='125910557787200'>
mock_embedding_service = <Mock id='125910557786432'>
mock_database_service = <Mock id='125910557787248'>

    def test_variant_diversity(self, mock_vector_store, mock_llm_service, mock_embedding_service, mock_database_service):
        """Test that generated variants are diverse."""
        config = MultiQueryConfig(num_variants=4, log_variants=True)
        strategy = MultiQueryRAGStrategy(
            config=config,
            dependencies=StrategyDependencies(
                llm_service=mock_llm_service,
                embedding_service=mock_embedding_service,
                database_service=mock_database_service
            )
        )
    
        # Retrieve
        results = strategy.retrieve("What is AI?")
    
        # Variants should have been generated
        # (We can't directly check variants without modifying the strategy,
        # but we can verify results came from multiple sources)
>       assert len(results) > 0
E       assert 0 > 0
E        +  where 0 = len([])

tests/integration/strategies/test_multi_query_integration.py:151: AssertionError
___________ TestMultiQueryIntegration.test_performance_requirements ____________

self = <tests.integration.strategies.test_multi_query_integration.TestMultiQueryIntegration object at 0x7283d8b50f50>
mock_vector_store = <Mock id='125910558642480'>
mock_llm_service = <Mock id='125910558642192'>
mock_embedding_service = <Mock id='125910558642096'>
mock_database_service = <Mock id='125910558644496'>

    @pytest.mark.asyncio
    async def test_performance_requirements(self, mock_vector_store, mock_llm_service, mock_embedding_service, mock_database_service):
        """Test that multi-query retrieval completes within timeout."""
        import time
    
        config = MultiQueryConfig(
            num_variants=5,
            query_timeout=5.0,
            variant_generation_timeout=5.0
        )
        strategy = MultiQueryRAGStrategy(
            config=config,
            dependencies=StrategyDependencies(
                llm_service=mock_llm_service,
                embedding_service=mock_embedding_service,
                database_service=mock_database_service
            )
        )
    
        start = time.time()
        results = await strategy.aretrieve("test query")
        elapsed = time.time() - start
    
        # Should complete reasonably fast (< 3s as per requirements)
        # In practice with mocks, should be much faster
        assert elapsed < 3.0
>       assert len(results) > 0
E       assert 0 > 0
E        +  where 0 = len([])

tests/integration/strategies/test_multi_query_integration.py:179: AssertionError
______________ TestMultiQueryIntegration.test_fallback_on_failure ______________

self = <tests.integration.strategies.test_multi_query_integration.TestMultiQueryIntegration object at 0x7283d8b51340>
mock_vector_store = <Mock id='125910558647088'>
mock_embedding_service = <Mock id='125910558650112'>
mock_database_service = <Mock id='125910558649152'>

    @pytest.mark.asyncio
    async def test_fallback_on_failure(self, mock_vector_store, mock_embedding_service, mock_database_service):
        """Test fallback to original query on variant generation failure."""
        # Mock LLM that fails
        llm_service = Mock()
        llm_service.agenerate = AsyncMock(side_effect=Exception("LLM failed"))
    
        config = MultiQueryConfig(fallback_to_original=True, final_top_k=3)
        strategy = MultiQueryRAGStrategy(
            config=config.dict() if hasattr(config, 'dict') else config.__dict__,
            dependencies=StrategyDependencies(
                llm_service=llm_service,
                embedding_service=mock_embedding_service,
                database_service=mock_database_service
            )
        )
    
        # Should fall back to original query
        results = await strategy.aretrieve("test query")
    
        # Should still get results from fallback
>       assert len(results) > 0
E       assert 0 > 0
E        +  where 0 = len([])

tests/integration/strategies/test_multi_query_integration.py:202: AssertionError
__________ TestMultiQueryIntegration.test_ranking_strategy_comparison __________

self = <tests.integration.strategies.test_multi_query_integration.TestMultiQueryIntegration object at 0x7283d8b51760>
mock_vector_store = <Mock id='125910579566144'>
mock_llm_service = <Mock id='125910579565856'>
mock_embedding_service = <Mock id='125910579565760'>
mock_database_service = <Mock id='125910579567968'>

    def test_ranking_strategy_comparison(self, mock_vector_store, mock_llm_service, mock_embedding_service, mock_database_service):
        """Test different ranking strategies produce different results."""
        query = "What is machine learning?"
    
        # Test with MAX_SCORE
        config_max = MultiQueryConfig(
            num_variants=3,
            ranking_strategy=RankingStrategy.MAX_SCORE,
            final_top_k=5
        )
        strategy_max = MultiQueryRAGStrategy(
            config=config_max.dict() if hasattr(config_max, 'dict') else config_max.__dict__,
            dependencies=StrategyDependencies(
                llm_service=mock_llm_service,
                embedding_service=mock_embedding_service,
                database_service=mock_database_service
            )
        )
        results_max = strategy_max.retrieve(query)
    
        # Test with FREQUENCY_BOOST
        config_freq = MultiQueryConfig(
            num_variants=3,
            ranking_strategy=RankingStrategy.FREQUENCY_BOOST,
            final_top_k=5
        )
        strategy_freq = MultiQueryRAGStrategy(
            config=config_freq.dict() if hasattr(config_freq, 'dict') else config_freq.__dict__,
            dependencies=StrategyDependencies(
                llm_service=mock_llm_service,
                embedding_service=mock_embedding_service,
                database_service=mock_database_service
            )
        )
        results_freq = strategy_freq.retrieve(query)
    
        # Both should return results
>       assert len(results_max) > 0
E       assert 0 > 0
E        +  where 0 = len([])

tests/integration/strategies/test_multi_query_integration.py:241: AssertionError
________________ TestMultiQueryWithLMStudio.test_with_real_llm _________________

self = <tests.integration.strategies.test_multi_query_integration.TestMultiQueryWithLMStudio object at 0x7283d8b521e0>
llm_service_from_env = <rag_factory.services.llm.service.LLMService object at 0x7283d75e1970>

    def test_with_real_llm(self, llm_service_from_env):
        """Test with real LLM service from environment (LM Studio)."""
        from unittest.mock import Mock
    
        # Mock vector store
        vector_store = Mock()
    
        async def mock_search(query, top_k):
            return [
                {"chunk_id": f"c{i}", "text": f"Result {i}", "score": 0.9 - i * 0.1}
                for i in range(top_k)
            ]
    
        vector_store.asearch = mock_search
    
        # Create strategy
        config = MultiQueryConfig(num_variants=3, final_top_k=5)
>       strategy = MultiQueryRAGStrategy(
            config=config,
            dependencies=StrategyDependencies(
                llm_service=llm_service_from_env
            )
        )

tests/integration/strategies/test_multi_query_integration.py:311: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
rag_factory/strategies/multi_query/strategy.py:43: in __init__
    super().__init__(config, dependencies)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <rag_factory.strategies.multi_query.strategy.MultiQueryRAGStrategy object at 0x7283d6121250>
config = MultiQueryConfig(num_variants=3, variant_types=[<VariantType.PARAPHRASE: 'paraphrase'>, <VariantType.EXPAND: 'expand'>...2, rrf_k=60, final_top_k=5, fallback_to_original=True, min_successful_queries=1, log_variants=True, track_metrics=True)
dependencies = StrategyDependencies(llm_service=<rag_factory.services.llm.service.LLMService object at 0x7283d75e1970>, embedding_service=None, graph_service=None, database_service=None, reranker_service=None)

    def __init__(
        self,
        config: Dict[str, Any],
        dependencies: StrategyDependencies
    ) -> None:
        """
        Initialize the strategy with configuration and dependencies.
    
        This method validates that all required services are present before
        allowing the strategy to be instantiated. Concrete strategies should
        call super().__init__() and then perform their own initialization.
    
        Args:
            config: Strategy-specific configuration parameters
            dependencies: Injected services required by the strategy
    
        Raises:
            ValueError: If required services are missing from dependencies
    
        Example:
            >>> from rag_factory.services.dependencies import StrategyDependencies, ServiceDependency
            >>> deps = StrategyDependencies(llm_service=my_llm, embedding_service=my_embedder)
            >>> config = {"chunk_size": 1024, "top_k": 10}
            >>> strategy = MyConcreteStrategy(config, deps)
        """
        self.config = config
        self.deps = dependencies
    
        # Validate dependencies
        required = self.requires_services()
        is_valid, missing = dependencies.validate_for_strategy(required)
    
        if not is_valid:
            service_names = [s.name for s in missing]
>           raise ValueError(
                f"{self.__class__.__name__} requires services: {', '.join(service_names)}"
            )
E           ValueError: MultiQueryRAGStrategy requires services: EMBEDDING, DATABASE

rag_factory/strategies/base.py:178: ValueError
___________________________ test_config_with_factory ___________________________

tmp_path = PosixPath('/tmp/pytest-of-admindevmac/pytest-103/test_config_with_factory0')

    @pytest.mark.integration
    def test_config_with_factory(tmp_path: Path) -> None:
        """Test configuration used with RAGFactory."""
        config_file = tmp_path / "config.yaml"
        config_file.write_text("""
    strategies:
      test_strategy:
        chunk_size: 1024
        top_k: 10
        strategy_name: test_strategy
    """)
    
        # Load config
        config = ConfigManager()
        config.load(str(config_file))
    
        # Register strategy
        RAGFactory.register_strategy(
            "test_strategy",
            TestIntegrationStrategy,
            override=True
        )
    
        # Get strategy config and create strategy
        strategy_config = config.get_strategy_config("test_strategy")
>       strategy = RAGFactory.create_strategy(
            "test_strategy",
            strategy_config.model_dump()
        )

tests/integration/test_config_integration.py:180: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = 'test_strategy'
name = {'chunk_overlap': 50, 'chunk_size': 1024, 'metadata': {}, 'strategy_name': 'test_strategy', ...}
config = None, override_deps = None

    def create_strategy(
        self,
        name: str,
        config: Optional[Dict[str, Any]] = None,
        override_deps: Optional[StrategyDependencies] = None,
    ) -> IRAGStrategy:
        """
        Create and initialize a strategy instance with dependency injection.
    
        Args:
            name: Name of the registered strategy to create
            config: Optional configuration dictionary for the strategy
            override_deps: Optional dependencies to override factory defaults
    
        Returns:
            IRAGStrategy: Initialized strategy instance
    
        Raises:
            StrategyNotFoundError: If strategy name not in registry
            ValueError: If required services are missing or config is invalid
    
        Example:
            >>> factory = RAGFactory(llm_service=my_llm)
            >>> config = {"chunk_size": 1024, "top_k": 10}
            >>> strategy = factory.create_strategy("my_strategy", config)
            >>>
            >>> # Or with override dependencies
            >>> override = StrategyDependencies(llm_service=different_llm)
            >>> strategy = factory.create_strategy("my_strategy", config, override)
        """
>       if name not in self._registry:
                       ^^^^^^^^^^^^^^
E       AttributeError: 'str' object has no attribute '_registry'

rag_factory/factory.py:202: AttributeError
______________________ test_register_create_use_strategy _______________________

factory = <rag_factory.factory.RAGFactory object at 0x7283d5c518e0>

    @pytest.mark.integration
    def test_register_create_use_strategy(factory: RAGFactory) -> None:
        """Test complete workflow: register -> create -> use."""
        # Register
        factory.register_strategy("dummy", DummyStrategy)
    
        # Create with config
        config = {"chunk_size": 512, "top_k": 3}
        strategy = factory.create_strategy("dummy", config)
    
        # Verify initialization
>       assert strategy.initialized
               ^^^^^^^^^^^^^^^^^^^^
E       AttributeError: 'DummyStrategy' object has no attribute 'initialized'. Did you mean: 'initialize'?

tests/integration/test_factory_integration.py:254: AttributeError
_______________ test_create_multiple_instances_of_same_strategy ________________

factory = <rag_factory.factory.RAGFactory object at 0x7283d5c52540>

    @pytest.mark.integration
    def test_create_multiple_instances_of_same_strategy(
        factory: RAGFactory,
    ) -> None:
        """Test creating multiple instances of the same strategy."""
        factory.register_strategy("dummy", DummyStrategy)
    
        config1 = {"chunk_size": 256, "top_k": 3}
        config2 = {"chunk_size": 1024, "top_k": 10}
    
        strategy1 = factory.create_strategy("dummy", config1)
        strategy2 = factory.create_strategy("dummy", config2)
    
        # Different instances with different configs
        assert strategy1 is not strategy2
>       assert strategy1.config.chunk_size == 256
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
E       AttributeError: 'dict' object has no attribute 'chunk_size'

tests/integration/test_factory_integration.py:318: AttributeError
__________________________ test_config_file_with_yaml __________________________

tmp_path = PosixPath('/tmp/pytest-of-admindevmac/pytest-103/test_config_file_with_yaml0')
factory = <rag_factory.factory.RAGFactory object at 0x7283d5c50b30>

    @pytest.mark.integration
    def test_config_file_with_yaml(tmp_path: Path, factory: RAGFactory) -> None:
        """Test loading configuration from YAML file."""
        factory.register_strategy("dummy", DummyStrategy)
    
        # Create YAML config file
        config_file = tmp_path / "config.yaml"
        config_file.write_text(
            """
    strategy_name: dummy
    chunk_size: 2048
    chunk_overlap: 100
    top_k: 15
    metadata:
      author: test
      version: 1.0
    """
        )
    
        # Create strategy from config file
        strategy = factory.create_from_config(str(config_file))
    
        assert isinstance(strategy, DummyStrategy)
>       assert strategy.config.chunk_size == 2048
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
E       AttributeError: 'dict' object has no attribute 'chunk_size'

tests/integration/test_factory_integration.py:374: AttributeError
__________________________ test_config_file_with_json __________________________

tmp_path = PosixPath('/tmp/pytest-of-admindevmac/pytest-103/test_config_file_with_json0')
factory = <rag_factory.factory.RAGFactory object at 0x7283d5cb3860>

    @pytest.mark.integration
    def test_config_file_with_json(tmp_path: Path, factory: RAGFactory) -> None:
        """Test loading configuration from JSON file."""
        factory.register_strategy("dummy", DummyStrategy)
    
        # Create JSON config file
        config_file = tmp_path / "config.json"
        config_file.write_text(
            """{
        "strategy_name": "dummy",
        "chunk_size": 768,
        "top_k": 7
    }"""
        )
    
        # Create strategy from config file
        strategy = factory.create_from_config(str(config_file))
    
        assert isinstance(strategy, DummyStrategy)
>       assert strategy.config.chunk_size == 768
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
E       AttributeError: 'dict' object has no attribute 'chunk_size'

tests/integration/test_factory_integration.py:400: AttributeError
_________________________ test_factory_error_recovery __________________________

factory = <rag_factory.factory.RAGFactory object at 0x7283d7d4a2d0>

    @pytest.mark.integration
    def test_factory_error_recovery(factory: RAGFactory) -> None:
        """Test factory handles errors gracefully and maintains state."""
        factory.register_strategy("working", WorkingStrategy)
        factory.register_strategy("broken", BrokenStrategy)
    
        # Try to create broken strategy
>       with pytest.raises(RuntimeError, match="Initialization failed"):
E       Failed: DID NOT RAISE <class 'RuntimeError'>

tests/integration/test_factory_integration.py:414: Failed
___________________ test_factory_state_after_failed_creation ___________________

factory = <rag_factory.factory.RAGFactory object at 0x7283d7d49670>

    @pytest.mark.integration
    def test_factory_state_after_failed_creation(factory: RAGFactory) -> None:
        """Test factory state remains consistent after failed strategy creation."""
        factory.register_strategy("dummy", DummyStrategy)
    
        # Try to create with invalid config
>       with pytest.raises(ValueError):
E       Failed: DID NOT RAISE <class 'ValueError'>

tests/integration/test_factory_integration.py:432: Failed
_______________ TestPackageInstallation.test_package_installable _______________

self = <tests.integration.test_package_integration.TestPackageInstallation object at 0x7283d896fa10>
tmp_path = PosixPath('/tmp/pytest-of-admindevmac/pytest-103/test_package_installable0')

    @pytest.mark.slow
    def test_package_installable(self, tmp_path: Path) -> None:
        """Test package can be installed in clean environment."""
        # Create virtual environment
        venv_dir = tmp_path / "venv"
        subprocess.run(
            [sys.executable, "-m", "venv", str(venv_dir)], check=True
        )
    
        # Determine pip and python executables based on OS
        if sys.platform == "win32":
            pip_executable = venv_dir / "Scripts" / "pip"
            python_executable = venv_dir / "Scripts" / "python"
        else:
            pip_executable = venv_dir / "bin" / "pip"
            python_executable = venv_dir / "bin" / "python"
    
        # Install package in editable mode
        project_root = Path(__file__).parent.parent.parent
        subprocess.run(
            [str(pip_executable), "install", "-e", str(project_root)],
            check=True,
        )
    
        # Test import in the venv
        result = subprocess.run(
            [
                str(python_executable),
                "-c",
                "import rag_factory; print(rag_factory.__version__)",
            ],
            capture_output=True,
            text=True,
            check=False,
        )
    
>       assert result.returncode == 0
E       assert 1 == 0
E        +  where 1 = CompletedProcess(args=['/tmp/pytest-of-admindevmac/pytest-103/test_package_installable0/venv/bin/python', '-c', 'import rag_factory; print(rag_factory.__version__)'], returncode=1, stdout='', stderr='Traceback (most recent call last):\n  File "<string>", line 1, in <module>\n  File "/mnt/MCPProyects/ragTools/rag_factory/__init__.py", line 12, in <module>\n    from rag_factory.factory import (\n  File "/mnt/MCPProyects/ragTools/rag_factory/factory.py", line 33, in <module>\n    from rag_factory.strategies.base import IRAGStrategy, StrategyConfig\n  File "/mnt/MCPProyects/ragTools/rag_factory/strategies/__init__.py", line 3, in <module>\n    from rag_factory.strategies.base import (\n  File "/mnt/MCPProyects/ragTools/rag_factory/strategies/base.py", line 34, in <module>\n    from rag_factory.services.dependencies import StrategyDependencies, ServiceDependency\n  File "/mnt/MCPProyects/ragTools/rag_factory/services/__init__.py", line 28, in <module>\n    from rag_factory.services.onnx import (\n  File "/mnt/MCPProyects/ragTools/rag_factory/services/onnx/__init__.py", line 7, in <module>\n    from rag_factory.services.onnx.embedding import ONNXEmbeddingService\n  File "/mnt/MCPProyects/ragTools/rag_factory/services/onnx/embedding.py", line 12, in <module>\n    from rag_factory.services.embedding.providers.onnx_local import ONNXLocalProvider\n  File "/mnt/MCPProyects/ragTools/rag_factory/services/embedding/__init__.py", line 3, in <module>\n    from .service import EmbeddingService\n  File "/mnt/MCPProyects/ragTools/rag_factory/services/embedding/service.py", line 11, in <module>\n    from .providers import OpenAIProvider, CohereProvider, LocalProvider, ONNXLocalProvider\n  File "/mnt/MCPProyects/ragTools/rag_factory/services/embedding/providers/__init__.py", line 6, in <module>\n    from .onnx_local import ONNXLocalProvider\n  File "/mnt/MCPProyects/ragTools/rag_factory/services/embedding/providers/onnx_local.py", line 12, in <module>\n    import numpy as np\nModuleNotFoundError: No module named \'numpy\'\n').returncode

tests/integration/test_package_integration.py:50: AssertionError
----------------------------- Captured stdout call -----------------------------
Obtaining file:///mnt/MCPProyects/ragTools
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Checking if build backend supports build_editable: started
  Checking if build backend supports build_editable: finished with status 'done'
  Getting requirements to build editable: started
  Getting requirements to build editable: finished with status 'done'
  Preparing editable metadata (pyproject.toml): started
  Preparing editable metadata (pyproject.toml): finished with status 'done'
Collecting pydantic>=2.0.0 (from rag-factory==0.1.0)
  Using cached pydantic-2.12.5-py3-none-any.whl.metadata (90 kB)
Collecting pyyaml>=6.0 (from rag-factory==0.1.0)
  Using cached pyyaml-6.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.4 kB)
Collecting annotated-types>=0.6.0 (from pydantic>=2.0.0->rag-factory==0.1.0)
  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)
Collecting pydantic-core==2.41.5 (from pydantic>=2.0.0->rag-factory==0.1.0)
  Using cached pydantic_core-2.41.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)
Collecting typing-extensions>=4.14.1 (from pydantic>=2.0.0->rag-factory==0.1.0)
  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)
Collecting typing-inspection>=0.4.2 (from pydantic>=2.0.0->rag-factory==0.1.0)
  Using cached typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)
Using cached pydantic-2.12.5-py3-none-any.whl (463 kB)
Using cached pydantic_core-2.41.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)
Using cached pyyaml-6.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (807 kB)
Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)
Using cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)
Using cached typing_inspection-0.4.2-py3-none-any.whl (14 kB)
Building wheels for collected packages: rag-factory
  Building editable for rag-factory (pyproject.toml): started
  Building editable for rag-factory (pyproject.toml): finished with status 'done'
  Created wheel for rag-factory: filename=rag_factory-0.1.0-0.editable-py3-none-any.whl size=6329 sha256=4938c6d4e7b51e7bd0194b625b5b8f735259a1eed88b0a67e80657b7739a2c9a
  Stored in directory: /tmp/pip-ephem-wheel-cache-44nk5xlz/wheels/08/27/d0/02501a029db205cc4e40972294db0f3cd8ac5253539696b270
Successfully built rag-factory
Installing collected packages: typing-extensions, pyyaml, annotated-types, typing-inspection, pydantic-core, pydantic, rag-factory
Successfully installed annotated-types-0.7.0 pydantic-2.12.5 pydantic-core-2.41.5 pyyaml-6.0.3 rag-factory-0.1.0 typing-extensions-4.15.0 typing-inspection-0.4.2
__________ TestFullWorkflow.test_full_workflow_with_installed_package __________

self = <tests.integration.test_package_integration.TestFullWorkflow object at 0x7283d9d9de50>

    def test_full_workflow_with_installed_package(self) -> None:
        """Test complete workflow using installed package."""
        from rag_factory import RAGFactory, StrategyPipeline
        from rag_factory.strategies import IRAGStrategy, Chunk
        from typing import List, Any, Optional
    
        # Define a test strategy
        class TestStrategy(IRAGStrategy):
            """Test strategy implementation."""
    
            def initialize(
                self, config: Optional[dict[str, Any]] = None
            ) -> None:
                """Initialize the strategy."""
                self.config = config
    
            def prepare_data(self, documents: List[str]) -> Any:
                """Prepare data for retrieval."""
                return {"prepared": True}
    
            def retrieve(self, query: str, top_k: int = 5) -> List[Chunk]:
                """Retrieve chunks."""
                return [
                    Chunk(
                        f"Result {i}",
                        {},
                        0.9,
                        f"doc{i}",
                        f"chunk{i}",
                    )
                    for i in range(top_k)
                ]
    
            async def aretrieve(
                self, query: str, top_k: int = 5
            ) -> List[Chunk]:
                """Asynchronously retrieve chunks."""
                return self.retrieve(query, top_k)
    
            def process_query(
                self, query: str, context: List[Chunk]
            ) -> str:
                """Process query with context."""
                return f"Processed: {query} with {len(context)} chunks"
    
        # Register strategy
        factory = RAGFactory()
        factory.register_strategy("test", TestStrategy)
    
        # Create strategy
>       strategy = factory.create_strategy("test")
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/integration/test_package_integration.py:138: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <rag_factory.factory.RAGFactory object at 0x7283d6122510>, name = 'test'
config = None, override_deps = None

    def create_strategy(
        self,
        name: str,
        config: Optional[Dict[str, Any]] = None,
        override_deps: Optional[StrategyDependencies] = None,
    ) -> IRAGStrategy:
        """
        Create and initialize a strategy instance with dependency injection.
    
        Args:
            name: Name of the registered strategy to create
            config: Optional configuration dictionary for the strategy
            override_deps: Optional dependencies to override factory defaults
    
        Returns:
            IRAGStrategy: Initialized strategy instance
    
        Raises:
            StrategyNotFoundError: If strategy name not in registry
            ValueError: If required services are missing or config is invalid
    
        Example:
            >>> factory = RAGFactory(llm_service=my_llm)
            >>> config = {"chunk_size": 1024, "top_k": 10}
            >>> strategy = factory.create_strategy("my_strategy", config)
            >>>
            >>> # Or with override dependencies
            >>> override = StrategyDependencies(llm_service=different_llm)
            >>> strategy = factory.create_strategy("my_strategy", config, override)
        """
        if name not in self._registry:
            available = list(self._registry.keys())
            raise StrategyNotFoundError(
                f"Strategy '{name}' not found. "
                f"Available strategies: {available}"
            )
    
        strategy_class = self._registry[name]
        deps = override_deps or self.dependencies
    
        # Use config dict or empty dict if not provided
        strategy_config = config or {}
    
        try:
            # Strategy constructor will validate dependencies
>           strategy = strategy_class(config=strategy_config, dependencies=deps)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E           TypeError: Can't instantiate abstract class TestStrategy without an implementation for abstract method 'requires_services'

rag_factory/factory.py:217: TypeError
______________ test_pipeline_continues_after_non_critical_failure ______________

    @pytest.mark.integration
    def test_pipeline_continues_after_non_critical_failure() -> None:
        """Test pipeline continues when non-required strategy fails."""
        class OptionalStrategy(IRAGStrategy):
            """Strategy that always fails."""
    
            def requires_services(self):
                """Declare required services."""
                from rag_factory.services.dependencies import ServiceDependency
                return set()
    
            def initialize(self, config: Any) -> None:
                """Initialize."""
                pass
    
            def prepare_data(self, documents: List[Dict[str, Any]]) -> Any:
                """Prepare data."""
                return None
    
            def retrieve(self, query: str, top_k: int) -> List[Chunk]:
                """Retrieve - raises error."""
                raise RuntimeError("Optional failed")
    
            async def aretrieve(self, query: str, top_k: int) -> List[Chunk]:
                """Async retrieve."""
                return []
    
            def process_query(self, query: str, context: List[Chunk]) -> str:
                """Process query."""
                return ""
    
        required_strategy = TestStrategy("Required")
    
        pipeline = StrategyPipeline()
        # Add optional failing stage
        from rag_factory.pipeline import PipelineStage
        optional_stage = PipelineStage(
>           strategy=OptionalStrategy(),
                     ^^^^^^^^^^^^^^^^^^
            name="optional",
            required=False
        )
E       TypeError: IRAGStrategy.__init__() missing 2 required positional arguments: 'config' and 'dependencies'

tests/integration/test_pipeline_integration.py:178: TypeError
________________________ test_async_fallback_execution _________________________

    @pytest.mark.integration
    @pytest.mark.asyncio
    async def test_async_fallback_execution() -> None:
        """Test fallback strategy in async mode."""
        class FailingAsyncStrategy(IRAGStrategy):
            """Strategy that always fails in async mode."""
    
            def requires_services(self):
                """Declare required services."""
                from rag_factory.services.dependencies import ServiceDependency
                return set()
    
            def initialize(self, config: Any) -> None:
                """Initialize."""
                pass
    
            def prepare_data(self, documents: List[Dict[str, Any]]) -> Any:
                """Prepare data."""
                return None
    
            def retrieve(self, query: str, top_k: int) -> List[Chunk]:
                """Retrieve."""
                return []
    
            async def aretrieve(self, query: str, top_k: int) -> List[Chunk]:
                """Async retrieve - raises error."""
                raise RuntimeError("Async primary failed")
    
            def process_query(self, query: str, context: List[Chunk]) -> str:
                """Process query."""
                return ""
    
        fallback_strategy = TestStrategy("Fallback")
>       primary_strategy = FailingAsyncStrategy()
                           ^^^^^^^^^^^^^^^^^^^^^^
E       TypeError: IRAGStrategy.__init__() missing 2 required positional arguments: 'config' and 'dependencies'

tests/integration/test_pipeline_integration.py:353: TypeError
____________________ test_parallel_execution_with_failures _____________________

    @pytest.mark.integration
    @pytest.mark.asyncio
    async def test_parallel_execution_with_failures() -> None:
        """Test parallel execution handles mixed success and failure."""
        class FailingParallelStrategy(IRAGStrategy):
            """Strategy that fails in parallel execution."""
    
            def requires_services(self):
                """Declare required services."""
                from rag_factory.services.dependencies import ServiceDependency
                return set()
    
            def initialize(self, config: Any) -> None:
                """Initialize."""
                pass
    
            def prepare_data(self, documents: List[Dict[str, Any]]) -> Any:
                """Prepare data."""
                return None
    
            def retrieve(self, query: str, top_k: int) -> List[Chunk]:
                """Retrieve."""
                return []
    
            async def aretrieve(self, query: str, top_k: int) -> List[Chunk]:
                """Async retrieve - raises error."""
                raise RuntimeError("Parallel strategy failed")
    
            def process_query(self, query: str, context: List[Chunk]) -> str:
                """Process query."""
                return ""
    
        working_strategy = TestStrategy("Working")
>       failing_strategy = FailingParallelStrategy()
                           ^^^^^^^^^^^^^^^^^^^^^^^^^
E       TypeError: IRAGStrategy.__init__() missing 2 required positional arguments: 'config' and 'dependencies'

tests/integration/test_pipeline_integration.py:399: TypeError
=============================== warnings summary ===============================
rag_factory/services/llm/config.py:8
  /mnt/MCPProyects/ragTools/rag_factory/services/llm/config.py:8: PydanticDeprecatedSince20: Support for class-based `config` is deprecated, use ConfigDict instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    class LLMServiceConfig(BaseModel):

rag_factory/database/config.py:12
  /mnt/MCPProyects/ragTools/rag_factory/database/config.py:12: PydanticDeprecatedSince20: Support for class-based `config` is deprecated, use ConfigDict instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    class DatabaseConfig(BaseSettings):

rag_factory/strategies/contextual/config.py:31
  /mnt/MCPProyects/ragTools/rag_factory/strategies/contextual/config.py:31: PydanticDeprecatedSince20: Support for class-based `config` is deprecated, use ConfigDict instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    class ContextualRetrievalConfig(BaseModel):

rag_factory/strategies/late_chunking/models.py:21
  /mnt/MCPProyects/ragTools/rag_factory/strategies/late_chunking/models.py:21: PydanticDeprecatedSince20: Support for class-based `config` is deprecated, use ConfigDict instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    class TokenEmbedding(BaseModel):

rag_factory/strategies/late_chunking/models.py:34
  /mnt/MCPProyects/ragTools/rag_factory/strategies/late_chunking/models.py:34: PydanticDeprecatedSince20: Support for class-based `config` is deprecated, use ConfigDict instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    class DocumentEmbedding(BaseModel):

rag_factory/strategies/late_chunking/models.py:49
  /mnt/MCPProyects/ragTools/rag_factory/strategies/late_chunking/models.py:49: PydanticDeprecatedSince20: Support for class-based `config` is deprecated, use ConfigDict instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    class EmbeddingChunk(BaseModel):

tests/integration/test_config_integration.py:34
  /mnt/MCPProyects/ragTools/tests/integration/test_config_integration.py:34: PytestCollectionWarning: cannot collect test class 'TestIntegrationStrategy' because it has a __init__ constructor (from: tests/integration/test_config_integration.py)
    class TestIntegrationStrategy(IRAGStrategy):

tests/integration/test_pipeline_integration.py:22
  /mnt/MCPProyects/ragTools/tests/integration/test_pipeline_integration.py:22: PytestCollectionWarning: cannot collect test class 'TestStrategy' because it has a __init__ constructor (from: tests/integration/test_pipeline_integration.py)
    class TestStrategy(IRAGStrategy):

rag_factory/strategies/agentic/config.py:9
  /mnt/MCPProyects/ragTools/rag_factory/strategies/agentic/config.py:9: PydanticDeprecatedSince20: Support for class-based `config` is deprecated, use ConfigDict instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    class AgenticStrategyConfig(BaseModel):

tests/integration/services/test_service_integration.py::test_embedding_database_consistency
  /mnt/MCPProyects/ragTools/rag_factory/services/database/postgres.py:157: RuntimeWarning: coroutine 'AsyncMockMixin._execute_mock_call' was never awaited
    async with pool.acquire() as conn:
  Enable tracemalloc to get traceback where the object was allocated.
  See https://docs.pytest.org/en/stable/how-to/capture-warnings.html#resource-warnings for more info.

tests/integration/strategies/test_contextual_integration.py::test_contextual_retrieval_complete_workflow
  /mnt/MCPProyects/ragTools/tests/integration/strategies/test_contextual_integration.py:95: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    config=config.dict(),

tests/integration/strategies/test_contextual_integration.py::test_cost_tracking_accuracy
  /mnt/MCPProyects/ragTools/tests/integration/strategies/test_contextual_integration.py:157: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    config=config.dict(),

tests/integration/strategies/test_contextual_integration.py::test_retrieval_with_different_formats
  /mnt/MCPProyects/ragTools/tests/integration/strategies/test_contextual_integration.py:201: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    config=config_original.dict(),

tests/integration/strategies/test_contextual_integration.py::test_error_recovery
  /mnt/MCPProyects/ragTools/tests/integration/strategies/test_contextual_integration.py:250: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    config=config.dict(),

tests/integration/strategies/test_contextual_integration.py::test_synchronous_indexing
  /mnt/MCPProyects/ragTools/tests/integration/strategies/test_contextual_integration.py:283: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    config=config.dict(),

tests/integration/strategies/test_contextual_integration.py::test_large_document_processing
  /mnt/MCPProyects/ragTools/tests/integration/strategies/test_contextual_integration.py:326: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    config=config.dict(),

tests/integration/strategies/test_knowledge_graph_integration.py::test_knowledge_graph_workflow
  /mnt/MCPProyects/ragTools/tests/integration/strategies/test_knowledge_graph_integration.py:118: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    config=config.dict() if hasattr(config, 'dict') else config.__dict__,

tests/integration/strategies/test_knowledge_graph_integration.py::test_hybrid_retrieval
  /mnt/MCPProyects/ragTools/tests/integration/strategies/test_knowledge_graph_integration.py:156: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    config=config.dict() if hasattr(config, 'dict') else config.__dict__,

tests/integration/strategies/test_knowledge_graph_integration.py::test_relationship_queries
  /mnt/MCPProyects/ragTools/tests/integration/strategies/test_knowledge_graph_integration.py:189: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    config=config.dict() if hasattr(config, 'dict') else config.__dict__,

tests/integration/strategies/test_knowledge_graph_integration.py::test_graph_statistics
  /mnt/MCPProyects/ragTools/tests/integration/strategies/test_knowledge_graph_integration.py:220: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    config=config.dict() if hasattr(config, 'dict') else config.__dict__,

tests/integration/strategies/test_multi_query_integration.py::TestMultiQueryIntegration::test_multi_query_complete_workflow
  /mnt/MCPProyects/ragTools/rag_factory/strategies/multi_query/strategy.py:140: RuntimeWarning: coroutine 'MultiQueryRAGStrategy.aretrieve' was never awaited
    return asyncio.run(self.aretrieve(query, **kwargs))
  Enable tracemalloc to get traceback where the object was allocated.
  See https://docs.pytest.org/en/stable/how-to/capture-warnings.html#resource-warnings for more info.

tests/integration/strategies/test_multi_query_integration.py::TestMultiQueryIntegration::test_fallback_on_failure
  /mnt/MCPProyects/ragTools/tests/integration/strategies/test_multi_query_integration.py:190: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    config=config.dict() if hasattr(config, 'dict') else config.__dict__,

tests/integration/strategies/test_multi_query_integration.py::TestMultiQueryIntegration::test_ranking_strategy_comparison
  /mnt/MCPProyects/ragTools/tests/integration/strategies/test_multi_query_integration.py:215: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    config=config_max.dict() if hasattr(config_max, 'dict') else config_max.__dict__,

tests/integration/strategies/test_multi_query_integration.py::TestMultiQueryIntegration::test_ranking_strategy_comparison
  /mnt/MCPProyects/ragTools/tests/integration/strategies/test_multi_query_integration.py:231: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    config=config_freq.dict() if hasattr(config_freq, 'dict') else config_freq.__dict__,

tests/unit/strategies/agentic/test_strategy.py::test_strategy_get_stats
  /mnt/MCPProyects/ragTools/rag_factory/strategies/agentic/strategy.py:287: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    "config": self.strategy_config.dict()

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
================================ tests coverage ================================
_______________ coverage: platform linux, python 3.12.3-final-0 ________________

Name                                                               Stmts   Miss  Cover   Missing
------------------------------------------------------------------------------------------------
rag_factory/__init__.py                                               37      9    76%   100-101, 107-109, 121-122, 130-131
rag_factory/__version__.py                                             1      0   100%
rag_factory/cli/__init__.py                                            2      0   100%
rag_factory/cli/commands/__init__.py                                   1      0   100%
rag_factory/cli/commands/benchmark.py                                 96     81    16%   40-53, 64-84, 148-263
rag_factory/cli/commands/check_consistency.py                         43      3    93%   77, 90, 118
rag_factory/cli/commands/config.py                                    78     68    13%   26-64, 102-188
rag_factory/cli/commands/index.py                                     65     52    20%   29-39, 93-185
rag_factory/cli/commands/query.py                                     47     36    23%   73-149
rag_factory/cli/commands/repl.py                                     152    104    32%   39-40, 63-108, 112-120, 124-133, 137-155, 159-172, 176-186, 203-207, 211-220, 256-260
rag_factory/cli/commands/strategies.py                                45     36    20%   48-120
rag_factory/cli/commands/validate_pipeline.py                         70     57    19%   57-156
rag_factory/cli/formatters/__init__.py                                 4      0   100%
rag_factory/cli/formatters/consistency.py                             61      0   100%
rag_factory/cli/formatters/output.py                                  20      3    85%   63-64, 84
rag_factory/cli/formatters/results.py                                 71     62    13%   28-55, 72-99, 116-144, 157-181
rag_factory/cli/formatters/validation.py                              63     53    16%   25-43, 48-56, 65-77, 86-98, 103-129, 134-137
rag_factory/cli/main.py                                               30      8    73%   26-28, 49, 74-76, 80
rag_factory/cli/utils/__init__.py                                      3      0   100%
rag_factory/cli/utils/progress.py                                     14      8    43%   34-47, 73-76
rag_factory/cli/utils/validation.py                                   53     42    21%   30-41, 57-77, 93-118, 135
rag_factory/config.py                                                155     50    68%   136, 222, 231-232, 248, 259-266, 275, 358, 367, 389, 395, 416-440, 450-451, 464-469, 479, 497, 506-508, 521-526, 536-542
rag_factory/core/__init__.py                                           4      4     0%   7-23
rag_factory/core/capabilities.py                                      61     16    74%   129, 155, 173-174, 239-253
rag_factory/core/indexing_interface.py                                54     35    35%   55-57, 118-123, 144, 164, 208, 260, 272, 292-313, 341-364
rag_factory/core/pipeline.py                                          49     35    29%   22-24, 33-40, 55-77, 95-96, 105-108, 117-120, 137-146
rag_factory/core/retrieval_interface.py                               38     20    47%   56-58, 112-117, 138, 158, 196, 247, 259, 285-309
rag_factory/database/__init__.py                                       4      0   100%
rag_factory/database/config.py                                        17      0   100%
rag_factory/database/connection.py                                    80     54    32%   40-48, 61-86, 96, 107, 126-137, 150-157, 165-170, 178-183, 196-197, 209-214, 218, 222
rag_factory/database/env_validator.py                                 38     18    53%   46-54, 66-77, 86-88, 118, 126, 139
rag_factory/database/models.py                                        85     32    62%   31-34, 37-45, 48-54, 66-69, 72-77, 80-85, 181, 323-325
rag_factory/database/vector_indexing.py                               38     38     0%   7-114
rag_factory/evaluation/__init__.py                                     4      4     0%   29-41
rag_factory/evaluation/analysis/__init__.py                            3      3     0%   8-11
rag_factory/evaluation/analysis/comparison.py                        135    135     0%   8-323
rag_factory/evaluation/analysis/statistics.py                         81     81     0%   8-320
rag_factory/evaluation/benchmarks/__init__.py                          3      3     0%   8-14
rag_factory/evaluation/benchmarks/config.py                           25     25     0%   7-64
rag_factory/evaluation/benchmarks/runner.py                          155    155     0%   8-423
rag_factory/evaluation/datasets/__init__.py                            3      3     0%   8-14
rag_factory/evaluation/datasets/loader.py                             88     88     0%   8-281
rag_factory/evaluation/datasets/schema.py                             52     52     0%   8-160
rag_factory/evaluation/datasets/statistics.py                         65     65     0%   8-226
rag_factory/evaluation/exporters/__init__.py                           4      4     0%   8-12
rag_factory/evaluation/exporters/csv_exporter.py                      52     52     0%   3-124
rag_factory/evaluation/exporters/html_exporter.py                     47     47     0%   3-293
rag_factory/evaluation/exporters/json_exporter.py                     19     19     0%   3-68
rag_factory/evaluation/metrics/__init__.py                             3      3     0%   12-25
rag_factory/evaluation/metrics/base.py                                31     31     0%   8-115
rag_factory/evaluation/metrics/cost.py                                65     65     0%   8-313
rag_factory/evaluation/metrics/performance.py                         42     42     0%   8-202
rag_factory/evaluation/metrics/quality.py                             84     84     0%   8-377
rag_factory/evaluation/metrics/retrieval.py                           77     77     0%   9-401
rag_factory/exceptions.py                                             13      0   100%
rag_factory/factory.py                                               187    110    41%   144, 165-170, 203-204, 226, 256-270, 303, 313, 319, 347-348, 418, 435, 452-454, 458-460, 480-502, 528-545, 568-611, 644-699, 703-715
rag_factory/models/__init__.py                                         6      0   100%
rag_factory/models/embedding/__init__.py                               4      0   100%
rag_factory/models/embedding/loader.py                               179    151    16%   8, 16-18, 23-25, 60-88, 92-97, 101-114, 118-135, 139-166, 175-191, 200-235, 244-313, 322-341, 350-367
rag_factory/models/embedding/models.py                                47      0   100%
rag_factory/models/embedding/registry.py                             128     35    73%   47-50, 57-59, 75-76, 97, 113, 117, 120, 153, 159, 177, 180-187, 212, 253, 259, 273-282
rag_factory/models/evaluation/__init__.py                              3      0   100%
rag_factory/models/evaluation/ab_testing.py                           97     34    65%   10-12, 57, 78-79, 107, 115, 127, 163-187, 238-249, 253, 255, 273-279
rag_factory/models/evaluation/models.py                               29      0   100%
rag_factory/observability/__init__.py                                  3      0   100%
rag_factory/observability/integrations/__init__.py                     1      1     0%   3
rag_factory/observability/integrations/prometheus.py                  47     47     0%   3-229
rag_factory/observability/logging/__init__.py                          2      0   100%
rag_factory/observability/logging/config.py                           16     16     0%   3-37
rag_factory/observability/logging/filters.py                          41     41     0%   3-103
rag_factory/observability/logging/logger.py                           86     46    47%   49, 99-103, 108-115, 140-162, 190-229, 250, 270, 290-291, 306, 315, 324, 333, 344-373, 394-396
rag_factory/observability/metrics/__init__.py                          2      0   100%
rag_factory/observability/metrics/collector.py                       143     96    33%   66-68, 77-79, 88-90, 99, 108, 117, 128-143, 193-198, 221-266, 284-290, 304, 335-340, 352-364, 372-404, 442-443, 457-459
rag_factory/observability/metrics/cost.py                             39     39     0%   3-221
rag_factory/observability/metrics/performance.py                      64     64     0%   3-196
rag_factory/observability/monitoring/__init__.py                       1      1     0%   3
rag_factory/observability/monitoring/api.py                          101    101     0%   3-328
rag_factory/pipeline.py                                              156      2    99%   187, 300
rag_factory/repositories/__init__.py                                   5      0   100%
rag_factory/repositories/base.py                                      42     20    52%   53, 70, 87, 103, 114-118, 125, 136-139, 159-164
rag_factory/repositories/chunk.py                                    206     59    71%   75-76, 94-95, 200-202, 229-231, 358, 360, 395-396, 425, 438, 473-474, 519-521, 537-543, 557-563, 577-587, 604-626, 639-670
rag_factory/repositories/document.py                                  93     74    20%   41-46, 63-68, 98-118, 140-156, 172-187, 206, 223-233, 247-255, 272-279, 290-293, 307-312
rag_factory/repositories/exceptions.py                                18      4    78%   56-59
rag_factory/services/__init__.py                                       8      0   100%
rag_factory/services/api/__init__.py                                   4      0   100%
rag_factory/services/api/anthropic.py                                 27     10    63%   118-141
rag_factory/services/api/cohere.py                                    30      7    77%   14-15, 50, 83, 111-113
rag_factory/services/api/openai.py                                    46     31    33%   45-51, 75-93, 117-140, 168-174, 189-199, 216-227, 235
rag_factory/services/consistency.py                                   32     24    25%   80-113, 144-170
rag_factory/services/database/__init__.py                              3      0   100%
rag_factory/services/database/neo4j.py                                54     36    33%   14, 60-71, 79-84, 103-114, 134-150, 172-181, 188-191, 195, 199
rag_factory/services/database/postgres.py                             91     14    85%   17-18, 73, 287, 333-351
rag_factory/services/dependencies.py                                  41     12    71%   99, 103, 107, 134-140, 176-180
rag_factory/services/embedding/__init__.py                             4      0   100%
rag_factory/services/embedding/base.py                                31      6    81%   44, 59, 68, 77, 86, 98
rag_factory/services/embedding/cache.py                               43     33    23%   26-32, 43-58, 67-76, 80-82, 90-94
rag_factory/services/embedding/config.py                              29      7    76%   43, 56-68, 80
rag_factory/services/embedding/providers/__init__.py                   5      0   100%
rag_factory/services/embedding/providers/cohere.py                    53     36    32%   10-20, 55-75, 90-117, 125, 133, 141, 152-153
rag_factory/services/embedding/providers/local.py                     43     27    37%   8-9, 46-67, 83-109, 117, 125, 133, 146
rag_factory/services/embedding/providers/onnx_local.py               116     10    91%   18-19, 24-25, 121, 145, 154, 165, 273, 298
rag_factory/services/embedding/providers/openai.py                    51     34    33%   10-20, 53-72, 87-108, 116, 124, 132, 143-144
rag_factory/services/embedding/rate_limiter.py                        20      1    95%   32
rag_factory/services/embedding/service.py                            100     74    26%   88, 117-198, 220-222, 233-239, 248-266, 273-275
rag_factory/services/interfaces.py                                    35      0   100%
rag_factory/services/llm/__init__.py                                   5      0   100%
rag_factory/services/llm/base.py                                      43      0   100%
rag_factory/services/llm/config.py                                    23      4    83%   48, 51-53
rag_factory/services/llm/prompt_template.py                           43     24    44%   47-82, 97-100, 111-115
rag_factory/services/llm/providers/__init__.py                        12     10    17%   10-22
rag_factory/services/llm/providers/anthropic.py                       57     42    26%   44-50, 64-97, 120-147, 171-172, 184-189, 197, 205
rag_factory/services/llm/providers/ollama.py                          55     42    24%   22-24, 37-67, 93-122, 142-143, 157, 165, 174, 185-196
rag_factory/services/llm/providers/openai.py                          57     20    65%   56, 62, 101-105, 133-158, 189-194, 202, 210
rag_factory/services/llm/service.py                                   66     25    62%   68, 94, 127-129, 154-175, 186, 194-198, 215-216
rag_factory/services/llm/token_counter.py                             27      4    85%   56-57, 71-72
rag_factory/services/local/__init__.py                                 2      0   100%
rag_factory/services/local/reranker.py                                32      7    78%   13-14, 46, 79, 114-116
rag_factory/services/onnx/__init__.py                                  2      0   100%
rag_factory/services/onnx/embedding.py                                29      9    69%   61, 63, 65, 93, 110-121
rag_factory/services/utils/__init__.py                                 2      0   100%
rag_factory/services/utils/model_converter.py                        104    104     0%   8-291
rag_factory/services/utils/onnx_utils.py                             171     79    54%   22-23, 28-29, 41, 48, 94, 100-101, 106-107, 123-193, 213-234, 263, 277-278, 282, 286-289, 304-306, 346, 353-356, 449-450, 464, 480-492
rag_factory/services/utils/reranker_selector.py                       68     68     0%   8-249
rag_factory/strategies/__init__.py                                     2      0   100%
rag_factory/strategies/agentic/__init__.py                             7      0   100%
rag_factory/strategies/agentic/agent.py                              151    127    16%   31-36, 45, 57, 66-90, 123-161, 190-214, 230-265, 276-293, 310-331, 339-346, 357-368, 381-420
rag_factory/strategies/agentic/config.py                              12      0   100%
rag_factory/strategies/agentic/frameworks/__init__.py                  1      1     0%   9
rag_factory/strategies/agentic/query_analyzer.py                      89     13    85%   119, 168, 172, 176, 199, 201, 203, 211-212, 233, 241, 249, 257
rag_factory/strategies/agentic/strategy.py                            85     10    88%   142, 154, 167, 240-241, 252-256
rag_factory/strategies/agentic/tool_implementations.py               135     61    55%   126-129, 182-247, 329-373, 446-511
rag_factory/strategies/agentic/tools.py                               40      8    80%   66, 79, 89, 101, 139-142
rag_factory/strategies/base.py                                        55      3    95%   81, 83, 85
rag_factory/strategies/chunking/__init__.py                           15      4    73%   45-48
rag_factory/strategies/chunking/base.py                               91     35    62%   115-128, 146, 159, 171, 182-196, 207-217, 228-256
rag_factory/strategies/chunking/docling_chunker.py                    45     26    42%   18, 61-73, 89-101, 112, 131-136, 147-152, 163-168, 186-188
rag_factory/strategies/chunking/fixed_size_chunker.py                 74     61    18%   8-9, 33-46, 58-111, 122, 145-159, 171-185, 196-204
rag_factory/strategies/chunking/hybrid_chunker.py                     70     58    17%   36-48, 63-132, 143, 157-160, 173-192
rag_factory/strategies/chunking/semantic_chunker.py                  195    171    12%   9-10, 14-15, 45-71, 83-128, 139, 155-156, 172-177, 193-206, 218-227, 245-277, 293-328, 340-386, 397-423, 434-441, 459-473, 485-534
rag_factory/strategies/chunking/structural_chunker.py                147    128    13%   9-10, 37-50, 62-69, 80, 95, 107-144, 155-201, 222-288, 299-305, 317-366, 377-385, 399-425
rag_factory/strategies/chunking/utils.py                              89     89     0%   3-264
rag_factory/strategies/contextual/__init__.py                          7      0   100%
rag_factory/strategies/contextual/batch_processor.py                  86     34    60%   69, 125-126, 146-162, 191-196, 225-251, 255-257
rag_factory/strategies/contextual/config.py                           46      0   100%
rag_factory/strategies/contextual/context_generator.py                84     57    32%   60, 67-99, 113, 124-135, 152-194, 224-234
rag_factory/strategies/contextual/cost_tracker.py                     32     10    69%   48-51, 69-82, 126
rag_factory/strategies/contextual/prompts.py                          25     17    32%   85-106, 119
rag_factory/strategies/contextual/storage.py                          44     14    68%   65-68, 72-73, 107-114
rag_factory/strategies/contextual/strategy.py                         65     12    82%   157, 170, 191-199, 229, 238, 258, 264, 269, 278
rag_factory/strategies/fine_tuned/__init__.py                          4      4     0%   1-5
rag_factory/strategies/fine_tuned/ab_testing.py                       78     78     0%   1-134
rag_factory/strategies/fine_tuned/config.py                           11     11     0%   1-30
rag_factory/strategies/fine_tuned/custom_loader.py                    40     40     0%   1-88
rag_factory/strategies/fine_tuned/model_registry.py                  126    126     0%   1-303
rag_factory/strategies/hierarchical/__init__.py                        5      0   100%
rag_factory/strategies/hierarchical/hierarchy_builder.py              79     25    68%   73, 117, 149, 220, 249-281, 310-335
rag_factory/strategies/hierarchical/models.py                         58      0   100%
rag_factory/strategies/hierarchical/parent_retriever.py               89     74    17%   56-92, 103-113, 130-149, 166-196, 213-227, 250-257, 268-278
rag_factory/strategies/hierarchical/strategy.py                       66     36    45%   83-84, 92, 103-135, 189-223, 237, 251-252, 268-284
rag_factory/strategies/indexing/__init__.py                            5      0   100%
rag_factory/strategies/indexing/context_aware.py                      97     79    19%   29, 40, 60-120, 141-142, 146-156, 168-174, 178-184, 194-223, 227-228
rag_factory/strategies/indexing/hierarchical.py                       83     68    18%   48, 60, 84-121, 143-172, 188-223, 240-265, 279-280
rag_factory/strategies/indexing/in_memory.py                          41     25    39%   54, 65, 93-121, 143, 160, 173, 194-200
rag_factory/strategies/indexing/keyword_indexing.py                   40     40     0%   8-155
rag_factory/strategies/indexing/vector_embedding.py                   29     21    28%   21, 30, 53-91
rag_factory/strategies/knowledge_graph/__init__.py                     4      0   100%
rag_factory/strategies/knowledge_graph/config.py                      21      2    90%   128-129
rag_factory/strategies/knowledge_graph/entity_extractor.py            70      7    90%   89, 130-131, 135-137, 179
rag_factory/strategies/knowledge_graph/graph_store.py                 31      9    71%   25, 35, 48, 66, 86, 99, 109, 114, 124
rag_factory/strategies/knowledge_graph/hybrid_retriever.py            56     37    34%   65-97, 101-108, 117-164
rag_factory/strategies/knowledge_graph/memory_graph_store.py          97     68    30%   60, 68-87, 96-152, 161-168, 172-182, 186-189
rag_factory/strategies/knowledge_graph/models.py                      53      0   100%
rag_factory/strategies/knowledge_graph/relationship_extractor.py      62      8    87%   57, 137-138, 142-144, 157-161
rag_factory/strategies/knowledge_graph/strategy.py                    78     15    81%   59, 101-112, 198-214, 237, 241, 245, 250, 255
rag_factory/strategies/late_chunking/__init__.py                       6      0   100%
rag_factory/strategies/late_chunking/coherence_analyzer.py            27      5    81%   59, 82-96
rag_factory/strategies/late_chunking/document_embedder.py             99      8    92%   35, 62-63, 72, 225-226, 270, 296
rag_factory/strategies/late_chunking/embedding_chunker.py            112     21    81%   53, 57, 122-125, 133-139, 164, 177-178, 201-211, 215-225, 284
rag_factory/strategies/late_chunking/models.py                        62      0   100%
rag_factory/strategies/late_chunking/strategy.py                      49      6    88%   48, 124-133
rag_factory/strategies/multi_query/__init__.py                         7      0   100%
rag_factory/strategies/multi_query/config.py                          36      0   100%
rag_factory/strategies/multi_query/deduplicator.py                    87     75    14%   41-100, 116-176, 188-197
rag_factory/strategies/multi_query/parallel_executor.py               52     11    79%   74-75, 84-86, 116-118, 128-132, 148, 154-155
rag_factory/strategies/multi_query/prompts.py                         10      2    80%   76-80
rag_factory/strategies/multi_query/ranker.py                          80     67    16%   35-70, 81-84, 98-103, 116-126, 141-177, 189-201
rag_factory/strategies/multi_query/strategy.py                        66     14    79%   86-93, 103, 107, 111, 130-134, 159-172
rag_factory/strategies/multi_query/variant_generator.py               62      9    85%   79, 115-129, 177, 182
rag_factory/strategies/query_expansion/__init__.py                     8      0   100%
rag_factory/strategies/query_expansion/base.py                        66      3    95%   103, 115, 118
rag_factory/strategies/query_expansion/cache.py                       52     25    52%   47-51, 70-73, 81-97, 105-112
rag_factory/strategies/query_expansion/expander_service.py            92      3    97%   178, 283-284
rag_factory/strategies/query_expansion/hyde_expander.py               19      1    95%   48
rag_factory/strategies/query_expansion/llm_expander.py                25      0   100%
rag_factory/strategies/query_expansion/metrics.py                     66     30    55%   44-45, 53-57, 76-109, 130, 134, 146-152, 160
rag_factory/strategies/query_expansion/prompts.py                     13      1    92%   29
rag_factory/strategies/reranking/__init__.py                           7      0   100%
rag_factory/strategies/reranking/base.py                              68     16    76%   81, 101, 106, 110-119, 123-130
rag_factory/strategies/reranking/bge_reranker.py                      51     37    27%   14, 53-81, 103-147, 151
rag_factory/strategies/reranking/cache.py                             48     34    29%   32-34, 51-66, 76-77, 81, 90-101, 110-113, 121, 136-138
rag_factory/strategies/reranking/cohere_reranker.py                   34     20    41%   15-16, 55-71, 94-115, 119
rag_factory/strategies/reranking/cosine_reranker.py                   62     47    24%   54-72, 97-139, 158-171, 188, 209-215, 227-230, 242-245, 249
rag_factory/strategies/reranking/cross_encoder_reranker.py            40     27    32%   13-14, 53-76, 98-120, 124
rag_factory/strategies/reranking/metrics.py                           67     67     0%   8-264
rag_factory/strategies/reranking/reranker_service.py                 115     88    23%   56-67, 71-96, 113-225, 235-255, 269, 282-283, 287-292, 296-300, 308-310
rag_factory/strategies/self_reflective/__init__.py                     6      6     0%   3-16
rag_factory/strategies/self_reflective/config.py                      20     20     0%   3-42
rag_factory/strategies/self_reflective/grader.py                      80     80     0%   3-266
rag_factory/strategies/self_reflective/models.py                      48     48     0%   3-109
rag_factory/strategies/self_reflective/refiner.py                     69     69     0%   3-228
rag_factory/strategies/self_reflective/strategy.py                    89     89     0%   3-264
rag_factory/utils/__init__.py                                          3      0   100%
rag_factory/utils/token_counter.py                                    45     30    33%   36-40, 52-62, 74-82, 86, 90, 105-106, 124-135, 153-158
rag_factory/utils/tokenization.py                                     95     59    38%   39-40, 53-64, 93-94, 100-101, 105-114, 129, 141-144, 156, 175-190, 209-228, 241-243, 251-252, 270-271, 292-293, 314-315
------------------------------------------------------------------------------------------------
TOTAL                                                              11098   6433    42%
=========================== short test summary info ============================
FAILED tests/integration/database/test_migration_integration.py::TestMigrationIntegration::test_real_migration_execution
FAILED tests/integration/database/test_migration_integration.py::TestMigrationIntegration::test_migration_with_existing_data
FAILED tests/integration/database/test_migration_integration.py::TestMigrationIntegration::test_rollback_functionality
FAILED tests/integration/models/test_fine_tuned_embeddings_integration.py::test_ab_testing_workflow
FAILED tests/integration/models/test_fine_tuned_embeddings_integration.py::test_model_comparison_workflow
FAILED tests/integration/services/test_onnx_embeddings_integration.py::TestONNXEmbeddingsIntegration::test_performance_target
FAILED tests/integration/services/test_service_integration.py::test_embedding_database_consistency
FAILED tests/integration/strategies/test_contextual_integration.py::test_contextual_retrieval_complete_workflow
FAILED tests/integration/strategies/test_contextual_integration.py::test_cost_tracking_accuracy
FAILED tests/integration/strategies/test_contextual_integration.py::test_retrieval_with_different_formats
FAILED tests/integration/strategies/test_contextual_integration.py::test_error_recovery
FAILED tests/integration/strategies/test_contextual_integration.py::test_synchronous_indexing
FAILED tests/integration/strategies/test_contextual_integration.py::test_large_document_processing
FAILED tests/integration/strategies/test_hierarchical_integration.py::TestHierarchicalIntegration::test_end_to_end_workflow
FAILED tests/integration/strategies/test_hierarchical_integration.py::TestHierarchicalIntegration::test_expansion_strategy_comparison
FAILED tests/integration/strategies/test_hierarchical_integration.py::TestHierarchicalIntegration::test_hierarchy_validation
FAILED tests/integration/strategies/test_hierarchical_integration.py::TestHierarchicalIntegration::test_multiple_documents
FAILED tests/integration/strategies/test_knowledge_graph_integration.py::test_hybrid_retrieval
FAILED tests/integration/strategies/test_knowledge_graph_integration.py::test_relationship_queries
FAILED tests/integration/strategies/test_late_chunking_integration.py::test_late_chunking_workflow
FAILED tests/integration/strategies/test_late_chunking_integration.py::test_multiple_documents
FAILED tests/integration/strategies/test_late_chunking_integration.py::test_short_document
FAILED tests/integration/strategies/test_multi_query_integration.py::TestMultiQueryIntegration::test_multi_query_complete_workflow
FAILED tests/integration/strategies/test_multi_query_integration.py::TestMultiQueryIntegration::test_multi_query_async_workflow
FAILED tests/integration/strategies/test_multi_query_integration.py::TestMultiQueryIntegration::test_variant_diversity
FAILED tests/integration/strategies/test_multi_query_integration.py::TestMultiQueryIntegration::test_performance_requirements
FAILED tests/integration/strategies/test_multi_query_integration.py::TestMultiQueryIntegration::test_fallback_on_failure
FAILED tests/integration/strategies/test_multi_query_integration.py::TestMultiQueryIntegration::test_ranking_strategy_comparison
FAILED tests/integration/strategies/test_multi_query_integration.py::TestMultiQueryWithLMStudio::test_with_real_llm
FAILED tests/integration/test_config_integration.py::test_config_with_factory
FAILED tests/integration/test_factory_integration.py::test_register_create_use_strategy
FAILED tests/integration/test_factory_integration.py::test_create_multiple_instances_of_same_strategy
FAILED tests/integration/test_factory_integration.py::test_config_file_with_yaml
FAILED tests/integration/test_factory_integration.py::test_config_file_with_json
FAILED tests/integration/test_factory_integration.py::test_factory_error_recovery
FAILED tests/integration/test_factory_integration.py::test_factory_state_after_failed_creation
FAILED tests/integration/test_package_integration.py::TestPackageInstallation::test_package_installable
FAILED tests/integration/test_package_integration.py::TestFullWorkflow::test_full_workflow_with_installed_package
FAILED tests/integration/test_pipeline_integration.py::test_pipeline_continues_after_non_critical_failure
FAILED tests/integration/test_pipeline_integration.py::test_async_fallback_execution
FAILED tests/integration/test_pipeline_integration.py::test_parallel_execution_with_failures
ERROR tests/integration/services/test_service_integration.py::test_rag_workflow
= 41 failed, 246 passed, 4 skipped, 25 warnings, 1 error in 437.41s (0:07:17) ==

========================================
Test run completed at 2025-12-14 23:40:05
========================================
